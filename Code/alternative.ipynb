{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_repo_raw = os.path.join(path_github_repo, 'Raw')\n",
    "path_gitlab_repo_raw = os.path.join(path_gitlab_repo, 'Raw')\n",
    "path_github_repo_scraped = os.path.join(path_github_repo, 'Scraped')\n",
    "path_gitlab_repo_scraped = os.path.join(path_gitlab_repo, 'Scraped')\n",
    "\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "path_github_issue_raw = os.path.join(path_github_issue, 'Raw')\n",
    "path_gitlab_issue_raw = os.path.join(path_gitlab_issue, 'Raw')\n",
    "path_github_issue_filtered = os.path.join(path_github_issue, 'Filtered')\n",
    "path_gitlab_issue_filtered = os.path.join(path_gitlab_issue, 'Filtered')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_labeling):\n",
    "    os.makedirs(path_labeling)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)\n",
    "\n",
    "if not os.path.exists(path_github_repo_raw):\n",
    "    os.makedirs(path_github_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_raw):\n",
    "    os.makedirs(path_gitlab_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_raw):\n",
    "    os.makedirs(path_github_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_raw):\n",
    "    os.makedirs(path_gitlab_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_filtered):\n",
    "    os.makedirs(path_github_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_filtered):\n",
    "    os.makedirs(path_gitlab_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_github_repo_scraped):\n",
    "    os.makedirs(path_github_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_scraped):\n",
    "    os.makedirs(path_gitlab_repo_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow\n"
     ]
    }
   ],
   "source": [
    "import gitlab\n",
    "import numpy as np\n",
    "\n",
    "gl = gitlab.Gitlab('https://gitlab.com', private_token='glpat-SvwyWD6pbPNvbsBSvxdy')\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "    if tool_name != 'MLflow':\n",
    "        continue\n",
    "    print(tool_name)\n",
    "    issues['Answer_list'] = np.empty((len(issues), 0)).tolist()\n",
    "    last_repo = ''\n",
    "\n",
    "    for index, row in issues.iterrows():\n",
    "        if index % 50 == 49:\n",
    "            print(f'persisting on issue {index}')\n",
    "            issues.to_json(os.path.join(\n",
    "                path_gitlab_issue_raw, f'{tool_name}_.json'), indent=4, orient='records')\n",
    "            \n",
    "        time.sleep(3)\n",
    "        issue_link = row['Issue_link'].split('/')\n",
    "        issue_repo = issue_link[3] + '/' + issue_link[4] + '/' + issue_link[5]\n",
    "        issue_id = int(issue_link[-1])\n",
    "        try:\n",
    "            if issue_repo != last_repo:\n",
    "                time.sleep(0.5)\n",
    "                repo = gl.projects.get(issue_repo)\n",
    "            time.sleep(0.5)\n",
    "            issue = repo.issues.get(issue_id)\n",
    "            comments = issue.notes.list(get_all=True)\n",
    "            answer_list = []\n",
    "            for comment in comments:\n",
    "                time.sleep(0.5)\n",
    "                answer = {}\n",
    "                answer['Answer_creation_time'] = comment.created_at\n",
    "                answer['Answer_body'] = comment.body\n",
    "                answer_list.append(answer)\n",
    "            issues.at[index, 'Answer_list'] = answer_list\n",
    "            last_repo = issue_repo\n",
    "        except Exception as e:\n",
    "            issues.drop(index, inplace=True)\n",
    "            print(f'error on issue {issue_repo, issue_id}: {e}')\n",
    "            \n",
    "    issues.to_json(os.path.join(\n",
    "        path_gitlab_issue_raw, f'{tool_name}_.json'), indent=4, orient='records')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

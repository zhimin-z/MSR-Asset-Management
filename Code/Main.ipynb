{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_labeling):\n",
    "    os.makedirs(path_labeling)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_repo = {\n",
    "    'Aim': 'aimhubio/aim',\n",
    "    'Amazon SageMaker': 'aws/sagemaker-python-sdk',\n",
    "    'Azure Machine Learning': 'Azure/azure-sdk-for-python',\n",
    "    'ClearML': 'allegroai/clearml',\n",
    "    'Codalab': 'codalab/codalab-worksheets',\n",
    "    'DVC': 'iterative/dvc',\n",
    "    'Determined': 'determined-ai/determined',\n",
    "    'Domino': 'dominodatalab/python-domino',\n",
    "    'Guild AI': 'guildai/guildai',\n",
    "    'Kedro': 'kedro-org/kedro',\n",
    "    'MLflow': 'mlflow/mlflow',\n",
    "    'MLRun': 'mlrun/mlrun',\n",
    "    'ModelDB': 'VertaAI/modeldb',\n",
    "    'Neptune': 'neptune-ai/neptune-client',\n",
    "    'Optuna': 'optuna/optuna',\n",
    "    'Polyaxon': 'polyaxon/polyaxon',\n",
    "    'Sacred': 'IDSIA/sacred',\n",
    "    'Valohai': 'valohai/valohai-cli',\n",
    "    'Weights & Biases': 'wandb/wandb'\n",
    "}\n",
    "\n",
    "tools_release_date = {\n",
    "    'Amazon SageMaker': '2017-11-19',\n",
    "    'Azure Machine Learning': '2015-02-18',\n",
    "    'cnvrg.io': '2020-03-31',\n",
    "    'Comet': '2017-01-01',\n",
    "    'Iterative Studio': '2021-05-12',\n",
    "    'Polyaxon': '2018-10-16',\n",
    "    'SigOpt': '2014-11-01',\n",
    "    'Vertex AI': '2019-03-01'\n",
    "}\n",
    "\n",
    "tools_link = {\n",
    "    'cnvrg.io': 'https://github.com/cnvrg',\n",
    "    'Comet': 'https://github.com/comet-ml',\n",
    "    'Iterative Studio': 'https://studio.iterative.ai',\n",
    "    'SigOpt': 'https://github.com/sigopt',\n",
    "    'Vertex AI': 'https://cloud.google.com/vertex-ai'\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Aim': ['aim'],\n",
    "    'Amazon SageMaker': ['sage maker', 'sagemaker'],\n",
    "    'Azure Machine Learning': ['azure machine learning', 'azure ml', 'azureml'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'cnvrg.io': ['cnvrg'],\n",
    "    'Codalab': ['codalab'],\n",
    "    'Comet': ['comet'],\n",
    "    'Determined': ['determined'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild ai', 'guildai'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'MLRun': ['mlrun'],\n",
    "    'ModelDB': ['modeldb'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Optuna': ['optuna'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Valohai': ['valohai'],\n",
    "    'Vertex AI': ['vertex ai', 'vertexai'],\n",
    "    'Weights & Biases': ['weights and biases', 'wandb', 'weights & biases', 'weights&biases', 'w & b', 'w&b']\n",
    "}\n",
    "\n",
    "issue_labels = {\n",
    "    'bug',\n",
    "    'error',\n",
    "    'invalid',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scrape.GHMiner import GitHubMiner\n",
    "from Scrape.GLMiner import GitLabMiner\n",
    "\n",
    "github_miner = GitHubMiner(private_token=os.getenv('GITHUB_TOKEN'))\n",
    "gitlab_miner = GitLabMiner(private_token=os.getenv('GITLAB_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_data = pd.DataFrame()\n",
    "\n",
    "# scrape open-source asset-management tools\n",
    "for tool_name, tool_repo in tools_repo.items():\n",
    "    if tool_name in tools_release_date:\n",
    "        tool_data = github_miner.scrape_repo(repo_name=tool_repo, real_name=tool_name, release_time=pd.to_datetime(tools_release_date[tool_name]))\n",
    "    else:\n",
    "        tool_data = github_miner.scrape_repo(repo_name=tool_repo, real_name=tool_name)\n",
    "\n",
    "    if not tool_data.empty:\n",
    "        tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "# add closed-source asset-management tools\n",
    "for tool_name in tools_link.keys():\n",
    "    tool_data = {\n",
    "        'Name': tool_name,\n",
    "        'Link': tools_link[tool_name],\n",
    "        'First Release Date': pd.to_datetime(tools_release_date[tool_name])\n",
    "    }\n",
    "    tool_data = pd.DataFrame([tool_data])\n",
    "    tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "tools_data.to_json(os.path.join(path_dataset, 'Tools.json'),\n",
    "                   indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dependents = pd.DataFrame()\n",
    "\n",
    "# collect dependents for tools with coding patterns\n",
    "for tool_name in tools_keywords.keys():\n",
    "    github_dependents = []\n",
    "    gitlab_dependents = []\n",
    "\n",
    "    # collect Github dependents\n",
    "    file_name = os.path.join(path_github_repo, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # either search by sourcegraph\n",
    "            if 'Results' in json_data:\n",
    "                for repo_file in json_data['Results']:\n",
    "                    # file name match pattern\n",
    "                    if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('github'):\n",
    "                        repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "                    # code usage match pattern\n",
    "                    elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('github'):\n",
    "                        repo_name = repo_file['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "            # or search by dependent graph\n",
    "            elif 'all_public_dependent_repos' in json_data:\n",
    "                for repo_file in json_data['all_public_dependent_repos']:\n",
    "                    github_dependents.append(repo_file['name'])\n",
    "\n",
    "    # collect Gitlab dependents\n",
    "    file_name = os.path.join(path_gitlab_repo, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # search by sourcegraph exclusively\n",
    "            for repo_file in json_data['Results']:\n",
    "                # file name match pattern\n",
    "                if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                        'gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "                # code usage match pattern\n",
    "                elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['name'].removeprefix('gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "\n",
    "    # remove tool repo from dependents if any\n",
    "    if tool_name in tools_repo and tools_repo[tool_name] in github_dependents:\n",
    "        github_dependents.remove(tools_repo[tool_name])\n",
    "\n",
    "    # no need to add tools without dependents\n",
    "    if not len(github_dependents) and not len(gitlab_dependents):\n",
    "        continue\n",
    "\n",
    "    dependent = {\n",
    "        'Tool': tool_name,\n",
    "        'GitHub Dependents': github_dependents,\n",
    "        'GitLab Dependents': gitlab_dependents\n",
    "    }\n",
    "\n",
    "    dependents = pd.concat(\n",
    "        [dependents, pd.DataFrame([dependent])], ignore_index=True)\n",
    "\n",
    "dependents.to_json(os.path.join(\n",
    "    path_dataset, 'Dependents.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37786\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "github_repos = set()\n",
    "gitlab_repos = set()\n",
    "\n",
    "for index, row in dependents.iterrows():\n",
    "    github_repos = github_repos.union(row['GitHub Dependents'])\n",
    "    gitlab_repos = gitlab_repos.union(row['GitLab Dependents'])\n",
    "\n",
    "print(len(github_repos))\n",
    "print(len(gitlab_repos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#GitHub Dependents</th>\n",
       "      <th>#GitLab Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aim</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>1114</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codalab</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comet</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Determined</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Domino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DVC</td>\n",
       "      <td>6099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>1184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLRun</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ModelDB</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>6370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Valohai</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>19952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool #GitHub Dependents #GitLab Dependents\n",
       "0                      Aim                189                  1\n",
       "1         Amazon SageMaker               1114                  3\n",
       "2   Azure Machine Learning                826                  0\n",
       "3                  ClearML                498                  0\n",
       "4                  Codalab                 40                  0\n",
       "5                    Comet                678                  0\n",
       "6               Determined                 36                  0\n",
       "7                   Domino                  1                  0\n",
       "8                      DVC               6099                  0\n",
       "9                 Guild AI                 67                  4\n",
       "10                   Kedro               1184                  0\n",
       "11                  MLflow               1575                  4\n",
       "12                   MLRun                 27                  0\n",
       "13                 ModelDB                  9                  0\n",
       "14                 Neptune                423                  0\n",
       "15                  Optuna               6370                  0\n",
       "16                Polyaxon                 36                  0\n",
       "17                  Sacred               1918                  0\n",
       "18                  SigOpt                 96                  0\n",
       "19                 Valohai                 31                  0\n",
       "20               Vertex AI                135                  0\n",
       "21        Weights & Biases              19952                  0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependents_summary = pd.DataFrame(\n",
    "    columns=['Tool', '#GitHub Dependents', '#GitLab Dependents'])\n",
    "for index, row in dependents.iterrows():\n",
    "    dependent_data = {\n",
    "        'Tool': row['Tool'],\n",
    "        '#GitHub Dependents': len(row['GitHub Dependents']),\n",
    "        '#GitLab Dependents': len(row['GitLab Dependents'])\n",
    "    }\n",
    "    dependent_data = pd.DataFrame([dependent_data])\n",
    "    dependents_summary = pd.concat(\n",
    "        [dependents_summary, dependent_data], ignore_index=True)\n",
    "dependents_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents = pd.read_json(os.path.join(path_dataset, 'Dependents.json'))\n",
    "df_tool = pd.read_json(os.path.join(path_dataset, 'Tools.json'))\n",
    "tools_release_date = pd.Series(pd.to_datetime(df_tool['First Release Date'].values), index=df_tool['Name']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Gitlab dependents for each tool\n",
    "\n",
    "df_issues = pd.DataFrame()\n",
    "\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(row['Tool'])\n",
    "    for repo in row['GitLab Dependents']:\n",
    "        print(repo)\n",
    "        repo_data = gitlab_miner.scrape_repo(repo)\n",
    "        if (not repo_data.empty) and (repo_data['Repo Created Date'].values[0] > tools_release_date[row['Tool']]) and repo_data['#Issue'].values[0]:\n",
    "            issues = gitlab_miner.scrape_issue(repo)\n",
    "            issues['Tool'] = row['Tool']\n",
    "            df_issues = pd.concat([df_issues, issues], ignore_index=True)\n",
    "            df_issues.to_json(os.path.join(path_gitlab_issue, 'raw.json'), indent=4, orient='records')\n",
    "    \n",
    "df_issues.to_json(os.path.join(path_gitlab_issue, 'raw.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "\n",
    "df_issues = pd.DataFrame()\n",
    "\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(row['Tool'])\n",
    "    for repo in row['GitHub Dependents']:\n",
    "        print(repo)\n",
    "        repo_data = github_miner.scrape_repo(repo)\n",
    "        if (not repo_data.empty) and (repo_data['Repo Created Date'].values[0] > tools_release_date[row['Tool']]) and repo_data['#Issue'].values[0]:\n",
    "            issues = github_miner.scrape_issue(repo)\n",
    "            issues['Tool'] = row['Tool']\n",
    "            df_issues = pd.concat([df_issues, issues], ignore_index=True)\n",
    "            df_issues.to_json(os.path.join(path_github_issue, 'raw.json'), indent=4, orient='records')\n",
    "    \n",
    "df_issues.to_json(os.path.join(path_github_issue, 'raw.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon SageMaker\n",
      "huggingface/transformers\n",
      "apache/airflow\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\packages\\six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 770\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    771\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:451\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_timeout(err\u001b[39m=\u001b[39;49me, url\u001b[39m=\u001b[39;49murl, timeout_value\u001b[39m=\u001b[39;49mread_timeout)\n\u001b[0;32m    452\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:340\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    341\u001b[0m         \u001b[39mself\u001b[39m, url, \u001b[39m\"\u001b[39m\u001b[39mRead timed out. (read timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m timeout_value\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    344\u001b[0m \u001b[39m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=15)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m repo_data\u001b[39m.\u001b[39mempty) \u001b[39mand\u001b[39;00m (repo_data[\u001b[39m'\u001b[39m\u001b[39mRepo Created Date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m tool_release_dates[row[\u001b[39m'\u001b[39m\u001b[39mTool\u001b[39m\u001b[39m'\u001b[39m]]) \u001b[39mand\u001b[39;00m repo_data[\u001b[39m'\u001b[39m\u001b[39m#Issue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]:\n\u001b[0;32m     22\u001b[0m     \u001b[39mprint\u001b[39m(repo)\n\u001b[1;32m---> 23\u001b[0m     issues \u001b[39m=\u001b[39m github_miner\u001b[39m.\u001b[39;49mscrape_issue(repo)\n\u001b[0;32m     24\u001b[0m     issues[\u001b[39m'\u001b[39m\u001b[39mTool\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mTool\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     25\u001b[0m     issues_raw \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([issues_raw, issues], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\Code\\Scrape\\GHMiner.py:59\u001b[0m, in \u001b[0;36mGitHubMiner.scrape_issue\u001b[1;34m(self, repo_name)\u001b[0m\n\u001b[0;32m     57\u001b[0m comments\u001b[39m.\u001b[39mappend(comment\u001b[39m.\u001b[39mbody)\n\u001b[0;32m     58\u001b[0m reactions \u001b[39m=\u001b[39m comment\u001b[39m.\u001b[39mget_reactions()\n\u001b[1;32m---> 59\u001b[0m upvote \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(reaction\u001b[39m.\u001b[39;49mcontent \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m+1\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mfor\u001b[39;49;00m reaction \u001b[39min\u001b[39;49;00m reactions)\n\u001b[0;32m     60\u001b[0m downvote \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(reaction\u001b[39m.\u001b[39mcontent \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-1\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m reaction \u001b[39min\u001b[39;00m reactions)\n\u001b[0;32m     61\u001b[0m upvotes\u001b[39m.\u001b[39mappend(upvote)\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\Code\\Scrape\\GHMiner.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m comments\u001b[39m.\u001b[39mappend(comment\u001b[39m.\u001b[39mbody)\n\u001b[0;32m     58\u001b[0m reactions \u001b[39m=\u001b[39m comment\u001b[39m.\u001b[39mget_reactions()\n\u001b[1;32m---> 59\u001b[0m upvote \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(reaction\u001b[39m.\u001b[39mcontent \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m+1\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m reaction \u001b[39min\u001b[39;00m reactions)\n\u001b[0;32m     60\u001b[0m downvote \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(reaction\u001b[39m.\u001b[39mcontent \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-1\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m reaction \u001b[39min\u001b[39;00m reactions)\n\u001b[0;32m     61\u001b[0m upvotes\u001b[39m.\u001b[39mappend(upvote)\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\PaginatedList.py:56\u001b[0m, in \u001b[0;36mPaginatedListBase.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__elements\n\u001b[0;32m     55\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_couldGrow():\n\u001b[1;32m---> 56\u001b[0m     newElements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow()\n\u001b[0;32m     57\u001b[0m     \u001b[39myield from\u001b[39;00m newElements\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\PaginatedList.py:67\u001b[0m, in \u001b[0;36mPaginatedListBase._grow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_grow\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 67\u001b[0m     newElements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetchNextPage()\n\u001b[0;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__elements \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m newElements\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m newElements\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\PaginatedList.py:201\u001b[0m, in \u001b[0;36mPaginatedList._fetchNextPage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetchNextPage\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 201\u001b[0m     headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__requester\u001b[39m.\u001b[39;49mrequestJsonAndCheck(\n\u001b[0;32m    202\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__nextUrl, parameters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__nextParams, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__headers\n\u001b[0;32m    203\u001b[0m     )\n\u001b[0;32m    204\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m data \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__nextUrl \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\Requester.py:399\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[1;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequestJsonAndCheck\u001b[39m(\u001b[39mself\u001b[39m, verb, url, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    398\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__check(\n\u001b[1;32m--> 399\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequestJson(\n\u001b[0;32m    400\u001b[0m             verb, url, parameters, headers, \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__customConnection(url)\n\u001b[0;32m    401\u001b[0m         )\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\Requester.py:499\u001b[0m, in \u001b[0;36mRequester.requestJson\u001b[1;34m(self, verb, url, parameters, headers, input, cnx)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39minput\u001b[39m):\n\u001b[0;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m, json\u001b[39m.\u001b[39mdumps(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 499\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__requestEncode(cnx, verb, url, parameters, headers, \u001b[39minput\u001b[39;49m, encode)\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\Requester.py:573\u001b[0m, in \u001b[0;36mRequester.__requestEncode\u001b[1;34m(self, cnx, verb, url, parameters, requestHeaders, input, encode)\u001b[0m\n\u001b[0;32m    569\u001b[0m     requestHeaders[\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m], encoded_input \u001b[39m=\u001b[39m encode(\u001b[39minput\u001b[39m)\n\u001b[0;32m    571\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNEW_DEBUG_FRAME(requestHeaders)\n\u001b[1;32m--> 573\u001b[0m status, responseHeaders, output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__requestRaw(\n\u001b[0;32m    574\u001b[0m     cnx, verb, url, requestHeaders, encoded_input\n\u001b[0;32m    575\u001b[0m )\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    578\u001b[0m     Consts\u001b[39m.\u001b[39mheaderRateRemaining \u001b[39min\u001b[39;00m responseHeaders\n\u001b[0;32m    579\u001b[0m     \u001b[39mand\u001b[39;00m Consts\u001b[39m.\u001b[39mheaderRateLimit \u001b[39min\u001b[39;00m responseHeaders\n\u001b[0;32m    580\u001b[0m ):\n\u001b[0;32m    581\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrate_limiting \u001b[39m=\u001b[39m (\n\u001b[0;32m    582\u001b[0m         \u001b[39mint\u001b[39m(responseHeaders[Consts\u001b[39m.\u001b[39mheaderRateRemaining]),\n\u001b[0;32m    583\u001b[0m         \u001b[39mint\u001b[39m(responseHeaders[Consts\u001b[39m.\u001b[39mheaderRateLimit]),\n\u001b[0;32m    584\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\Requester.py:600\u001b[0m, in \u001b[0;36mRequester.__requestRaw\u001b[1;34m(self, cnx, verb, url, requestHeaders, input)\u001b[0m\n\u001b[0;32m    598\u001b[0m     cnx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__createConnection()\n\u001b[0;32m    599\u001b[0m cnx\u001b[39m.\u001b[39mrequest(verb, url, \u001b[39minput\u001b[39m, requestHeaders)\n\u001b[1;32m--> 600\u001b[0m response \u001b[39m=\u001b[39m cnx\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    602\u001b[0m status \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[0;32m    603\u001b[0m responseHeaders \u001b[39m=\u001b[39m {k\u001b[39m.\u001b[39mlower(): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mgetheaders()}\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\github\\Requester.py:131\u001b[0m, in \u001b[0;36mHTTPSRequestsConnectionClass.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m verb \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverb\u001b[39m.\u001b[39mlower())\n\u001b[0;32m    130\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprotocol\u001b[39m}\u001b[39;00m\u001b[39m://\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 131\u001b[0m r \u001b[39m=\u001b[39m verb(\n\u001b[0;32m    132\u001b[0m     url,\n\u001b[0;32m    133\u001b[0m     headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    134\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput,\n\u001b[0;32m    135\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    136\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverify,\n\u001b[0;32m    137\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    138\u001b[0m )\n\u001b[0;32m    139\u001b[0m \u001b[39mreturn\u001b[39;00m RequestsResponse(r)\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\requests\\sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \n\u001b[0;32m    594\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    599\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 600\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(\u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\zhimi\\Downloads\\MSR-Asset-Management\\.venv\\lib\\site-packages\\requests\\adapters.py:578\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    577\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 578\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[0;32m    580\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidHeader(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=15)"
     ]
    }
   ],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "\n",
    "from Scrape.GHMiner import GitHubMiner\n",
    "\n",
    "github_miner = GitHubMiner(private_token='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')\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_github_issue, 'raw.json'))\n",
    "mark = False\n",
    "repo_done = ['Aim']\n",
    "\n",
    "for index, row in df_dependents.iterrows():\n",
    "    if row['Tool'] in repo_done:\n",
    "        continue\n",
    "    print(row['Tool'])\n",
    "    for repo in row['GitHub Dependents']:\n",
    "        if (not mark) and (repo != 'apache/airflow'):\n",
    "            continue\n",
    "        elif (not mark) and (repo == 'apache/airflow'):\n",
    "            mark = True\n",
    "        repo_data = github_miner.scrape_repo(repo)\n",
    "        if (not repo_data.empty) and (repo_data['Repo Created Date'].values[0] > tools_release_date[row['Tool']]) and repo_data['#Issue'].values[0]:\n",
    "            print(repo)\n",
    "            issues = github_miner.scrape_issue(repo)\n",
    "            issues['Tool'] = row['Tool']\n",
    "            df_issues = pd.concat([df_issues, issues], ignore_index=True)\n",
    "            df_issues.to_json(os.path.join(path_github_issue, 'raw.json'), indent=4, orient='records')\n",
    "    \n",
    "df_issues.to_json(os.path.join(path_github_issue, 'raw.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2719"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude issues that are not related to each tool\n",
    "\n",
    "issues_gitlab = pd.read_json(os.path.join(path_gitlab_issue, 'raw.json'))\n",
    "issues_github = pd.read_json(os.path.join(path_github_issue, 'raw.json'))\n",
    "\n",
    "for index, row in issues_gitlab.iterrows():\n",
    "    for keyword in tools_keywords[row['Tool']]:\n",
    "        if keyword in row['Issue_title'].lower():\n",
    "            break\n",
    "    else:\n",
    "        issues_gitlab.drop(index, inplace=True)\n",
    "\n",
    "for index, row in issues_github.iterrows():\n",
    "    for keyword in tools_keywords[row['Tool']]:\n",
    "        if keyword in row['Issue_title'].lower():\n",
    "            break\n",
    "    else:\n",
    "        issues_github.drop(index, inplace=True)\n",
    "\n",
    "issues_github['Platform'] = 'Github'\n",
    "issues_gitlab['Platform'] = 'Gitlab'\n",
    "\n",
    "df_issues = pd.concat([issues_gitlab, issues_github], ignore_index=True)        \n",
    "len(df_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"experiments\"',\n",
       " '0.4.6',\n",
       " '1.1',\n",
       " '1.4',\n",
       " '1.6',\n",
       " '1.7',\n",
       " '2.0',\n",
       " '3 - Quality of Life',\n",
       " '3rd party',\n",
       " '3rd party update',\n",
       " ':bridge_at_night:  Bridge',\n",
       " ':bug: bug',\n",
       " ':rotating_light:',\n",
       " '? - Needs Triage',\n",
       " 'A: example-dvc-experiments',\n",
       " 'A: example-get-started',\n",
       " 'ADO',\n",
       " 'AI\\u202fFrameworks/ONNX',\n",
       " 'AML Compute Instance',\n",
       " 'API',\n",
       " 'API & Doc',\n",
       " 'Auto\\u202fML',\n",
       " 'BF',\n",
       " 'Cloud',\n",
       " 'Community',\n",
       " 'Compute',\n",
       " 'Core UI',\n",
       " 'DRL',\n",
       " 'Data Labeling',\n",
       " 'Data4ML',\n",
       " 'Data\\u202fDrift',\n",
       " 'Data\\u202fPrep\\u202fServices',\n",
       " 'Documentation',\n",
       " 'ERRATA_CANDIDATE',\n",
       " 'Enhancement',\n",
       " 'Environments',\n",
       " 'Evaluation',\n",
       " 'Experimentation UI',\n",
       " 'FAQ',\n",
       " 'Feature - Medium Priority',\n",
       " 'HIGH',\n",
       " 'HPO',\n",
       " 'Hyperdrive',\n",
       " 'Important',\n",
       " 'In the roadmap',\n",
       " 'Inf1',\n",
       " 'Inference',\n",
       " 'Ingestion',\n",
       " 'Issue: Bug Report ',\n",
       " 'Issue: Feature Request',\n",
       " 'L',\n",
       " 'LOE: S',\n",
       " 'Localized',\n",
       " 'MLOps',\n",
       " 'NLP',\n",
       " 'NUM',\n",
       " 'Needs Triage',\n",
       " 'Not related to PyCaret',\n",
       " 'Notebook',\n",
       " 'Optional',\n",
       " 'P0',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'Pipelines',\n",
       " 'Priority 1',\n",
       " 'Reinforcement Learning',\n",
       " 'RepoOfficiel',\n",
       " 'Review One',\n",
       " 'Review Two',\n",
       " 'SDK',\n",
       " 'Stage: Technical Design ',\n",
       " 'Stale',\n",
       " 'TA',\n",
       " 'TODO',\n",
       " 'TODO before 1.0',\n",
       " 'Training',\n",
       " 'Training Service',\n",
       " 'Trn1',\n",
       " 'Usage',\n",
       " 'VISION',\n",
       " 'WIP',\n",
       " 'WIP - Susankha',\n",
       " 'Workspace Management',\n",
       " '[module] pipeline',\n",
       " 'accelerator: tpu',\n",
       " 'accessibility',\n",
       " 'ai',\n",
       " 'aiplatform',\n",
       " 'air',\n",
       " 'alonet',\n",
       " 'api: aiplatform',\n",
       " 'api: vertex-ai',\n",
       " 'app-ui',\n",
       " 'apply',\n",
       " 'arc_ml',\n",
       " 'architecture',\n",
       " 'area / SDK-storage',\n",
       " 'area / integrations',\n",
       " 'area-getting-started',\n",
       " 'area-ml-resource-management',\n",
       " 'area-remote-desktop',\n",
       " 'area-remote-web',\n",
       " 'area-sign-in',\n",
       " 'area-telemetry',\n",
       " 'area-treeview',\n",
       " 'area-yaml',\n",
       " 'area/async',\n",
       " 'area/components',\n",
       " 'area/components/aws/sagemaker',\n",
       " 'area/operator',\n",
       " 'area/registry',\n",
       " 'area/samples',\n",
       " 'area:databuilder',\n",
       " 'arena::security',\n",
       " 'assigned',\n",
       " 'assigned-to-author',\n",
       " 'audience/technical',\n",
       " 'august-rewrite',\n",
       " 'automations',\n",
       " 'automl',\n",
       " 'awaiting response',\n",
       " 'awaiting-product-team-response',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'azure-provider',\n",
       " 'azureml',\n",
       " 'backlog',\n",
       " 'benchmark',\n",
       " 'bittensor',\n",
       " 'blocked',\n",
       " 'blocker',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'bug',\n",
       " 'bug-bash',\n",
       " 'build',\n",
       " 'chapter: appendix-tools',\n",
       " 'checkpointing',\n",
       " 'chore',\n",
       " 'cleanup',\n",
       " 'closing-soon-if-no-response',\n",
       " 'code',\n",
       " 'concerns: agents',\n",
       " 'concerns: documentation',\n",
       " 'concerns: main API',\n",
       " 'configs',\n",
       " 'connectors',\n",
       " 'contribution welcomed',\n",
       " 'core/subsvc',\n",
       " 'customer-inquiry',\n",
       " 'customer-issue',\n",
       " 'cxp',\n",
       " 'data',\n",
       " 'data-sync',\n",
       " 'debt',\n",
       " 'dependencies',\n",
       " 'deploy',\n",
       " 'design',\n",
       " 'dev',\n",
       " 'dev workflow',\n",
       " 'devflows',\n",
       " 'discussion',\n",
       " 'diy_container',\n",
       " 'doc-bug',\n",
       " 'doc-enhancement',\n",
       " 'docker images',\n",
       " 'docs',\n",
       " 'documentation',\n",
       " 'duplicate',\n",
       " 'enhancement',\n",
       " 'enhancement request',\n",
       " 'env: new',\n",
       " 'env: sagemaker',\n",
       " 'environment',\n",
       " 'environment: slurm',\n",
       " 'ep:CUDA',\n",
       " 'epic',\n",
       " 'error',\n",
       " 'evaluate_model',\n",
       " 'example issue',\n",
       " 'example request',\n",
       " 'experimental',\n",
       " 'explore',\n",
       " 'feature',\n",
       " 'feature request',\n",
       " 'feature-request',\n",
       " 'fixme',\n",
       " 'forum',\n",
       " 'future release',\n",
       " 'good first issue',\n",
       " 'graphistry',\n",
       " 'guides',\n",
       " 'help wanted',\n",
       " 'hi-ml-azure',\n",
       " 'high-priority',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in progress',\n",
       " 'inference',\n",
       " 'inferencing-benchmark',\n",
       " 'info-needed',\n",
       " 'infrastructure',\n",
       " 'integration',\n",
       " 'invalid',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'iteration-candidate',\n",
       " 'journey:intermediate',\n",
       " 'keep fresh',\n",
       " 'kind/bug',\n",
       " 'kind/enhancement',\n",
       " 'kind/feature',\n",
       " 'kind/question',\n",
       " 'kind/reproducibility',\n",
       " 'kind/usability',\n",
       " 'kubeflow',\n",
       " 'learn',\n",
       " 'lifecycle/frozen',\n",
       " 'lifecycle/stale',\n",
       " 'lightning',\n",
       " 'linting / formatting / cleaning',\n",
       " 'logger',\n",
       " 'logger: comet',\n",
       " 'logger: mlflow',\n",
       " 'logger: wandb',\n",
       " 'logging',\n",
       " 'looking into it',\n",
       " 'low priority',\n",
       " 'machine-learning',\n",
       " 'machine-learning/svc',\n",
       " 'major',\n",
       " 'metrics',\n",
       " 'missing_info',\n",
       " 'ml',\n",
       " 'ml-engineering',\n",
       " 'mlflow',\n",
       " 'model',\n",
       " 'module: text',\n",
       " 'must have',\n",
       " 'need-design-decision',\n",
       " 'needs triage',\n",
       " 'needs-more-info',\n",
       " 'needs-tests',\n",
       " 'needs-triage',\n",
       " 'neptune',\n",
       " 'new',\n",
       " 'new feature',\n",
       " 'new table',\n",
       " 'nnidev',\n",
       " 'no-issue-activity',\n",
       " 'normal',\n",
       " 'notebook',\n",
       " 'on hold',\n",
       " 'open for contribution',\n",
       " 'operationalization',\n",
       " 'optimization',\n",
       " 'organizational',\n",
       " 'p0-critical',\n",
       " 'p1',\n",
       " 'p1-important',\n",
       " 'p2-medium',\n",
       " 'p3-nice-to-have',\n",
       " 'phase / shipped',\n",
       " 'pipeline',\n",
       " 'pipeline 6: infer',\n",
       " 'pl',\n",
       " 'platform/aws',\n",
       " 'platform/other',\n",
       " 'plot_model',\n",
       " 'practice',\n",
       " 'pri/medium',\n",
       " 'priority 3 - nice to have',\n",
       " 'priority-p0',\n",
       " 'priority-p1',\n",
       " 'priority/important-longterm',\n",
       " 'priority/p1',\n",
       " 'priority: 1',\n",
       " 'priority: 2',\n",
       " 'priority: high',\n",
       " 'priority: medium',\n",
       " 'priority: p2',\n",
       " 'priority:high',\n",
       " 'priority:medium',\n",
       " 'priority_high',\n",
       " 'product-feedback',\n",
       " 'product-gap',\n",
       " 'product-issue',\n",
       " 'product-question',\n",
       " 'product::sorts',\n",
       " 'progress bar: rich',\n",
       " 'python',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick-fix',\n",
       " 'refactor',\n",
       " 'refactoring',\n",
       " 'reporting and diagnostics',\n",
       " 'research',\n",
       " 'roadmap',\n",
       " 'sagemaker',\n",
       " 'sagemaker-dsk-v2',\n",
       " 'sagemaker_container',\n",
       " 'samples',\n",
       " 'scenario',\n",
       " 'sdk-docs',\n",
       " 'section',\n",
       " 'service update',\n",
       " 'service:executor',\n",
       " 'service:sm-executor',\n",
       " 'setup',\n",
       " 'snippets-request',\n",
       " 'spark',\n",
       " 'stale',\n",
       " 'stale :zzz:',\n",
       " 'status/triaged',\n",
       " 'status: phase 1',\n",
       " 'status: phase 2',\n",
       " 'status:completed',\n",
       " 'status:needs_reproducing',\n",
       " 'status:needs_votes',\n",
       " 'streaming',\n",
       " 'studio',\n",
       " 'support',\n",
       " 't-must-fix',\n",
       " 't-nice-to-have-fix',\n",
       " 't-unknown-sub-error',\n",
       " 'task',\n",
       " 'technical debt',\n",
       " 'test',\n",
       " 'tests',\n",
       " 'time_series',\n",
       " 'timecodes',\n",
       " 'to refine',\n",
       " 'todo',\n",
       " 'tooling and CI',\n",
       " 'topic:dependencies',\n",
       " 'topic:eval',\n",
       " 'topic:models',\n",
       " 'topic:reader',\n",
       " 'training-benchmark',\n",
       " 'triage',\n",
       " 'triage me',\n",
       " 'triage-needed',\n",
       " 'triage/intermediate-priotrity',\n",
       " 'triaged',\n",
       " 'tune',\n",
       " 'type / bug',\n",
       " 'type / code-health',\n",
       " 'type / enhancement',\n",
       " 'type/maintenance',\n",
       " 'type: bug',\n",
       " 'type: enhancement',\n",
       " 'type: feature request',\n",
       " 'type: question',\n",
       " 'type::bug',\n",
       " 'type:bug',\n",
       " 'type:feature',\n",
       " 'type:maintenance',\n",
       " 'type:question',\n",
       " 'up-for-grabs',\n",
       " 'upstream-azml',\n",
       " 'urgent',\n",
       " 'user raised',\n",
       " 'ux',\n",
       " 'v0.8.5',\n",
       " 'waiting',\n",
       " 'waiting feedback',\n",
       " \"won't fix\",\n",
       " 'wontfix',\n",
       " 'work-item',\n",
       " 'workflow',\n",
       " 'working as intended',\n",
       " ' feat',\n",
       " '',\n",
       " '',\n",
       " ' bug fix',\n",
       " ' bug',\n",
       " ' experiment',\n",
       " ' Tracker',\n",
       " '\\u200d\\u200d\\u200d discussion',\n",
       " ' New Component',\n",
       " ' Paper',\n",
       " ' named-entity-recognition',\n",
       " ' New Feature',\n",
       " ' checkpoint',\n",
       " ' dvc',\n",
       " ' testing'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = set()\n",
    "for _, row in df_issues['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1657"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        df_issues.drop(index, inplace=True)\n",
    "        continue\n",
    "    \n",
    "    if not row['Issue_label']:\n",
    "        continue\n",
    "    else:\n",
    "        for label in row['Issue_label']:\n",
    "            for issue_label in issue_labels:\n",
    "                if issue_label in label.lower():\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        else:\n",
    "            df_issues.drop(index, inplace=True)\n",
    "\n",
    "len(df_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create issue dataset\n",
    "\n",
    "df_issues['Issue_score_count'] = df_issues['Issue_upvote_count'] - df_issues['Issue_downvote_count']\n",
    "df_issues['Comment_score_count'] = df_issues['Comment_upvote_count'] - df_issues['Comment_downvote_count']\n",
    "df_issues['Issue_body'] = df_issues['Issue_body'].fillna('')\n",
    "\n",
    "del df_issues['Issue_upvote_count']\n",
    "del df_issues['Issue_downvote_count']\n",
    "del df_issues['Comment_upvote_count']\n",
    "del df_issues['Comment_downvote_count']\n",
    "del df_issues['Issue_label']\n",
    "\n",
    "df_issues = df_issues.reindex(sorted(df_issues.columns), axis=1)\n",
    "df_issues.to_json(os.path.join(path_labeling, 'issues.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

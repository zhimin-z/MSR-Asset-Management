{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from GHMiner import GitHubMiner\n",
    "from GLMiner import GitLabMiner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_repo = {\n",
    "    'Aim': 'aimhubio/aim',\n",
    "    'Amazon SageMaker': 'aws/sagemaker-python-sdk',\n",
    "    'Azure Machine Learning': 'Azure/azure-sdk-for-python',\n",
    "    'ClearML': 'allegroai/clearml',\n",
    "    'Codalab': 'codalab/codalab-worksheets',\n",
    "    'DVC': 'iterative/dvc',\n",
    "    'Determined': 'determined-ai/determined',\n",
    "    'Domino': 'dominodatalab/python-domino',\n",
    "    'Guild AI': 'guildai/guildai',\n",
    "    'Kedro': 'kedro-org/kedro',\n",
    "    'MLflow': 'mlflow/mlflow',\n",
    "    'MLRun': 'mlrun/mlrun',\n",
    "    'ModelDB': 'VertaAI/modeldb',\n",
    "    'Neptune': 'neptune-ai/neptune-client',\n",
    "    'Polyaxon': 'polyaxon/polyaxon',\n",
    "    'Sacred': 'IDSIA/sacred',\n",
    "    'Valohai': 'valohai/valohai-cli',\n",
    "    'Weights & Biases': 'wandb/wandb'\n",
    "}\n",
    "\n",
    "tools_release_date = {\n",
    "    'Amazon SageMaker': '2017-11-19',\n",
    "    'Azure Machine Learning': '2015-02-18',\n",
    "    'cnvrg.io': '2020-03-31',\n",
    "    'Comet': '2017-01-01',\n",
    "    'Iterative Studio': '2021-05-12',\n",
    "    'Polyaxon': '2018-10-16',\n",
    "    'SigOpt': '2014-11-01',\n",
    "    'Vertex AI': '2019-03-01'\n",
    "}\n",
    "\n",
    "tools_link = {\n",
    "    'cnvrg.io': 'https://github.com/cnvrg',\n",
    "    'Comet': 'https://github.com/comet-ml',\n",
    "    'Iterative Studio': 'https://studio.iterative.ai',\n",
    "    'SigOpt': 'https://github.com/sigopt',\n",
    "    'Vertex AI': 'https://cloud.google.com/vertex-ai'\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Aim': ['aim'],\n",
    "    'Amazon SageMaker': ['sagemaker', 'amazon sagemaker'],\n",
    "    'Azure Machine Learning': ['azureml', 'azure machine learning'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'cnvrg.io': ['cnvrg'],\n",
    "    'Codalab': ['codalab'],\n",
    "    'Comet': ['comet'],\n",
    "    'Determined': ['determined'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild ai'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'MLRun': ['mlrun'],\n",
    "    'ModelDB': ['modeldb'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Valohai': ['valohai'],\n",
    "    'Vertex AI': ['vertex ai'],\n",
    "    'Weights & Biases': ['wandb', 'weights & biases', 'weights and biases']\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "\n",
    "}\n",
    "\n",
    "issue_labels = {\n",
    "    'bug',\n",
    "    'error',\n",
    "    'invalid',\n",
    "    'looking into it',\n",
    "    'waiting feedback',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_repo_raw = os.path.join(path_github_repo, 'Raw')\n",
    "path_gitlab_repo_raw = os.path.join(path_gitlab_repo, 'Raw')\n",
    "path_github_repo_scraped = os.path.join(path_github_repo, 'Scraped')\n",
    "path_gitlab_repo_scraped = os.path.join(path_gitlab_repo, 'Scraped')\n",
    "\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "path_github_issue_raw = os.path.join(path_github_issue, 'Raw')\n",
    "path_gitlab_issue_raw = os.path.join(path_gitlab_issue, 'Raw')\n",
    "path_github_issue_filtered = os.path.join(path_github_issue, 'Filtered')\n",
    "path_gitlab_issue_filtered = os.path.join(path_gitlab_issue, 'Filtered')\n",
    "\n",
    "path_labeling_issue = os.path.join(path_labeling, 'Issue')\n",
    "path_labeling_issue_gpt = os.path.join(path_labeling_issue, 'GPT')\n",
    "path_labeling_issue_gpt_text = os.path.join(path_labeling_issue_gpt, 'Text')\n",
    "path_labeling_issue_gpt_code = os.path.join(path_labeling_issue_gpt, 'Code')\n",
    "path_labeling_issue_native = os.path.join(path_labeling_issue, 'Native')\n",
    "path_labeling_issue_native_text = os.path.join(path_labeling_issue_native, 'Text')\n",
    "path_labeling_issue_native_code = os.path.join(path_labeling_issue_native, 'Code')\n",
    "\n",
    "path_labeling_fix = os.path.join(path_labeling, 'Fix')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_labeling):\n",
    "    os.makedirs(path_labeling)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)\n",
    "\n",
    "if not os.path.exists(path_github_repo_raw):\n",
    "    os.makedirs(path_github_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_raw):\n",
    "    os.makedirs(path_gitlab_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_raw):\n",
    "    os.makedirs(path_github_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_raw):\n",
    "    os.makedirs(path_gitlab_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_filtered):\n",
    "    os.makedirs(path_github_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_filtered):\n",
    "    os.makedirs(path_gitlab_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_github_repo_scraped):\n",
    "    os.makedirs(path_github_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_scraped):\n",
    "    os.makedirs(path_gitlab_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue):\n",
    "    os.makedirs(path_labeling_issue)\n",
    "\n",
    "if not os.path.exists(path_labeling_fix):\n",
    "    os.makedirs(path_labeling_fix)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue_gpt):\n",
    "    os.makedirs(path_labeling_issue_gpt)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue_native):\n",
    "    os.makedirs(path_labeling_issue_native)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue_gpt_text):\n",
    "    os.makedirs(path_labeling_issue_gpt_text)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue_gpt_code):\n",
    "    os.makedirs(path_labeling_issue_gpt_code)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue_native_text):\n",
    "    os.makedirs(path_labeling_issue_native_text)\n",
    "\n",
    "if not os.path.exists(path_labeling_issue_native_code):\n",
    "    os.makedirs(path_labeling_issue_native_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "GITLAB_TOKEN = os.getenv('GITLAB_TOKEN')\n",
    "\n",
    "github_miner = GitHubMiner(private_token=GITHUB_TOKEN)\n",
    "gitlab_miner = GitLabMiner(private_token=GITLAB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo</th>\n",
       "      <th>Link</th>\n",
       "      <th>Repo Creation Date</th>\n",
       "      <th>Last Commit Date</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Language</th>\n",
       "      <th>Size</th>\n",
       "      <th>#Star</th>\n",
       "      <th>#Watch</th>\n",
       "      <th>#Fork</th>\n",
       "      <th>#Contributors</th>\n",
       "      <th>#Branches</th>\n",
       "      <th>#Releases</th>\n",
       "      <th>#Commits</th>\n",
       "      <th>#Pull Requests</th>\n",
       "      <th>#Pull Requests (Open)</th>\n",
       "      <th>#Issues</th>\n",
       "      <th>#Issues (Open)</th>\n",
       "      <th>Name</th>\n",
       "      <th>First Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aimhubio/aim</td>\n",
       "      <td>https://github.com/aimhubio/aim</td>\n",
       "      <td>2019-05-31 18:25:07</td>\n",
       "      <td>2023-01-31 12:13:08</td>\n",
       "      <td>[python, ai, data-science, data-visualization,...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>59947.0</td>\n",
       "      <td>3065.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>Aim</td>\n",
       "      <td>2022-01-22 13:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws/sagemaker-python-sdk</td>\n",
       "      <td>https://github.com/aws/sagemaker-python-sdk</td>\n",
       "      <td>2017-11-14 01:03:33</td>\n",
       "      <td>2023-01-31 01:53:20</td>\n",
       "      <td>[aws, mxnet, tensorflow, machine-learning, pyt...</td>\n",
       "      <td>Python</td>\n",
       "      <td>108723.0</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2017-11-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure/azure-sdk-for-python</td>\n",
       "      <td>https://github.com/Azure/azure-sdk-for-python</td>\n",
       "      <td>2012-04-24 16:46:12</td>\n",
       "      <td>2023-02-01 02:54:36</td>\n",
       "      <td>[python, azure, azure-sdk, hacktoberfest]</td>\n",
       "      <td>Python</td>\n",
       "      <td>537971.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>2186.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>13516.0</td>\n",
       "      <td>20859.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>28484.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>2015-02-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegroai/clearml</td>\n",
       "      <td>https://github.com/allegroai/clearml</td>\n",
       "      <td>2019-06-10 08:18:32</td>\n",
       "      <td>2023-01-26 17:11:47</td>\n",
       "      <td>[version-control, experiment-manager, version,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>42437.0</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>2019-06-11 17:27:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codalab/codalab-worksheets</td>\n",
       "      <td>https://github.com/codalab/codalab-worksheets</td>\n",
       "      <td>2014-11-30 22:33:18</td>\n",
       "      <td>2023-01-29 22:07:50</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>28204.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>4541.0</td>\n",
       "      <td>2242.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4366.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>Codalab</td>\n",
       "      <td>2017-05-14 00:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iterative/dvc</td>\n",
       "      <td>https://github.com/iterative/dvc</td>\n",
       "      <td>2017-03-04 08:16:33</td>\n",
       "      <td>2023-02-01 03:25:50</td>\n",
       "      <td>[data-science, machine-learning, reproducibili...</td>\n",
       "      <td>Python</td>\n",
       "      <td>17626.0</td>\n",
       "      <td>11008.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>8365.0</td>\n",
       "      <td>4544.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8652.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>DVC</td>\n",
       "      <td>2017-05-04 08:03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>determined-ai/determined</td>\n",
       "      <td>https://github.com/determined-ai/determined</td>\n",
       "      <td>2020-04-07 16:12:29</td>\n",
       "      <td>2023-02-01 03:19:51</td>\n",
       "      <td>[deep-learning, machine-learning, ml-platform,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>108561.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4923.0</td>\n",
       "      <td>5637.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5891.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Determined</td>\n",
       "      <td>2020-04-08 20:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dominodatalab/python-domino</td>\n",
       "      <td>https://github.com/dominodatalab/python-domino</td>\n",
       "      <td>2016-05-16 22:58:02</td>\n",
       "      <td>2023-01-17 21:37:32</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>488.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Domino</td>\n",
       "      <td>2020-08-05 05:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>guildai/guildai</td>\n",
       "      <td>https://github.com/guildai/guildai</td>\n",
       "      <td>2017-09-27 18:57:50</td>\n",
       "      <td>2023-01-25 14:47:47</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>16971.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5382.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Guild AI</td>\n",
       "      <td>2022-04-28 14:31:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kedro-org/kedro</td>\n",
       "      <td>https://github.com/kedro-org/kedro</td>\n",
       "      <td>2019-04-18 10:29:56</td>\n",
       "      <td>2023-01-30 10:11:12</td>\n",
       "      <td>[pipeline, kedro, hacktoberfest, mlops, experi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>165970.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>2019-06-03 16:15:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow</td>\n",
       "      <td>2018-06-05 16:05:58</td>\n",
       "      <td>2023-01-31 21:19:34</td>\n",
       "      <td>[machine-learning, ai, ml, mlflow, apache-spar...</td>\n",
       "      <td>Python</td>\n",
       "      <td>123966.0</td>\n",
       "      <td>13546.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3166.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3683.0</td>\n",
       "      <td>4920.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>7632.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>2018-06-27 16:19:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlrun/mlrun</td>\n",
       "      <td>https://github.com/mlrun/mlrun</td>\n",
       "      <td>2019-09-01 16:59:19</td>\n",
       "      <td>2023-01-31 19:23:02</td>\n",
       "      <td>[mlops, python, data-science, machine-learning...</td>\n",
       "      <td>Python</td>\n",
       "      <td>45313.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>2751.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>MLRun</td>\n",
       "      <td>2019-09-08 21:21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VertaAI/modeldb</td>\n",
       "      <td>https://github.com/VertaAI/modeldb</td>\n",
       "      <td>2016-10-19 01:07:26</td>\n",
       "      <td>2023-01-31 19:56:03</td>\n",
       "      <td>[machine-learning, model-management, modeldb, ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>47335.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3653.0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>ModelDB</td>\n",
       "      <td>2020-04-01 03:47:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neptune-ai/neptune-client</td>\n",
       "      <td>https://github.com/neptune-ai/neptune-client</td>\n",
       "      <td>2019-02-11 11:25:57</td>\n",
       "      <td>2023-01-31 12:58:06</td>\n",
       "      <td>[pytorch, keras, lightgbm, xgboost, optuna, te...</td>\n",
       "      <td>Python</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>2019-04-02 11:58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polyaxon/polyaxon</td>\n",
       "      <td>https://github.com/polyaxon/polyaxon</td>\n",
       "      <td>2016-12-26 12:48:47</td>\n",
       "      <td>2023-02-01 00:59:26</td>\n",
       "      <td>[deep-learning, machine-learning, artificial-i...</td>\n",
       "      <td>None</td>\n",
       "      <td>126260.0</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10038.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>2018-10-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IDSIA/sacred</td>\n",
       "      <td>https://github.com/IDSIA/sacred</td>\n",
       "      <td>2014-03-31 18:05:29</td>\n",
       "      <td>2023-01-28 22:28:19</td>\n",
       "      <td>[python, machine-learning, infrastructure, rep...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6166.0</td>\n",
       "      <td>3989.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>2016-01-13 18:56:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>valohai/valohai-cli</td>\n",
       "      <td>https://github.com/valohai/valohai-cli</td>\n",
       "      <td>2017-02-08 12:46:54</td>\n",
       "      <td>2023-01-18 12:30:37</td>\n",
       "      <td>[machine-learning, client, api, command-line, ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>624.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Valohai</td>\n",
       "      <td>2019-07-26 10:05:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wandb/wandb</td>\n",
       "      <td>https://github.com/wandb/wandb</td>\n",
       "      <td>2017-03-24 05:46:23</td>\n",
       "      <td>2023-02-01 00:10:44</td>\n",
       "      <td>[machine-learning, experiment-track, deep-lear...</td>\n",
       "      <td>Python</td>\n",
       "      <td>63315.0</td>\n",
       "      <td>5382.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>5046.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>2018-11-11 21:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/cnvrg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnvrg.io</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/comet-ml</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comet</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://studio.iterative.ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iterative Studio</td>\n",
       "      <td>2021-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/sigopt</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>2014-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cloud.google.com/vertex-ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repo  \\\n",
       "0                  aimhubio/aim   \n",
       "1      aws/sagemaker-python-sdk   \n",
       "2    Azure/azure-sdk-for-python   \n",
       "3             allegroai/clearml   \n",
       "4    codalab/codalab-worksheets   \n",
       "5                 iterative/dvc   \n",
       "6      determined-ai/determined   \n",
       "7   dominodatalab/python-domino   \n",
       "8               guildai/guildai   \n",
       "9               kedro-org/kedro   \n",
       "10                mlflow/mlflow   \n",
       "11                  mlrun/mlrun   \n",
       "12              VertaAI/modeldb   \n",
       "13    neptune-ai/neptune-client   \n",
       "14            polyaxon/polyaxon   \n",
       "15                 IDSIA/sacred   \n",
       "16          valohai/valohai-cli   \n",
       "17                  wandb/wandb   \n",
       "18                          NaN   \n",
       "19                          NaN   \n",
       "20                          NaN   \n",
       "21                          NaN   \n",
       "22                          NaN   \n",
       "\n",
       "                                              Link  Repo Creation Date  \\\n",
       "0                  https://github.com/aimhubio/aim 2019-05-31 18:25:07   \n",
       "1      https://github.com/aws/sagemaker-python-sdk 2017-11-14 01:03:33   \n",
       "2    https://github.com/Azure/azure-sdk-for-python 2012-04-24 16:46:12   \n",
       "3             https://github.com/allegroai/clearml 2019-06-10 08:18:32   \n",
       "4    https://github.com/codalab/codalab-worksheets 2014-11-30 22:33:18   \n",
       "5                 https://github.com/iterative/dvc 2017-03-04 08:16:33   \n",
       "6      https://github.com/determined-ai/determined 2020-04-07 16:12:29   \n",
       "7   https://github.com/dominodatalab/python-domino 2016-05-16 22:58:02   \n",
       "8               https://github.com/guildai/guildai 2017-09-27 18:57:50   \n",
       "9               https://github.com/kedro-org/kedro 2019-04-18 10:29:56   \n",
       "10                https://github.com/mlflow/mlflow 2018-06-05 16:05:58   \n",
       "11                  https://github.com/mlrun/mlrun 2019-09-01 16:59:19   \n",
       "12              https://github.com/VertaAI/modeldb 2016-10-19 01:07:26   \n",
       "13    https://github.com/neptune-ai/neptune-client 2019-02-11 11:25:57   \n",
       "14            https://github.com/polyaxon/polyaxon 2016-12-26 12:48:47   \n",
       "15                 https://github.com/IDSIA/sacred 2014-03-31 18:05:29   \n",
       "16          https://github.com/valohai/valohai-cli 2017-02-08 12:46:54   \n",
       "17                  https://github.com/wandb/wandb 2017-03-24 05:46:23   \n",
       "18                        https://github.com/cnvrg                 NaT   \n",
       "19                     https://github.com/comet-ml                 NaT   \n",
       "20                     https://studio.iterative.ai                 NaT   \n",
       "21                       https://github.com/sigopt                 NaT   \n",
       "22              https://cloud.google.com/vertex-ai                 NaT   \n",
       "\n",
       "      Last Commit Date                                             Topics  \\\n",
       "0  2023-01-31 12:13:08  [python, ai, data-science, data-visualization,...   \n",
       "1  2023-01-31 01:53:20  [aws, mxnet, tensorflow, machine-learning, pyt...   \n",
       "2  2023-02-01 02:54:36          [python, azure, azure-sdk, hacktoberfest]   \n",
       "3  2023-01-26 17:11:47  [version-control, experiment-manager, version,...   \n",
       "4  2023-01-29 22:07:50                                                 []   \n",
       "5  2023-02-01 03:25:50  [data-science, machine-learning, reproducibili...   \n",
       "6  2023-02-01 03:19:51  [deep-learning, machine-learning, ml-platform,...   \n",
       "7  2023-01-17 21:37:32                                                 []   \n",
       "8  2023-01-25 14:47:47                                                 []   \n",
       "9  2023-01-30 10:11:12  [pipeline, kedro, hacktoberfest, mlops, experi...   \n",
       "10 2023-01-31 21:19:34  [machine-learning, ai, ml, mlflow, apache-spar...   \n",
       "11 2023-01-31 19:23:02  [mlops, python, data-science, machine-learning...   \n",
       "12 2023-01-31 19:56:03  [machine-learning, model-management, modeldb, ...   \n",
       "13 2023-01-31 12:58:06  [pytorch, keras, lightgbm, xgboost, optuna, te...   \n",
       "14 2023-02-01 00:59:26  [deep-learning, machine-learning, artificial-i...   \n",
       "15 2023-01-28 22:28:19  [python, machine-learning, infrastructure, rep...   \n",
       "16 2023-01-18 12:30:37  [machine-learning, client, api, command-line, ...   \n",
       "17 2023-02-01 00:10:44  [machine-learning, experiment-track, deep-lear...   \n",
       "18                 NaT                                                NaN   \n",
       "19                 NaT                                                NaN   \n",
       "20                 NaT                                                NaN   \n",
       "21                 NaT                                                NaN   \n",
       "22                 NaT                                                NaN   \n",
       "\n",
       "      Language      Size    #Star  #Watch   #Fork  #Contributors  #Branches  \\\n",
       "0   TypeScript   59947.0   3065.0    36.0   191.0           50.0       77.0   \n",
       "1       Python  108723.0   1770.0   132.0   926.0          309.0       15.0   \n",
       "2       Python  537971.0   3473.0   362.0  2186.0          398.0      583.0   \n",
       "3       Python   42437.0   4027.0    83.0   542.0           62.0        3.0   \n",
       "4       Python   28204.0    135.0    18.0    79.0           54.0      133.0   \n",
       "5       Python   17626.0  11008.0   136.0  1024.0          254.0       10.0   \n",
       "6       Python  108561.0   2024.0    62.0   276.0           73.0      182.0   \n",
       "7       Python     488.0     51.0    28.0    50.0           32.0       52.0   \n",
       "8       Python   16971.0    771.0    13.0    71.0           20.0       65.0   \n",
       "9       Python  165970.0   8041.0   102.0   760.0          169.0       32.0   \n",
       "10      Python  123966.0  13546.0   288.0  3166.0          456.0      208.0   \n",
       "11      Python   45313.0    893.0    25.0   170.0           58.0       24.0   \n",
       "12        Java   47335.0   1552.0    71.0   265.0           48.0      546.0   \n",
       "13      Python    8408.0    364.0    17.0    37.0           29.0       28.0   \n",
       "14        None  126260.0   3239.0    78.0   319.0           90.0       16.0   \n",
       "15      Python    6166.0   3989.0    70.0   366.0           93.0       11.0   \n",
       "16      Python     624.0     13.0     6.0     6.0            8.0        8.0   \n",
       "17      Python   63315.0   5382.0    38.0   414.0          117.0      576.0   \n",
       "18         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "19         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "20         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "21         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "22         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "\n",
       "    #Releases  #Commits  #Pull Requests  #Pull Requests (Open)  #Issues  \\\n",
       "0        46.0    2009.0          1708.0                   21.0   2491.0   \n",
       "1       479.0    2850.0          2294.0                   51.0   3458.0   \n",
       "2      2697.0   13516.0         20859.0                  145.0  28484.0   \n",
       "3        75.0    1979.0           180.0                    2.0    890.0   \n",
       "4       114.0    4541.0          2242.0                   30.0   4366.0   \n",
       "5       415.0    8365.0          4544.0                    8.0   8652.0   \n",
       "6        76.0    4923.0          5637.0                   65.0   5891.0   \n",
       "7        14.0     201.0           132.0                    4.0    167.0   \n",
       "8         2.0    5382.0            69.0                    1.0    467.0   \n",
       "9        34.0    2148.0           972.0                   16.0   2064.0   \n",
       "10       62.0    3683.0          4920.0                  137.0   7632.0   \n",
       "11      367.0    2751.0          2800.0                   31.0   3011.0   \n",
       "12        2.0    3653.0          3418.0                   92.0   3550.0   \n",
       "13      124.0    1269.0          1019.0                    7.0   1193.0   \n",
       "14        0.0   10038.0           398.0                    2.0   1462.0   \n",
       "15       12.0    1339.0           360.0                    1.0    909.0   \n",
       "16        2.0     532.0           184.0                    1.0    268.0   \n",
       "17      108.0    5046.0          2650.0                  188.0   4878.0   \n",
       "18        NaN       NaN             NaN                    NaN      NaN   \n",
       "19        NaN       NaN             NaN                    NaN      NaN   \n",
       "20        NaN       NaN             NaN                    NaN      NaN   \n",
       "21        NaN       NaN             NaN                    NaN      NaN   \n",
       "22        NaN       NaN             NaN                    NaN      NaN   \n",
       "\n",
       "    #Issues (Open)                    Name  First Release Date  \n",
       "0            223.0                     Aim 2022-01-22 13:45:58  \n",
       "1            455.0        Amazon SageMaker 2017-11-19 00:00:00  \n",
       "2            927.0  Azure Machine Learning 2015-02-18 00:00:00  \n",
       "3            333.0                 ClearML 2019-06-11 17:27:11  \n",
       "4            382.0                 Codalab 2017-05-14 00:32:55  \n",
       "5            626.0                     DVC 2017-05-04 08:03:08  \n",
       "6             86.0              Determined 2020-04-08 20:01:20  \n",
       "7             15.0                  Domino 2020-08-05 05:16:39  \n",
       "8            185.0                Guild AI 2022-04-28 14:31:07  \n",
       "9            245.0                   Kedro 2019-06-03 16:15:43  \n",
       "10          1011.0                  MLflow 2018-06-27 16:19:13  \n",
       "11            84.0                   MLRun 2019-09-08 21:21:26  \n",
       "12           172.0                 ModelDB 2020-04-01 03:47:14  \n",
       "13            19.0                 Neptune 2019-04-02 11:58:35  \n",
       "14           121.0                Polyaxon 2018-10-16 00:00:00  \n",
       "15            92.0                  Sacred 2016-01-13 18:56:23  \n",
       "16            17.0                 Valohai 2019-07-26 10:05:34  \n",
       "17           797.0        Weights & Biases 2018-11-11 21:54:26  \n",
       "18             NaN                cnvrg.io 2020-03-31 00:00:00  \n",
       "19             NaN                   Comet 2017-01-01 00:00:00  \n",
       "20             NaN        Iterative Studio 2021-05-12 00:00:00  \n",
       "21             NaN                  SigOpt 2014-11-01 00:00:00  \n",
       "22             NaN               Vertex AI 2019-03-01 00:00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_data = pd.DataFrame()\n",
    "\n",
    "# scrape open-source asset-management tools\n",
    "for tool_name, tool_repo in tools_repo.items():\n",
    "    if tool_name in tools_release_date:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name, release_date=pd.to_datetime(tools_release_date[tool_name]))\n",
    "    else:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name)\n",
    "\n",
    "    if not tool_data.empty:\n",
    "        tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "    else:\n",
    "        print(error_data)\n",
    "\n",
    "# add closed-source asset-management tools\n",
    "for tool_name in tools_link.keys():\n",
    "    tool_data = {\n",
    "        'Name': tool_name,\n",
    "        'Link': tools_link[tool_name],\n",
    "        'First Release Date': pd.to_datetime(tools_release_date[tool_name])\n",
    "    }\n",
    "    tool_data = pd.DataFrame([tool_data])\n",
    "    tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "tools_data.to_json(os.path.join(path_dataset, 'Tools.json'),\n",
    "                   indent=4, orient='records')\n",
    "tools_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependents = pd.DataFrame()\n",
    "\n",
    "# collect dependents for tools with coding patterns\n",
    "for tool_name in tools_keywords.keys():\n",
    "    github_dependents = []\n",
    "    gitlab_dependents = []\n",
    "\n",
    "    # collect Github dependents\n",
    "    file_name = os.path.join(path_github_repo_raw, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # either search by sourcegraph\n",
    "            if 'Results' in json_data:\n",
    "                for repo_file in json_data['Results']:\n",
    "                    # file name match pattern\n",
    "                    if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('github'):\n",
    "                        repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "                    # code usage match pattern\n",
    "                    elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('github'):\n",
    "                        repo_name = repo_file['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "            # or search by dependent graph\n",
    "            elif 'all_public_dependent_repos' in json_data:\n",
    "                for repo_file in json_data['all_public_dependent_repos']:\n",
    "                    github_dependents.append(repo_file['name'])\n",
    "\n",
    "    # collect Gitlab dependents\n",
    "    file_name = os.path.join(path_gitlab_repo_raw, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # search by sourcegraph exclusively\n",
    "            for repo_file in json_data['Results']:\n",
    "                # file name match pattern\n",
    "                if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                        'gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "                # code usage match pattern\n",
    "                elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['name'].removeprefix('gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "\n",
    "    # remove tool repo from dependents if any\n",
    "    if tool_name in tools_repo and tools_repo[tool_name] in github_dependents:\n",
    "        github_dependents.remove(tools_repo[tool_name])\n",
    "\n",
    "    # no need to add tools without dependents\n",
    "    if not len(github_dependents) and not len(gitlab_dependents):\n",
    "        continue\n",
    "\n",
    "    dependent = {\n",
    "        'Tool': tool_name,\n",
    "        'GitHub Dependents': github_dependents,\n",
    "        'GitLab Dependents': gitlab_dependents\n",
    "    }\n",
    "\n",
    "    dependents = pd.concat(\n",
    "        [dependents, pd.DataFrame([dependent])], ignore_index=True)\n",
    "\n",
    "dependents.to_json(os.path.join(\n",
    "    path_dataset, 'Dependents.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#GitHub Dependents</th>\n",
       "      <th>#GitLab Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aim</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codalab</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comet</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Determined</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Domino</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DVC</td>\n",
       "      <td>4229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLRun</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ModelDB</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Valohai</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>10730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool #GitHub Dependents #GitLab Dependents\n",
       "0                      Aim                 92                  1\n",
       "1         Amazon SageMaker                931                  3\n",
       "2   Azure Machine Learning                689                  0\n",
       "3                  ClearML                303                  0\n",
       "4                  Codalab                 30                  0\n",
       "5                    Comet                480                  0\n",
       "6               Determined                 44                  0\n",
       "7                   Domino                  2                  0\n",
       "8                      DVC               4229                  0\n",
       "9                 Guild AI                 53                  4\n",
       "10                   Kedro                838                  0\n",
       "11                  MLflow               1189                  3\n",
       "12                   MLRun                 17                  0\n",
       "13                 ModelDB                  7                  0\n",
       "14                 Neptune                280                  0\n",
       "15                Polyaxon                 35                  0\n",
       "16                  Sacred               1289                  0\n",
       "17                  SigOpt                 55                  0\n",
       "18                 Valohai                 31                  0\n",
       "19               Vertex AI                 96                  0\n",
       "20        Weights & Biases              10730                  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependents_summary = pd.DataFrame(\n",
    "    columns=['Tool', '#GitHub Dependents', '#GitLab Dependents'])\n",
    "for index, row in dependents.iterrows():\n",
    "    dependent_data = {\n",
    "        'Tool': row['Tool'],\n",
    "        '#GitHub Dependents': len(row['GitHub Dependents']),\n",
    "        '#GitLab Dependents': len(row['GitLab Dependents'])\n",
    "    }\n",
    "    dependent_data = pd.DataFrame([dependent_data])\n",
    "    dependents_summary = pd.concat(\n",
    "        [dependents_summary, dependent_data], ignore_index=True)\n",
    "# dependents_summary.sort_values(by=['#GitHub Dependents', '#GitLab Dependents'], ascending=False, inplace=True)\n",
    "dependents_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents = pd.read_json(os.path.join(path_dataset, 'Dependents.json'))\n",
    "df_tools = pd.read_json(os.path.join(path_dataset, 'Tools.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Gitlab dependents general information for each tool\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(f'{index}: {row[\"Tool\"]}')\n",
    "    repos_data, errors_data = gitlab_miner.scrape_repo_list(\n",
    "        row['GitLab Dependents'])\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_gitlab_repo_scraped, f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n",
    "\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(path_gitlab_repo_scraped,\n",
    "                            f'Discarded.{row[\"Tool\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Gitlab dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_gitlab_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos without any issues\n",
    "        repos = repos[repos['#Issues'] > 0]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(f'{row[\"Name\"]}: {repos[\"#Issues\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = gitlab_miner.scrape_issue_list(repos['Repo'].tolist())\n",
    "        if not issues.empty:\n",
    "            issues.to_json(os.path.join(path_gitlab_issue_raw,\n",
    "                                        f'{row[\"Name\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_link</th>\n",
       "      <th>Issue_title</th>\n",
       "      <th>Issue_label</th>\n",
       "      <th>Issue_creation_time</th>\n",
       "      <th>Issue_closed_time</th>\n",
       "      <th>Issue_upvote_count</th>\n",
       "      <th>Issue_downvote_count</th>\n",
       "      <th>Issue_body</th>\n",
       "      <th>Tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>[Sorts] Add sagemaker dependencies</td>\n",
       "      <td>[arena::security, product::sorts, type::bug]</td>\n",
       "      <td>2022-12-19 20:28:18.985</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;!-- Issues are public, they should not contai...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>Enable sagemaker</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-04-21 18:40:24.230</td>\n",
       "      <td>2020-05-07 21:34:48.408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://docs.aws.amazon.com/sagemaker/</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>Saving behave logs in MLflow</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-07-06 19:33:14.309</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Like we do in learn, we should also save the p...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>ML Database vs. MLflow</td>\n",
       "      <td>[learn]</td>\n",
       "      <td>2020-04-25 17:51:29.061</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am mainly working on the feature selection p...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>Namespacing polaris runs for logging purposes ...</td>\n",
       "      <td>[improvement, learn]</td>\n",
       "      <td>2020-01-31 21:57:59.518</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Background\\n==========\\n\\nEverytime analysis i...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Issue_link  \\\n",
       "0  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "1  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "2  https://gitlab.com/librespacefoundation/polari...   \n",
       "3  https://gitlab.com/librespacefoundation/polari...   \n",
       "4  https://gitlab.com/librespacefoundation/polari...   \n",
       "\n",
       "                                         Issue_title  \\\n",
       "0                 [Sorts] Add sagemaker dependencies   \n",
       "1                                   Enable sagemaker   \n",
       "2                       Saving behave logs in MLflow   \n",
       "3                             ML Database vs. MLflow   \n",
       "4  Namespacing polaris runs for logging purposes ...   \n",
       "\n",
       "                                    Issue_label     Issue_creation_time  \\\n",
       "0  [arena::security, product::sorts, type::bug] 2022-12-19 20:28:18.985   \n",
       "1                                            [] 2020-04-21 18:40:24.230   \n",
       "2                                            [] 2021-07-06 19:33:14.309   \n",
       "3                                       [learn] 2020-04-25 17:51:29.061   \n",
       "4                          [improvement, learn] 2020-01-31 21:57:59.518   \n",
       "\n",
       "        Issue_closed_time  Issue_upvote_count  Issue_downvote_count  \\\n",
       "0                     NaT                   0                     0   \n",
       "1 2020-05-07 21:34:48.408                   0                     0   \n",
       "2                     NaT                   0                     0   \n",
       "3                     NaT                   1                     0   \n",
       "4                     NaT                   0                     0   \n",
       "\n",
       "                                          Issue_body              Tool  \n",
       "0  <!-- Issues are public, they should not contai...  Amazon SageMaker  \n",
       "1             https://docs.aws.amazon.com/sagemaker/  Amazon SageMaker  \n",
       "2  Like we do in learn, we should also save the p...            MLflow  \n",
       "3  I am mainly working on the feature selection p...            MLflow  \n",
       "4  Background\\n==========\\n\\nEverytime analysis i...            MLflow  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude Gitlab issues that are not related to each tool\n",
    "valid_issues_all = pd.DataFrame()\n",
    "valid_fixes_all = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    valid_fixes = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "    \n",
    "    for index, issue in issues.iterrows():\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if 'amazon' in keyword:\n",
    "                continue\n",
    "            if keyword in issue['Issue_title'].lower():\n",
    "                valid_issue = pd.DataFrame([issue])\n",
    "                valid_issues = pd.concat(\n",
    "                    [valid_issues, valid_issue], ignore_index=True)\n",
    "                if not pd.isnull(issue['Issue_closed_time']):\n",
    "                    valid_fixes = pd.concat(\n",
    "                        [valid_fixes, valid_issue], ignore_index=True)\n",
    "                break\n",
    "\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues['Tool'] = tool_name\n",
    "        valid_issues_all = pd.concat(\n",
    "            [valid_issues_all, valid_issues], ignore_index=True)\n",
    "        if not valid_fixes.empty:\n",
    "            valid_fixes['Tool'] = tool_name\n",
    "            valid_fixes_all = pd.concat(\n",
    "                [valid_fixes_all, valid_fixes], ignore_index=True)\n",
    "\n",
    "valid_issues_all = valid_issues_all[~valid_issues_all['Tool'].isin(\n",
    "    ignore_tools)]\n",
    "valid_fixes_all = valid_fixes_all[~valid_fixes_all['Tool'].isin(ignore_tools)]\n",
    "valid_issues_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arena::security', 'improvement', 'learn', 'product::sorts', 'type::bug'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = set()\n",
    "for _, row in valid_issues_all['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "valid_issues_filtered = []\n",
    "valid_fixes_filtered = []\n",
    "\n",
    "for index, row in valid_issues_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "       \n",
    "    break_sign = False\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for label_question in issue_labels:\n",
    "            if not break_sign and label_question in label_repo.lower():\n",
    "                valid_issues_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "for index, row in valid_fixes_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "       \n",
    "    break_sign = False\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for label_question in issue_labels:\n",
    "            if not break_sign and label_question in label_repo.lower():\n",
    "                valid_fixes_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "valid_issues_filtered = pd.concat(valid_issues_filtered, axis=1).T\n",
    "valid_issues_filtered.to_json(os.path.join(\n",
    "    path_gitlab_issue_filtered, 'issues.json'), indent=4, orient='records')\n",
    "\n",
    "if valid_fixes_filtered:\n",
    "    valid_fixes_filtered = pd.concat(valid_fixes_filtered, axis=1).T\n",
    "    valid_fixes_filtered.to_json(os.path.join(\n",
    "        path_gitlab_issue_filtered, 'fixes.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tool  #Issue\n",
       "0  Amazon SageMaker       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_issues = summary_issues.astype({'#Issue': 'int32'})\n",
    "summary_issues.to_csv(os.path.join(\n",
    "    path_gitlab_issue, 'summary.csv'), index=False)\n",
    "summary_issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Github dependents general information for each tool\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(f'{index}: {row[\"Tool\"]}')\n",
    "    repos_data, errors_data = github_miner.scrape_repo_list(\n",
    "        row['GitHub Dependents'])\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_github_repo_scraped, f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n",
    "\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(path_github_repo_scraped,\n",
    "                            f'Discarded.{row[\"Tool\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_github_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos with only pr-based issues\n",
    "        repos = repos[repos['#Issues'] > repos['#Pull Requests']]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(\n",
    "            f'{row[\"Name\"]}: {repos[\"#Issues\"].sum() - repos[\"#Pull Requests\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = github_miner.scrape_issue_list(repos['Repo'].tolist())\n",
    "        if not issues.empty:\n",
    "            issues.to_json(os.path.join(path_github_issue_raw,\n",
    "                           f'{row[\"Name\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_link</th>\n",
       "      <th>Issue_title</th>\n",
       "      <th>Issue_label</th>\n",
       "      <th>Issue_creation_time</th>\n",
       "      <th>Issue_closed_time</th>\n",
       "      <th>Issue_upvote_count</th>\n",
       "      <th>Issue_downvote_count</th>\n",
       "      <th>Issue_comment_count</th>\n",
       "      <th>Issue_body</th>\n",
       "      <th>Tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/h2oai/dai-deployment-templa...</td>\n",
       "      <td>[Feature Request] Propagate mojo scorer images...</td>\n",
       "      <td>[WIP - Susankha]</td>\n",
       "      <td>2021-11-10 19:28:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>### Request:\\r\\nThis request is a follow up to...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/h2oai/dai-deployment-templa...</td>\n",
       "      <td>[AWS/Sagemaker] Reduce Code Base</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-13 21:07:27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>After research stemming from gcp deployment me...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/utterworks/fast-bert/issues...</td>\n",
       "      <td>Issue with finetuning  pretraining Language mo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-21 14:28:14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi Iam using the container_lm code base to fin...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/utterworks/fast-bert/issues...</td>\n",
       "      <td>Error for training job failed. reason: algorit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-03 13:37:14</td>\n",
       "      <td>2020-10-09 17:13:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello, \\r\\n\\r\\nI was training a DistilBERT mod...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/utterworks/fast-bert/issues...</td>\n",
       "      <td>Using multiple training instances in AWS Sagem...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-04-23 12:22:33</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Is it possible to speedup BERT training by usi...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Issue_link  \\\n",
       "0  https://github.com/h2oai/dai-deployment-templa...   \n",
       "1  https://github.com/h2oai/dai-deployment-templa...   \n",
       "2  https://github.com/utterworks/fast-bert/issues...   \n",
       "3  https://github.com/utterworks/fast-bert/issues...   \n",
       "4  https://github.com/utterworks/fast-bert/issues...   \n",
       "\n",
       "                                         Issue_title       Issue_label  \\\n",
       "0  [Feature Request] Propagate mojo scorer images...  [WIP - Susankha]   \n",
       "1                   [AWS/Sagemaker] Reduce Code Base                []   \n",
       "2  Issue with finetuning  pretraining Language mo...                []   \n",
       "3  Error for training job failed. reason: algorit...                []   \n",
       "4  Using multiple training instances in AWS Sagem...                []   \n",
       "\n",
       "  Issue_creation_time   Issue_closed_time  Issue_upvote_count  \\\n",
       "0 2021-11-10 19:28:00                 NaT                   0   \n",
       "1 2020-02-13 21:07:27                 NaT                   0   \n",
       "2 2020-10-21 14:28:14                 NaT                   0   \n",
       "3 2020-10-03 13:37:14 2020-10-09 17:13:38                   0   \n",
       "4 2020-04-23 12:22:33                 NaT                   0   \n",
       "\n",
       "   Issue_downvote_count  Issue_comment_count  \\\n",
       "0                     0                    2   \n",
       "1                     0                    0   \n",
       "2                     0                    0   \n",
       "3                     0                    1   \n",
       "4                     0                    4   \n",
       "\n",
       "                                          Issue_body              Tool  \n",
       "0  ### Request:\\r\\nThis request is a follow up to...  Amazon SageMaker  \n",
       "1  After research stemming from gcp deployment me...  Amazon SageMaker  \n",
       "2  Hi Iam using the container_lm code base to fin...  Amazon SageMaker  \n",
       "3  Hello, \\r\\n\\r\\nI was training a DistilBERT mod...  Amazon SageMaker  \n",
       "4  Is it possible to speedup BERT training by usi...  Amazon SageMaker  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude Github issues that are not related to each tool\n",
    "valid_issues_all = pd.DataFrame()\n",
    "valid_fixes_all = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_github_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    valid_fixes = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    for index, issue in issues.iterrows():\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if 'amazon' in keyword:\n",
    "                continue\n",
    "            if keyword in issue['Issue_title'].lower():\n",
    "                valid_issue = pd.DataFrame([issue])\n",
    "                valid_issues = pd.concat(\n",
    "                    [valid_issues, valid_issue], ignore_index=True)\n",
    "                if not pd.isnull(issue['Issue_closed_time']):\n",
    "                    valid_fixes = pd.concat(\n",
    "                        [valid_fixes, valid_issue], ignore_index=True)\n",
    "                break\n",
    "\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues['Tool'] = tool_name\n",
    "        valid_issues_all = pd.concat(\n",
    "            [valid_issues_all, valid_issues], ignore_index=True)\n",
    "        if not valid_fixes.empty:\n",
    "            valid_fixes['Tool'] = tool_name\n",
    "            valid_fixes_all = pd.concat(\n",
    "                [valid_fixes_all, valid_fixes], ignore_index=True)\n",
    "\n",
    "valid_issues_all = valid_issues_all[~valid_issues_all['Tool'].isin(\n",
    "    ignore_tools)]\n",
    "valid_fixes_all = valid_fixes_all[~valid_fixes_all['Tool'].isin(ignore_tools)]\n",
    "valid_issues_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"experiments\"',\n",
       " '0.4.6',\n",
       " '1.1',\n",
       " '1.4',\n",
       " '1.6',\n",
       " '1.7',\n",
       " '3 - Quality of Life',\n",
       " '3rd party',\n",
       " '3rd party update',\n",
       " ':bridge_at_night:  Bridge',\n",
       " ':bug: bug',\n",
       " ':rotating_light:',\n",
       " '? - Needs Triage',\n",
       " 'A: example-dvc-experiments',\n",
       " 'A: example-get-started',\n",
       " 'ADO',\n",
       " 'AI\\u202fFrameworks/ONNX',\n",
       " 'AML Compute Instance',\n",
       " 'API',\n",
       " 'API & Doc',\n",
       " 'Auto\\u202fML',\n",
       " 'Cloud',\n",
       " 'Community',\n",
       " 'Compute',\n",
       " 'Core UI',\n",
       " 'DRL',\n",
       " 'Data4ML',\n",
       " 'Data\\u202fDrift',\n",
       " 'Data\\u202fPrep\\u202fServices',\n",
       " 'Documentation',\n",
       " 'ERRATA_CANDIDATE',\n",
       " 'Enhancement',\n",
       " 'Environments',\n",
       " 'Evaluation',\n",
       " 'Experimentation UI',\n",
       " 'FAQ',\n",
       " 'Feature - Medium Priority',\n",
       " 'HIGH',\n",
       " 'HPO',\n",
       " 'Hyperdrive',\n",
       " 'Important',\n",
       " 'In the roadmap',\n",
       " 'Inf1',\n",
       " 'Inference',\n",
       " 'Ingestion',\n",
       " 'Issue: Bug Report 🐞',\n",
       " 'Issue: Feature Request',\n",
       " 'L',\n",
       " 'LOE: S',\n",
       " 'Localized',\n",
       " 'MLOps',\n",
       " 'NLP',\n",
       " 'NUM',\n",
       " 'Needs Triage',\n",
       " 'Not related to PyCaret',\n",
       " 'Notebook',\n",
       " 'Optional',\n",
       " 'P0',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'Pipelines',\n",
       " 'Priority 1',\n",
       " 'Reinforcement Learning',\n",
       " 'RepoOfficiel',\n",
       " 'Review One',\n",
       " 'Review Two',\n",
       " 'SDK',\n",
       " 'Stage: Technical Design 🎨',\n",
       " 'Stale',\n",
       " 'TA',\n",
       " 'TODO',\n",
       " 'TODO before 1.0',\n",
       " 'Training',\n",
       " 'Training Service',\n",
       " 'Trn1',\n",
       " 'Usage',\n",
       " 'VISION',\n",
       " 'WIP',\n",
       " 'WIP - Susankha',\n",
       " 'Workspace Management',\n",
       " '[module] pipeline',\n",
       " 'accelerator: tpu',\n",
       " 'ai',\n",
       " 'aiplatform',\n",
       " 'air',\n",
       " 'alonet',\n",
       " 'api: aiplatform',\n",
       " 'api: vertex-ai',\n",
       " 'app-ui',\n",
       " 'apply',\n",
       " 'architecture',\n",
       " 'area / SDK-storage',\n",
       " 'area / integrations',\n",
       " 'area-remote-desktop',\n",
       " 'area-sign-in',\n",
       " 'area-yaml',\n",
       " 'area/async',\n",
       " 'area/components',\n",
       " 'area/components/aws/sagemaker',\n",
       " 'area/operator',\n",
       " 'area/registry',\n",
       " 'area/samples',\n",
       " 'area:databuilder',\n",
       " 'assigned',\n",
       " 'assigned-to-author',\n",
       " 'august-rewrite',\n",
       " 'automations',\n",
       " 'automl',\n",
       " 'awaiting response',\n",
       " 'awaiting-product-team-response',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'azure-provider',\n",
       " 'azureml',\n",
       " 'backlog',\n",
       " 'benchmark',\n",
       " 'bittensor',\n",
       " 'blocked',\n",
       " 'blocker',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'bug',\n",
       " 'bug-bash',\n",
       " 'build',\n",
       " 'chapter: appendix-tools',\n",
       " 'checkpointing',\n",
       " 'chore',\n",
       " 'cleanup',\n",
       " 'closing-soon-if-no-response',\n",
       " 'code',\n",
       " 'concerns: agents',\n",
       " 'concerns: documentation',\n",
       " 'concerns: main API',\n",
       " 'configs',\n",
       " 'connectors',\n",
       " 'contribution welcomed',\n",
       " 'core/subsvc',\n",
       " 'customer-inquiry',\n",
       " 'customer-issue',\n",
       " 'cxp',\n",
       " 'data',\n",
       " 'data-sync',\n",
       " 'debt',\n",
       " 'dependencies',\n",
       " 'deploy',\n",
       " 'design',\n",
       " 'dev',\n",
       " 'dev workflow',\n",
       " 'devflows',\n",
       " 'discussion',\n",
       " 'diy_container',\n",
       " 'doc-bug',\n",
       " 'doc-enhancement',\n",
       " 'docker images',\n",
       " 'docs',\n",
       " 'documentation',\n",
       " 'duplicate',\n",
       " 'enhancement',\n",
       " 'enhancement request',\n",
       " 'env: new',\n",
       " 'env: sagemaker',\n",
       " 'environment',\n",
       " 'environment: slurm',\n",
       " 'epic',\n",
       " 'error',\n",
       " 'evaluate_model',\n",
       " 'example issue',\n",
       " 'example request',\n",
       " 'experimental',\n",
       " 'explore',\n",
       " 'feature',\n",
       " 'feature request',\n",
       " 'feature-request',\n",
       " 'fixme',\n",
       " 'functionality',\n",
       " 'future release',\n",
       " 'good first issue',\n",
       " 'graphistry',\n",
       " 'gui',\n",
       " 'guides',\n",
       " 'help wanted',\n",
       " 'hi-ml-azure',\n",
       " 'high-priority',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in progress',\n",
       " 'inference',\n",
       " 'inferencing-benchmark',\n",
       " 'infrastructure',\n",
       " 'integration',\n",
       " 'invalid',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'journey:intermediate',\n",
       " 'keep fresh',\n",
       " 'kind/bug',\n",
       " 'kind/feature',\n",
       " 'kind/question',\n",
       " 'kubeflow',\n",
       " 'lifecycle/frozen',\n",
       " 'lifecycle/stale',\n",
       " 'lightning',\n",
       " 'linting / formatting / cleaning',\n",
       " 'logger',\n",
       " 'logger: comet',\n",
       " 'logger: mlflow',\n",
       " 'logger: wandb',\n",
       " 'logging',\n",
       " 'looking into it',\n",
       " 'low priority',\n",
       " 'machine-learning/svc',\n",
       " 'major',\n",
       " 'metrics',\n",
       " 'missing_info',\n",
       " 'ml',\n",
       " 'ml-engineering',\n",
       " 'mlflow',\n",
       " 'model',\n",
       " 'module: text',\n",
       " 'must have',\n",
       " 'need-design-decision',\n",
       " 'needs triage',\n",
       " 'needs-more-info',\n",
       " 'needs-tests',\n",
       " 'needs-triage',\n",
       " 'neptune',\n",
       " 'new',\n",
       " 'new feature',\n",
       " 'new table',\n",
       " 'no-issue-activity',\n",
       " 'normal',\n",
       " 'notebook',\n",
       " 'on hold',\n",
       " 'open for contribution',\n",
       " 'operationalization',\n",
       " 'optimization',\n",
       " 'organizational',\n",
       " 'p0-critical',\n",
       " 'p1',\n",
       " 'p1-important',\n",
       " 'p2-medium',\n",
       " 'p3-nice-to-have',\n",
       " 'phase / shipped',\n",
       " 'pipeline',\n",
       " 'pipeline 6: infer',\n",
       " 'platform/aws',\n",
       " 'platform/other',\n",
       " 'plot_model',\n",
       " 'practice',\n",
       " 'pri/medium',\n",
       " 'priority 3 - nice to have',\n",
       " 'priority-p0',\n",
       " 'priority-p1',\n",
       " 'priority/important-longterm',\n",
       " 'priority/p1',\n",
       " 'priority: 1',\n",
       " 'priority: 2',\n",
       " 'priority: high',\n",
       " 'priority: medium',\n",
       " 'priority: p2',\n",
       " 'priority:high',\n",
       " 'priority:medium',\n",
       " 'priority_high',\n",
       " 'product-feedback',\n",
       " 'product-gap',\n",
       " 'product-issue',\n",
       " 'product-question',\n",
       " 'progress bar: rich',\n",
       " 'python',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick-fix',\n",
       " 'refactor',\n",
       " 'refactoring',\n",
       " 'reporting and diagnostics',\n",
       " 'research',\n",
       " 'roadmap',\n",
       " 'sagemaker',\n",
       " 'sagemaker-dsk-v2',\n",
       " 'sagemaker_container',\n",
       " 'scenario',\n",
       " 'sdk-docs',\n",
       " 'section',\n",
       " 'service update',\n",
       " 'service:executor',\n",
       " 'service:sm-executor',\n",
       " 'setup',\n",
       " 'snippets-request',\n",
       " 'spark',\n",
       " 'stale',\n",
       " 'stale :zzz:',\n",
       " 'status/triaged',\n",
       " 'status: phase 1',\n",
       " 'status: phase 2',\n",
       " 'status:completed',\n",
       " 'status:needs_reproducing',\n",
       " 'status:needs_votes',\n",
       " 'streaming',\n",
       " 'studio',\n",
       " 'support',\n",
       " 't-nice-to-have-fix',\n",
       " 't-unknown-sub-error',\n",
       " 'task',\n",
       " 'technical debt',\n",
       " 'test',\n",
       " 'tests',\n",
       " 'time_series',\n",
       " 'timecodes',\n",
       " 'to refine',\n",
       " 'todo',\n",
       " 'tooling and CI',\n",
       " 'topic:dependencies',\n",
       " 'topic:eval',\n",
       " 'topic:models',\n",
       " 'topic:reader',\n",
       " 'training-benchmark',\n",
       " 'triage',\n",
       " 'triage me',\n",
       " 'triage-needed',\n",
       " 'triaged',\n",
       " 'tune',\n",
       " 'type / bug',\n",
       " 'type / code-health',\n",
       " 'type / enhancement',\n",
       " 'type/maintenance',\n",
       " 'type: bug',\n",
       " 'type: docs',\n",
       " 'type: enhancement',\n",
       " 'type: feature request',\n",
       " 'type: question',\n",
       " 'type:bug',\n",
       " 'type:feature',\n",
       " 'type:maintenance',\n",
       " 'type:question',\n",
       " 'up-for-grabs',\n",
       " 'upstream-azml',\n",
       " 'urgent',\n",
       " 'user raised',\n",
       " 'ux',\n",
       " 'waiting',\n",
       " 'waiting feedback',\n",
       " \"won't fix\",\n",
       " 'wontfix',\n",
       " 'work-item',\n",
       " 'workflow',\n",
       " 'working as intended',\n",
       " '✨ feat',\n",
       " '민지',\n",
       " '찬국',\n",
       " '🐛 bug fix',\n",
       " '🐞 bug',\n",
       " '🐥 experiment',\n",
       " '🐺 Tracker',\n",
       " '👨\\u200d👩\\u200d👧\\u200d👧 discussion',\n",
       " '💎 New Component',\n",
       " '📜 Paper',\n",
       " '🔤 named-entity-recognition',\n",
       " '🔥 New Feature',\n",
       " '🛂 checkpoint',\n",
       " '🦉 dvc',\n",
       " '🧪 testing'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = set()\n",
    "for _, row in valid_issues_all['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "valid_issues_filtered = []\n",
    "valid_fixes_filtered = []\n",
    "\n",
    "for index, row in valid_issues_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "    \n",
    "    break_sign = False\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for label_question in issue_labels:\n",
    "            if not break_sign and label_question in label_repo.lower():\n",
    "                valid_issues_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "for index, row in valid_fixes_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "       \n",
    "    break_sign = False\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for label_question in issue_labels:\n",
    "            if not break_sign and label_question in label_repo.lower():\n",
    "                valid_fixes_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "valid_issues_filtered = pd.concat(valid_issues_filtered, axis=1).T\n",
    "valid_fixes_filtered = pd.concat(valid_fixes_filtered, axis=1).T\n",
    "\n",
    "valid_issues_filtered.to_json(os.path.join(\n",
    "    path_github_issue_filtered, 'issues.json'), indent=4, orient='records')\n",
    "valid_fixes_filtered.to_json(os.path.join(\n",
    "    path_github_issue_filtered, 'fixes.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>69</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>105</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Issue  #Closed\n",
       "0         Amazon SageMaker      69       57\n",
       "1   Azure Machine Learning      36       19\n",
       "2                  ClearML       3        2\n",
       "3                    Comet      22       20\n",
       "4                      DVC      29       22\n",
       "5                    Kedro      18       14\n",
       "6                   MLflow     105       89\n",
       "7                  Neptune      12       10\n",
       "8                   SigOpt       4        3\n",
       "9                Vertex AI       5        4\n",
       "10        Weights & Biases      41       39"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_fixes = valid_fixes_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_fixes.rename(columns={'Issue_title': '#Closed'}, inplace=True)\n",
    "summary_github = summary_issues.merge(\n",
    "    summary_fixes, on='Tool', how='outer').fillna(0)\n",
    "summary_github = summary_github.astype({'#Issue': 'int32', '#Closed': 'int32'})\n",
    "summary_github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate Github and Gitlab issues\n",
    "df_issue_github = pd.read_json(os.path.join(path_github_issue_filtered, 'issues.json'))\n",
    "df_issue_gitlab = pd.read_json(os.path.join(path_gitlab_issue_filtered, 'issues.json'))\n",
    "\n",
    "df_issue_github['Platform'] = 'Github'\n",
    "df_issue_gitlab['Platform'] = 'Gitlab'\n",
    "\n",
    "df_issue_all = pd.concat([df_issue_github, df_issue_gitlab], ignore_index=True)\n",
    "df_issue_all.to_json(os.path.join(path_labeling_issue_native, 'issues.json'), indent=4, orient='records')\n",
    "\n",
    "df_issue_all['Issue_summary'] = ''\n",
    "df_issue_all.to_json(os.path.join(path_labeling_issue_gpt, 'issues.json'), indent=4, orient='records')\n",
    "\n",
    "# concatenate Github and Gitlab fixes\n",
    "df_fix_github = pd.read_json(os.path.join(path_github_issue_filtered, 'fixes.json'))\n",
    "df_fix_github['Platform'] = 'Github'\n",
    "df_fix_github['Fix_summary'] = ''\n",
    "df_fix_github.to_json(os.path.join(path_labeling_fix, 'fixes_prefill.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/autogluon/autogluon/issues/268\n",
      "https://github.com/awslabs/gluonts/issues/426\n",
      "https://github.com/kedro-org/kedro/issues/308\n",
      "https://github.com/zenml-io/zenml/issues/767\n",
      "https://github.com/microsoft/computervision-recipes/issues/332\n",
      "https://github.com/microsoft/computervision-recipes/issues/320\n",
      "https://github.com/microsoft/nni/issues/3518\n",
      "https://github.com/Lightning-AI/lightning/issues/9879\n",
      "https://github.com/databrickslabs/dbx/issues/548\n",
      "https://github.com/nv-morpheus/Morpheus/issues/512\n",
      "https://github.com/prinz-nussknacker/prinz/issues/78\n",
      "https://github.com/pycaret/pycaret/issues/2838\n",
      "https://github.com/pycaret/pycaret/issues/931\n",
      "https://github.com/microsoft/qlib/issues/1035\n",
      "https://github.com/graphnet-team/graphnet/issues/316\n"
     ]
    }
   ],
   "source": [
    "# manually preprocess the content of the issues and then save the results back to the json files\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue_gpt, 'issues.json'))\n",
    "for index, row in df_issues.iterrows():\n",
    "    if (len(str(row['Issue_body'])) > 10000):\n",
    "        print(row['Issue_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 345)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example No.1: feed the issue content (with code) to the text-davinci-003 model and get the summary, then feed the summary to topic model and get the topics\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue_gpt, 'issues.json'))\n",
    "df_issues_todo = df_issues[df_issues['Issue_summary'] == '']\n",
    "df_issues_done = df_issues[df_issues['Issue_summary'] != '']\n",
    "df_issues_todo.shape[0], df_issues_done.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_requests = []\n",
    "\n",
    "for index, row in df_issues_todo.iterrows():\n",
    "    print(f'working on issue {index}')\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model='text-davinci-003',\n",
    "            prompt='Use 1 to 2 sentences to summarize the following issue.\\nText: \"\"\"' + 'Title: ' +\n",
    "            row['Issue_title'].strip() + '; Content: ' +\n",
    "            str(row['Issue_body']).strip() + '\"\"\"\"\\n',\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        df_issues_todo.at[index,\n",
    "                          'Issue_summary'] = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        error_requests.append(index)\n",
    "    time.sleep(5)\n",
    "\n",
    "error_requests\n",
    "\n",
    "df_issues = pd.concat(\n",
    "    [df_issues_todo, df_issues_done], ignore_index=True)\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling_issue_gpt_code, 'issues_summary.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aim',\n",
       " 'amazon sagemaker',\n",
       " 'azureml',\n",
       " 'azure machine learning',\n",
       " 'clearml',\n",
       " 'cnvrg',\n",
       " 'codalab',\n",
       " 'comet',\n",
       " 'determined',\n",
       " 'domino',\n",
       " 'dvc',\n",
       " 'guild ai',\n",
       " 'kedro',\n",
       " 'mlflow',\n",
       " 'mlrun',\n",
       " 'modeldb',\n",
       " 'neptune',\n",
       " 'polyaxon',\n",
       " 'sacred',\n",
       " 'sigopt',\n",
       " 'valohai',\n",
       " 'vertex ai',\n",
       " 'wandb',\n",
       " 'weights & biases',\n",
       " 'weights and biases',\n",
       " 'sagemaker']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare tool-related keywords that would be removed from the issue content for better topic modeling \n",
    "tool_keyword_list = []\n",
    "for tool_keyword in tools_keywords.values():\n",
    "    tool_keyword_list.extend(tool_keyword)\n",
    "# handle special cases on amazon sagemaker\n",
    "tool_keyword_list.remove('sagemaker')\n",
    "tool_keyword_list.append('sagemaker')\n",
    "tool_keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the summary of the issues\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue_gpt_code, 'issues_summary.json'))\n",
    "df_issues['Issue_summary_preprocessed'] = ''\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    summary = row['Issue_summary'].lower()\n",
    "    for tool_keyword in tool_keyword_list:\n",
    "        if tool_keyword in summary:\n",
    "            summary = summary.replace(tool_keyword, 'tool')\n",
    "    df_issues.at[index, 'Issue_summary_preprocessed'] = summary\n",
    "df_issues.to_json(os.path.join(path_labeling_issue_gpt_code, 'issues_summary_preprocessed.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9c038955834407a3117ebe69fe9db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 09:23:41,506 - BERTopic - Transformed documents to Embeddings\n",
      "2023-02-11 09:23:44,682 - BERTopic - Reduced dimensionality\n",
      "2023-02-11 09:23:44,704 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>106</td>\n",
       "      <td>-1_logger_config_bug_yaml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0_toollogger_metrics_training_experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1_ui_configuration_does_artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2_bucket_tool_16_instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3_train_error_caused_callback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4_model_saving_loaded_dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>5_deployment_ml_sdk_yml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6_workspace_cloning_bug_instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7_run_failing_ui_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8_cluster_updated_github_pull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9_code_notebook_filenotfounderror_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10_library_installing_import_experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11_function_installed_issue_dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12_pipeline_py_contrib_pip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                      Name\n",
       "0      -1    106                 -1_logger_config_bug_yaml\n",
       "1       0     47  0_toollogger_metrics_training_experiment\n",
       "2       1     46          1_ui_configuration_does_artifact\n",
       "3       2     29                2_bucket_tool_16_instances\n",
       "4       3     27             3_train_error_caused_callback\n",
       "5       4     18             4_model_saving_loaded_dataset\n",
       "6       5     13                   5_deployment_ml_sdk_yml\n",
       "7       6     10          6_workspace_cloning_bug_instance\n",
       "8       7     10                      7_run_failing_ui_job\n",
       "9       8     10             8_cluster_updated_github_pull\n",
       "10      9      8   9_code_notebook_filenotfounderror_limit\n",
       "11     10      8  10_library_installing_import_experiments\n",
       "12     11      7     11_function_installed_issue_dashboard\n",
       "13     12      6                12_pipeline_py_contrib_pip"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "toollogger | metrics | training | experiment | tracking",
           47
          ],
          [
           1,
           "ui | configuration | does | artifact | yml",
           46
          ],
          [
           2,
           "bucket | tool | 16 | instances | artifacts",
           29
          ],
          [
           3,
           "train | error | caused | callback | created",
           27
          ],
          [
           4,
           "model | saving | loaded | dataset | old",
           18
          ],
          [
           5,
           "deployment | ml | sdk | yml | path",
           13
          ],
          [
           6,
           "workspace | cloning | bug | instance | swb",
           10
          ],
          [
           7,
           "run | failing | ui | job | pipeline",
           10
          ],
          [
           8,
           "cluster | updated | github | pull | 20",
           10
          ],
          [
           9,
           "code | notebook | filenotfounderror | limit | allowing",
           8
          ],
          [
           10,
           "library | installing | import | experiments | encountered",
           8
          ],
          [
           11,
           "function | installed | issue | dashboard | module",
           7
          ],
          [
           12,
           "pipeline | py | contrib | pip | versions",
           6
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>Words: %{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           47,
           46,
           29,
           27,
           18,
           13,
           10,
           10,
           10,
           8,
           8,
           7,
           6
          ],
          "sizemode": "area",
          "sizeref": 0.029375,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          4.944104194641113,
          10.33793830871582,
          5.93166971206665,
          4.366823673248291,
          4.040019512176514,
          10.17676830291748,
          7.228667259216309,
          8.093928337097168,
          6.237793922424316,
          10.753621101379395,
          7.4198503494262695,
          4.496528148651123,
          6.473517417907715
         ],
         "xaxis": "x",
         "y": [
          -0.6249459981918335,
          4.230438709259033,
          0.5543458461761475,
          -1.1876767873764038,
          -1.45359468460083,
          3.9308974742889404,
          1.657911777496338,
          0.016875101253390312,
          1.0665960311889648,
          4.424510955810547,
          0.8652621507644653,
          -0.3034206032752991,
          0.48891139030456543
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": 3.4340165853500366,
          "y": 1.7082768559455874,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 7.90034042596817,
          "xshift": 10,
          "y": 5.088187599182129
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 7.90034042596817,
          "x1": 7.90034042596817,
          "y0": -1.6716338872909546,
          "y1": 5.088187599182129
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": 3.4340165853500366,
          "x1": 12.366664266586303,
          "y0": 1.7082768559455874,
          "y1": 1.7082768559455874
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 7",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 8",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 9",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 10",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 11",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 12",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          3.4340165853500366,
          12.366664266586303
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -1.6716338872909546,
          5.088187599182129
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "tool logger is not logging with tpu_cores=8; a clear and concise description of the bug is needed, along with a boringmodel colab link, expected behavior, environment details, and any other relevant information.",
          "the prompt in the tool install process is not rendered as markdown, as seen in the github link provided.",
          "tool notebooks are raising an error when trying to use pandas.csvdataset, preventing the user from using it as a development environment.",
          "this bug report is about an error in tool test for xdeepfm, which can be replicated by running a unit test with pytest. the expected behavior is for the tests to pass successfully.",
          "a user encountered an issue when using the tool helm chart with servicemonitor and prometheus metrics, which was resolved by changing the `targetport: 80` to `port: http` in the deployed servicemonitor manifest. a proposed fix is to change `targetport: 80` to `port: http` in `templates/servicemonitor.yaml` to use the port name instead of port number.",
          "this article discusses an issue with tool, where an error is encountered when attempting to load the software. the cause of the error and potential solutions are discussed.\n\nthis article covers an issue with tool where an error is encountered when attempting to load the software, and provides potential solutions.",
          "the tool server was unable to start when using branch-22.11, but downgrading the tool version to <1.29.0 fixed the issue and an error message was displayed.",
          "there is an issue with the tool timeseries_beta branch where setting log_plot to true causes an error in self._tool_log_model().",
          "the user is trying to use tool.ml to track learning rate updates, but the plot is not what they expected, and they believe it may be related to an error.",
          "the bug is that the newly added staticprefix parameter under extraargs breaks the chart when used, and a pull request is being created to address this.",
          "the bug is that a tool pyfunc model cannot be loaded into bentoml 1.0, resulting in an attributeerror.",
          "this question is about how to save hydra config to tool config.yaml, which has changed recently. the post includes code snippets of the config before and after the change, and a link to a related file.",
          "translate is attempting to use tool despite it not being requested, resulting in an error about tool credentials.",
          "the bug report is about an error occurring when trying to access a bucket of processed data in the tool notebook, which does not exist.",
          "the problem is that an anonymous function is not registered when running a query with ml_predict() in the spark thrift server. steps to reproduce the issue are provided.",
          "the recent release of tool-inference v1.5.3 included a commit that changed the name of the model server artifact and command from `mxnet-model-server` to `multi-model-server`, causing the `entrypoint` with `serve` as a build arg to fail.",
          "running benchmark causes an error due to `.tool.lock` being in `.gitignore`, which can be solved by deleting the line. a better solution is being explored due to #168.",
          "the issue of failing to pull tool on windows when running the pull command on dagshub remote is a permanent issue, but is not urgent and is more of an annoyance.",
          "the user is unable to connect to a remote tool cluster with ssl enabled, and is receiving an sslerror. they are using macos 10.15.7 catalina, chrome 86.0.4240.198, and have followed the steps to reproduce the behavior.",
          "the tool callback changes the train step's unique id, but does not affect the results.",
          "when attempting to install the tool-core package on windows 10 with python 3.9.5, an error occurs during the installation of the ruamel.yaml package. the latest version of ruamel.yaml (0.17.10) can be installed without issue, so it is possible to use a later version.",
          "there is a lack of documentation regarding the `tool-defaults` package, which is necessary for deployment, and is believed to include `tool-core`.",
          "this bug report requests the removal of the contrib package from the tool-sdk and to check that all tests pass on dsvm and db platforms.",
          "tool failed to run benchmark.py due to a config that was too large, resulting in a httperror and a brokenpipeerror.",
          "users are getting an illegible error message when trying to connect to a tool notebook, and this issue can be resolved by providing a more descriptive error message.",
          "this bug report is about the helm fetch command for ai-engine, sdk-helper and tool, which includes the 22.09 release instead of the 22.11 release.",
          "it is not possible to combine zn.params and tool.params.",
          "models that override crossval_count with a value bigger than 1 will automatically train on tool, even if the user specifies --tool=false, which is confusing and unexpected. a repro example is provided, as well as a suggestion to flag base classes as not trainable.",
          "i got an importerror and an attributeerror when trying to use autogluon in a tool instance, and there were two errors in the second installation step.",
          "this issue is about fixing the docstring and testing with a node that has `tool.params` and `tool.outs` in the zntrack repository.",
          "a bug has been identified where all values except for lr are not updating, and it is thought to be caused by indexing list[0] without realizing it is a list that continues to add values.",
          "when running the command `dbx deploy --environment=default`, an error is returned stating that the experiment with the given id does not exist. this is occurring when trying to set up dbx for the first time on a mac os m1 2021 with macos monterey 12.5, using dbx version 0.6.11 and databricks runtime version 0.17.1.",
          "this bug report describes an issue with `tool deployment create ...` failing unexpectedly, and suggests deleting the tool pod and starting over as a fix. the bug occurs in a launchpad helm deployment on a30.",
          "experiments with tool can fail if the tool_tracking_uri container variable specifies an incorrect ip address, and it is important to handle this exception correctly.",
          "the toollogger creates a new run when resuming from an hpc checkpoint, which should not be the case as it should be reusing the run id. this issue can be patched into the hpc checkpoint using the logger, and can be reproduced by using toollogger on a slurm cluster.",
          "when using nn.dataparallel, the name of the model saved in tool.ml will be dataparallel, as expected in an environment with enchanter version 0.7.0, python version 3.6.6, and os ubuntu 18.04.",
          "an error occurred when running qrun qrun benchmarks\\gats\\workflow_config_gats_alpha158.yaml, resulting in an toolexception due to a parameter value exceeding the length limit of 500.",
          "this article provides instructions on how to configure a tool api key for github ci, with a link to a specific run.",
          "there is an issue with the tool_ml widget in version 2.0.9 where a jsondecodeerror is thrown when running the 01-introduction-to-node-classification-gremlin notebook and attempting to export. this does not occur in version 2.0.7.",
          "this bug report describes an error thrown when running a multi-label classification script, with the error message being \"connection aborted.\" and \"remote end closed connection without response\". additional context and steps to reproduce the behavior are provided.",
          "pip install \"sacremoses>=0.0.50\" breaks on tool studio, and the workaround is to install \"sacremoses==0.0.49\".",
          "the bug is a modulenotfounderror when trying to import from six.moves.collections_abc, and it can only be reproduced on a centos server.",
          "the `fds add` command was used to add the raw-data directory containing image files to tool tracking, but it failed to execute.",
          "an ancestor of the url 'https://tool.ai/' violates the content security policy directive \"frame-ancestors 'self'\", causing the url to be refused for framing. reproduction instructions and code sample are provided.",
          "the bug is that the tool jupyter notebook workspace in swb 5.2.6 version is unable to mount a study, and the fuse package failed to install during on-start. to fix the issue, the user should run \"sudo yum install fuse\" and then run the mount_sh.sh script.",
          "this article discusses an issue with logging models to tool on mac, which results in a permissionerror due to lack of permission to access '/var/lib/tool'.",
          "the tool api logger is warning users to switch from tool_ml.papi to tool_ml.api as the former is now deprecated.",
          "running the tool-pipeline \"dp\" via tool-cli results in an error due to an issue with the 'charmap' codec. steps to reproduce and code snippets are provided.",
          "the tool-sdk downgrades pyarrow to 3.0.0 which breaks cudf, causing an attributeerror when trying to import cudf.",
          "this question is about troubleshooting an issue with a double ensemble model in tool, which was solved by cloning the repo, installing via setup.py, and uninstalling/reinstalling numpy. the question also includes a yaml file with the configuration for the model.",
          "using log_gpu_memory with tool logger causes an error due to an invalid metric name, which can be reproduced using the boringmodel in the provided link.",
          "azure ml's mnist_pytorch example training is taking an unreasonably long time, with each trial taking 3-5 minutes and the entire experiment taking 50 minutes. attempts to speed up the process by adding gpunum and useactivegpu to the config file only made it slower.",
          "when using hydra and tool together, an error occurs due to the parameters passed to the lightningmodule being a `dictconfig`, which does not meet the condition in the `logger/base.py`.",
          "the user is having issues with hydra-optuna-sweeper and tool versions conflicting when running a hyperparametric search. the user has to change the syntax to the new version of hydra and pass certain parameters to the pytorch lighting wrapper when initializing the logger to avoid the error.",
          "when attempting to run a benchmark on tool with anubis, the request could not be executed. additionally, when running the sample for tool, the same error occurred. the author is asking if there is anything else that needs to be specified or changed when running with tool.",
          "there are errors in some of the tool tests, which can be replicated by creating a conda environment for pyspark and running unit test `test_sar_pyspark.py` with `pytest -m 'spark'`. the expected behavior is that the tests should pass successfully.",
          "the tool_catalyst.ipynb is failing and it appears to be missing the 'run' object. more information can be found at the provided github link.",
          "this bug report outlines the steps to connect tool with github actions, including creating a new tool workspace, creating two new clusters, adding the subscription id to github action secrets, installing azure cli, selecting the subscription, and creating a service principal.",
          "this bug report is about an issue with tool remote test reporting, where the pr commit status says \"failed\" but the codebuild log does not show any errors and abruptly terminates. the sm-cloudwatch log shows that the job ran for 2 hours and ended successfully.",
          "there is an error in the pipeline in githubactions which is causing tests to not pass due to a duplicate key value violating a unique constraint.",
          "the text is about a bug in tool ml notebooks where the genre for the movie \"toy story\" is incorrectly stated as \"comedy\" when it should be \"drama\".",
          "the use of `zn.method` without `zn.params` in a node will not add any parameters to the `tool.yaml` file.",
          "tool successfully logs default parameters set with hydra, but modified parameters are not logged when using hydra.",
          "when attempting to import the `numbertracker` from the `whylogs` package, an exception is thrown due to the lack of the optional tool dependency. however, the import works on the second attempt.",
          "this paragraph discusses an error encountered when deploying the tool ui, and suggests that the configuration parameters need to be reviewed.",
          "the bug is that when trying to view the results of a job after it has been completed, an error message is received. unmounting the data folder with fusermount -u data resolves the issue.",
          "enchanter v0.7.0 raises a tool warning when using the context api, advising to use log_asset_data(..., name=...) instead of log_asset_data(..., file_name=...).",
          "this error occurs when using a logger (tool or tool.ml) during multi-core tpu training, but not when using self.print or normal print. it is likely not a memory issue.",
          "the tool evaluation is crashing due to an issue with json serialization, which was introduced by #348. reproduction instructions are provided.",
          "this paragraph discusses the need to update the `icenet/model/train.py` file to make the tool.init entity either default to the user, icenet_tool_user, or be overridden by command line, and to do the same for the project.",
          "an issue was encountered when using amundsen metadata with tool database, resulting in a 500 internal server error. a pr has been created to solve the two identified problems.",
          "the issue is that the `.drone.yaml` is referencing a k8s secret that doesn't exist, and the solution is to change the name of the secret to `{{ .projectid }}-tool-secret`.",
          "calling the tool client's `stop_training_job` method against a job that is not \"inprogress\" causes the client to hang, and the request is rejected because the training job is in status stopped.",
          "the default value for projectoperator.tool.image.tag in chart release v0.13.2 is set to \"latest\" instead of \"v0.13.2\", as specified in values.yml.",
          "the tests/conftest.py file is trying to import tool, but it is not found, resulting in a modulenotfounderror.",
          "tool tests are not returning a signal when they fail, making it difficult to identify errors, and a signal needs to be sent back to github so that the badge is red and notifications are sent when tests fail.",
          "the tool ml widget is throwing an error when attempting to export data, instead of running to completion as expected.",
          "the author encountered an issue when attempting to run the benchmark_m4.py script on an aws gpu-instance \"ml.p2.xlarge\" using tool, resulting in a keyerror.",
          "this task involves creating separate graphs for each individual's performance and sub runs on tool, with each graph appended with the individual's population index.",
          "the example dag for tool needs to be updated to use a temporary access token instead of access key and secret key. additional context can be provided to help explain the problem.",
          "running the example workflow_by_code.ipynb resulted in an toolexception with the message \"invalid experiment id: '.ipynb_checkpoints'\".",
          "this bug report is about missing documentation on how to connect to tool from a macos device, and suggests that a host alias needs to be made in order to get things working properly.",
          "the tool studio lab team is working to restore the service due to an elevated fault rate in the start runtime api, however it has been more than 3 days and the issue is still present.",
          "this paragraph discusses the current implementation of the rename action and why it is invalid, and suggests using the tool rename command instead for consistency.",
          "an error occurred when trying to use the 'toollive' package in a checkpoints tutorial, but the issue was resolved by using a different code. system information is provided.",
          "the paragraph describes a trainingjob deployed to tool, which includes hyperparameters, input data config, output data config, resource config, and a stopping condition.",
          "an attributeerror is thrown when running a notebook, indicating that the 'workspace' object has no attribute 'get_tool_tracking_uri'.",
          "the pipeline tool-notebook-test-linux-cpu is failing due to an ssl error and a keyerror.",
          "the bug is that the new tool async operators are throwing errors with the user access key, secret, and session token, while the traditional operators work fine with the same credentials.",
          "this paragraph discusses the issue of running distributed training on aws tool with the accelerate feature, and the expected behavior of the inference not working properly.",
          "this article provides a solution to resolving tool bad requests with minio, illustrated with an image.",
          "tool deployment has failed when attempted from the user interface.",
          "this issue has been observed with a specific model, and it appears that sweeps may be corrupting subsequent runs if the runs are not cleared.",
          "when using the suggested vscode configuration for tool, a typeerror is thrown due to commandline arguments being `none` when running the pipeline directly through `run.py`.",
          "the issue is caused by a wrong dependency check, and the fix is to specify 'docker<5.0.0' in the conda environment.",
          "the user is trying to install glounts on a tool notebook instance from github, but is getting an error message. the user has already installed gluon-ts 0.5.2 with mxnet 1.6.",
          "this issue is about a broken link in the tool python documentation for the tool.core.scriptrunconfig class, and includes details such as the id, version, content source, and service and sub-service.",
          "apt-get is failing in tool-local-test builds due to an active process already using the dpkg frontend lock.",
          "tool api request 409 conflict was encountered when deploying a job with the latest dbx version, indicating that a file already exists and cannot be overwritten.",
          "pandas dataframes with array column values are not correctly persisted as tool datasets, as demonstrated by the example given in the text.",
          "the refactoring of logger imports changed the ordering of imports for the `toollogger`, causing users to manually add an unused import for `tool_ml` before importing `toollogger` to avoid an `importerror`. an example is provided to reproduce the error.",
          "this issue is related to missing permissions which is causing a notebook to be broken, and is of medium severity. it can be reproduced by running the script `bazel test //doc/source/tune/examples:tool_example`.",
          "tool is attempting to launch an updater using an asv script, but it is failing. a workaround is to set the ci or tool_test environment variable to make tool skip launching the updater.",
          "this bug report describes an issue where the graph tab does not render in tool studio when running a .path() query in jupyter lab, instead of the expected behavior.",
          "the user has cloned a repository and set up the ide workspace, but the tool view and plots dashboard do not load, and the experiments table says \"no experiments to display\".",
          "running a workflow with tool v1.27.0 works fine, but fails when using tool v1.28.0 due to a parameter value length limit of 500 which cannot be overwritten. this may be related to a recent tool feature.",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          4.544020175933838,
          7.103360652923584,
          6.069582462310791,
          5.68093204498291,
          8.387165069580078,
          6.383411884307861,
          7.38302755355835,
          2.8272318840026855,
          4.8005876541137695,
          7.7311201095581055,
          5.839473247528076,
          3.6234841346740723,
          6.984410762786865,
          6.86222505569458,
          5.787417411804199,
          5.659134864807129,
          7.077288627624512,
          8.147595405578613,
          7.604523658752441,
          4.36686372756958,
          7.342380523681641,
          7.335394382476807,
          7.021181106567383,
          6.898792266845703,
          6.2798614501953125,
          7.934856414794922,
          7.551057815551758,
          4.57811164855957,
          5.930977821350098,
          7.4458112716674805,
          4.691634654998779,
          6.4352803230285645,
          8.15596866607666,
          6.074831485748291,
          4.061700344085693,
          4.983936786651611,
          3.8114137649536133,
          8.15194320678711,
          6.428223609924316,
          5.212381839752197,
          7.260384559631348,
          6.70736026763916,
          7.675405979156494,
          6.059314727783203,
          8.388570785522461,
          3.718336343765259,
          3.5567266941070557,
          6.710350036621094,
          6.980930805206299,
          6.5208659172058105,
          4.665996074676514,
          5.421393871307373,
          3.601051092147827,
          3.7000842094421387,
          6.707535266876221,
          5.882369041442871,
          5.907512187957764,
          8.11523151397705,
          7.209806442260742,
          7.159754753112793,
          5.692187786102295,
          7.605354309082031,
          3.61114501953125,
          6.1110076904296875,
          6.4540300369262695,
          8.518105506896973,
          7.080801486968994,
          4.978156566619873,
          6.358084201812744,
          6.636241912841797,
          6.393495082855225,
          8.302679061889648,
          4.632095813751221,
          7.699132442474365,
          6.762965202331543,
          7.2151641845703125,
          6.394870758056641,
          5.870648384094238,
          4.189335346221924,
          8.085020065307617,
          5.802934646606445,
          7.990015029907227,
          8.000992774963379,
          5.332817554473877,
          5.971412181854248,
          4.952217102050781,
          8.096454620361328,
          7.076300144195557,
          7.901687145233154,
          5.384567737579346,
          6.18422794342041,
          6.739419937133789,
          4.578723430633545,
          6.75959587097168,
          7.754547595977783,
          7.533292293548584,
          6.985934257507324,
          6.965490818023682,
          6.658012390136719,
          5.7738938331604,
          3.6511740684509277,
          7.013952255249023,
          6.886246681213379,
          7.9874467849731445,
          7.797450542449951,
          3.807399034500122,
          6.314285755157471
         ],
         "y": [
          8.83424186706543,
          7.213788986206055,
          6.035885334014893,
          8.626690864562988,
          6.727502346038818,
          6.425217628479004,
          6.427444934844971,
          8.238844871520996,
          7.775145530700684,
          6.1379475593566895,
          8.481552124023438,
          9.211427688598633,
          5.60130500793457,
          6.667857646942139,
          8.867895126342773,
          6.373356819152832,
          6.539620399475098,
          6.974968910217285,
          6.066152572631836,
          7.668764591217041,
          7.9348907470703125,
          5.2690911293029785,
          7.102332592010498,
          7.761630058288574,
          6.4642462730407715,
          6.753546237945557,
          7.199750900268555,
          7.2683868408203125,
          9.19225788116455,
          7.274450778961182,
          6.90481424331665,
          6.288644313812256,
          6.756174087524414,
          6.924294948577881,
          7.16687536239624,
          6.060087203979492,
          7.323517799377441,
          7.246191024780273,
          7.068665981292725,
          7.755226135253906,
          6.578315734863281,
          7.855990886688232,
          7.897219657897949,
          6.558935642242432,
          6.231661796569824,
          8.538809776306152,
          8.134267807006836,
          7.242782115936279,
          7.787184715270996,
          8.019254684448242,
          8.850695610046387,
          8.852916717529297,
          9.242058753967285,
          9.283425331115723,
          7.496617794036865,
          8.776407241821289,
          6.611362934112549,
          7.473373889923096,
          6.336440563201904,
          6.437858581542969,
          8.0135498046875,
          7.14497184753418,
          9.211950302124023,
          7.921139240264893,
          6.414063930511475,
          6.373993396759033,
          4.382417678833008,
          9.140190124511719,
          6.831409931182861,
          8.14725399017334,
          6.535707473754883,
          7.348001956939697,
          7.923899173736572,
          6.107568264007568,
          7.855888366699219,
          6.373049259185791,
          6.8970441818237305,
          8.7667875289917,
          7.39113712310791,
          7.1064839363098145,
          6.5423760414123535,
          6.900016784667969,
          6.25084924697876,
          5.716389179229736,
          6.446505546569824,
          8.073505401611328,
          6.122454643249512,
          6.885655879974365,
          7.062947750091553,
          8.709638595581055,
          6.8777971267700195,
          6.398553848266602,
          6.897972106933594,
          7.397629737854004,
          8.192182540893555,
          7.492116928100586,
          6.083725452423096,
          6.285020351409912,
          6.3830342292785645,
          5.960245132446289,
          8.517521858215332,
          6.712826251983643,
          6.198644638061523,
          5.952561378479004,
          5.443586826324463,
          7.317071914672852,
          7.203052997589111
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "run 2236 in experiment \"master\" in radiomicsnn is not displaying memory utilization metrics correctly, as only metrics for 3 out of the 4 gpus are visible and the memallocated and memreserved metrics are all zero.",
          "a bug exists where toollogging is always disabled when training a farmreader model, preventing the user from logging training statistics and metrics. as a workaround, the user can manually set `toollogger.disable_logging = false` before calling the `train` method.",
          "this article discusses the fact that auxiliary values such as \"retriever/entropy\" are not logged when using the tool logging tool.",
          "this paragraph describes an issue with tool failing to log to a tracking server when running a training job, and provides the system info, tasks, and reproduction steps to help troubleshoot the issue.",
          "tool is a tool that only logs the top k validation losses, allowing users to focus on the most important metrics.\n\ntool is a tool that logs the top k validation losses, allowing users to focus on the most important metrics.",
          "toollogger with an api key and without a save directory results in an error due to the train loop trying to read the directory and failing. this can be fixed by setting the save directory to none.",
          "metrics are not logged to tool when testing a model that was previously trained using `trainer.fit`, which is unexpected behavior. a possible solution is to use the `existingexperiment` object from the tool sdk.",
          "profiling with tool without an tool writer configured fails silently, and whylogs should mention the missing tool writer in a warning. the expected correct behavior is for tool integration to write to tool by default and warn if missing or inconsistent config is set.",
          "an error was encountered when using tool with binder, resulting in a runtimeerror that the session was already closed and could not create more loggers.",
          "this suggestion proposes that the toollogger's `config` parameter should be more general in terms of config input, by allowing conversion to a dictionary to be done outside the logger.",
          "toollogger does not update its status to 'failed' when `pl.trainer.fit` fails, resulting in the tool tracking server screen showing that training is still in progress even though it has been terminated with an error.",
          "the tool callback prints an error when a training run is resumed instead of starting from scratch. it warns that the step must only increase in log calls.",
          "toollogger throws a jsondecodeerror when trying to get the experiment_id, which is unexpected behavior.",
          "this bug report discusses an unexpected argument error when using the toollogger with the argument run_name. a colab link is provided to reproduce the issue.",
          "richprogressbar does not display a progress bar when using tool logger, but works correctly with tensorboard and tool.",
          "trainer.fit fails with a pickle error when using toollogger, distributed_backend='ddp' on gpus without slurm. reproducing the error requires setting environment variables and running trainer.fit.",
          "the tool logger cannot be pickled after an experiment has been created, resulting in a typeerror when attempting to pickle the logger.",
          "when running a code from a colab notebook, tool views the entire thing as one training session and continues gradient steps indefinitely, resulting in more training steps than expected.",
          "experiment_gbdt can raise errors when using long parameters or tool, and two possible solutions are to catch and ignore all errors from tool or to truncate logging parameters automatically.",
          "explicitly creating a toollogger instance and passing it to trainer raises a notimplementederror because toollogger does not implement the name() and version() class methods.",
          "user is having trouble using tool as a logger and has tried different conda environments and versions of torch and pl, but has not been able to get it working.",
          "the code is not running on ddp mode with toollogger due to an attributeerror caused by an inability to pickle a local object.",
          "when using distributed data parallelism (ddp) with tool and multirun in test.py, only one run is logged instead of the expected three.",
          "this bug report describes an issue with toollogger not sending parameters longer than 250 characters to tool and log warning to user, and provides additional context about the problem.",
          "setting the tool experiment does not work in interactive mode, causing runs to be stored in the \"default\" experiment instead of the specified experiment in tool.yml. a potential solution is to use tool's set_experiment method.",
          "toolmetricsdataset ignores the specified run_id when no prefix is specified, resulting in the metric being logged in a new run instead.",
          "our current tool logging requires an api key, but we should configure it so it works without one when running locally.",
          "toollogger.log_metrics within steps behaves inconsistently with the documentation, raising errors when used in a lightningmodule. a minimum code example is provided to reproduce the bug.",
          "the tool logger is overriding the tool_experiment_key environment variable, even if it is already set, and deleting it later, which is causing an issue that will be fixed in a pull request.",
          "using the experiment id to convert an tool experiment fails, but using the experiment name works as expected.",
          "when using tool logger, log_param() function requires a run_id argument which is not present in the tool api, causing a typeerror. a code sample is provided to demonstrate the expected behavior.",
          "when activating the tool contrib, most of ludwig's log messages disappear, which is unexpected behavior. the issue is caused by ludwig using the root-level logger configured through `logging.basicconfig`.",
          "the linter checks for two functions, `subprocess.call` and `tool.log_artifact`, are inconsistent and causing the template create wfs to fail, which is not the expected behavior. a discussion is needed to determine why they fail and how to fix them.",
          "using the tool logger with a remote server introduces latency which slows the training loop, even when metrics are only logged per epoch. a potential fix is proposed to eliminate the overhead and make the tool logger as fast as the tensorboard logger.",
          "when using toollogger with the tool tracking uri hosted in databricks, logging to tool can fail due to updates, causing the entire training pipeline to fail with limited error handling options.",
          "this project will use tensorboard as the default logger, with the option to use tool (tool) as an alternative.",
          "the random agent script skips a few steps when logging full episode data with tool, and a potential solution is to add a metric to log the timestep and day.",
          "the bug is that to_tool is not sectioning by train/test and is overriding runs by checks when running a suite with duplicate checks.",
          "test set metrics are written to the same charts as validation metrics in tensorboard and are rejected for logging by tool (w&b), resulting in the deletion of validation metrics. a proposed solution is to write test metrics to their own charts.",
          "this bug report describes an exception that occurs when running a backtest with `aggregate_metrics=true` inside `toollogger`. the exception appears in `tslogger.log_backtest_metrics` while constructing `metrics_df`.",
          "this article discusses how to show lightgbm logs in tool logs, as they are currently printed in stdout but not visible in tool.",
          "tool logging does not distinguish between training and testing modes when logging metrics.",
          "when using tool, it shows steps instead of episodes, making it difficult to compare longer runs.",
          "tool allows users to write out dataset profiles as json format by calling tool.log_artifact directly and saving the profile json, however, if a format config is passed to tool writer specifying 'json', it is not supported.",
          "this article is about the tool logger, which is a tool for tracking and visualizing machine learning experiments.",
          "this bug report discusses an issue with tool where runs started in toollogger are never ended, resulting in all runs shown in the tool dashboard being nested recursively. tool 1.28.0 fixed the display of deeply nested runs correctly, so the bug is now problematic.",
          "the toollogger currently modifies logged metrics in-place, which can lead to confusing errors. a pr is proposed to fix this, and opinions are sought on whether to use `val.cpu().detach()` or `val.item()` for tensor conversion, and whether to update other loggers to accept `metrics: dict[str, union[float, torch.tensor]]`.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_toollogger_metrics_training",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_toollogger_metrics_training"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.77467155456543,
          4.519969463348389,
          3.479661464691162,
          4.644265174865723,
          4.801961898803711,
          3.5735023021698,
          4.4662556648254395,
          3.3381528854370117,
          3.461557149887085,
          3.4487972259521484,
          4.348575592041016,
          4.59749698638916,
          3.4021713733673096,
          3.687406063079834,
          3.9503085613250732,
          5.225980281829834,
          3.385310411453247,
          4.87054443359375,
          3.526109457015991,
          4.114716529846191,
          3.789433002471924,
          3.49656081199646,
          3.8985655307769775,
          3.640108108520508,
          3.3466956615448,
          4.291627407073975,
          3.3590285778045654,
          3.792010545730591,
          3.4310996532440186,
          3.402509927749634,
          3.558356523513794,
          3.417201519012451,
          3.2647864818573,
          4.949021339416504,
          4.0252461433410645,
          4.773815155029297,
          3.5792236328125,
          4.488367080688477,
          4.658208847045898,
          4.0810699462890625,
          3.773134708404541,
          4.276060104370117,
          3.9053192138671875,
          3.2378954887390137,
          4.9155144691467285,
          3.9448347091674805,
          4.736123561859131,
          3.992537260055542
         ],
         "y": [
          8.891671180725098,
          8.241584777832031,
          7.9697723388671875,
          7.978515148162842,
          8.147979736328125,
          8.179059028625488,
          8.288627624511719,
          7.8762335777282715,
          8.130209922790527,
          8.048869132995605,
          8.145336151123047,
          7.984932899475098,
          7.60361385345459,
          8.154415130615234,
          8.016679763793945,
          9.208200454711914,
          8.176117897033691,
          8.816875457763672,
          7.575544357299805,
          8.202649116516113,
          8.530482292175293,
          8.078567504882812,
          7.707818508148193,
          7.803677558898926,
          7.4182586669921875,
          7.773245334625244,
          7.987300872802734,
          8.377422332763672,
          7.74237585067749,
          7.54290246963501,
          8.2166109085083,
          7.9873270988464355,
          8.26255989074707,
          8.561116218566895,
          8.084732055664062,
          8.480775833129883,
          7.46508264541626,
          7.194238185882568,
          8.43423080444336,
          8.229535102844238,
          8.589229583740234,
          8.191314697265625,
          7.285065174102783,
          7.820385456085205,
          8.281620025634766,
          6.968571186065674,
          8.709973335266113,
          8.071516036987305
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the user is unable to initialize a tool project using the `tool-tool` functionality, as the `tool tool` cli commands are not available. the bug is present in the latest version of tool and tool-tool.",
          "when using fds clone for non-tool repos, it throws an error. this use case can be handled by checking if the repo contains tool files and then either initializing tool or setting the remote url, name, username, and password.",
          "the tool tool cli is broken if configuration is declared in pyproject.toml, causing the \"init\" command to not be available. the error is caused by the \"is_tool_project\" function not considering a folder to be the root of a tool project if it does not contain a \".tool.yml\" file.",
          "the right way to delete a file that has been previously added to tool is to use the tool remove command, which removes the file pointer and is already available in the wrapper.",
          "the post-gen hook should not configure a tool remote if no name is provided, as this will raise a non-fatal error.",
          "toolfilesystem.ls is not working properly when dealing with nested directories, as seen in the example provided in the link.",
          "the `tool tool ui` command does not use the options specified in `tool.yml`, and the expected result of the ui opening on port 5001 does not occur. the bug is present in both the current version and the last version on master.",
          "this paragraph outlines the steps necessary to create a tool instance for each project and make the experiments visible to all users.",
          "when running \"tool tool init --env=xxx\", a wrong success message is displayed if the env \"xxx\" folder does not exist, instead of an error message.",
          "tool telemetry installed alongside a packaged and installed tool project breaks the project by incorrectly assuming the existence of the `pyproject.toml` file. this issue was introduced with a pull request on github.",
          "it is not possible to store a partitioneddataset as an tool artifact with the toolartifactdataset, and an error is raised when attempting to do so. a potential solution is suggested in the text.",
          "this plugin is only compatible with tool-tool versions lower than 0.8.0, as the `context` package has been moved or refactored.",
          "the user is having trouble opening their project on tool and has tried various solutions to no avail. they have included a screenshot to help explain the issue.",
          "the user is unable to initialize a tool project using the `tool-tool` functionality, as the `tool tool` cli commands are not available. the bug is present in the latest version of tool and tool-tool.",
          "the bug is that if the tool/config file is created with whitespaces, tool-cc cannot read the config file. this occurs with tool version 0.87.0, faice version 9.1.0, and tool-cc version 0.8.66.",
          "tool and git services have difficulty detecting the repository root directory, which affects their ability to automatically initialize the user. resources are provided to help with this issue.",
          "the user is following a tutorial to get introduced to tool tool, but when they run the command \"tool tool ui\" they get a filenotfounderror.",
          "this commit changes the tool add prompt so that it will only display if there is something to add, rather than always displaying it even when the list of files is empty.",
          "when running \"tool tool init --env=xxx\", a wrong success message is displayed if the env \"xxx\" folder does not exist, instead of an error message.",
          "this paragraph explains how to remove binary files from the repo's history using the open-source tool `bfg`, and suggests deleting local clones and cloning a fresh, cleaned version from upstream once all local changes have been committed.",
          "this change to get_tool_config may cause unexpected results when used in interactive mode outside of the tool project root.",
          "the tool-tool plugin does not work with projects created with tool==0.18.1, and the solution is to use the \"after_context_created\" hook to retrieve and set up the configuration.",
          "the tool guide's quicklaunch link is pointing to the full launcher instead of the minimal launcher, which is not the expected behavior.",
          "there is an issue with running \"tool ui\" which results in a \"filenotfounderror\" and the expected behavior is that it should run without any issues.",
          "in the example job, the output of the artifact upload was overwritten by the tool process running in a separate process, resulting in one line being missing.",
          "tool's default artifact folder does not replace the environment variable `$artifacts_bucket`, which can lead to unexpected results.",
          "when using toolartifactdataset with toolmodelsaverdataset, an error occurs due to an unsupported operand type for '/' between two strings. this bug is present in tool 0.16.6, tool-tool 0.4.0, python 3.7.7, and macos catalina.",
          "a warning message appears when calling ``tool tool init``, but it can be safely ignored as the command works as intended. this is due to a bug with the dynamic creation of the command.",
          "users can access any tool project, but access is restricted to project members only.",
          "the tool.yml file is not parsed properly when using templatedconfigloader, as global variables are not replaced by their values. this issue will be fixed by #66.",
          "when a pull request is opened, the chart-testing (lint) step in the release.yaml file returns an error validating the maintainer name, which must be a github username rather than a real name.",
          "a warning message appears when calling ``tool tool init``, but it can be safely ignored as the command works as intended. this is due to a bug with the dynamic creation of the command.",
          "specifying an artifact path and a run_id in an toolartifactdataset will result in an error, as demonstrated by the code examples given.",
          "the user is asking how to reimage their tool studio lab instance to get the space back after trying to build a conda environment and running out of space.",
          "running tool projects from remote sources since version 1.28 causes a \"tool: not found\" error when starting the project, which can be reproduced by running testtoolprojects.test_tool_gitproject_remote_https. this issue should be resolved as it was previously supported.",
          "the bug encountered by @ucsky is that running \"make one-click-tool\" is not working after \"make destroy\" due to an existing artifacts' bucket. reproducing the behavior requires running the two commands and then seeing the error. the expected behavior is that the second command should work.",
          "the tool-tool plugin does not work with projects created with tool==0.18.1, and the solution is to use the \"after_context_created\" hook to retrieve and set up the configuration.",
          "the user is following a tutorial to get introduced to tool tool, but when they run the command \"tool tool ui\" they get a filenotfounderror.",
          "this plugin is only compatible with tool-tool versions lower than 0.8.0, as the `context` package has been moved or refactored.",
          "this post explains how to get root access in tool studio lab, including running the 'whoami' command to check if the user is root, attempting to install sudo, and asking for help to install libraries that require root access.",
          "the experience of using tool is broken since it changes the `.gitignore` file, making it difficult to switch between branches.",
          "the tool tool cli is broken if configuration is declared in pyproject.toml, causing the \"init\" command to not be available. the error is caused by the \"is_tool_project\" function not considering a folder to be the root of a tool project if it does not contain a \".tool.yml\" file.",
          "the `tool tool ui` command does not use the options specified in `tool.yml`, and the expected result of the ui opening on port 5001 does not occur. the bug is present in both the current version and the last version on master.",
          "this issue is about making the 'tool tool init' command compatible with the new 'pyproject.toml' configuration file, which is only available in tool versions 0.16.5 and above.",
          "the author is wondering if they can initialize a tool studio lab.",
          "when using \"tool-cc init\", you can specify the folder where the tool files will be stored on the tool storage server, with the default being the username followed by the first three letters of the repo name.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_ui_configuration_does",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_ui_configuration_does"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.219181537628174,
          7.545842170715332,
          7.904961109161377,
          6.450789928436279,
          7.1673808097839355,
          6.288930416107178,
          7.552977561950684,
          6.5705647468566895,
          7.2002272605896,
          7.930678844451904,
          6.040240287780762,
          7.263385772705078,
          7.0573296546936035,
          7.2781524658203125,
          7.500001907348633,
          7.373587608337402,
          6.725637435913086,
          6.698012351989746,
          7.198228359222412,
          7.225070953369141,
          7.526623249053955,
          7.301558494567871,
          7.63275146484375,
          6.704833984375,
          6.220495700836182,
          6.31826114654541,
          5.989687442779541,
          7.152125358581543,
          7.140438079833984,
          7.705834865570068,
          7.469024181365967,
          7.165700435638428,
          6.08563756942749,
          6.558323860168457,
          7.432540416717529,
          6.48951530456543,
          7.2064104080200195,
          6.736090660095215,
          7.21889591217041,
          7.181725025177002,
          7.2241082191467285,
          7.756176948547363,
          7.537325859069824,
          7.906015872955322,
          6.58249568939209,
          7.319926738739014,
          7.081601142883301
         ],
         "y": [
          4.772449493408203,
          5.614694595336914,
          4.811607360839844,
          4.814775466918945,
          4.307003974914551,
          5.117739200592041,
          4.688735008239746,
          5.600677967071533,
          4.225708961486816,
          4.912954330444336,
          5.530391216278076,
          4.777441501617432,
          4.995314598083496,
          4.8050312995910645,
          4.733428001403809,
          5.612626075744629,
          4.526240825653076,
          4.513507843017578,
          4.245173931121826,
          5.845757007598877,
          4.703663349151611,
          4.885852336883545,
          4.666277885437012,
          4.536070823669434,
          5.373593807220459,
          5.227973461151123,
          5.474172115325928,
          4.3060302734375,
          4.941888809204102,
          4.96726655960083,
          6.206593036651611,
          4.3006463050842285,
          5.46240758895874,
          5.618070602416992,
          5.4917426109313965,
          4.910328388214111,
          4.800991535186768,
          4.5839338302612305,
          4.886115550994873,
          4.93000602722168,
          5.898318290710449,
          4.849776268005371,
          4.705718517303467,
          4.913303375244141,
          5.611415386199951,
          5.159326076507568,
          4.997016429901123
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "code in the kubeflow pipelines sdk does not handle the tool training job status 'stopped', causing an infinite loop. this issue should be addressed to cater for the 'stopped' status.",
          "a bug was found in the tool autostop script, causing instances to hang around for days. the script was updated in the last 16 hours to remove the syntax error, and the expected behavior is for the autostop script in the s3 bucket to be used for swb tool instances.",
          "a tool user reported that cloud formation for tool fails on a p3.2 and p3.16 yet succeeds on a g4dn, and the expected behavior of launching is not happening as the formation template stalls out and auto-deletes.",
          "the author is trying to use aws built-in algorithms in tool studio lab, but is getting an error when running their code. they are asking if it is possible to link access aws resources in studiolab.",
          "the bug is related to the lack of an aws credentials file in the `~/.aws` folder, which is generated by the `mount_s3.sh` script, preventing the study folders from being mounted when a tool notebook is launched. versions 5.0.0 & 4.3.1 are affected.",
          "the problem arises when using boto3 to manually download an object from s3, resulting in an error of \"unable to locate credentials\". the credentials were found in environment variables, but somehow they never made their way to the boto3 client.",
          "this bug report discusses an issue with the scikit learn model in the kubeflow_pipelines/pipelines directory, where it cannot handle json from web api. the solution is to rewrite the feature definition part of the train.py file and 8 other files should be updated.",
          "an error occurred while building tool types due to missing types in common/manual_deepcopy, which was caused by the import of tool types in go client. the environment used was kubernetes v1.1.0.",
          "@jweiss-ocurate is trying to use tool-airflow with astrocloud, but is experiencing a failure in the local airflow image. the environment includes tool-airflow plugin version 0.4.1, airflow version, tool version 0.17.7, python version > 2.0.0, and ubuntu linux 20.04.",
          "the bug is that checks for tool clusters in aws cn regions are misidentifying endpoints, resulting in required config options not being set correctly. these checks need to be changed to \"amazonaws.com\".",
          "this paragraph discusses an issue with tool namespaces causing issues in kfp artifacts, and suggests disabling the function to create kfp artifacts in the `kubeflow.yaml` config to avoid errors.",
          "a user is getting a typeerror when trying to update an endpoint using the re-usable tool components for building kubeflow pipelines, and is asking for help.",
          "the issue is that `toolbulkloaderapi` constructs an incorrect iam role arn for aws other than global, causing an error when trying to upload csv data from s3. there are two solutions to fix this: adding partition into current code or adding an option of passing iam role arn directly.",
          "tool operator types fail kubebuilder pattern validation check when included as part of kubebuilder v2 custom crd definition due to unescaped regex patterns.",
          "an error is appearing while running a kubeflow pipeline with aws tool, due to missing values for the required hyperparameters 'k' and 'feature_dim'.",
          "an older tool instance was turned on and one of the two study folders associated with it was not syncing any of the files, resulting in a \"permission denied\" error. comparing the s3mounts parameter for the tool stack of the older instance that fails to sync and a newer instance, the fs role number for the private workspace study that wouldn't sync is different.",
          "the tool bucket name is hardcoded, making it impossible to use tool with aws s3. this is the first issue to be addressed.",
          "when running the tool studio tour for the first time in a new aws account, a resourcelimitexceeded error is encountered when creating an endpoint to host the model due to the default service limit of 0 instances for ml.m4.xlarge. suggestions are to either address this proactively in the prerequisites section or to change the notebook to use an instance type with a higher default service limit.",
          "there was an error related to numpy in the lambda of \"createmodel\" when running the pipeline from scratch, which was solved by modifying the code and using the default aws library that comes with numpy. the version of the solution can be found in the description of the created cloudformation stack.",
          "this issue is about a prediction error when running a demo on a mac m1 pro with node.js v16.16.0, npm 8.11.0, and `@google-cloud/aiplatform` version ^2.3.0, which pauses and shows `4 deadline_exceeded: deadline exceeded` in the line `await predictionserviceclient.predict(request);`.",
          "a bug was found when trying to upgrade tool from an old version to a new one, where the db migration job should have run before the tool pod upgrade, but it was not. running the job manually with kubectl fixed the issue.",
          "this error message indicates that the \"trainingjob\" version \"tool.aws.amazon.com/v1\" is not registered in the \"k8s.io/kubectl/pkg/scheme/scheme.go:28\" scheme.",
          "when running a query on the `aws_tool_notebook_instance` table, an error was encountered. the steampipe version used was v0.4.1 and the aws plugin version was v0.15.0.",
          "zenml is trying to create a s3 bucket but fails due to an incorrect regex in its name, resulting in a valueerror.",
          "the modeluploadop from \"tool pipelines: model upload using google-cloud-pipeline-components\" does not work as intended, and an alternative method is provided. the issue is reproducible with the specified versions of kfp and google cloud tool.",
          "the steps taken were to remove the hpo and training jobs from tool, resulting in output being properly displayed in kubeflow. the expectation is to be able to see custom model output without hpo and batch job in tool.",
          "attempting to install aws stepfunctions in a tool studio notebook using the python3 (data science) kernel failed, resulting in an attributeerror.",
          "the `tool pull` command requires authentication credentials, so readers cannot access the remote storage. to make the bucket publicly accessible, it needs to be set to read-only.",
          "a user has installed the helm chart with some changed settings and is running a simple training example from the tool docs, but the artifacts are not being saved in the remote s3 artifact store.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_bucket_tool_16",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_bucket_tool_16"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.658902168273926,
          9.128817558288574,
          8.95407772064209,
          9.291984558105469,
          9.154890060424805,
          9.08397388458252,
          9.534388542175293,
          9.69295883178711,
          9.316317558288574,
          9.199714660644531,
          9.676985740661621,
          9.608152389526367,
          9.189787864685059,
          9.663926124572754,
          9.522563934326172,
          9.138063430786133,
          9.173694610595703,
          9.100018501281738,
          9.370853424072266,
          9.279252052307129,
          9.681337356567383,
          9.496658325195312,
          9.383307456970215,
          9.178751945495605,
          9.624459266662598,
          9.658334732055664,
          9.201214790344238,
          9.081701278686523,
          9.005669593811035,
          9.346578598022461
         ],
         "y": [
          8.040775299072266,
          6.630557060241699,
          7.165192604064941,
          7.037841320037842,
          6.778557777404785,
          6.628609657287598,
          7.8991923332214355,
          8.02749252319336,
          7.326106548309326,
          7.160382270812988,
          8.011299133300781,
          8.028182029724121,
          6.698588848114014,
          8.028353691101074,
          7.816488265991211,
          6.655882835388184,
          6.767956256866455,
          7.242308616638184,
          7.640590667724609,
          7.595586776733398,
          8.028436660766602,
          7.788584232330322,
          7.340689182281494,
          6.63110876083374,
          7.928793907165527,
          8.002832412719727,
          7.151973247528076,
          6.713487148284912,
          6.665252208709717,
          7.359692573547363
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the error occurs when creating a trainer with tool-ml callback enabled, despite tool-ml being installed. the expected behavior is for the trainer to be successfully created with toolml callback enabled.",
          "the trainingpipeline needs to be updated to support the new `tool.tensorflow.serving.model` from the tensorflow package. see the related thread for more information.",
          "i'm using tool as a logger with pytorch-lightning 0.8.5, but the checkpoints are being saved in the wrong location. it may be an issue with tool rather than pytorch-lightning.",
          "a warning was printed after every epoch when training tool-pytorch 2.0.0, indicating an unexpected error during autologging.",
          "this bug report describes an unexpected error while saving a file in d2l-pytorch-tool-studio-lab/dash/untitled.ipynb, which was caused by deleting some unwanted notebooks from the studio lab's files.",
          "when attempting to train autogluon 0.4.0 textpredictor on a p3.8xl 4-gpu instance in tool notebook terminal, an error is thrown when spawning multiprocessing, preventing the training from running across all 4 gpus.",
          "this bug report describes an error when attempting to create a tool logger when using pytorch lightning cli. the error is caused by an unexpected keyword argument 'agg_key_funcs' in the `self._kwargs` variable.",
          "this post is a follow-up to a related post about an led model returning an algorithmerror when using tool smp training. the user has tried several fixes, including matching the python, transformers, and pytorch versions, but is still facing issues and has received a new error.",
          "upgrading from pytorch-lightning 1.2.4 to 1.3.1 causes multiple tool experiments to be created when running a ddp multi-gpu experiment on a slurm cluster, with only one of them logging metrics.",
          "the tool api is outdated in the transformers trainer.py, causing the old api to not work, and a warning to be displayed. @sgugger can help to enable tool hpo in the example and run it correctly.",
          "when training text classification models using xlnet-large-cased, albert-base-v2, xlnet-base-cased and tool enabled, an error was encountered due to incompatible view size and input tensor's size and stride.",
          "running train_model from examples after install yields an error due to a missing \"tool\" directory, which can be fixed by creating the folder. it is suggested that this folder be automatically created if it is not present.",
          "toollogger throws an error when imported if pytorch is not installed, even though it should work regardless of pytorch installation.",
          "this bug report discusses the lack of supplementary info about a run when using toollogger as a logger in pytorch_lightning, and suggests that the tags should be added internally to provide a seamless experience.",
          "the paragraph discusses an issue with pytorch images where prints in stderr are not catched and are ignored, and provides logs to demonstrate the problem.",
          "the training loss is not reported in tool until the end of the run, but the validation loss is updated each epoch. this may be an issue with tool rather than pytorch-lightning.",
          "the issue is that the dataset file name was changed from training to train, which caused the data to not be loaded properly. the solution is to go to the data loading part and change the file name to train.tsv.",
          "pytorch lightning 1.2.0 requires a new version of tool, so users should be aware of this before updating.",
          "the user followed instructions to run the nvidia image for tool, but when running the command to start training, no tensorflow was reported and an error was thrown.",
          "the load_dataset function from hugging face is unable to access the tool tracked data directory, resulting in an oserror.",
          "the user is trying to train an led model using huggingface estimator and tool smp, but is receiving an algorithmerror. they expect to be able to successfully train the model with their training data.",
          "the user is unable to train yolov5 on windows 11 and has searched the issues and discussions but found no similar questions. they have tested many datasets but still get the same error.",
          "an error occurred when training on tool using huggingface, which was caused by an undefined value has_torch_function_variadic.",
          "commit https://github.com/pytorchlightning/pytorch-lightning/commit/ddbf7de6dc97924de07331f1575ee0b37cb7f7aa has broken the functionality of publishing test metrics to tool.ml in pytorch lightning 0.7.2.",
          "in order to fix an error when using \"tool.pytorch.pytorch\", \"framework_version\" and \"py_version\" must be specified, or alternatively \"image_uri\" can be specified.",
          "the bug is related to trying to integrate tool with a bentoml workflow, resulting in an error when running `bentoml containerize tool_pytorch_mnist_demo:latest`. the environment is bentoml version 1.0.7 and python version 3.9.12.",
          "this bug report is about the unusually long runtime of a sasrec integration test on tool compute cluster, which is much longer than when run as part of an ado pipeline. the machines used are of the same type and have the same cuda and cudnn versions. to replicate the issue, the github workflow should be triggered manually and the pytest logs should be checked.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_train_error_caused",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_train_error_caused"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.652134418487549,
          5.549880027770996,
          4.451042175292969,
          5.140631675720215,
          5.084981918334961,
          5.746828556060791,
          4.4778032302856445,
          5.254065990447998,
          4.5574469566345215,
          5.551234722137451,
          5.565449237823486,
          5.7025885581970215,
          4.86647367477417,
          4.509581565856934,
          4.965519428253174,
          4.523603916168213,
          5.630194187164307,
          4.7131667137146,
          5.402774333953857,
          5.347263813018799,
          5.355403900146484,
          5.67126989364624,
          5.378448009490967,
          4.5476531982421875,
          5.0687575340271,
          5.382411003112793,
          5.73560094833374,
          5.178970813751221
         ],
         "y": [
          9.941410064697266,
          9.986520767211914,
          9.396255493164062,
          9.565166473388672,
          9.582913398742676,
          9.31563663482666,
          9.450247764587402,
          9.632099151611328,
          9.406329154968262,
          9.888839721679688,
          9.96146011352539,
          9.975858688354492,
          9.462641716003418,
          9.398489952087402,
          9.392882347106934,
          9.451153755187988,
          9.985797882080078,
          9.533967018127441,
          9.802984237670898,
          9.720417976379395,
          9.695952415466309,
          9.947196006774902,
          9.738849639892578,
          9.372995376586914,
          9.544044494628906,
          9.339094161987305,
          8.802614212036133,
          9.603401184082031
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "we should check if a valid tool model is served at the url before creating or linking the model in a byom tool predictor.",
          "the user is having an issue with the tool ui not showing any models, despite several models having already converged and logged to the file system. they have tried both the nightly and the release branch, but have not been able to resolve the issue.",
          "a toolpipelinemodel cannot be loaded from tool if its catalog contains non deepcopy-able datasets, which is due to an error raised when saving the model with a dataset containing an object which cannot be deepcopied.",
          "the tool endpoint appears unable to find / open the model file when attempting to deploy a multi-modal model using the petfinder dataset, resulting in a modelerror. the full traceback is provided.",
          "tool was stuck in an infinite loop due to a mistake in the model's location, but the issue was resolved by adding logging to make it more verbose.",
          "the toolpipelinemodel has an unnecessary `initial_catalog` property which causes problems when trying to load a model, as it requires the old tool catalog with the old plugin version. it would be beneficial to log only what is necessary in tool to avoid having to retrain models.",
          "the user is receiving an error when attempting to save a plot through tool, indicating that the keyword argument 'system' is unexpected.",
          "tool is having issues saving model artifacts and some plots, resulting in an error message. additionally, a valueerror is being thrown when using all scalar values.",
          "loading configs from tool yields incorrect parameters, which can be seen when attempting to load the model checkpoint or when comparing the object with the info panel for the run on tool. the bug has been understood and fixed, allowing the same config to be loaded and be correct.",
          "an error occurred when attempting to create a model in toolcatalog, resulting in an org.tool.tracking.toolhttpexception.",
          "this bug report is about an error when invoking a mme on tool setup using a specific container image, resulting in the model not loading and returning a prediction. the checklist has been completed and additional context is provided.",
          "when trying to download a registered model from the amls workspace, an toolexception is thrown due to a filenotfounderror. the file is created, but no data is transferred into it.",
          "child models need to copy the dict.*.txt files from the parent model when launching an experiment on tool in order to successfully preprocess; otherwise, preprocessing will fail.",
          "this bug report describes an issue with the writing of checkpoints to tool, and how to reproduce it. it also outlines the expected behavior and provides additional context.",
          "i am having an issue saving an xgboost run in tool server, which results in an \"unfinished\" status with no metrics or artifacts created. an error message of \"invalid_parameter_value\" is displayed when using tool server with sqlite as the backend store.",
          "the `publish_model_to_tool.py` script is overly particular with inputs, and if the value given for the `--model_directory` argument has a trailing `/`, the script will fail. removing the trailing `/` should provide the same outcome.",
          "the tool index name was modified to \"modelname + save_folder_name\" to fix the create index name error.",
          "a toolpipelinemodel cannot be loaded from tool if its catalog contains non deepcopy-able datasets, which is due to an error raised when saving the model with a dataset containing an object which cannot be deepcopied.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_model_saving_loaded",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_model_saving_loaded"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.200018405914307,
          5.109828948974609,
          5.0121259689331055,
          5.377823829650879,
          5.04962682723999,
          4.9212493896484375,
          4.82373046875,
          4.941936016082764,
          5.1988911628723145,
          5.100794792175293,
          5.491604804992676,
          5.132944107055664,
          5.081315040588379,
          4.985773086547852,
          4.9257025718688965,
          5.185359954833984,
          5.175472736358643,
          5.058048725128174,
          5.098458766937256
         ],
         "y": [
          6.3387250900268555,
          6.2372541427612305,
          6.348255634307861,
          6.117980003356934,
          6.218428134918213,
          6.58216667175293,
          6.033287048339844,
          6.135589122772217,
          6.531148910522461,
          6.131224155426025,
          6.3114705085754395,
          6.198668479919434,
          6.269094944000244,
          6.737255573272705,
          5.88277006149292,
          5.941014766693115,
          5.952877521514893,
          6.312089443206787,
          6.237739086151123
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the azure ml extension prompts the user to login twice when vs code (insiders) is reloaded, even if the user clicks \"cancel\" the first time.",
          "this error appears to be related to the deployment of azure container instances (aci) and azure kubernetes service (aks) resources, and the service is currently in an unhealthy state.",
          "when registering a dataset in the catalog.yml and running `tool run`, an error occurs when the local path is linux and the `tool_tracking_uri` is an azure blob storage. this issue can be fixed by replacing `self._filepath` with `self._filepath.as_posix()` in two locations.",
          "an exception is thrown when importing the tool.core module after installing the azure ml using a conda environment yml. azure ml sdk version: 1.31.0.",
          "an error is occurring when trying to call the azure computer vision ocr api from an tool notebook, but the same code works when running it on a local machine.",
          "a regression was introduced in a2ml which caused tool.core.authentication to be loaded when it was not needed, resulting in a modulenotfounderror. to fix this, the import statement should be lazy-imported and the unnecessary statement should be removed.",
          "this question is about connecting to vscode to tool, and an error occurred with the action \"azureaccount.onsessionschanged\" and an error type of 123. the version, os, os release, product, product version, and language are also provided.",
          "the endpoint failed to deploy due to a conflict between the deployment code and model training code parameters. additionally, the backend worker process had died.",
          "running any command with tool prints out a warning message about failure while loading tool_run_type_providers, which should not happen. reproducing the issue requires running `make build install`, `cd /path/to/azure/a2ml-project` and `a2ml experiment leaderboard` on macos 10.15 with a2ml version master branch rev 6fe45a4619e0fc80efde5c84015afbfb91b54d34 and python version 3.7.7.",
          "this notebook contains a reference to an unsupported azure ml sdk preview private index, which should be removed as the sdk is now available through regular pypi.",
          "the tool-example batch endpoint nyc-taxi-tool-deployment.yml file refers to a folder that doesn't exist, causing the code to fail, and it looks like the folder needs to be re-added.",
          "the yaml file in the example for deploying an tool model using the azure cli is out of date and fails when using the command `az create deployment`.",
          "the user is experiencing an unknown error when signing in to azure using the azure account extension, with an error type of 123. the os is windows 10.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_deployment_ml_sdk",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_deployment_ml_sdk"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.23060131072998,
          8.460808753967285,
          7.8671345710754395,
          7.94372034072876,
          8.0995512008667,
          7.772704124450684,
          8.23863697052002,
          8.56162166595459,
          8.003762245178223,
          8.014066696166992,
          8.350095748901367,
          8.098286628723145,
          8.230134010314941,
          8.143933296203613
         ],
         "y": [
          8.17927360534668,
          7.869892120361328,
          7.9575653076171875,
          8.056598663330078,
          8.133378028869629,
          7.801540374755859,
          8.098745346069336,
          7.620908737182617,
          7.937640190124512,
          8.116796493530273,
          7.599368095397949,
          7.800655841827393,
          8.166282653808594,
          7.949126720428467
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "this bug report describes an issue where idle tool notebook instances do not stop after the specified time, despite the autostop.py script being used by the instance cfn template. reproduction steps and additional context are provided.",
          "users are experiencing an intermittent issue where a blank browser launches instead of tool when connecting to tool workspaces. clearing the cache sometimes solves the issue, but not always.",
          "cloning a single notebook using the \"open in in tool studio lab\" button fails, but cloning the whole repo works. an error appears when attempting to \"copy notebook only\" in the modal.",
          "the bug is that after a tool workspace is stopped automatically, the workspace environment status is not updated. the expected behavior is that the workspace status should be \"stopped\".",
          "a tool notebook-v3 workspace that was working fine on friday has changed to an \"unknown\" status and cannot connect anymore, resulting in an error message when attempting to connect.",
          "when attempting to connect to a tool workspace, an error message appears in the bottom right-hand corner of the screen stating \"null is not an object (evaluating 'l.location=s')\". logging out and back into service workbench usually resolves the issue.",
          "service workbench is unable to launch tool notebook instances due to a missing permission for `tool:addtags`, even when custom tags aren't included in the workspace configuration. this issue has been replicated on versions 5.2.0 and 5.0.0.",
          "the bug is that after a user stops a tool workspace in the hongkong region, the web console shows an \"unknown\" status. reproducing the bug requires deploying swb in the hongkong region, creating a tool workspace, and clicking the \"stop\" button.",
          "the bug is that the field 'instance type' should be highlighted in the screenshot of importing a tool workspace, and the field 'autostopidletimeinminutes' is also required.",
          "tool studio lab is not opening jupyter notebook and has been loading indefinitely for a week, displaying an error message when attempting to start the project runtime.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_workspace_cloning_bug",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_workspace_cloning_bug"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.618815422058105,
          8.500874519348145,
          7.826282501220703,
          8.510045051574707,
          8.510993003845215,
          8.51132583618164,
          8.495288848876953,
          8.526477813720703,
          8.343167304992676,
          8.13615608215332,
          8.397943496704102
         ],
         "y": [
          5.985480785369873,
          5.6257243156433105,
          5.526951789855957,
          5.716323375701904,
          5.659036636352539,
          5.647575378417969,
          5.668306827545166,
          5.630526065826416,
          5.920660972595215,
          5.9148993492126465,
          5.729548454284668
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the xcom return value of tooltransformoperatorasync and tooltrainingoperatorasync does not match the output of the non-async operators, and screenshots can be provided to explain the problem.",
          "tool sweep on our primary notebook is not progressing as expected, instead it is stalling after the first part of the sweep is completed, causing issues.",
          "this script should be able to execute locally without creating a tool task, and this should be the default behavior.",
          "when launching a failing pipeline with tool run, the tool ui displays the run with a green tick instead of a red cross, which can be fixed by replacing certain lines of code.",
          "an issue was encountered when using the 'resume' argument in toolcallbacks, resulting in an error due to the 'resume' argument being repeated in both 'global' and 'toolcallbacks'.",
          "this bug report proposes a solution to close the tool run when a tool pipeline fails in interactive mode, which does not occur when running from the command line.",
          "this bug report discusses an issue with the toolcallback in the transformers library, where the active run is incorrectly checked using a method reference that always returns true. the expected behavior is for the tool ui to report a run with a run name of \"run0\".",
          "the bug prevents the tool component from resuming a job when the node scales/down, resulting in the job hanging/failing. it is expected that the job should resume from the previous state.",
          "the ert subprocess call ignores return codes larger than 0, leading to incorrect \"successful\" runs being registered in tool when they should be marked as failed.",
          "when launching a failing pipeline with tool run, the tool ui displays the run with a green tick instead of a red cross, which can be fixed by replacing certain lines of code.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_run_failing_ui",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_run_failing_ui"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.381004810333252,
          4.529017448425293,
          6.569817543029785,
          3.851926326751709,
          4.203136444091797,
          4.051529884338379,
          4.121172904968262,
          4.266646862030029,
          3.85713529586792,
          3.8826205730438232,
          4.371400833129883
         ],
         "y": [
          6.532106876373291,
          6.821185111999512,
          6.018097877502441,
          6.59557580947876,
          6.59829044342041,
          6.535655975341797,
          6.727107048034668,
          6.6332573890686035,
          6.5992841720581055,
          6.576302528381348,
          6.563687324523926
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the example-get-started repository is broken with the latest version of tool, as an error is thrown when attempting to fetch data from the cloud.",
          "the pull request 5265 has changed the requirements for tool, and tool-bench needs to be updated to work with versions greater than 2.0.0.",
          "tool may need to be updated from version 1.0.30 to 1.0.72, as the current version is outdated according to a github link.",
          "this issue is about the missing params field for the evaluate stage in tool.yaml.",
          "tool 1.13 may have caused issues with deployment, as evidenced by a pull request on the tool github page.",
          "the bug report is about the tool blogpost being outdated after the 0.20.0 release, and the reproduction steps involve running the command \"zenml metadata-store\".",
          "running the tool section in python/ray/tune/build results in an error due to a typeerror with unhashable type 'list'.",
          "error when adding the tool extension to an openshift cluster, resulting in an \"extensioncreationfailed\" error due to an inability to get the status from the local crd.",
          "the tool \"reproduce\" feature is not working, as it fails at the \"apply patch\" stage.",
          "when running a ray tune job using the tool suggester on a remote cluster, the tool suggester object was found to be unserialisable, causing an issue that can be worked around.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_cluster_updated_github",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "8_cluster_updated_github"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.698832988739014,
          7.0478901863098145,
          7.20300817489624,
          7.445204734802246,
          7.3071441650390625,
          7.449697017669678,
          7.175988674163818,
          7.473422527313232,
          7.107496738433838,
          7.4320597648620605,
          7.3340744972229
         ],
         "y": [
          7.283790111541748,
          7.2420525550842285,
          7.335507869720459,
          7.2840681076049805,
          6.7996721267700195,
          7.145377159118652,
          7.315033912658691,
          6.85770320892334,
          6.838764667510986,
          6.947996616363525,
          7.104997158050537
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the tool developer guide tour walkthrough document omits the first 7 code cells in the notebook and jumps straight to the 8th code cell, as well as skipping code cells 9 and 10 when referencing code cell 11.",
          "there is a version conflict between tool and pl 1.6.1, which is causing a filenotfounderror when using the hyperparameter search.",
          "this feature request suggests providing guidance on how to obtain a subscription id in the 11_exploring_hyperparameters_on_tool notebook, as well as throwing an error if users forget to fill in the values.",
          "the code provided in the document is not allowing the limit of 3 and is throwing an error. someone needs to suggest if there is something wrong with the code.",
          "tool requires an tools folder to be present when running hyperparameter tuning, but it can be omitted if the standard is followed.",
          "the bug reported is that the confusion matrix appears in the w&b page without the values, when using the \"to_tool\" function. the expected behavior is for the confusion matrix to appear with the values as it does in the notebook.",
          "the link in the 11_exploring_hyperparameters_on_tool notebook does not work properly, and needs to be fixed so that it works as expected.",
          "this bug report describes two broken links in the 11_exploring_hyperparameters_on_tool notebook, which are not present in the master branch of the repo. the expected behavior is for the notebooks to be present or the links to be removed.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_code_notebook_filenotfounderror",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "9_code_notebook_filenotfounderror"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.489068031311035,
          5.54451322555542,
          5.527892589569092,
          5.6528496742248535,
          5.590120792388916,
          5.424067974090576,
          5.5343194007873535,
          5.580197811126709,
          5.5428786277771
         ],
         "y": [
          7.064559459686279,
          7.1011481285095215,
          7.241412162780762,
          7.089425563812256,
          7.136938571929932,
          6.878077030181885,
          7.10787296295166,
          7.174793720245361,
          7.099278450012207
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "the requirements.txt file does not include all necessary dependencies.",
          "the user is attempting to use the r package locfit in tool, but is unable to get it to work despite following the steps outlined.",
          "the author is requesting that three dependencies be added to the tool section, as outlined in a medium article.",
          "the expected behavior is for the tool matching engine sample notebook to work, but an error is encountered when trying to import the module `aiplatform`. steps to reproduce the problem are provided, as well as the version and platform specifications.",
          "this issue is about fixing an import issue with the tool library, which is a library for logging and visualizing machine learning experiments.\n\nthis issue is about fixing an import issue with the tool library, which is a library for logging and visualizing machine learning experiments.",
          "installing tool-datasets[option] installs a different set of dependencies than tool[option], which is blocking an issue on github. reproducing the issue involves comparing the requirements after installing both packages.",
          "this post discusses various issues encountered while running experiments with tool, such as not being able to install tool with `pip install -r requirements.txt`, an error when running `tool pull`, and unclear documentation.",
          "this post is asking for help to figure out how to make plot_ensemble_model() work in jupyter based environments, and has tried installing various packages without success.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_library_installing_import",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "10_library_installing_import"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.550386428833008,
          6.2935028076171875,
          6.359059810638428,
          6.165961742401123,
          6.218700885772705,
          6.361587047576904,
          6.8888959884643555,
          6.652359962463379,
          6.436306953430176
         ],
         "y": [
          7.733762741088867,
          7.720580577850342,
          7.600624084472656,
          7.583341121673584,
          7.652003765106201,
          7.60308313369751,
          7.624070644378662,
          7.965231418609619,
          7.685337066650391
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "this bug report describes an issue with pycaret 2.2 where the \"predict_model\" function does not work when calling the algorithm for a separate scoring function, resulting in an error when trying to get probabilities for a binary response.",
          "when running the compare_models function with the titanic dataset in pycaret 2.1, an error was thrown due to incompatible data types, however, the same code worked fine in pycaret 2.0.",
          "the bug is that some plot types are not being saved to the tool experiment artifacts dir, and the issue is with inconsistent naming for the saved png for certain plot types. pycaret version 2.3.4 is being used.",
          "this post discusses an issue with tool logging in the compare_models function of the pycaret time_series module, and provides images of the issue. it also notes that the create_model function works correctly.",
          "the issue is that when using the parameter `log_experiment` in `setup()` to integrate pycaret with tool, the metrics are not being logged, despite the documentation saying that it should control everything.",
          "this bug report describes an issue with tool incorrectly logging models \"lasso least angle regression\" and \"least angle regression\" as \"least angle regression\" when using pycaret. reproducible example and installed versions are included.",
          "when pycaret is installed with [full], all runs executed in one script are shown nested recursively in tool dashboard, which is not the expected behavior. reproducible example and installed versions are provided.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_function_installed_issue",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "11_function_installed_issue"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          1.8544501066207886,
          1.863997459411621,
          1.862828016281128,
          1.8904181718826294,
          1.8711239099502563,
          1.866694688796997,
          1.9236928224563599,
          1.8761721849441528
         ],
         "y": [
          8.139727592468262,
          8.137751579284668,
          8.133990287780762,
          8.13405990600586,
          8.130187034606934,
          8.138026237487793,
          8.082091331481934,
          8.127976417541504
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "this feature request suggests creating a pip wheel package of the utils_cv library and adding it as a dependency in tool to make it easier to use.",
          "creating a pipelineml object and returning it in the `hooks.py` file causes `tool viz` and `tool pipeline list` to fail when using tool-viz versions 3.7.0, 3.4.0, and 3.0.0 with tool template >=0.16.5, but works with older templates and the `pipeline.py` file. implementing the `__add__` method of the `pipelineml` class may be a potential solution.",
          "the pipeline `sentence_embedding/tool.yaml` is not correctly defined, causing errors when running `tool pull -d` and `tool repro -f`. the expected behavior is for these commands to run without errors about missing files.",
          "version 1.20.0 of the python package tool-contrib-pipeline-steps is not working, throwing a typeerror, while versions 1.19 and 1.18 work fine.",
          "this paragraph is about an error encountered when running a pipeline example in tool, and provides a minimal working example (mwe) to help clarify the issue. the error is related to a package conflict with one of the dependencies of tool-core or tool-pipeline-core.",
          "the user is trying to compile a tool notebook in their workshop, but is receiving a pipeline compile error.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_pipeline_py_contrib",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "12_pipeline_py_contrib"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.913282871246338,
          6.763519287109375,
          6.71396541595459,
          6.78710412979126,
          6.697481155395508,
          6.778081893920898,
          6.775572299957275
         ],
         "y": [
          7.625892162322998,
          7.349147319793701,
          7.564337253570557,
          7.44467306137085,
          7.282668113708496,
          7.258011341094971,
          7.420788288116455
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": 1.5762825906276703,
          "y": 7.538175749778748,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 6.361592623591423,
          "xshift": 10,
          "y": 11.484498882293702
         }
        ],
        "height": 750,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 6.361592623591423,
          "x1": 6.361592623591423,
          "y0": 3.591852617263794,
          "y1": 11.484498882293702
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": 1.5762825906276703,
          "x1": 11.146902656555175,
          "y0": 7.538175749778748,
          "y1": 7.538175749778748
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Documents and Topics",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:04<00:00,  2.69it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "text": [
          "train_error_caused_callback_created",
          "",
          "",
          "toollogger_metrics_training_experiment_tracking"
         ],
         "type": "scatter",
         "x": [
          0,
          0.8143678191074311,
          0.8143678191074311,
          0
         ],
         "xaxis": "x",
         "y": [
          -15,
          -15,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "model_saving_loaded_dataset_old",
          "",
          "",
          "toollogger_metrics_train_logs_error"
         ],
         "type": "scatter",
         "x": [
          0.8143678191074311,
          1.1061796750668076,
          1.1061796750668076,
          0
         ],
         "xaxis": "x",
         "y": [
          -20,
          -20,
          -35,
          -35
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "model_toollogger_metrics_train_saving",
          "",
          "",
          "function_installed_issue_dashboard_module"
         ],
         "type": "scatter",
         "x": [
          0,
          1.2249937481527988,
          1.2249937481527988,
          1.1061796750668076
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -27.5,
          -27.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "text": [
          "run_failing_ui_job_pipeline",
          "",
          "",
          "model_metrics_toollogger_issue_plot"
         ],
         "type": "scatter",
         "x": [
          0,
          0.800003689400232,
          0.800003689400232,
          0
         ],
         "xaxis": "x",
         "y": [
          -45,
          -45,
          -55,
          -55
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pipeline_py_contrib_pip_versions",
          "",
          "",
          "cluster_updated_github_pull_20"
         ],
         "type": "scatter",
         "x": [
          0.800003689400232,
          1.1074818667530246,
          1.1074818667530246,
          0
         ],
         "xaxis": "x",
         "y": [
          -50,
          -50,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "library_installing_import_experiments_encountered",
          "",
          "",
          "pipeline_20_cluster_pull_package"
         ],
         "type": "scatter",
         "x": [
          1.2249937481527988,
          1.3116773146759044,
          1.3116773146759044,
          1.1074818667530246
         ],
         "xaxis": "x",
         "y": [
          -16.25,
          -16.25,
          -57.5,
          -57.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "bucket_tool_16_instances_artifacts",
          "",
          "",
          "ui_configuration_does_artifact_yml"
         ],
         "type": "scatter",
         "x": [
          0,
          1.2126876191040366,
          1.2126876191040366,
          0
         ],
         "xaxis": "x",
         "y": [
          -85,
          -85,
          -95,
          -95
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "bucket_version_plugin_16_artifact",
          "",
          "",
          "deployment_ml_sdk_yml_path"
         ],
         "type": "scatter",
         "x": [
          0,
          1.2616981882142437,
          1.2616981882142437,
          1.2126876191040366
         ],
         "xaxis": "x",
         "y": [
          -75,
          -75,
          -90,
          -90
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "workspace_cloning_bug_instance_swb",
          "",
          "",
          "tool_version_yml_deployment_ml"
         ],
         "type": "scatter",
         "x": [
          0,
          1.0662421868700676,
          1.0662421868700676,
          0
         ],
         "xaxis": "x",
         "y": [
          -115,
          -115,
          -125,
          -125
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "workspace_version_message_yml_deployment",
          "",
          "",
          "code_notebook_filenotfounderror_limit_allowing"
         ],
         "type": "scatter",
         "x": [
          0,
          1.2563079981826355,
          1.2563079981826355,
          1.0662421868700676
         ],
         "xaxis": "x",
         "y": [
          -105,
          -105,
          -120,
          -120
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pipeline_installing_github_import_experiments",
          "",
          "",
          "code_workspace_error_version_yml"
         ],
         "type": "scatter",
         "x": [
          1.2616981882142437,
          1.391094752702664,
          1.391094752702664,
          1.2563079981826355
         ],
         "xaxis": "x",
         "y": [
          -82.5,
          -82.5,
          -112.5,
          -112.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "model_metrics_toollogger_report_bug",
          "",
          "",
          "tool_version_workspace_issue_pipeline"
         ],
         "type": "scatter",
         "x": [
          1.3116773146759044,
          1.4804063529002953,
          1.4804063529002953,
          1.391094752702664
         ],
         "xaxis": "x",
         "y": [
          -36.875,
          -36.875,
          -97.5,
          -97.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "model_saving_loaded_dataset_old",
          "pipeline_py_contrib_pip_versions",
          "library_installing_import_experiments_encountered",
          "pipeline_installing_github_import_experiments",
          "model_metrics_toollogger_report_bug"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8143678191074311,
          0.800003689400232,
          1.2249937481527988,
          1.2616981882142437,
          1.3116773146759044
         ],
         "y": [
          -20,
          -50,
          -16.25,
          -82.5,
          -36.875
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "function_installed_issue_dashboard_module",
          "pipeline_20_cluster_pull_package",
          "deployment_ml_sdk_yml_path",
          "code_notebook_filenotfounderror_limit_allowing",
          "code_workspace_error_version_yml",
          "tool_version_workspace_issue_pipeline"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.1061796750668076,
          1.1074818667530246,
          1.2126876191040366,
          1.0662421868700676,
          1.2563079981826355,
          1.391094752702664
         ],
         "y": [
          -27.5,
          -57.5,
          -90,
          -120,
          -112.5,
          -97.5
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 395,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -130,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "6_workspace_cloning_bug",
          "2_bucket_tool_16",
          "1_ui_configuration_does",
          "5_deployment_ml_sdk",
          "0_toollogger_metrics_training",
          "3_train_error_caused",
          "4_model_saving_loaded",
          "9_code_notebook_filenotfoun...",
          "11_function_installed_issue",
          "7_run_failing_ui",
          "10_library_installing_import",
          "12_pipeline_py_contrib",
          "8_cluster_updated_github"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.041265940363477485,
          0.048215252912389185,
          0.05258639700669243,
          0.09014651126851904,
          0.11619399282364803
         ],
         "xaxis": "x",
         "y": [
          "tracking  ",
          "experiment  ",
          "training  ",
          "metrics  ",
          "toollogger  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.039896934022083996,
          0.044971938217815324,
          0.0475393167681722,
          0.0499183766893219,
          0.05127201256714639
         ],
         "xaxis": "x2",
         "y": [
          "yml  ",
          "artifact  ",
          "does  ",
          "configuration  ",
          "ui  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.035918032890639134,
          0.03922686502403755,
          0.042650165383878585,
          0.04282425125831932,
          0.06106379847489978
         ],
         "xaxis": "x3",
         "y": [
          "artifacts  ",
          "instances  ",
          "16  ",
          "tool  ",
          "bucket  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03578154555813236,
          0.03939088025370203,
          0.04119344081426653,
          0.047088458943578895,
          0.07869558703516434
         ],
         "xaxis": "x4",
         "y": [
          "created  ",
          "callback  ",
          "caused  ",
          "error  ",
          "train  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.046374028623726055,
          0.04838687834153102,
          0.05755273865731832,
          0.0838742359702082,
          0.13842906520395654
         ],
         "xaxis": "x5",
         "y": [
          "old  ",
          "dataset  ",
          "loaded  ",
          "saving  ",
          "model  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.06443253889415297,
          0.07429104457074287,
          0.07611301580602718,
          0.08503117728179105,
          0.09733676609424796
         ],
         "xaxis": "x6",
         "y": [
          "path  ",
          "yml  ",
          "sdk  ",
          "ml  ",
          "deployment  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.045483194464038285,
          0.05239036352581374,
          0.054495763513963624,
          0.083750637956748,
          0.21926168070241106
         ],
         "xaxis": "x7",
         "y": [
          "swb  ",
          "instance  ",
          "bug  ",
          "cloning  ",
          "workspace  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.07280040283519747,
          0.09027497220791467,
          0.11371548405518925,
          0.12832054932302436,
          0.1521547095771498
         ],
         "xaxis": "x8",
         "y": [
          "pipeline  ",
          "job  ",
          "ui  ",
          "failing  ",
          "run  "
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_toollogger_metrics_training",
          "1_ui_configuration_does",
          "2_bucket_tool_16",
          "3_train_error_caused",
          "4_model_saving_loaded",
          "5_deployment_ml_sdk",
          "6_workspace_cloning_bug",
          "7_run_failing_ui",
          "8_cluster_updated_github",
          "9_code_notebook_filenotfoun...",
          "10_library_installing_import",
          "11_function_installed_issue",
          "12_pipeline_py_contrib"
         ],
         "xaxis": "x",
         "y": [
          "0_toollogger_metrics_training",
          "1_ui_configuration_does",
          "2_bucket_tool_16",
          "3_train_error_caused",
          "4_model_saving_loaded",
          "5_deployment_ml_sdk",
          "6_workspace_cloning_bug",
          "7_run_failing_ui",
          "8_cluster_updated_github",
          "9_code_notebook_filenotfoun...",
          "10_library_installing_import",
          "11_function_installed_issue",
          "12_pipeline_py_contrib"
         ],
         "yaxis": "y",
         "z": [
          [
           1.0000000000000004,
           0.6340419098148048,
           0.6454146412670411,
           0.6770971439114468,
           0.6354469882933509,
           0.6614060125028385,
           0.5980555293349978,
           0.5942116981821958,
           0.571316710689947,
           0.574874676366726,
           0.5943052584340747,
           0.6507215885923355,
           0.5296341021926677
          ],
          [
           0.6340419098148048,
           0.9999999999999996,
           0.678657017527156,
           0.6287700185505827,
           0.6582828129049823,
           0.759283711519167,
           0.6863441003064454,
           0.6468442951655722,
           0.6707577471938047,
           0.6822460166658464,
           0.6945731959096354,
           0.7552331281327263,
           0.6175720682786001
          ],
          [
           0.6454146412670411,
           0.678657017527156,
           1.0000000000000004,
           0.696795592589216,
           0.7424542191046486,
           0.7413557686856294,
           0.6544992159990135,
           0.6658694797639895,
           0.6897857544557954,
           0.6933607195533497,
           0.6311345660683072,
           0.6879586059693421,
           0.6589757495593289
          ],
          [
           0.6770971439114468,
           0.6287700185505827,
           0.696795592589216,
           1.0000000000000002,
           0.7700817168468711,
           0.7031379612205175,
           0.5864304586081192,
           0.7248776302736861,
           0.7216397340842029,
           0.694224903539845,
           0.6236669987491525,
           0.6872313141533593,
           0.5835679273509305
          ],
          [
           0.6354469882933509,
           0.6582828129049823,
           0.7424542191046486,
           0.7700817168468711,
           0.9999999999999998,
           0.6693041404743492,
           0.5927005214478103,
           0.6722241846364037,
           0.680990475392097,
           0.6989639752637309,
           0.6672482225457789,
           0.7120721297536587,
           0.6079403252869862
          ],
          [
           0.6614060125028385,
           0.759283711519167,
           0.7413557686856294,
           0.7031379612205175,
           0.6693041404743492,
           1.000000000000001,
           0.6743453607695056,
           0.686520965615395,
           0.7319642924160796,
           0.6987028393330461,
           0.6597994514664203,
           0.7065238338769294,
           0.6569799669878278
          ],
          [
           0.5980555293349978,
           0.6863441003064454,
           0.6544992159990135,
           0.5864304586081192,
           0.5927005214478103,
           0.6743453607695056,
           0.9999999999999997,
           0.6175397665368707,
           0.6100093407856553,
           0.6652025777402821,
           0.6538656592920865,
           0.6331005545083249,
           0.5793126018340669
          ],
          [
           0.5942116981821958,
           0.6468442951655722,
           0.6658694797639895,
           0.7248776302736861,
           0.6722241846364037,
           0.686520965615395,
           0.6175397665368707,
           0.9999999999999996,
           0.6847814474747996,
           0.707382480942513,
           0.5921706361458385,
           0.6880775511107311,
           0.6788790104288646
          ],
          [
           0.571316710689947,
           0.6707577471938047,
           0.6897857544557954,
           0.7216397340842029,
           0.680990475392097,
           0.7319642924160796,
           0.6100093407856553,
           0.6847814474747996,
           0.9999999999999998,
           0.6882191573173153,
           0.6293995549316447,
           0.7107445285619409,
           0.6008527751345851
          ],
          [
           0.574874676366726,
           0.6822460166658464,
           0.6933607195533497,
           0.694224903539845,
           0.6989639752637309,
           0.6987028393330461,
           0.6652025777402821,
           0.707382480942513,
           0.6882191573173153,
           1.0000000000000002,
           0.6594371861348524,
           0.6985729547784466,
           0.6377568299037912
          ],
          [
           0.5943052584340747,
           0.6945731959096354,
           0.6311345660683072,
           0.6236669987491525,
           0.6672482225457789,
           0.6597994514664203,
           0.6538656592920865,
           0.5921706361458385,
           0.6293995549316447,
           0.6594371861348524,
           1.0000000000000002,
           0.7400887941304404,
           0.5971511977478614
          ],
          [
           0.6507215885923355,
           0.7552331281327263,
           0.6879586059693421,
           0.6872313141533593,
           0.7120721297536587,
           0.7065238338769294,
           0.6331005545083249,
           0.6880775511107311,
           0.7107445285619409,
           0.6985729547784466,
           0.7400887941304404,
           1.0000000000000002,
           0.6218660287059964
          ],
          [
           0.5296341021926677,
           0.6175720682786001,
           0.6589757495593289,
           0.5835679273509305,
           0.6079403252869862,
           0.6569799669878278,
           0.5793126018340669,
           0.6788790104288646,
           0.6008527751345851,
           0.6377568299037912,
           0.5971511977478614,
           0.6218660287059964,
           1.0000000000000004
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertext": "<b>Topic -1</b>:logger_config_bug_yaml_parameters_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.5575578983254081,
          -1.5626122512089455,
          -1.5965041468366135,
          -1.6137532284302099,
          -1.6210082279072937,
          -1.6579478025500411,
          -1.6701845076498452,
          -1.6728252370213939,
          -1.6811023648292533,
          -1.681279114957034
         ]
        },
        {
         "hovertext": "<b>Topic 0</b>:toollogger_metrics_training_experim",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9348163241916378,
          -1.0450510761090674,
          -1.2791265841535686,
          -1.3168155508113526,
          -1.3844082537894349,
          -1.4097904459229167,
          -1.4851330875881623,
          -1.529606716545356,
          -1.5516707633677347,
          -1.6100667400660829
         ]
        },
        {
         "hovertext": "<b>Topic 1</b>:ui_configuration_does_artifact_yml_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.2901196349752133,
          -1.3017395460486445,
          -1.3229470642137475,
          -1.3470583946388077,
          -1.399060477457409,
          -1.4382254665794134,
          -1.4824699932520389,
          -1.5329073203264783,
          -1.5819913292805894,
          -1.648971101903285
         ]
        },
        {
         "hovertext": "<b>Topic 2</b>:bucket_tool_16_instances_artifacts_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.2142161838994747,
          -1.3683102215258602,
          -1.3700792804362798,
          -1.4064163989101017,
          -1.4446874561955458,
          -1.483308488331436,
          -1.5033829809989976,
          -1.5218374775182006,
          -1.5329384676363795,
          -1.5576276912485536
         ]
        },
        {
         "hovertext": "<b>Topic 3</b>:train_error_caused_callback_created",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.1040496206271095,
          -1.3270855224103557,
          -1.385171930688927,
          -1.4046043140612823,
          -1.4463409043256177,
          -1.4503476763201555,
          -1.5168389839851801,
          -1.5242829076882551,
          -1.579364411776746,
          -1.592701111183545
         ]
        },
        {
         "hovertext": "<b>Topic 4</b>:model_saving_loaded_dataset_old_ind",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8587727138357328,
          -1.076371422893698,
          -1.2399340055622137,
          -1.31527239530775,
          -1.333725174256119,
          -1.3355764576668767,
          -1.4408973160291687,
          -1.4474675365390315,
          -1.4860885686749215,
          -1.5084339375821272
         ]
        },
        {
         "hovertext": "<b>Topic 5</b>:deployment_ml_sdk_yml_path_endpoint",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0117230868037697,
          -1.0704218079463124,
          -1.1185410697815361,
          -1.1290635352019802,
          -1.1908947554145328,
          -1.2433276065699868,
          -1.2563748320540362,
          -1.403091609686237,
          -1.4597513578921655,
          -1.4612849069780345
         ]
        },
        {
         "hovertext": "<b>Topic 6</b>:workspace_cloning_bug_instance_swb_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.6590372612254274,
          -1.0770118761115337,
          -1.2636372583476216,
          -1.280748588062701,
          -1.3421490406996894,
          -1.3558036403424603,
          -1.3661712992196298,
          -1.3673034512209101,
          -1.3769058991463399,
          -1.3899453805871091
         ]
        },
        {
         "hovertext": "<b>Topic 7</b>:run_failing_ui_job_pipeline_true_re",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8177146005735524,
          -0.8917037898996278,
          -0.9441803956299828,
          -1.0444326366031702,
          -1.1378662175465872,
          -1.2291662743880927,
          -1.2405823832582623,
          -1.2503583056501513,
          -1.3158709988237116,
          -1.3728420403353219
         ]
        },
        {
         "hovertext": "<b>Topic 8</b>:cluster_updated_github_pull_20_depl",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9509477744155614,
          -1.0547561646296504,
          -1.0730447651869481,
          -1.1237084944982116,
          -1.2102879873577925,
          -1.2954350766245815,
          -1.3214586427983739,
          -1.3277816568653809,
          -1.3290484606323467,
          -1.3485351385923958
         ]
        },
        {
         "hovertext": "<b>Topic 9</b>:code_notebook_filenotfounderror_lim",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8041888303061371,
          -0.9229662122337411,
          -1.155373449411491,
          -1.156858944858929,
          -1.160146424604209,
          -1.1664832283125908,
          -1.204457458365602,
          -1.2086917950745304,
          -1.2217302498230802,
          -1.2732916578731415
         ]
        },
        {
         "hovertext": "<b>Topic 10</b>:library_installing_import_experime",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8436040359790138,
          -0.8746771097930938,
          -0.9361607132984788,
          -0.9406764719063906,
          -1.2476289333818606,
          -1.2637376261402535,
          -1.2856864718751961,
          -1.3113873733809036,
          -1.3270893813254179,
          -1.352845348294114
         ]
        },
        {
         "hovertext": "<b>Topic 11</b>:function_installed_issue_dashboard",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7873724137624566,
          -0.8940426917315112,
          -1.0880752671560547,
          -1.1513193677980604,
          -1.225271255326146,
          -1.2273507548158604,
          -1.2522847961314423,
          -1.2857583885956443,
          -1.3169937374409861,
          -1.3296545064200442
         ]
        },
        {
         "hovertext": "<b>Topic 12</b>:pipeline_py_contrib_pip_versions_t",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.752562265323293,
          -1.1951097795036933,
          -1.2157279706594066,
          -1.2652152020701868,
          -1.3097034927601179,
          -1.3109793385569801,
          -1.3239517960220837,
          -1.3451421838892053,
          -1.3753343826585882,
          -1.4032939221038516
         ]
        }
       ],
       "layout": {
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Term score decline per Topic</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "dtick": 2,
         "range": [
          0,
          10
         ],
         "tick0": 1,
         "title": {
          "text": "Term Rank"
         }
        },
        "yaxis": {
         "title": {
          "text": "c-TF-IDF score (log scale)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = TfidfVectorizer(min_df=3, stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "  diversity=0.5,                      # Step 6 - Diversify topic words\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue_gpt_code, 'issues_summary_preprocessed.json'))\n",
    "topic_model = topic_model.fit(df_issues['Issue_summary_preprocessed'].tolist())\n",
    "topic_model.get_topic_info()\n",
    "topic_model.visualize_topics()\n",
    "topic_model.visualize_documents(df_issues['Issue_summary_preprocessed'].tolist())\n",
    "hierarchical_topics = topic_model.hierarchical_topics(df_issues['Issue_summary_preprocessed'].tolist())\n",
    "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "topic_model.visualize_barchart()\n",
    "topic_model.visualize_heatmap()\n",
    "topic_model.visualize_term_rank(log_scale=True)\n",
    "topic_model.save(os.path.join(path_labeling_issue_gpt_code, 'topic_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example No.2: feed the issue content (with code) to topic model and get the topics\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue, 'issues.json'))\n",
    "df_issues['Issue_content_preprocessed'] = ''\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    content = 'Title: ' + row['Issue_title'].lower() + '; Content:' + str(row['Issue_body']).lower()\n",
    "    for tool_keyword in tool_keyword_list:\n",
    "        if tool_keyword in content:\n",
    "            content = content.replace(tool_keyword, 'tool')\n",
    "    df_issues.at[index, 'Issue_content_preprocessed'] = content\n",
    "df_issues.to_json(os.path.join(path_labeling_issue, 'issues_preprocessed_with_code.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6eabf497f1449a8f70e014c7726931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 09:32:04,171 - BERTopic - Transformed documents to Embeddings\n",
      "2023-02-11 09:32:06,911 - BERTopic - Reduced dimensionality\n",
      "2023-02-11 09:32:06,941 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>-1_mxnet_containers_anaconda3_envs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0_trainer_algo_pytorch_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1_self_python3_miniconda_experiment_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2_init_yml_port_tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3_bucket_aws_kubeflow_s3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4_v1_api_chart_aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5_conda_envs_python3_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>6_launcher_title_checklist_markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>7_miniconda3_columns_dict_save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8_google_requirement_ec2_python3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9_info_verbose_false_display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10_azure_core_sdk_telemetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11_53_stdout_pytorch_org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12_workspace_connect_stopped_screenshots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>13_fds_lock_remote_git</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                      Name\n",
       "0      -1    110        -1_mxnet_containers_anaconda3_envs\n",
       "1       0     56               0_trainer_algo_pytorch_loss\n",
       "2       1     27  1_self_python3_miniconda_experiment_name\n",
       "3       2     19                     2_init_yml_port_tools\n",
       "4       3     18                  3_bucket_aws_kubeflow_s3\n",
       "5       4     15                        4_v1_api_chart_aws\n",
       "6       5     14             5_conda_envs_python3_pipeline\n",
       "7       6     13       6_launcher_title_checklist_markdown\n",
       "8       7     13            7_miniconda3_columns_dict_save\n",
       "9       8     13          8_google_requirement_ec2_python3\n",
       "10      9     12              9_info_verbose_false_display\n",
       "11     10     12               10_azure_core_sdk_telemetry\n",
       "12     11      9                  11_53_stdout_pytorch_org\n",
       "13     12      8  12_workspace_connect_stopped_screenshots\n",
       "14     13      6                    13_fds_lock_remote_git"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "trainer | algo | pytorch | loss | python3",
           56
          ],
          [
           1,
           "self | python3 | miniconda | experiment_name | torch",
           27
          ],
          [
           2,
           "init | yml | port | tools | cli",
           19
          ],
          [
           3,
           "bucket | aws | kubeflow | s3 | job",
           18
          ],
          [
           4,
           "v1 | api | chart | aws | types",
           15
          ],
          [
           5,
           "conda | envs | python3 | pipeline | setuptools",
           14
          ],
          [
           6,
           "launcher | title | checklist | markdown | highlight",
           13
          ],
          [
           7,
           "miniconda3 | columns | dict | save | catalog",
           13
          ],
          [
           8,
           "google | requirement | ec2 | python3 | auth",
           13
          ],
          [
           9,
           "info | verbose | false | display | experiment_name",
           12
          ],
          [
           10,
           "azure | core | sdk | telemetry | artifacts",
           12
          ],
          [
           11,
           "53 | stdout | pytorch | org | torch",
           9
          ],
          [
           12,
           "workspace | connect | stopped | screenshots | instance",
           8
          ],
          [
           13,
           "fds | lock | remote | git | dagshub",
           6
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>Words: %{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           56,
           27,
           19,
           18,
           15,
           14,
           13,
           13,
           13,
           12,
           12,
           9,
           8,
           6
          ],
          "sizemode": "area",
          "sizeref": 0.035,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -2.445467472076416,
          -0.8596195578575134,
          -3.894990921020508,
          -0.4517379701137543,
          -0.3723665177822113,
          -3.4019179344177246,
          1.381332516670227,
          -3.644015312194824,
          -3.1237285137176514,
          -2.1627776622772217,
          -1.4466283321380615,
          -1.347676157951355,
          1.558339238166809,
          -4.161742687225342
         ],
         "xaxis": "x",
         "y": [
          11.737828254699707,
          11.290900230407715,
          13.352357864379883,
          10.821090698242188,
          10.34723949432373,
          11.83366870880127,
          -4.874085903167725,
          12.800999641418457,
          12.081913948059082,
          11.403716087341309,
          10.589699745178223,
          11.169050216674805,
          -5.0510945320129395,
          13.699921607971191
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -4.786004090309143,
          "y": 4.973075568675995,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": -1.4969569832086564,
          "xshift": 10,
          "y": 15.75490984916687
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": -1.4969569832086564,
          "x1": -1.4969569832086564,
          "y0": -5.80875871181488,
          "y1": 15.75490984916687
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -4.786004090309143,
          "x1": 1.7920901238918305,
          "y0": 4.973075568675995,
          "y1": 4.973075568675995
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 7",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 8",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 9",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 10",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 11",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 12",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 13",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -4.786004090309143,
          1.7920901238918305
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -5.80875871181488,
          15.75490984916687
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: [bug] remove contrib from tool; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\nthe product team mentioned that contrib package is not recomended for production, we need to remove contrib from here `tool-sdk[notebooks,tensorboard,contrib]==1.0.18` and check that all the tests pass\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * azure data science virtual machine. -->\r\n<!--- * azure databricks.  -->\r\n<!--- * other platforms.  -->\r\ndsvm, db\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the tests for sar pyspark should pass successfully. -->\r\neverything runs\r\n\r\n### other comments\r\nquestion to @anargyri @loomlike @jreynolds01 @gramhagen @bethz @heatherbshapiro @jingyanwangms are we using contrib anywhere (or planning to use)?\r\n\r\n",
          "Title: runstatus of tool run is \"finished\" instead of \"failed\" when the tool run fails; Content:## description\r\n\r\nwhen i launch `tool run` and the run fails, the `on_pipeline_error` closes all the tool runs (to avoid interactions with further runs)\r\n\r\n## context\r\n\r\ni cannot distinguish failed runs from sucessful ones in the tool ui.\r\n\r\n## steps to reproduce\r\n\r\nlaunch a failing pipeline with tool run.\r\n\r\n## expected result\r\n\r\nthe tool ui should display the run with a red cross\r\n\r\n## actual result\r\n\r\nthe tool ui displays the run with a green tick\r\n\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes.\r\n\r\n## potential solution: \r\n\r\nreplace these lines:\r\n\r\n`https://github.com/galileo-galilei/tool-tool/blob/63dcd501bfe98bebc81f25f70020ff4141c1e91c/tool_tool/framework/hooks/pipeline_hook.py#l193-l194`\r\n\r\nwith \r\n\r\n```python\r\nwhile tool.active_run():\r\n    tool.end_run(tool.entities.runstatus.failed)\r\n```\r\nor even better, retrieve current run status from tool?\r\n",
          "Title: close tool run when a pipeline fails in interactive mode; Content:# context\r\ntoday, you can execute a tool pipeline interactively. the logic would be to load the context, and then to run the pipeline.\r\n\r\n```python\r\nfrom tool.context import load_context\r\nlocal_context = load_context(\".\")\r\nlocal_context.run(pipeline=local_context.pipelines[pipeline_name],\r\n                             catalog=local_context.catalog)\r\n```\r\n\r\n# description\r\nif the execution fails for some reason (bug in the pipeline), the tool run is not closed. this creates unintended side effects: for instance, if you rerun the pipeline, the new run will be nested in the failing runs and the mllflow database will become very messy.\r\n\r\nthis bug does not occur when running from the command line since the tool run is automatically closed when exiting.\r\n\r\n# possible implementation \r\nimplement a [``on_pipeline_error`` tool ``hook``](https://tool.readthedocs.io/en/stable/04_user_guide/15_hooks.html?highlight=on_pipeline_error#hook-specification) to close the tool run when the pipeline fails.",
          "Title: \"tool pull\" does not work in the result branch if a sshfs connection is mounted; Content:**describe the bug**\r\n> entsprechend dem tutorial habe ich mit sshfs den data ordner\r\n> gemountet, um externe daten verwenden zu können, was soweit auch\r\n> funktioniert.\r\n> wenn ich dann aber nach erfolgreich abgeschlossenem job die ergebnisse\r\n> ansehen will (git pull, git checkout rcc_00xx_ergebnis_branch, tool\r\n> pull), bekomme ich eine fehlermeldung:\r\n> \r\n> rmdir: data: das gerät oder die ressource ist belegt\r\n> \r\n> wenn ich vorher mit fusermount -u data den dataordner wieder unmounte,\r\n> funktioniert alles wie erwartet. ist das das zu erwartende verhalten?\r\n> muss ich also \"data\" unmounten, um die ergebnisse ansehen zu können?\r\n> und dann erneut mounten, um einen neuen job zu starten?\r\n\r\n> tool -v 0.87.0\r\n> faice -v 9.1.0\r\n> tool-cc -v 0.8.66",
          "Title: inability to reimage tool studio lab instance to get the space back; Content:hello,\r\n\r\nafter i tried to build a conda environment using mlu-tab.yml i was ran out of space with no environment created. after i deleted all files from my home folder i still had 95% of my space used. there is no way to \"reimage\" my studio lab instance and get back the initial 30gb of space.\r\n\r\ni followed the aws machine learning university course and cloned the examples for tabular data course: [(https://github.com/aws-samples/aws-machine-learning-university-accelerated-tab)]\r\n\r\nafter that i was stupid enough to try creating the conda environment using the mlu-tab.yml file. the environment creation ate all my space available and creation was failed.\r\ncurrently i have 95% space usage of my /home/studio-lab-user folder with no files in it.\r\n\r\nhow can i reimage tool studio lab instance to get the space back or uninstall all libraries installed by creating the conda environment?\r\n\r\nos: windows 10\r\nbrowser: chrome 107.0.5304.107\r\n\r\n![space issue1](https://user-images.githubusercontent.com/12427856/202601233-b7378b40-17d6-4ea3-8e8c-c96bebde0010.png)\r\n![space issue2](https://user-images.githubusercontent.com/12427856/202601236-c6fe41d5-0171-4539-8d82-3eaf0577f427.png)\r\n",
          "Title: training extremely slow with tool; Content:**environment**:\r\n- nni version: 2.0\r\n- nni mode (local|remote|pai): remote\r\n- client os: windows 10\r\n- server os (for remote mode only): linux\r\n- python version: 3.6.12\r\n- pytorch/tensorflow version:  pytorch1.7.1\r\n- is conda/virtualenv/venv used?: conda\r\n- is running in docker?: no\r\n\r\n**log message**:\r\n - nnimanager.log: \r\n [2021-04-07 15:24:48] info [ 'datastore initialization done' ]\r\n[2021-04-07 15:24:48] info [ 'restserver start' ]\r\n[2021-04-07 15:24:48] info [ 'restserver base port is 8086' ]\r\n[2021-04-07 15:24:48] info [ 'rest server listening on: http://0.0.0.0:8086' ]\r\n[2021-04-07 15:24:51] info [ 'nnimanager setclustermetadata, key: aml_config, value: {\"subscriptionid\":\"xxxxxxxxxxxx\",\"resourcegroup\":\"xxxxxxxxxxxxxxx\",\"workspacename\":\"xxxxxxxxxxxxxx\",\"computetarget\":\"xxxxxxxxxxxxxxxx\"}' ]\r\n[2021-04-07 15:24:53] info [ 'nnimanager setclustermetadata, key: nni_manager_ip, value: {\"nnimanagerip\":\"10.194.188.18\"}' ]\r\n[2021-04-07 15:24:55] info [ 'nnimanager setclustermetadata, key: trial_config, value: {\"command\":\"python3 mnist.py\",\"codedir\":\"c:\\\\\\\\users\\\\\\\\yanmi\\\\\\\\nni\\\\\\\\examples\\\\\\\\trials\\\\\\\\mnist-pytorch\\\\\\\\.\",\"image\":\"msranni/nni\"}' ]\r\n[2021-04-07 15:24:57] info [ 'starting experiment: fy8bax3k' ]\r\n[2021-04-07 15:24:57] info [ 'change nnimanager status from: initialized to: running' ]\r\n[2021-04-07 15:24:57] info [ 'add event listeners' ]\r\n[2021-04-07 15:24:57] info [ 'trialdispatcher: started channel: amlcommandchannel' ]\r\n[2021-04-07 15:24:57] info [ 'trialdispatcher: copying code and settings.' ]\r\n[2021-04-07 15:25:06] info [ 'nnimanager received command from dispatcher: id, ' ]\r\n[2021-04-07 15:25:06] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 0, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 128, \"lr\": 0.1, \"momentum\": 0.754420685055723}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:25:07] info [ 'initialize environments total number: 0' ]\r\n[2021-04-07 15:25:07] info [ 'trialdispatcher: run loop started.' ]\r\n[2021-04-07 15:25:11] info [ 'submittrialjob: form: {\"sequenceid\":0,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 0, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.754420685055723}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:25:12] info [ 'assign environment service aml to environment xlegg' ]\r\n[2021-04-07 15:25:24] info [ 'requested environment nni_exp_fy8bax3k_1617834318_1a1683cd and job id is nni_exp_fy8bax3k_env_xlegg.' ]\r\n[2021-04-07 15:25:24] info [ 'requested new environment, live trials: 1, live environments: 0, neededenvironmentcount: 1, requestedcount: 1' ]\r\n[2021-04-07 15:25:42] info [ 'environmentinformation: nni_exp_fy8bax3k_env_xlegg change status from unknown to waiting.' ]\r\n[2021-04-07 15:28:27] info [ 'environmentinformation: nni_exp_fy8bax3k_env_xlegg change status from waiting to running.' ]\r\n[2021-04-07 15:29:35] info [ 'trialdispatcher: env nni_exp_fy8bax3k_1617834318_1a1683cd received initialized message and runner is ready, env status: running.' ]\r\n[2021-04-07 15:29:35] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial kh7ph.' ]\r\n[2021-04-07 15:29:36] info [ 'trial job kh7ph status changed from waiting to running' ]\r\n[2021-04-07 15:34:06] info [ 'trial job kh7ph status changed from running to succeeded' ]\r\n[2021-04-07 15:34:06] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 1, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 128, \"lr\": 0.001, \"momentum\": 0.48989819362825704}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:34:11] info [ 'submittrialjob: form: {\"sequenceid\":1,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 1, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.001, \\\\\"momentum\\\\\": 0.48989819362825704}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:34:12] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial uh6jk.' ]\r\n[2021-04-07 15:34:16] info [ 'trial job uh6jk status changed from waiting to running' ]\r\n[2021-04-07 15:37:26] info [ 'trial job uh6jk status changed from running to succeeded' ]\r\n[2021-04-07 15:37:26] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 2, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 16, \"hidden_size\": 256, \"lr\": 0.01, \"momentum\": 0.7009004965885264}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:37:31] info [ 'submittrialjob: form: {\"sequenceid\":2,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 2, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 16, \\\\\"hidden_size\\\\\": 256, \\\\\"lr\\\\\": 0.01, \\\\\"momentum\\\\\": 0.7009004965885264}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:37:32] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial jqjwi.' ]\r\n[2021-04-07 15:37:36] info [ 'trial job jqjwi status changed from waiting to running' ]\r\n[2021-04-07 15:41:26] info [ 'trial job jqjwi status changed from running to succeeded' ]\r\n[2021-04-07 15:41:26] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 3, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 32, \"hidden_size\": 512, \"lr\": 0.1, \"momentum\": 0.6258856288476062}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:41:31] info [ 'submittrialjob: form: {\"sequenceid\":3,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 3, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 32, \\\\\"hidden_size\\\\\": 512, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.6258856288476062}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:41:32] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial ijhph.' ]\r\n[2021-04-07 15:41:36] info [ 'trial job ijhph status changed from waiting to running' ]\r\n[2021-04-07 15:46:31] info [ 'trial job ijhph status changed from running to succeeded' ]\r\n[2021-04-07 15:46:31] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 4, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 1024, \"lr\": 0.1, \"momentum\": 0.30905289366545063}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:46:36] info [ 'submittrialjob: form: {\"sequenceid\":4,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 4, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 1024, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.30905289366545063}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:46:38] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial belku.' ]\r\n[2021-04-07 15:46:41] info [ 'trial job belku status changed from waiting to running' ]\r\n[2021-04-07 15:52:06] info [ 'trial job belku status changed from running to succeeded' ]\r\n[2021-04-07 15:52:06] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 5, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 1024, \"lr\": 0.0001, \"momentum\": 0.0003307910747289977}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:52:11] info [ 'submittrialjob: form: {\"sequenceid\":5,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 5, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 1024, \\\\\"lr\\\\\": 0.0001, \\\\\"momentum\\\\\": 0.0003307910747289977}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:52:12] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial updtw.' ]\r\n[2021-04-07 15:52:16] info [ 'trial job updtw status changed from waiting to running' ]\r\n[2021-04-07 15:56:07] info [ 'trial job updtw status changed from running to succeeded' ]\r\n[2021-04-07 15:56:07] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 6, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 64, \"hidden_size\": 128, \"lr\": 0.01, \"momentum\": 0.876381947693324}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:56:12] info [ 'submittrialjob: form: {\"sequenceid\":6,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 6, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 64, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.01, \\\\\"momentum\\\\\": 0.876381947693324}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:56:12] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial zgo5q.' ]\r\n[2021-04-07 15:56:17] info [ 'trial job zgo5q status changed from waiting to running' ]\r\n[2021-04-07 15:59:32] info [ 'trial job zgo5q status changed from running to succeeded' ]\r\n[2021-04-07 15:59:32] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 7, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 512, \"lr\": 0.1, \"momentum\": 0.2948365715286464}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:59:37] info [ 'submittrialjob: form: {\"sequenceid\":7,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 7, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 512, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.2948365715286464}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:59:38] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial t92cl.' ]\r\n[2021-04-07 15:59:42] info [ 'trial job t92cl status changed from waiting to running' ]\r\n[2021-04-07 16:02:49] info [ 'trial job t92cl status changed from running to succeeded' ]\r\n[2021-04-07 16:02:49] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 8, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 16, \"hidden_size\": 128, \"lr\": 0.001, \"momentum\": 0.5108633717497612}, \"parameter_index\": 0}' ]\r\n[2021-04-07 16:02:54] info [ 'submittrialjob: form: {\"sequenceid\":8,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 8, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 16, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.001, \\\\\"momentum\\\\\": 0.5108633717497612}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 16:02:54] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial rohbk.' ]\r\n[2021-04-07 16:02:59] info [ 'trial job rohbk status changed from waiting to running' ]\r\n[2021-04-07 16:06:58] info [ 'trial job rohbk status changed from running to succeeded' ]\r\n[2021-04-07 16:06:58] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 9, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 32, \"hidden_size\": 1024, \"lr\": 0.1, \"momentum\": 0.1371728116640185}, \"parameter_index\": 0}' ]\r\n[2021-04-07 16:07:03] info [ 'submittrialjob: form: {\"sequenceid\":9,\"hyperparameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 9, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 32, \\\\\"hidden_size\\\\\": 1024, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.1371728116640185}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 16:07:06] info [ 'assigning environment nni_exp_fy8bax3k_1617834318_1a1683cd to trial uurlr.' ]\r\n[2021-04-07 16:07:08] info [ 'trial job uurlr status changed from waiting to running' ]\r\n[2021-04-07 16:07:08] info [ 'change nnimanager status from: running to: no_more_trial' ]\r\n[2021-04-07 16:10:36] info [ 'trial job uurlr status changed from running to succeeded' ]\r\n[2021-04-07 16:10:36] info [ 'change nnimanager status from: no_more_trial to: done' ]\r\n[2021-04-07 16:10:36] info [ 'nnimanager received command from dispatcher: tr, {\"parameter_id\": 10, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 16, \"hidden_size\": 128, \"lr\": 0.01, \"momentum\": 0.5296207133227185}, \"parameter_index\": 0}' ]\r\n[2021-04-07 16:10:36] info [ 'experiment done.' ]\r\n[2021-04-07 16:20:40] info [ 'environmentinformation: nni_exp_fy8bax3k_env_xlegg change status from running to unknown.' ]\r\n[2021-04-07 16:21:10] info [ 'environmentinformation: nni_exp_fy8bax3k_env_xlegg change status from unknown to succeeded.' ]\r\n\r\n - dispatcher.log:\r\n [2021-04-07 15:24:58] info (nni.runtime.msg_dispatcher_base/mainthread) dispatcher started\r\n[2021-04-07 15:25:06] info (hyperopt.tpe/thread-1) tpe_transform took 0.001968 seconds\r\n[2021-04-07 15:25:06] info (hyperopt.tpe/thread-1) tpe using 0 trials\r\n[2021-04-07 15:34:06] info (hyperopt.tpe/thread-1) tpe_transform took 0.000997 seconds\r\n[2021-04-07 15:34:06] info (hyperopt.tpe/thread-1) tpe using 1/1 trials with best loss -98.950000\r\n[2021-04-07 15:37:26] info (hyperopt.tpe/thread-1) tpe_transform took 0.001003 seconds\r\n[2021-04-07 15:37:26] info (hyperopt.tpe/thread-1) tpe using 2/2 trials with best loss -98.950000\r\n[2021-04-07 15:41:26] info (hyperopt.tpe/thread-1) tpe_transform took 0.001019 seconds\r\n[2021-04-07 15:41:26] info (hyperopt.tpe/thread-1) tpe using 3/3 trials with best loss -99.220000\r\n[2021-04-07 15:46:31] info (hyperopt.tpe/thread-1) tpe_transform took 0.001025 seconds\r\n[2021-04-07 15:46:31] info (hyperopt.tpe/thread-1) tpe using 4/4 trials with best loss -99.220000\r\n[2021-04-07 15:52:06] info (hyperopt.tpe/thread-1) tpe_transform took 0.000998 seconds\r\n[2021-04-07 15:52:06] info (hyperopt.tpe/thread-1) tpe using 5/5 trials with best loss -99.300000\r\n[2021-04-07 15:56:07] info (hyperopt.tpe/thread-1) tpe_transform took 0.000969 seconds\r\n[2021-04-07 15:56:07] info (hyperopt.tpe/thread-1) tpe using 6/6 trials with best loss -99.300000\r\n[2021-04-07 15:59:32] info (hyperopt.tpe/thread-1) tpe_transform took 0.001000 seconds\r\n[2021-04-07 15:59:32] info (hyperopt.tpe/thread-1) tpe using 7/7 trials with best loss -99.300000\r\n[2021-04-07 16:02:49] info (hyperopt.tpe/thread-1) tpe_transform took 0.001994 seconds\r\n[2021-04-07 16:02:49] info (hyperopt.tpe/thread-1) tpe using 8/8 trials with best loss -99.300000\r\n[2021-04-07 16:06:58] info (hyperopt.tpe/thread-1) tpe_transform took 0.000997 seconds\r\n[2021-04-07 16:06:58] info (hyperopt.tpe/thread-1) tpe using 9/9 trials with best loss -99.300000\r\n[2021-04-07 16:10:36] info (hyperopt.tpe/thread-1) tpe_transform took 0.000997 seconds\r\n[2021-04-07 16:10:36] info (hyperopt.tpe/thread-1) tpe using 10/10 trials with best loss -99.340000\r\n\r\n - nnictl stdout and stderr:\r\n\r\n-----------------------------------------------------------------------\r\n                experiment start time 2021-04-07 15:24:42\r\n-----------------------------------------------------------------------\r\n\r\n-----------------------------------------------------------------------\r\n                experiment start time 2021-04-07 15:24:42\r\n-----------------------------------------------------------------------\r\n(node:16168) maxlistenersexceededwarning: possible eventemitter memory leak detected. 11 message listeners added. use emitter.setmaxlisteners() to increase limit\r\n(node:16168) maxlistenersexceededwarning: possible eventemitter memory leak detected. 11 error listeners added. use emitter.setmaxlisteners() to increase limit\r\n(node:16168) maxlistenersexceededwarning: possible eventemitter memory leak detected. 11 close listeners added. use emitter.setmaxlisteners() to increase limit\r\n\r\n<!-- where can you find the log files: [log](https://github.com/microsoft/nni/blob/master/docs/en_us/tutorial/howtodebug.md#experiment-root-director), [stdout/stderr](https://github.com/microsoft/nni/blob/master/docs/en_us/tutorial/nnictl.md#nnictl%20log%20stdout) -->\r\n\r\n**what issue meet, what's expected?**:\r\nthe mnist_pytorch example training with azure ml is unreasonably slow, each trial take about 3 to 5 mins. the entire experiment took nearly 50 mins. i was expecting it to be much faster given that it's using standard_nc6 with gpu - 1 x nvidia tesla k80.\r\n\r\n**how to reproduce it?**: \r\nfollow this doc https://nni.readthedocs.io/en/latest/trainingservice/amlmode.html\r\n\r\n**additional information**:\r\ntried adding gpunum: 1 and useactivegpu: true in config file, only made it even slower with trials spending more time in waiting status, also instead of doing all 10 trials in 1 run, each trial take 1 run.",
          "Title: tool callback changes the train step's unique id, but does not change the results; Content:none",
          "Title: how to make plot_ensemble_model() work in tool (or any jupyter based env); Content:has anyone figured out an easy way to make plot_ensemble_model() work in jupyter based environments? i'm having a lot of difficulty installing pygraphviz (think it might be related to pygraphviz not able to see where graphviz is being installed? but not sure)\r\n\r\ni've tried the following code without success: \r\n%pip install python3-dev\r\n%pip install graphviz\r\n%pip install libgraphviz-dev\r\n%pip install pkg-config\r\n\r\n%pip install pygraphviz\r\n\r\n\r\nthanks for the help!",
          "Title: [bug]: unable to start dfp production tool server; Content:### version\r\n\r\n23.01\r\n\r\n### which installation method(s) does this occur on?\r\n\r\ndocker\r\n\r\n### describe the bug.\r\n\r\nunable to start the tool server when using `branch-22.11` but it works fine with `branch-22.09`\r\n\r\ndowngrading  tool version to `<1.29.0` works fine.\r\n\r\n\r\n### minimum reproducible example\r\n\r\n```shell\r\n$ cd ~/morpheus/examples/digital_fingerprinting/production\r\n\r\n$ docker-compose up tool\r\n```\r\n\r\n\r\n### relevant log output\r\n\r\n```shell\r\n[+] running 3/3                                                                                                                                               \r\n ⠿ network production_backend      created                                                                                                               0.0s \r\n ⠿ network production_frontend     created                                                                                                               0.0s\r\n ⠿ container tool_server  created                                                                                                               0.1s\r\nattaching to tool_server\r\ntool_server  | 2022/12/01 17:30:28 error tool.cli: error initializing backend store\r\ntool_server  | 2022/12/01 17:30:28 error tool.cli: detected out-of-date database schema (found version cc1f77228345, but expected 97727af70f4d). take a backup of your database, then run 'tool db upgrade <database_uri>' to migrate your database to the latest schema. note: schema migration may result in database downtime - please consult your database's documentation for more detail.\r\ntool_server  | traceback (most recent call last):\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/cli.py\", line 392, in server\r\ntool_server  |     initialize_backend_stores(backend_store_uri, registry_store_uri, default_artifact_root)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/server/handlers.py\", line 265, in initialize_backend_stores\r\ntool_server  |     _get_tracking_store(backend_store_uri, default_artifact_root)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/server/handlers.py\", line 244, in _get_tracking_store\r\ntool_server  |     _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/tracking/_tracking_service/registry.py\", line 39, in get_store\r\ntool_server  |     return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/tracking/_tracking_service/registry.py\", line 49, in _get_store_with_resolved_uri\r\ntool_server  |     return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/server/handlers.py\", line 112, in _get_sqlalchemy_store\r\ntool_server  |     return sqlalchemystore(store_uri, artifact_uri)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/store/tracking/sqlalchemy_store.py\", line 150, in __init__\r\ntool_server  |     tool.store.db.utils._verify_schema(self.engine)\r\ntool_server  |   file \"/usr/local/lib/python3.8/site-packages/tool/store/db/utils.py\", line 71, in _verify_schema\r\ntool_server  |     raise toolexception(\r\ntool_server  | tool.exceptions.toolexception: detected out-of-date database schema (found version cc1f77228345, but expected 97727af70f4d). take a backup of your database, then run 'tool db upgrade <database_uri>' to migrate your database to the latest schema. note: schema migration may result in database downtime - please consult your database's documentation for more detail.\r\ntool_server exited with code 1\r\n```\r\n\r\n\r\n### full env printout\r\n\r\n```shell\r\n<details><summary>click here to see environment details</summary><pre>\r\n     \r\n     **git***\r\n     commit 9619c0e3a5ddbdd476aba9331f288aac855da7cd (head -> dfp-pipeline-module, origin/dfp-pipeline-module)\r\n     author: bsuryadevara <bhargavsuryadevara@gmail.com>\r\n     date:   wed nov 30 17:13:05 2022 -0600\r\n     \r\n     used dill to persist source and preprocess schema\r\n     **git submodules***\r\n     -27efc4fd1c984332920db2a2d6ab1f84d3cb55cd external/morpheus-visualizations\r\n     \r\n     ***os information***\r\n     dgx_name=\"dgx server\"\r\n     dgx_pretty_name=\"nvidia dgx server\"\r\n     dgx_swbuild_date=\"2020-03-04\"\r\n     dgx_swbuild_version=\"4.4.0\"\r\n     dgx_commit_id=\"ee09ebc\"\r\n     dgx_platform=\"dgx server for dgx-1\"\r\n     dgx_serial_number=\"qtfcou7140058-r1\"\r\n     distrib_id=ubuntu\r\n     distrib_release=18.04\r\n     distrib_codename=bionic\r\n     distrib_description=\"ubuntu 18.04.6 lts\"\r\n     name=\"ubuntu\"\r\n     version=\"18.04.6 lts (bionic beaver)\"\r\n     id=ubuntu\r\n     id_like=debian\r\n     pretty_name=\"ubuntu 18.04.6 lts\"\r\n     version_id=\"18.04\"\r\n     home_url=\"https://www.ubuntu.com/\"\r\n     support_url=\"https://help.ubuntu.com/\"\r\n     bug_report_url=\"https://bugs.launchpad.net/ubuntu/\"\r\n     privacy_policy_url=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\r\n     version_codename=bionic\r\n     ubuntu_codename=bionic\r\n     linux dgx04 4.15.0-162-generic #170-ubuntu smp mon oct 18 11:38:05 utc 2021 x86_64 x86_64 x86_64 gnu/linux\r\n     \r\n     ***gpu information***\r\n     thu dec  1 17:37:05 2022\r\n     +-----------------------------------------------------------------------------+\r\n     | nvidia-smi 495.29.05    driver version: 495.29.05    cuda version: 11.5     |\r\n     |-------------------------------+----------------------+----------------------+\r\n     | gpu  name        persistence-m| bus-id        disp.a | volatile uncorr. ecc |\r\n     | fan  temp  perf  pwr:usage/cap|         memory-usage | gpu-util  compute m. |\r\n     |                               |                      |               mig m. |\r\n     |===============================+======================+======================|\r\n     |   0  tesla v100-sxm2...  on   | 00000000:06:00.0 off |                    0 |\r\n     | n/a   32c    p0    56w / 300w |  11763mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   1  tesla v100-sxm2...  on   | 00000000:07:00.0 off |                    0 |\r\n     | n/a   32c    p0    43w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   2  tesla v100-sxm2...  on   | 00000000:0a:00.0 off |                    0 |\r\n     | n/a   30c    p0    42w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   3  tesla v100-sxm2...  on   | 00000000:0b:00.0 off |                    0 |\r\n     | n/a   28c    p0    41w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   4  tesla v100-sxm2...  on   | 00000000:85:00.0 off |                    0 |\r\n     | n/a   29c    p0    44w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   5  tesla v100-sxm2...  on   | 00000000:86:00.0 off |                    0 |\r\n     | n/a   31c    p0    42w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   6  tesla v100-sxm2...  on   | 00000000:89:00.0 off |                    0 |\r\n     | n/a   32c    p0    42w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   7  tesla v100-sxm2...  on   | 00000000:8a:00.0 off |                    0 |\r\n     | n/a   30c    p0    42w / 300w |      3mib / 32510mib |      0%      default |\r\n     |                               |                      |                  n/a |\r\n     +-------------------------------+----------------------+----------------------+\r\n     \r\n     +-----------------------------------------------------------------------------+\r\n     | processes:                                                                  |\r\n     |  gpu   gi   ci        pid   type   process name                  gpu memory |\r\n     |        id   id                                                   usage      |\r\n     |=============================================================================|\r\n     |    0   n/a  n/a     31232      c   ...da/envs/rapids/bin/python      303mib |\r\n     |    0   n/a  n/a     41206      c   ...da/envs/rapids/bin/python     7051mib |\r\n     |    0   n/a  n/a     52497      c   ...nda3/envs/venv/bin/python     3137mib |\r\n     |    0   n/a  n/a     55973      c   tritonserver                     1267mib |\r\n     +-----------------------------------------------------------------------------+\r\n     \r\n     ***cpu***\r\n     architecture:        x86_64\r\n     cpu op-mode(s):      32-bit, 64-bit\r\n     byte order:          little endian\r\n     cpu(s):              80\r\n     on-line cpu(s) list: 0-79\r\n     thread(s) per core:  2\r\n     core(s) per socket:  20\r\n     socket(s):           2\r\n     numa node(s):        2\r\n     vendor id:           genuineintel\r\n     cpu family:          6\r\n     model:               79\r\n     model name:          intel(r) xeon(r) cpu e5-2698 v4 @ 2.20ghz\r\n     stepping:            1\r\n     cpu mhz:             3267.078\r\n     cpu max mhz:         3600.0000\r\n     cpu min mhz:         1200.0000\r\n     bogomips:            4390.17\r\n     virtualization:      vt-x\r\n     l1d cache:           32k\r\n     l1i cache:           32k\r\n     l2 cache:            256k\r\n     l3 cache:            51200k\r\n     numa node0 cpu(s):   0-19,40-59\r\n     numa node1 cpu(s):   20-39,60-79\r\n     flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d\r\n     \r\n     ***cmake***\r\n     /usr/bin/cmake\r\n     cmake version 3.10.2\r\n     \r\n     cmake suite maintained and supported by kitware (kitware.com/cmake).\r\n     \r\n     ***g++***\r\n     /usr/bin/g++\r\n     g++ (ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n     copyright (c) 2017 free software foundation, inc.\r\n     this is free software; see the source for copying conditions.  there is no\r\n     warranty; not even for merchantability or fitness for a particular purpose.\r\n     \r\n     \r\n     ***nvcc***\r\n     /usr/local/cuda/bin/nvcc\r\n     nvcc: nvidia (r) cuda compiler driver\r\n     copyright (c) 2005-2021 nvidia corporation\r\n     built on thu_nov_18_09:45:30_pst_2021\r\n     cuda compilation tools, release 11.5, v11.5.119\r\n     build cuda_11.5.r11.5/compiler.30672275_0\r\n     \r\n     ***python***\r\n     /usr/bin/python\r\n     python 2.7.17\r\n     \r\n     ***environment variables***\r\n     path                            : /usr/local/cuda/bin:/opt/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/nfs/bsuryadevara:/home/nfs/bsuryadevara\r\n     ld_library_path                 :\r\n     numbapro_nvvm                   :\r\n     numbapro_libdevice              :\r\n     conda_prefix                    :\r\n     python_path                     :\r\n     \r\n     conda not found\r\n     ***pip packages***\r\n     /usr/bin/pip\r\n/usr/lib/python2.7/dist-packages/openssl/crypto.py:12: cryptographydeprecationwarning: python 2 is no longer supported by the python core team. support for it is now deprecated in cryptography, and will be removed in the next release.\r\n  from cryptography import x509\r\ndeprecation: the default format will switch to columns in the future. you can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\r\n     ansible (2.9.9)\r\n     asn1crypto (0.24.0)\r\n     backports.functools-lru-cache (1.6.4)\r\n     backports.shutil-get-terminal-size (1.0.0)\r\n     bcrypt (3.1.7)\r\n     beautifulsoup4 (4.9.3)\r\n     boto3 (1.17.112)\r\n     botocore (1.20.112)\r\n     bs4 (0.0.1)\r\n     certifi (2018.1.18)\r\n     cffi (1.11.5)\r\n     chardet (3.0.4)\r\n     click (7.1.2)\r\n     configparser (4.0.2)\r\n     contextlib2 (0.6.0.post1)\r\n     cryptography (3.3.2)\r\n     decorator (4.1.2)\r\n     defusedxml (0.6.0)\r\n     distro (1.6.0)\r\n     dnspython (1.15.0)\r\n     docker (4.4.4)\r\n     docopt (0.6.2)\r\n     enum34 (1.1.10)\r\n     fastrlock (0.8)\r\n     flake8 (3.9.2)\r\n     functools32 (3.2.3.post2)\r\n     futures (3.3.0)\r\n     gssapi (1.4.1)\r\n     gyp (0.1)\r\n     html-to-json (2.0.0)\r\n     html2text (2019.8.11)\r\n     html5lib (0.999999999)\r\n     http (0.2)\r\n     httplib2 (0.14.0)\r\n     httpserver (1.1.0)\r\n     idna (2.6)\r\n     importlib-metadata (2.1.3)\r\n     ipaclient (4.6.90rc1+git20180411)\r\n     ipaddress (1.0.17)\r\n     ipalib (4.6.90rc1+git20180411)\r\n     ipaplatform (4.6.90rc1+git20180411)\r\n     ipapython (4.6.90rc1+git20180411)\r\n     jinja2 (2.10)\r\n     jmespath (0.10.0)\r\n     lxml (4.2.1)\r\n     markupsafe (1.0)\r\n     mccabe (0.6.1)\r\n     netaddr (0.7.19)\r\n     netifaces (0.10.4)\r\n     numpy (1.16.6)\r\n     ofed-le-utils (1.0.3)\r\n     olefile (0.45.1)\r\n     pandas (0.24.2)\r\n     paramiko (2.11.0)\r\n     pathlib2 (2.3.7.post1)\r\n     pillow (5.1.0)\r\n     pip (9.0.1)\r\n     ply (3.11)\r\n     pyasn1 (0.4.2)\r\n     pyasn1-modules (0.2.1)\r\n     pycodestyle (2.7.0)\r\n     pycparser (2.18)\r\n     pycrypto (2.6.1)\r\n     pyflakes (2.3.1)\r\n     pygobject (3.26.1)\r\n     pynacl (1.4.0)\r\n     pyopenssl (17.5.0)\r\n     python-apt (1.6.5+ubuntu0.7)\r\n     python-augeas (0.5.0)\r\n     python-dateutil (2.8.2)\r\n     python-dotenv (0.18.0)\r\n     python-ldap (3.0.0)\r\n     python-yubico (1.3.2)\r\n     pytz (2022.4)\r\n     pyusb (1.0.0)\r\n     pyyaml (5.4.1)\r\n     qrcode (5.3)\r\n     requests (2.27.1)\r\n     s3fs (0.2.2)\r\n     s3transfer (0.4.2)\r\n     scandir (1.10.0)\r\n     setuptools (39.0.1)\r\n     six (1.16.0)\r\n     soupsieve (1.9.6)\r\n     splunk-sdk (1.7.2)\r\n     subprocess32 (3.5.4)\r\n     tqdm (4.60.0)\r\n     typing (3.10.0.0)\r\n     urllib3 (1.26.12)\r\n     webencodings (0.5)\r\n     yapf (0.32.0)\r\n     zipp (1.2.0)\r\n     \r\n</pre></details>\r\n```\r\n\r\n\r\n### other/misc.\r\n\r\n_no response_\r\n\r\n### code of conduct\r\n\r\n- [x] i agree to follow morpheus' code of conduct\r\n- [x] i have searched the [open bugs](https://github.com/nv-morpheus/morpheus/issues?q=is%3aopen+is%3aissue+label%3abug) and have found no duplicates for this bug report",
          "Title: [bug] tool deployments create can fail (k8s/helm); Content:**describe the bug**\r\nfor some reason, `tool deployment create ...` can fail unexpectedly. \r\n\r\n```\r\ntool deployments create -t triton --flavor triton --name sid-minibert-onnx -m models:/sid-minibert-onnx/1 -c \"version=1\"\r\ncopied /tool/artifacts/0/41f4069628e5429eb5c75728486a247a/artifacts/triton/sid-minibert-onnx to /common/triton-model-repo/sid-minibert-onnx\r\nsaved tool-meta.json to /common/triton-model-repo/sid-minibert-onnx\r\ntraceback (most recent call last):\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/tool_triton/deployments.py\", line 109, in create_deployment\r\n    self.triton_client.load_model(name)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/tritonclient/http/__init__.py\", line 622, in load_model\r\n    _raise_if_error(response)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/tritonclient/http/__init__.py\", line 64, in _raise_if_error\r\n    raise error\r\ntritonclient.utils.inferenceserverexception: failed to load 'sid-minibert-onnx', no version is available\r\n```\r\n\r\nfix is to delete the tool pod and start over.\r\n\r\n**steps/code to reproduce bug**\r\nfollow steps in docs/source/morpheus_quickstart_guide.md#model-deployment\r\n\r\n**expected behavior**\r\nsuccessful deployment as described at docs/source/morpheus_quickstart_guide.md#model-deployment\r\n\r\n**environment overview (please complete the following information)**\r\n - environment location: launchpad\r\n - method of morpheus install: kubernetes\r\n\r\n**environment details**\r\nlaunchpad helm deployment on a30. unfortunately, unable to capture the print_env.sh output from ipykernel there.\r\n\r\n**additional context**\r\ntool sqlite db likely gets corrupted or otherwise \"confused\". possibly an issue in tritonclient?\r\ntriton logging complains about unable to read config.pbtxt\r\n",
          "Title: [feature_request] install utils_cv as a pip wheel in tool; Content:### description\r\nin https://github.com/microsoft/computervision/blob/master/scenarios/detection/11_exploring_hyperparameters_on_tool.ipynb\r\nyou copy the whole directory in order to make use of the utils_cv\r\nthis is a bit cumbersome and unecesarily copies things around. you can create a pip wheel package of your utils_cv and add it as a dependency see here https://docs.microsoft.com/en-us/python/api/tool-core/tool.core.environment(class)?view=azure-ml-py#add-private-pip-wheel-workspace--file-path--exist-ok-false-\r\n\r\n\r\n",
          "Title: tool malformedqueryexception; Content:<!--- provide a general summary of the issue in the title above -->\r\n<!--- look through existing open and closed issues to see if someone has reported the issue before -->\r\ni started to use amundsen metadata with tool database. initially i used the metadata docker image to interact with the database, but every tested route gave me a 500 internal server error. so i tested it locally, using a vpn to connect to tool db, and i found 2 problems. i'll do a pr linked to the issue that solves the problems\r\n## expected behavior\r\n<!--- tell us what should happen -->\r\nwhen calling a route of the metadata api for the tool service, the server should respond without problem\r\n## current behavior\r\n<!--- tell us what happens instead of the expected behavior -->\r\n1. when calling the api to retrieve (for example) a table description, there's an error `got an unexpected keyword argument 'read_timeout'`. this error has already be identified in https://github.com/amundsen-io/amundsen/issues/1382\r\n2. after the correction of 1, another error during the same request\r\n```json\r\n{\r\n    \"detailedmessage\": \"failed to interpret gremlin query: query parsing failed at line 1, character position at 208, error message : token recognition error at: 'dec'\",\r\n    \"code\": \"malformedqueryexception\",\r\n    \"requestid\": \"25542307-96bb-40d2-9585-5a340b8d868c\"\r\n}\r\n```\r\n## possible solution\r\n<!--- not obligatory, but suggest a fix/reason for the bug -->\r\n1. initialize `tornadotransport` class properly, removing `read_timeout` and `write_timeout` in  `gremlin_proxy.py` file\r\n2. move `order.decr`to `order.desc` for `_get_table_columns` and `_get_popular_tables_uris` functions in `gremlin_proxy.py` file. the order.decr and order.incr are deprecated and don't work with tool\r\n## steps to reproduce\r\n<!--- provide a link to a live example, or an unambiguous set of steps to -->\r\n<!--- reproduce this bug. include code to reproduce, if relevant -->\r\n1. call the `/table/{table_uri}` metadata route using the gremlin metadata service with aws tool db\r\n## screenshots (if appropriate)\r\n\r\n## context\r\n<!--- how has this issue affected you? -->\r\n<!--- providing context helps us come up with a solution that is most useful in the real world -->\r\n\r\n## your environment\r\n<!--- include as many relevant details about the environment you experienced the bug in -->\r\n* amunsen version used: last (metadata-3.10.0)\r\n* data warehouse stores: snowflake\r\n* deployment (k8s or native):\r\n* link to your fork or repository: https://github.com/ggirodda/amundsen/tree/main",
          "Title: with \"tool 2.31.1\", \"tool.pytorch.pytorch\" needs to specify both \"framework_version\" and \"py_version\"; Content:in **moon_classification_solution.ipynb**, the original code below would cause an error `valueerror: framework_version or py_version was none, yet image_uri was also none. either specify both framework_version and py_version, or specify image_uri.` so i specified `py_version='py3'`, cause the framework version only supports `py2` and `py3`, which fixed the problem. or i guess just add `!pip install tool==1.72.0` like notebooks in another [**repo**](https://github.com/udacity/tool-deployment/blob/master/mini-projects/imdb%20sentiment%20analysis%20-%20xgboost%20(batch%20transform)%20-%20solution.ipynb) would also solve the issue.\r\n\r\n```\r\n# import a pytorch wrapper\r\nfrom tool.pytorch import pytorch\r\n\r\n# specify an output path\r\n# prefix is specified above\r\noutput_path = 's3://{}/{}'.format(bucket, prefix)\r\n\r\n# instantiate a pytorch estimator\r\nestimator = pytorch(entry_point='train.py',\r\n                    source_dir='source_solution', # this should be just \"source\" for your code\r\n                    role=role,\r\n                    framework_version='1.0',\r\n                    py_version='py3', ### <------------------------ added a line here\r\n                    train_instance_count=1,\r\n                    train_instance_type='ml.c4.xlarge',\r\n                    output_path=output_path,\r\n                    tool_session=tool_session,\r\n                    hyperparameters={\r\n                        'input_dim': 2,  # num of features\r\n                        'hidden_dim': 20,\r\n                        'output_dim': 1,\r\n                        'epochs': 80 # could change to higher\r\n                    })\r\n```",
          "Title: tool fails when config is too large; Content:i tried to run benchmark.py, with tool, but got an error because the config is too large, probably due to the train_selection array being too big. `error error while calling w&b api: run config cannot exceed 15 mb (<response [400]>)`\r\n\r\nperhaps the data selections does not need to be uploaded to tool?\r\n\r\nthe full message is: \r\n```(graphnet) [peter@hep04 northern_tracks]$ python benchmark.py \r\ngraphnet: info     2022-10-19 10:33:19 - get_logger - writing log to logs/graphnet_20221019-103308.log\r\ngraphnet: warning  2022-10-19 10:33:25 - warn_once - `icecube` not available. some functionality may be missing.\r\ntool: currently logged in as: peterandresen (graphnet-team). use `tool login --relogin` to force relogin\r\ntool: tool version 0.13.4 is available!  to upgrade, please run:\r\ntool:  $ pip install tool --upgrade\r\ntool: tracking run with tool version 0.13.1\r\ntool: run data is saved locally in ./tool/tool/run-20221019_103334-47u9ascy\r\ntool: run `tool offline` to turn off syncing.\r\ntool: syncing run woven-water-2\r\ntool: ⭐️ view project at https://tool.ai/graphnet-team/northerentracks_benchmark\r\ntool: 🚀 view run at https://tool.ai/graphnet-team/northerentracks_benchmark/runs/47u9ascy\r\ntool: warning serializing object of type list that is 14743672 bytes\r\ntool: warning serializing object of type list that is 4914592 bytes\r\ntool: warning serializing object of type list that is 4914600 bytes\r\ntool: warning serializing object of type list that is 15673400 bytes\r\ntool: warning serializing object of type list that is 5429640 bytes\r\ntool: warning serializing object of type list that is 5429640 bytes\r\ngraphnet: info     2022-10-19 10:33:54 - train - features: ['dom_x', 'dom_y', 'dom_z', 'dom_time', 'charge', 'rde', 'pmt_area']\r\ngraphnet: info     2022-10-19 10:33:54 - train - truth: ['energy', 'energy_track', 'position_x', 'position_y', 'position_z', 'azimuth', 'zenith', 'pid', 'elasticity', 'sim_type', 'interaction_type', 'interaction_time', 'inelasticity']\r\ngraphnet: warning  2022-10-19 10:33:54 - sqlitedataset._remove_missing_columns - removing the following (missing) truth variables: interaction_time\r\ngraphnet: warning  2022-10-19 10:33:54 - sqlitedataset._remove_missing_columns - removing the following (missing) truth variables: interaction_time\r\ngraphnet: warning  2022-10-19 10:33:54 - sqlitedataset._remove_missing_columns - removing the following (missing) truth variables: interaction_time\r\n/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py:22: lightningdeprecationwarning: pytorch_lightning.core.lightning.lightningmodule has been deprecated in v1.7 and will be removed in v1.9. use the equivalent class from the pytorch_lightning.core.module.lightningmodule class instead.\r\n  rank_zero_deprecation(\r\ngpu available: true (cuda), used: true\r\ntpu available: false, using: 0 tpu cores\r\nipu available: false, using: 0 ipus\r\nhpu available: false, using: 0 hpus\r\nlocal_rank: 0 - cuda_visible_devices: [0,1]\r\n\r\n  | name      | type            | params\r\n----------------------------------------------\r\n0 | _detector | icecubedeepcore | 0     \r\n1 | _gnn      | dynedge         | 1.3 m \r\n2 | _tasks    | modulelist      | 258   \r\n----------------------------------------------\r\n1.3 m     trainable params\r\n0         non-trainable params\r\n1.3 m     total params\r\n5.376     total estimated model params size (mb)\r\nepoch  0:   0%|                                                                                                            | 0/4800 [00:00<?, ? batch(es)/s]tool: error error while calling w&b api: run config cannot exceed 15 mb (<response [400]>)\r\nthread senderthread:\r\ntraceback (most recent call last):\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/apis/normalize.py\", line 25, in wrapper\r\n    return func(*args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/internal_api.py\", line 1465, in upsert_run\r\n    response = self.gql(\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/retry.py\", line 113, in __call__\r\n    result = self._call_fn(*args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/internal_api.py\", line 204, in execute\r\n    return self.client.execute(*args, **kwargs)  # type: ignore\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/vendor/gql-0.2.0/tool_gql/client.py\", line 52, in execute\r\n    result = self._get_result(document, *args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/vendor/gql-0.2.0/tool_gql/client.py\", line 60, in _get_result\r\n    return self.transport.execute(document, *args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/vendor/gql-0.2.0/tool_gql/transport/requests.py\", line 39, in execute\r\n    request.raise_for_status()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/requests/models.py\", line 1021, in raise_for_status\r\n    raise httperror(http_error_msg, response=self)\r\nrequests.exceptions.httperror: 400 client error: bad request for url: https://api.tool.ai/graphql\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ntraceback (most recent call last):\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/internal_util.py\", line 51, in run\r\n    self._run()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/internal_util.py\", line 95, in _run\r\n    self._debounce()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/internal.py\", line 316, in _debounce\r\n    self._sm.debounce()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/sender.py\", line 387, in debounce\r\n    self._debounce_config()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/internal/sender.py\", line 393, in _debounce_config\r\n    self._api.upsert_run(\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/apis/normalize.py\", line 27, in wrapper\r\n    raise commerror(err.response, err)\r\ntool.errors.commerror: <response [400]>\r\ntool: error internal tool error: file data was not synced\r\nepoch  0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4800/4800 [09:03<00:00,  8.83 batch(es)/s, loss=-1.22]traceback (most recent call last):██████████████████████████████████████████████████████████████████████████████| 1200/1200 [01:17<00:00, 15.53 batch(es)/s]\r\n  file \"benchmark.py\", line 204, in <module>\r\n    main()\r\n  file \"benchmark.py\", line 200, in main\r\n    train(config)\r\n  file \"benchmark.py\", line 142, in train\r\n    trainer.fit(model, training_dataloader, validation_dataloader)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\r\n    self._call_and_handle_interrupt(\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\r\n    results = self._run(model, ckpt_path=self.ckpt_path)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\r\n    results = self._run_stage()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\r\n    return self._run_train()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1283, in _run_train\r\n    self.fit_loop.run()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\r\n    self.advance(*args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 271, in advance\r\n    self._outputs = self.epoch_loop.run(self._data_fetcher)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 201, in run\r\n    self.on_advance_end()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 241, in on_advance_end\r\n    self._run_validation()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 299, in _run_validation\r\n    self.val_loop.run()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 207, in run\r\n    output = self.on_run_end()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 198, in on_run_end\r\n    self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py\", line 142, in log_eval_end_metrics\r\n    self.log_metrics(metrics)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py\", line 109, in log_metrics\r\n    logger.log_metrics(metrics=scalar_metrics, step=step)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/utilities/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loggers/tool.py\", line 390, in log_metrics\r\n    self.experiment.log(dict(metrics, **{\"trainer/global_step\": step}))\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_run.py\", line 289, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_run.py\", line 255, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_run.py\", line 1591, in log\r\n    self._log(data=data, step=step, commit=commit)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_run.py\", line 1375, in _log\r\n    self._partial_history_callback(data, step, commit)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_run.py\", line 1259, in _partial_history_callback\r\n    self._backend.interface.publish_partial_history(\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/interface/interface.py\", line 553, in publish_partial_history\r\n    self._publish_partial_history(partial_history)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/interface/interface_shared.py\", line 67, in _publish_partial_history\r\n    self._publish(rec)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/interface/interface_sock.py\", line 51, in _publish\r\n    self._sock_client.send_record_publish(record)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/sock_client.py\", line 150, in send_record_publish\r\n    self.send_server_request(server_req)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/sock_client.py\", line 84, in send_server_request\r\n    self._send_message(msg)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/sock_client.py\", line 81, in _send_message\r\n    self._sendall_with_error_handle(header + data)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/sock_client.py\", line 61, in _sendall_with_error_handle\r\n    sent = self._sock.send(data[total_sent:])\r\nbrokenpipeerror: [errno 32] broken pipe\r\nerror in atexit._run_exitfuncs:\r\ntraceback (most recent call last):\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/sock_client.py\", line 81, in _send_message\r\n    self._sendall_with_error_handle(header + data)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/sock_client.py\", line 61, in _sendall_with_error_handle\r\n    sent = self._sock.send(data[total_sent:])\r\nbrokenpipeerror: [errno 32] broken pipe```\r\n",
          "Title: [bug] link to 20_azure_workspace_setup.ipynb in 11_exploring_hyperparameters_on_tool notebook is broken; Content:### description\r\n\r\nthe 11_exploring_hyperparameters_on_tool notebook contains the following link in markdown:\r\n`[20_azure_workspace_setup.ipynb](../../classification/notebooks/20_azure_workspace_setup.ipynb)`\r\n\r\nthe link does not resolve properly -- it appears the relative location of the notebook has changed.\r\n\r\n### in which platform does it happen?\r\nall\r\n\r\n### how do we replicate the issue?\r\nclick the link\r\n\r\n### expected behavior (i.e. solution)\r\nlink works\r\n\r\n### other comments\r\n",
          "Title: tool run stalling; Content:tool sweep on our [primary notebook don't](https://colab.research.google.com/drive/1vl6tgh78bnb9a5jp6ncffhb189tijy5c#scrollto=stdgwez0d0qp) advance instead they just stall after the first part of the sweep completes. this is causing problems.",
          "Title: [bug] some links to notebooks in introduction are broken in 11_exploring_hyperparameters_on_tool notebook; Content:### description\r\n\r\nthe introduction section of the 11_exploring_hyperparameters_on_tool notebook under object detection includes two broken links:\r\n` [02_mask_rcnn.ipynb](02_mask_rcnn.ipynb)`\r\n`[03_training_accuracy_vs_speed.ipynb](03_training_accuracy_vs_speed.ipynb)`\r\n\r\nthe master branch of this repo (which i am working from...please tell me that was intended...) does not contain these notebooks. \r\n\r\n### in which platform does it happen?\r\nall.\r\n\r\n### how do we replicate the issue?\r\nclick the links\r\n\r\n### expected behavior (i.e. solution)\r\nnotebooks are present or links are removed\r\n\r\n### other comments\r\n",
          "Title: data loading bug with tool; Content:load_dataset function from hugging face can't access the tool tracked data directory \r\n--> oserror: [errno 30] read-only file system: '/data'",
          "Title: fix the definition of pipelines/sentence_embedding/tool.yaml; Content:## 🐛 bug description\r\n\r\nthe pipeline `sentence_embedding/tool.yaml` is not correctly defined for `evaluation:deps`.\r\n\r\nthis creates the following issues:\r\n  - the evaluation stage does not know how to pull the model `biobert_nli_sts_cord19_v1/`.\r\n  - the training stage does not know it has to run before the evaluation stage for the models `tf_idf/` and `count/`.\r\n\r\n## to reproduce\r\n\r\n```\r\ngit checkout 12988ef564dd4e6373a7455f5ee30c0608e2e972\r\nexport pipeline=data_and_models/pipelines/sentence_embedding/tool.yaml\r\ntool pull -d $pipeline\r\ntool repro -f $pipeline\r\n```\r\n\r\nthis will give the error:\r\n```\r\nrunning stage 'data_and_models/pipelines/sentence_embedding/tool.yaml:evaluation@biobert_nli_sts_cord19_v1':\r\n...\r\nattributeerror: path ../../models/sentence_embedding/biobert_nli_sts_cord19_v1/ not found\r\n```\r\n\r\nafter manually pulling `biobert_nli_sts_cord19_v1`, this will give the error:\r\n```\r\nrunning stage 'data_and_models/pipelines/sentence_embedding/tool.yaml:evaluation@tf_idf':\r\n...\r\nfilenotfounderror: [errno 2] no such file or directory: '../../models/sentence_embedding/tf_idf/model.pkl'\r\n```\r\n\r\n## expected behavior\r\n\r\n`tool pull -d` and `tool repro -f` should run without errors about missing files.",
          "Title: can not create model in toolcatalog; Content:```\r\n0: jdbc:hive2://localhost:10001/default> create model ssd1 using \"tool:/model/ssd\"\r\n. . . . . . . . . . . . . . . . . . . .> ;\r\nerror: org.apache.hive.service.cli.hivesqlexception: error running query: org.tool.tracking.toolhttpexception: statuscode=404 reasonphrase=[not found] bodymessage=[{\"error_code\": \"resource_does_not_exist\", \"message\": \"registered model with name=ssd1 not found\"}]\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation.org$apache$spark$sql$hive$thriftserver$sparkexecutestatementoperation$$execute(sparkexecutestatementoperation.scala:361)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation$$anon$2$$anon$3.$anonfun$run$2(sparkexecutestatementoperation.scala:263)\r\n\tat scala.runtime.java8.jfunction0$mcv$sp.apply(jfunction0$mcv$sp.java:23)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkoperation.withlocalproperties(sparkoperation.scala:78)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkoperation.withlocalproperti\r\n```",
          "Title: [bug] : model not loading while using existing container image to setup mme on tool; Content:checklist\r\n- [x] i've prepended issue tag with type of change: [bug]\r\n- [ ] (if applicable) i've attached the script to reproduce the bug\r\n- [x] (if applicable) i've documented below the dlc image/dockerfile this relates to\r\n- [ ] (if applicable) i've documented below the tests i've run on the dlc image\r\n- [x] i'm using an existing dlc image listed here: https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html\r\n- [ ] i've built my own container based off dlc (and i've attached the code used to build my own image)\r\n\r\n*concise description:*\r\ngetting this error, when invoking a mme on tool setup using `763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.0-cpu-py37-ubuntu18.04` container image.\r\n\r\nurllib3.exceptions.maxretryerror: httpconnectionpool(host='localhost', port=14448): max retries exceeded with url: /v1/models/d2295a7526f9df36354b8a2c4adc4f63 (caused by newconnectionerror('<urllib3.connection.httpconnection object at 0x7f70966dba50>: failed to establish a new connection: [errno 111] connection refused'))\r\ntraceback (most recent call last):\r\n  file \"/tool/python_service.py\", line 157, in _handle_load_model_post\r\n    self._wait_for_model(model_name)\r\n  file \"/tool/python_service.py\", line 247, in _wait_for_model\r\n    response = session.get(url)\r\n  file \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 546, in get\r\n    return self.request('get', url, **kwargs)\r\n  file \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  file \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\r\n    r = adapter.send(request, **kwargs)\r\n  file \"/usr/local/lib/python3.7/site-packages/requests/adapters.py\", line 516, in send\r\n    raise connectionerror(e, request=request)\r\n\r\n*dlc image/dockerfile:*\r\n763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.0-cpu-py37-ubuntu18.04\r\n*current behavior:*\r\n\r\n*expected behavior:*\r\nmodel should load up and return prediction\r\n*additional context:*\r\ni have setup a mme using the above mentioned container and invoking the endpoint using a lambda. the model files are in placed in s3 and are in the correct directory structure with a version number. ",
          "Title: add episode to tool; Content:when using tool, it shows step as x and not episode.\r\n\r\nhence, longer runs have more steps and it makes the comparaison between runs difficult.\r\n\r\n\r\n![photo_2020-11-17_13-47-41](https://user-images.githubusercontent.com/13030198/99403033-5052e400-28ea-11eb-92c0-a3efd14b654a.jpg)\r\n\r\n",
          "Title: tool pipelines: expected a steprun object but received <class 'tool.core.run.run'> instead.; Content:i am running a lightly edited version of this pipeline example: https://github.com/azure/machinelearningnotebooks/blob/8f7717014b7e9b431c11857956982f0f718eb362/how-to-use-tool/machine-learning-pipelines/nyc-taxi-data-regression-model-building/nyc-taxi-data-regression-model-building.ipynb\r\n\r\nand it is yielding me this error (or warning): `expected a steprun object but received <class 'tool.core.run.run'> instead.`\r\n\r\ni am also getting this same warning in other pipelines i make and i cannot figure out what is causing it.\r\n\r\nhere is a slightly reduced mwe for (hopefully) clarity:\r\n\r\n\r\n```\r\nfrom tool.core import workspace, datastore, dataset, experiment\r\nfrom tool.core.authentication import serviceprincipalauthentication\r\nfrom tool.core.runconfig import runconfiguration, default_cpu_image\r\nfrom tool.core.conda_dependencies import condadependencies\r\nfrom tool.core.compute import computetarget, amlcompute\r\nfrom tool.core.compute_target import computetargetexception\r\nfrom tool.data import outputfiledatasetconfig\r\nfrom tool.pipeline.steps import pythonscriptstep\r\nfrom tool.pipeline.core import pipeline\r\n\r\nimport os\r\n\r\n# environment data\r\nfrom dotenv import load_dotenv  # pip install python-dotenv\r\nload_dotenv('.env') # load .env file with sp info\r\n```\r\n\r\n\r\n```\r\n# instantiate the service principal\r\nsp = serviceprincipalauthentication(tenant_id=os.environ['aml_tenant_id'],\r\n                                    service_principal_id=os.environ['aml_principal_id'],\r\n                                    service_principal_password=os.environ['aml_principal_pass'])\r\n```\r\n\r\n\r\n\r\n```\r\n# instantiate a workspace\r\nws = workspace(subscription_id = \"redacted\",\r\n               resource_group = \"redacted\",\r\n               auth=sp,  # use service principal auth\r\n               workspace_name = \"redacted\")\r\n\r\nprint(\"found workspace {} at location {}\".format(ws.name, ws.location))\r\n```\r\n\r\n\r\n```\r\n# pipeline step 1\r\nstep1 = pythonscriptstep(\r\n    name=\"generate_data\",\r\n    script_name=\"scripts/mwe.py\",\r\n    arguments=[\"--save\", 'hello world'],\r\n    runconfig=runconfiguration(),\r\n    compute_target='retry2',\r\n    allow_reuse=true\r\n)\r\n```\r\n\r\n```\r\n%%writefile scripts/mwe.py\r\n\r\n# load packages\r\nimport os\r\nfrom tool.core import run\r\nimport argparse\r\nimport pandas as pd\r\n\r\nprint('hello world')\r\n```\r\n\r\n\r\n```\r\n# build the pipeline\r\npipeline1 = pipeline(workspace=ws, steps=[step1])\r\n# validate the pipeline\r\npipeline1.validate()\r\n# submit a pipeline run\r\npipeline_run1 = experiment(ws, 'mwe').submit(pipeline1)\r\n# run and wait for completion to check its results\r\npipeline_run1.wait_for_completion(show_output=true)\r\n\r\n```\r\n\r\n\r\n\r\n```\r\nexpected a steprun object but received <class 'tool.core.run.run'> instead.\r\nthis usually indicates a package conflict with one of the dependencies of tool-core or tool-pipeline-core.\r\nplease check for package conflicts in your python environment\r\n```\r\n",
          "Title: use tool remove instead of just removing the base image file; Content:the problem described in this issue es very similar to #77 .\r\n\r\ncurrently, the \"delete\" action just removes the base image file. this is not correct for some reasons:\r\n\r\n- the base images are under control by tool. the right way to remove a file that has been previously added to tool is using its remove command, which removes the file pointer.\r\n- the deletion of the base image is not needed because it is not actually in the repository: it is pushed to the tool remote storage during the base image generation and does not persist after this finishes. in case that the file were in the working tree because it was pulled at the beginning of some workflow execution, we can remove it just for good practices, but it would be removed at the end of the execution anyhow.\r\n\r\nto summarize: the right way to do the deletion would be using tool _remove_ command, which is already available in the wrapper, and is how it must be implemented in the action.\r\n",
          "Title: [bug] error in o16n with tool  notebooks; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\n\r\nthis is the error, it looks it is related to the deployment of aci and aks resources. \r\n\r\n\r\n```\r\n.fff.                                                                    [100%]\r\n=================================== failures ===================================\r\n_____________________________ test_21_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '/home/vsts/work/1/s/classification/notebooks/00_webcam.ipynb', '01_training_introduction': '/home/vsts/...3_training_accuracy_vs_speed': '/home/vsts/work/1/s/classification/notebooks/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.toolnotebooks\r\n    def test_21_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"21_deployment_on_azure_container_instances\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            parameters=dict(\r\n                pm_version=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=kernel_name,\r\n        )\r\n\r\ntests/smoke/test_tool_notebooks.py:58: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:108: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputhidden': true, 'hide_input': true}, 'execution_count': none, 'sour..._time': '2019-09-24t17:35:17.380577', 'duration': 1113.334717, 'exception': true}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"assigned parameters into the appropriate place in the input notebook\r\n    \r\n        parameters\r\n        ----------\r\n        nb : notebooknode\r\n           executable notebook object\r\n        output_path : str\r\n           path to write executed notebook\r\n        \"\"\"\r\n        error = none\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is none:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = papermillexecutionerror(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # write notebook back out with the error message at the top of the notebook.\r\n            error_msg = error_message_template % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text/html\": error_msg})\r\n                ],\r\n                metadata={\"inputhidden\": true, \"hide_input\": true},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\ne           papermill.exceptions.papermillexecutionerror: \r\ne           ---------------------------------------------------------------------------\r\ne           exception encountered at \"in [26]\":\r\ne           ---------------------------------------------------------------------------\r\ne           webserviceexception                       traceback (most recent call last)\r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/tool/core/webservice/webservice.py in wait_for_deployment(self, show_output)\r\ne               511                                           'error:\\n'\r\ne           --> 512                                           '{}'.format(self.state, logs_response, error_response), logger=module_logger)\r\ne               513             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\r\ne           \r\ne           webserviceexception: webserviceexception:\r\ne           \tmessage: service deployment polling reached non-successful terminal state, current service state: unhealthy\r\ne           more information can be found using '.get_logs()'\r\ne           error:\r\ne           {\r\ne             \"code\": \"acideploymentfailed\",\r\ne             \"message\": \"aci deployment failed with exception: your container application crashed. this may be caused by errors in your scoring file's init() function.\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\",\r\ne             \"details\": [\r\ne               {\r\ne                 \"code\": \"crashloopbackoff\",\r\ne                 \"message\": \"your container application crashed. this may be caused by errors in your scoring file's init() function.\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\"\r\ne               }\r\ne             ]\r\ne           }\r\ne           \tinnerexception none\r\ne           \terrorresponse \r\ne           {\r\ne               \"error\": {\r\ne                   \"message\": \"service deployment polling reached non-successful terminal state, current service state: unhealthy\\nmore information can be found using '.get_logs()'\\nerror:\\n{\\n  \\\"code\\\": \\\"acideploymentfailed\\\",\\n  \\\"message\\\": \\\"aci deployment failed with exception: your container application crashed. this may be caused by errors in your scoring file's init() function.\\\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"crashloopbackoff\\\",\\n      \\\"message\\\": \\\"your container application crashed. this may be caused by errors in your scoring file's init() function.\\\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\ne               }\r\ne           }\r\ne           \r\ne           during handling of the above exception, another exception occurred:\r\ne           \r\ne           webserviceexception                       traceback (most recent call last)\r\ne           <ipython-input-26-21aec20dbbb2> in <module>\r\ne                 1 # deploy the web service\r\ne           ----> 2 service.wait_for_deployment(show_output=true)\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/tool/core/webservice/webservice.py in wait_for_deployment(self, show_output)\r\ne               519                                           'current state is {}'.format(self.state), logger=module_logger)\r\ne               520             else:\r\ne           --> 521                 raise webserviceexception(e.message, logger=module_logger)\r\ne               522 \r\ne               523     def _wait_for_operation_to_complete(self, show_output):\r\ne           \r\ne           webserviceexception: webserviceexception:\r\ne           \tmessage: service deployment polling reached non-successful terminal state, current service state: unhealthy\r\ne           more information can be found using '.get_logs()'\r\ne           error:\r\ne           {\r\ne             \"code\": \"acideploymentfailed\",\r\ne             \"message\": \"aci deployment failed with exception: your container application crashed. this may be caused by errors in your scoring file's init() function.\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\",\r\ne             \"details\": [\r\ne               {\r\ne                 \"code\": \"crashloopbackoff\",\r\ne                 \"message\": \"your container application crashed. this may be caused by errors in your scoring file's init() function.\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\"\r\ne               }\r\ne             ]\r\ne           }\r\ne           \tinnerexception none\r\ne           \terrorresponse \r\ne           {\r\ne               \"error\": {\r\ne                   \"message\": \"service deployment polling reached non-successful terminal state, current service state: unhealthy\\nmore information can be found using '.get_logs()'\\nerror:\\n{\\n  \\\"code\\\": \\\"acideploymentfailed\\\",\\n  \\\"message\\\": \\\"aci deployment failed with exception: your container application crashed. this may be caused by errors in your scoring file's init() function.\\\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"crashloopbackoff\\\",\\n      \\\"message\\\": \\\"your container application crashed. this may be caused by errors in your scoring file's init() function.\\\\nplease check the logs for your container instance: im-classif-websvc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\ne               }\r\ne           }\r\n\r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:192: papermillexecutionerror\r\n----------------------------- captured stderr call -----------------------------\r\n\r\nexecuting:   0%|          | 0/65 [00:00<?, ?cell/s]\r\nexecuting:   2%|▏         | 1/65 [00:00<01:03,  1.01cell/s]\r\nexecuting:   5%|▍         | 3/65 [00:01<00:44,  1.40cell/s]\r\nexecuting:   8%|▊         | 5/65 [00:01<00:31,  1.92cell/s]\r\nexecuting:   9%|▉         | 6/65 [00:04<01:13,  1.24s/cell]\r\nexecuting:  12%|█▏        | 8/65 [00:05<01:00,  1.07s/cell]\r\nexecuting:  15%|█▌        | 10/65 [00:05<00:43,  1.27cell/s]\r\nexecuting:  18%|█▊        | 12/65 [00:05<00:30,  1.72cell/s]\r\nexecuting:  20%|██        | 13/65 [00:06<00:22,  2.26cell/s]\r\nexecuting:  23%|██▎       | 15/65 [00:07<00:23,  2.15cell/s]\r\nexecuting:  26%|██▌       | 17/65 [00:07<00:16,  2.87cell/s]\r\nexecuting:  28%|██▊       | 18/65 [00:13<01:34,  2.00s/cell]\r\nexecuting:  31%|███       | 20/65 [00:13<01:04,  1.43s/cell]\r\nexecuting:  32%|███▏      | 21/65 [00:15<01:06,  1.51s/cell]\r\nexecuting:  35%|███▌      | 23/65 [00:15<00:45,  1.08s/cell]\r\nexecuting:  37%|███▋      | 24/65 [00:16<00:45,  1.11s/cell]\r\nexecuting:  38%|███▊      | 25/65 [00:18<00:54,  1.37s/cell]\r\nexecuting:  42%|████▏     | 27/65 [00:18<00:37,  1.01cell/s]\r\nexecuting:  43%|████▎     | 28/65 [00:20<00:50,  1.37s/cell]\r\nexecuting:  45%|████▍     | 29/65 [00:21<00:38,  1.07s/cell]\r\nexecuting:  48%|████▊     | 31/65 [00:22<00:33,  1.01cell/s]\r\nexecuting:  51%|█████     | 33/65 [00:22<00:22,  1.39cell/s]\r\nexecuting:  52%|█████▏    | 34/65 [00:23<00:19,  1.61cell/s]\r\nexecuting:  54%|█████▍    | 35/65 [00:23<00:14,  2.11cell/s]\r\nexecuting:  57%|█████▋    | 37/65 [00:23<00:10,  2.76cell/s]\r\nexecuting:  58%|█████▊    | 38/65 [00:23<00:07,  3.41cell/s]\r\nexecuting:  62%|██████▏   | 40/65 [00:24<00:05,  4.18cell/s]\r\nexecuting:  65%|██████▍   | 42/65 [00:24<00:04,  5.02cell/s]\r\nexecuting:  66%|██████▌   | 43/65 [00:32<00:59,  2.70s/cell]\r\nexecuting:  68%|██████▊   | 44/65 [11:52<1:12:00, 205.75s/cell]\r\nexecuting:  69%|██████▉   | 45/65 [11:52<48:01, 144.08s/cell]  \r\nexecuting:  71%|███████   | 46/65 [11:53<32:00, 101.08s/cell]\r\nexecuting:  72%|███████▏  | 47/65 [11:53<21:14, 70.80s/cell] \r\nexecuting:  74%|███████▍  | 48/65 [11:53<14:03, 49.63s/cell]\r\nexecuting:  75%|███████▌  | 49/65 [11:53<09:16, 34.79s/cell]\r\nexecuting:  77%|███████▋  | 50/65 [11:53<06:05, 24.40s/cell]\r\nexecuting:  78%|███████▊  | 51/65 [11:56<04:07, 17.70s/cell]\r\nexecuting:  80%|████████  | 52/65 [11:56<02:41, 12.44s/cell]\r\nexecuting:  82%|████████▏ | 53/65 [18:32<25:30, 127.58s/cell]\r\nexecuting:  82%|████████▏ | 53/65 [18:33<04:12, 21.01s/cell] \r\n_____________________________ test_22_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '/home/vsts/work/1/s/classification/notebooks/00_webcam.ipynb', '01_training_introduction': '/home/vsts/...3_training_accuracy_vs_speed': '/home/vsts/work/1/s/classification/notebooks/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.toolnotebooks\r\n    def test_22_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"22_deployment_on_azure_kubernetes_service\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            parameters=dict(\r\n                pm_version=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=kernel_name,\r\n        )\r\n\r\ntests/smoke/test_tool_notebooks.py:83: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:108: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputhidden': true, 'hide_input': true}, 'execution_count': none, 'sour..._time': '2019-09-24t17:58:40.389449', 'duration': 1402.445046, 'exception': true}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"assigned parameters into the appropriate place in the input notebook\r\n    \r\n        parameters\r\n        ----------\r\n        nb : notebooknode\r\n           executable notebook object\r\n        output_path : str\r\n           path to write executed notebook\r\n        \"\"\"\r\n        error = none\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is none:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = papermillexecutionerror(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # write notebook back out with the error message at the top of the notebook.\r\n            error_msg = error_message_template % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text/html\": error_msg})\r\n                ],\r\n                metadata={\"inputhidden\": true, \"hide_input\": true},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\ne           papermill.exceptions.papermillexecutionerror: \r\ne           ---------------------------------------------------------------------------\r\ne           exception encountered at \"in [12]\":\r\ne           ---------------------------------------------------------------------------\r\ne           webserviceexception                       traceback (most recent call last)\r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/tool/core/webservice/webservice.py in wait_for_deployment(self, show_output)\r\ne               511                                           'error:\\n'\r\ne           --> 512                                           '{}'.format(self.state, logs_response, error_response), logger=module_logger)\r\ne               513             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\r\ne           \r\ne           webserviceexception: webserviceexception:\r\ne           \tmessage: service deployment polling reached non-successful terminal state, current service state: failed\r\ne           more information can be found using '.get_logs()'\r\ne           error:\r\ne           {\r\ne             \"code\": \"kubernetesdeploymentfailed\",\r\ne             \"statuscode\": 400,\r\ne             \"message\": \"kubernetes deployment failed\",\r\ne             \"details\": [\r\ne               {\r\ne                 \"code\": \"crashloopbackoff\",\r\ne                 \"message\": \"your container application crashed. this may be caused by errors in your scoring file's init() function.\\nplease check the logs for your container instance: aks-cpu-image-classif-web-svc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\"\r\ne               }\r\ne             ]\r\ne           }\r\ne           \tinnerexception none\r\ne           \terrorresponse \r\ne           {\r\ne               \"error\": {\r\ne                   \"message\": \"service deployment polling reached non-successful terminal state, current service state: failed\\nmore information can be found using '.get_logs()'\\nerror:\\n{\\n  \\\"code\\\": \\\"kubernetesdeploymentfailed\\\",\\n  \\\"statuscode\\\": 400,\\n  \\\"message\\\": \\\"kubernetes deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"crashloopbackoff\\\",\\n      \\\"message\\\": \\\"your container application crashed. this may be caused by errors in your scoring file's init() function.\\\\nplease check the logs for your container instance: aks-cpu-image-classif-web-svc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\ne               }\r\ne           }\r\ne           \r\ne           during handling of the above exception, another exception occurred:\r\ne           \r\ne           webserviceexception                       traceback (most recent call last)\r\ne           <ipython-input-12-ea5338712650> in <module>\r\ne                 8         deployment_target = aks_target\r\ne                 9     )\r\ne           ---> 10     aks_service.wait_for_deployment(show_output = true)\r\ne                11     print(f\"the web service is {aks_service.state}\")\r\ne                12 else:\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/tool/core/webservice/webservice.py in wait_for_deployment(self, show_output)\r\ne               519                                           'current state is {}'.format(self.state), logger=module_logger)\r\ne               520             else:\r\ne           --> 521                 raise webserviceexception(e.message, logger=module_logger)\r\ne               522 \r\ne               523     def _wait_for_operation_to_complete(self, show_output):\r\ne           \r\ne           webserviceexception: webserviceexception:\r\ne           \tmessage: service deployment polling reached non-successful terminal state, current service state: failed\r\ne           more information can be found using '.get_logs()'\r\ne           error:\r\ne           {\r\ne             \"code\": \"kubernetesdeploymentfailed\",\r\ne             \"statuscode\": 400,\r\ne             \"message\": \"kubernetes deployment failed\",\r\ne             \"details\": [\r\ne               {\r\ne                 \"code\": \"crashloopbackoff\",\r\ne                 \"message\": \"your container application crashed. this may be caused by errors in your scoring file's init() function.\\nplease check the logs for your container instance: aks-cpu-image-classif-web-svc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\"\r\ne               }\r\ne             ]\r\ne           }\r\ne           \tinnerexception none\r\ne           \terrorresponse \r\ne           {\r\ne               \"error\": {\r\ne                   \"message\": \"service deployment polling reached non-successful terminal state, current service state: failed\\nmore information can be found using '.get_logs()'\\nerror:\\n{\\n  \\\"code\\\": \\\"kubernetesdeploymentfailed\\\",\\n  \\\"statuscode\\\": 400,\\n  \\\"message\\\": \\\"kubernetes deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"crashloopbackoff\\\",\\n      \\\"message\\\": \\\"your container application crashed. this may be caused by errors in your scoring file's init() function.\\\\nplease check the logs for your container instance: aks-cpu-image-classif-web-svc. from the aml sdk, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nyou can also try to run image amlnotebookw04a7b513.azurecr.io/image-classif-resnet18-f48:1 locally. please refer to http://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\ne               }\r\ne           }\r\n\r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:192: papermillexecutionerror\r\n```\r\n\r\nfyi @patrickbue @jiata any idea of what could be happening?\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * windows/linux.  -->\r\n<!--- * cpu/gpu.  -->\r\n<!--- * azure data science virtual machine. -->\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a linux data science virtual machine one azure with v100 gpu -->\r\n<!--- * run unit test `test_classification_data.py` -->\r\n<!--- * ... -->\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the test `test_is_data_multilabel` for gpu model training should pass successfully. -->\r\n\r\n### other comments\r\n",
          "Title: [bug] tool endpoint appears unable to load model file / use image paths as features; Content:- [x] i have checked that this bug exists on the latest stable version of autogluon\r\n- [ ] and/or i have checked that this bug exists on the latest mainline of autogluon via source installation\r\n\r\n**describe the bug**\r\n```python\r\n...\r\nmodelerror: an error occurred (modelerror) when calling the invokeendpoint operation: received server error (500) from primary with message \"[errno 2] no such file or directory: '/.tool/mms/models/model/predictor.pkl'\r\n...\r\nfilenotfounderror: [errno 2] no such file or directory: '/.tool/mms/models/model/predictor.pkl'\r\n```\r\n\r\nit appears that the tool endpoint isn't able to find / open the model file. i was able to use the example code in the tutorial [deploying autogluon models with aws tool](https://auto.gluon.ai/stable/tutorials/cloud_fit_deploy/cloud-aws-tool-deployment.html) and managed to deploy an endpoint to tool. but i get this error when i go to make predictions with test data. i wonder if this might be related to transition from mxnet to pytorch and how their artifacts are typically stored? i'm using `v0.4.0` but the predictor object is `tool.mxnet.model.mxnetpredictor`. this discrepancy in framework seems supported be a related error that i found in a github issue [here](https://github.com/aws/amazon-tool-examples/issues/1238).\r\n\r\nnote also that i am attempting to adapt the example model trained in the [multi-modal documentation](https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-multimodal.html) (i.e., using the petfinder dataset), because i'm ultimately try to deploy a multi-modal model and figure out how to pass image_paths to the tool endpoint. \r\n\r\nhere's the full traceback:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nmodelerror                                traceback (most recent call last)\r\n<ipython-input-51-abf97eb84e0a> in <module>\r\n----> 1 predictions = predictor.predict(test_data[:1].values)\r\n\r\n~/anaconda3/envs/betterbin/lib/python3.8/site-packages/tool/predictor.py in predict(self, data, initial_args, target_model, target_variant, inference_id)\r\n    159             data, initial_args, target_model, target_variant, inference_id\r\n    160         )\r\n--> 161         response = self.tool_session.tool_runtime_client.invoke_endpoint(**request_args)\r\n    162         return self._handle_response(response)\r\n    163 \r\n\r\n~/anaconda3/envs/betterbin/lib/python3.8/site-packages/botocore/client.py in _api_call(self, *args, **kwargs)\r\n    389                     \"%s() only accepts keyword arguments.\" % py_operation_name)\r\n    390             # the \"self\" in this scope is referring to the baseclient.\r\n--> 391             return self._make_api_call(operation_name, kwargs)\r\n    392 \r\n    393         _api_call.__name__ = str(py_operation_name)\r\n\r\n~/anaconda3/envs/betterbin/lib/python3.8/site-packages/botocore/client.py in _make_api_call(self, operation_name, api_params)\r\n    717             error_code = parsed_response.get(\"error\", {}).get(\"code\")\r\n    718             error_class = self.exceptions.from_code(error_code)\r\n--> 719             raise error_class(parsed_response, operation_name)\r\n    720         else:\r\n    721             return parsed_response\r\n\r\nmodelerror: an error occurred (modelerror) when calling the invokeendpoint operation: received server error (500) from primary with message \"[errno 2] no such file or directory: '/.tool/mms/models/model/predictor.pkl'\r\ntraceback (most recent call last):\r\n  file \"/usr/local/lib/python3.8/dist-packages/tool_inference/transformer.py\", line 110, in transform\r\n    self.validate_and_initialize(model_dir=model_dir)\r\n  file \"/usr/local/lib/python3.8/dist-packages/tool_inference/transformer.py\", line 158, in validate_and_initialize\r\n    self._model = self._model_fn(model_dir)\r\n  file \"/opt/ml/model/code/tabular_serve.py\", line 11, in model_fn\r\n    model = tabularpredictor.load(model_dir)\r\n  file \"/usr/local/lib/python3.8/dist-packages/autogluon/tabular/predictor/predictor.py\", line 2816, in load\r\n    predictor = cls._load(path=path)\r\n  file \"/usr/local/lib/python3.8/dist-packages/autogluon/tabular/predictor/predictor.py\", line 2772, in _load\r\n    predictor: tabularpredictor = load_pkl.load(path=path + cls.predictor_file_name)\r\n  file \"/usr/local/lib/python3.8/dist-packages/autogluon/common/loaders/load_pkl.py\", line 37, in load\r\n    with compression_fn_map[compression_fn]['open'](validated_path, 'rb', **compression_fn_kwargs) as fin:\r\nfilenotfounderror: [errno 2] no such file or directory: '/.tool/mms/models/model/predictor.pkl'\r\n```\r\n\r\n**expected behavior**\r\na clear and concise description of what you expected to happen.\r\n\r\n**to reproduce**\r\n\r\n1. train a multi modal model, using code adapted from [multimodal data tables: tabular, text, and image tutorial](https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-multimodal.html): [petfinder_train.py](https://gist.github.com/ijmiller2/f5837977077674fe741fee031d2bad2a)\r\n2. deploy the pet finder model: [petfinder_deploy.py](https://gist.github.com/ijmiller2/f6b21c2b0b40211161d1fb0252542189)\r\n\r\n**screenshots**\r\nna\r\n\r\n**installed versions**\r\nwhich version of autogluon are you are using?  \r\n`0.4.0`\r\n<details>\r\n\r\n```python\r\n# replace this code with the output of the following:\r\ninstalled versions\r\n------------------\r\ndate                 : 2022-04-02\r\ntime                 : 19:45:52.692253\r\npython               : 3.9.7.final.0\r\nos                   : linux\r\nos-release           : 5.4.0-66-generic\r\nversion              : #74~18.04.2-ubuntu smp fri feb 5 11:17:31 utc 2021\r\nmachine              : x86_64\r\nprocessor            : x86_64\r\nnum_cores            : 12\r\ncpu_ram_mb           : 64324\r\ncuda version         : none\r\nnum_gpus             : 0\r\ngpu_ram_mb           : []\r\navail_disk_size_mb   : 289302\r\n\r\nautogluon.common     : 0.4.0\r\nautogluon.core       : 0.4.0\r\nautogluon.features   : 0.4.0\r\nautogluon.tabular    : 0.4.0\r\nautogluon.text       : 0.4.0\r\nautogluon.vision     : 0.4.0\r\nautogluon_contrib_nlp: none\r\nboto3                : 1.21.21\r\ncatboost             : 1.0.4\r\ndask                 : 2021.11.2\r\ndistributed          : 2021.11.2\r\nfairscale            : 0.4.6\r\nfastai               : 2.5.3\r\ngluoncv              : 0.11.0\r\nlightgbm             : 3.3.2\r\nmatplotlib           : 3.5.1\r\nnetworkx             : 2.7.1\r\nnptyping             : 1.4.4\r\nnumpy                : 1.22.3\r\nomegaconf            : 2.1.1\r\npandas               : 1.3.5\r\npil                  : 9.0.1\r\npsutil               : 5.8.0\r\npytorch_lightning    : 1.5.10\r\nray                  : 1.8.0\r\nrequests             : 2.27.1\r\nscipy                : 1.7.3\r\nsentencepiece        : none\r\nskimage              : 0.19.2\r\nsklearn              : 1.0.2\r\nsmart_open           : 5.2.1\r\ntimm                 : 0.5.4\r\ntorch                : 1.10.1+cpu\r\ntorchmetrics         : 0.7.2\r\ntqdm                 : 4.63.0\r\ntransformers         : 4.16.2\r\nxgboost              : 1.4.2\r\n```\r\n\r\n</details>\r\n\r\n**additional context**\r\n\r\ni am attempting to follow the [tutorial to deploy a model via tool](https://auto.gluon.ai/stable/tutorials/cloud_fit_deploy/cloud-aws-tool-deployment.html), however, adapting to use the example model trained in the [multi-modal documentation](https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-multimodal.html) (i.e., using the petfinder dataset).\r\n",
          "Title: problems using gpu with tool on aws-instance \"ml.p2.xlarge\".; Content:## description\r\nusing tool on an aws gpu-instance \"ml.p2.xlarge\", i was not able to run the example `benchmark_m4.py` script (copy/pasted in tool) on gpu. \r\n\r\n## to reproduce\r\nafter starting the instance: \r\n```\r\n!pip install gluonts\r\n```\r\n\r\nnext cell: paste the slightly modified script `benchmark_m4.py` with a little modification:\r\n \r\n```python\r\nestimators = [\r\n    partial(\r\n        deeparestimator,\r\n        trainer=trainer(\r\n            epochs=epochs, \r\n            num_batches_per_epoch=num_batches_per_epoch,\r\n            ctx=\"gpu\"\r\n        ),\r\n    ),\r\n]\r\n```\r\n(without specifying the context this works fine, but is only running on cpu)\r\n\r\n## error message\r\n\r\n```\r\ninfo:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_quarterly.\r\ninfo:root:start model training\r\ninfo:root:using dataset already processed in path /home/ec2-user/.mxnet/gluon-ts/datasets/m4_yearly.\r\ninfo:root:start model training\r\nevaluating gluonts.model.deepar._estimator.deeparestimator(cardinality=[24000], cell_type=\"lstm\", context_length=none, distr_output=gluonts.distribution.student_t.studenttoutput(), dropout_rate=0.1, embedding_dimension=20, freq=\"3m\", lags_seq=none, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=8, scaling=true, time_features=none, trainer=gluonts.trainer._base.trainer(batch_size=32, clip_gradient=10.0, ctx=mxnet.context.context(\"gpu\", 0), epochs=100, hybridize=true, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08), use_feat_dynamic_real=false, use_feat_static_cat=true) on traindatasets(metadata=<metadata freq='3m' target=none feat_static_cat=[<categoricalfeatureinfo name='feat_static_cat' cardinality='24000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=8>, train=<gluonts.dataset.common.filedataset object at 0x7f9377c9e748>, test=<gluonts.dataset.common.filedataset object at 0x7f9377c53208>)\r\n[22:17:01] src/ndarray/ndarray.cc:1279: gpu is not enabled\r\n\r\nstack trace returned 10 entries:\r\n[bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23d55a) [0x7f93951c155a]\r\n[bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23dbc1) [0x7f93951c1bc1]\r\n[bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::copyfromto(mxnet::ndarray const&, mxnet::ndarray const&, int, bool)+0x723) [0x7f9397cf7623]\r\n[bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::pushfcomputeex(std::function<void (nnvm::nodeattrs const&, mxnet::opcontext const&, std::vector<mxnet::ndarray, std::allocator<mxnet::ndarray> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&, std::vector<mxnet::ndarray, std::allocator<mxnet::ndarray> > const&)> const&, nnvm::op const*, nnvm::nodeattrs const&, mxnet::context const&, std::vector<mxnet::engine::var*, std::allocator<mxnet::engine::var*> > const&, std::vector<mxnet::engine::var*, std::allocator<mxnet::engine::var*> > const&, std::vector<mxnet::resource, std::allocator<mxnet::resource> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&)+0x47e) [0x7f9397bad59e]\r\n[bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::invokeop(mxnet::context const&, nnvm::nodeattrs const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&, mxnet::dispatchmode, mxnet::opstateptr)+0x839) [0x7f9397bb28f9]\r\n[bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::invoke(mxnet::context const&, nnvm::nodeattrs const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&)+0x38c) [0x7f9397bb317c]\r\n[bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b34989) [0x7f9397ab8989]\r\n[bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mximperativeinvokeex+0x6f) [0x7f9397ab8f7f]\r\n[bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f93d58efec0]\r\n[bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f93d58ef87d]\r\n\r\n\r\nevaluating gluonts.model.deepar._estimator.deeparestimator(cardinality=[23000], cell_type=\"lstm\", context_length=none, distr_output=gluonts.distribution.student_t.studenttoutput(), dropout_rate=0.1, embedding_dimension=20, freq=\"12m\", lags_seq=none, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=6, scaling=true, time_features=none, trainer=gluonts.trainer._base.trainer(batch_size=32, clip_gradient=10.0, ctx=mxnet.context.context(\"gpu\", 0), epochs=100, hybridize=true, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08), use_feat_dynamic_real=false, use_feat_static_cat=true) on traindatasets(metadata=<metadata freq='12m' target=none feat_static_cat=[<categoricalfeatureinfo name='feat_static_cat' cardinality='23000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=6>, train=<gluonts.dataset.common.filedataset object at 0x7f937812ce48>, test=<gluonts.dataset.common.filedataset object at 0x7f9377c53208>)\r\n[22:17:01] src/ndarray/ndarray.cc:1279: gpu is not enabled\r\n\r\nstack trace returned 10 entries:\r\n[bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23d55a) [0x7f93951c155a]\r\n[bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23dbc1) [0x7f93951c1bc1]\r\n[bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::copyfromto(mxnet::ndarray const&, mxnet::ndarray const&, int, bool)+0x723) [0x7f9397cf7623]\r\n[bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::pushfcomputeex(std::function<void (nnvm::nodeattrs const&, mxnet::opcontext const&, std::vector<mxnet::ndarray, std::allocator<mxnet::ndarray> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&, std::vector<mxnet::ndarray, std::allocator<mxnet::ndarray> > const&)> const&, nnvm::op const*, nnvm::nodeattrs const&, mxnet::context const&, std::vector<mxnet::engine::var*, std::allocator<mxnet::engine::var*> > const&, std::vector<mxnet::engine::var*, std::allocator<mxnet::engine::var*> > const&, std::vector<mxnet::resource, std::allocator<mxnet::resource> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&)+0x47e) [0x7f9397bad59e]\r\n[bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::invokeop(mxnet::context const&, nnvm::nodeattrs const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&, mxnet::dispatchmode, mxnet::opstateptr)+0x839) [0x7f9397bb28f9]\r\n[bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::invoke(mxnet::context const&, nnvm::nodeattrs const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&)+0x38c) [0x7f9397bb317c]\r\n[bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b34989) [0x7f9397ab8989]\r\n[bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mximperativeinvokeex+0x6f) [0x7f9397ab8f7f]\r\n[bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f93d58efec0]\r\n[bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f93d58ef87d]\r\n\r\n\r\n---------------------------------------------------------------------------\r\nkeyerror                                  traceback (most recent call last)\r\n<ipython-input-15-b3fbc3bdf424> in <module>()\r\n     88             \"mase\",\r\n     89             \"smape\",\r\n---> 90             \"msis\",\r\n     91         ]\r\n     92     ]\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key)\r\n   2999             if is_iterator(key):\r\n   3000                 key = list(key)\r\n-> 3001             indexer = self.loc._convert_to_indexer(key, axis=1, raise_missing=true)\r\n   3002 \r\n   3003         # take() does not accept boolean indexers\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pandas/core/indexing.py in _convert_to_indexer(self, obj, axis, is_setter, raise_missing)\r\n   1283                 # when setting, missing keys are not allowed, even with .loc:\r\n   1284                 kwargs = {\"raise_missing\": true if is_setter else raise_missing}\r\n-> 1285                 return self._get_listlike_indexer(obj, axis, **kwargs)[1]\r\n   1286         else:\r\n   1287             try:\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis, raise_missing)\r\n   1090 \r\n   1091         self._validate_read_indexer(\r\n-> 1092             keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing\r\n   1093         )\r\n   1094         return keyarr, indexer\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing)\r\n   1175                 raise keyerror(\r\n   1176                     \"none of [{key}] are in the [{axis}]\".format(\r\n-> 1177                         key=key, axis=self.obj._get_axis_name(axis)\r\n   1178                     )\r\n   1179                 )\r\n\r\nkeyerror: \"none of [index(['dataset', 'estimator', 'rmse', 'mean_wquantileloss', 'mase', 'smape',\\n       'msis'],\\n      dtype='object')] are in the [columns]\"\r\n```\r\n\r\n## other\r\nin addition, before installing gluonts (from https://beta.mxnet.io/guide/crash-course/6-use_gpus.html): \r\n```python\r\nx = nd.ones((3,4), ctx=gpu())\r\nx\r\n```\r\n```\r\n[[1. 1. 1. 1.]\r\n [1. 1. 1. 1.]\r\n [1. 1. 1. 1.]]\r\n<ndarray 3x4 @gpu(0)>\r\n```\r\n\r\nafter installing gluonts: \r\n\r\n```python\r\nx = nd.ones((3,4), ctx=gpu())\r\nx\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nmxneterror                                traceback (most recent call last)\r\n<ipython-input-16-749bd657d613> in <module>()\r\n      5 \r\n      6 \r\n----> 7 x = nd.ones((3,4), ctx=gpu())\r\n      8 x\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py in ones(shape, ctx, dtype, **kwargs)\r\n   2419     dtype = mx_real_t if dtype is none else dtype\r\n   2420     # pylint: disable= no-member, protected-access\r\n-> 2421     return _internal._ones(shape=shape, ctx=ctx, dtype=dtype, **kwargs)\r\n   2422     # pylint: enable= no-member, protected-access\r\n   2423 \r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/register.py in _ones(shape, ctx, dtype, out, name, **kwargs)\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py in _imperative_invoke(handle, ndargs, keys, vals, out)\r\n     90         c_str_array(keys),\r\n     91         c_str_array([str(s) for s in vals]),\r\n---> 92         ctypes.byref(out_stypes)))\r\n     93 \r\n     94     if original_output is not none:\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)\r\n    250     \"\"\"\r\n    251     if ret != 0:\r\n--> 252         raise mxneterror(py_str(_lib.mxgetlasterror()))\r\n    253 \r\n    254 \r\n\r\nmxneterror: [22:29:51] src/imperative/imperative.cc:79: operator _ones is not implemented for gpu.\r\n\r\nstack trace returned 10 entries:\r\n[bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23d55a) [0x7f93951c155a]\r\n[bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23dbc1) [0x7f93951c1bc1]\r\n[bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::invokeop(mxnet::context const&, nnvm::nodeattrs const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::opreqtype, std::allocator<mxnet::opreqtype> > const&, mxnet::dispatchmode, mxnet::opstateptr)+0x9fb) [0x7f9397bb2abb]\r\n[bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::invoke(mxnet::context const&, nnvm::nodeattrs const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&, std::vector<mxnet::ndarray*, std::allocator<mxnet::ndarray*> > const&)+0x38c) [0x7f9397bb317c]\r\n[bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b34989) [0x7f9397ab8989]\r\n[bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mximperativeinvokeex+0x6f) [0x7f9397ab8f7f]\r\n[bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f93d58efec0]\r\n[bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f93d58ef87d]\r\n[bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f93d5b04e2e]\r\n[bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865) [0x7f93d5b05865]\r\n```\r\n\r\n## environment\r\n\r\n- tool, running on aws instance \"ml.p2.xlarge\". \r\n- gluonts version: 0.3.3 installed using pip.\r\n- kernel: conda_mxnet_p36 \r\n\r\n",
          "Title: [bug] \"open in in tool studio lab\" button process fails when attempting to \"copy notebooks only\"; Content:**describe the bug**\r\ncloning a single notebook using the \"open in in tool studio lab\" fails.  cloning the whole repo works.  \r\n\r\nusing tool's sample, https://github.com/aws/studio-lab-examples/tree/main/open-in-studio-lab, i get this error:\r\n```\r\nunable to copy notebook to project.\r\nthe link to this notebook is broken or blocked. if this is a private github notebook, sign in to github before copying the notebook.aws/studio-lab-examples/blob/main/natural-language-processing/nlp_disaster_recovery_translation.ipynb\r\n```\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. create md cell with `[![open in tool studio lab](https://studiolab.tool.aws/studiolab.svg)](https://studiolab.tool.aws/import/github/aws/studio-lab-examples/blob/main/natural-language-processing/nlp_disaster_recovery_translation.ipynb)`  and run it\r\n2. click on the button that appears once you run the cell.  will open new tab in browser\r\n3. in the new pop up tab, click \"copy to project\".  will open new tab in browser\r\n4. in the new pop up tab's modal, select \"copy notebook only\"\r\n5. error will now appear\r\n\r\n**expected behavior**\r\nmy notebook will open and appear, just as it would with cloning a directory\r\n\r\n**screenshots**\r\n![image](https://user-images.githubusercontent.com/46935140/151415892-7d033f97-f98c-4ac8-9c50-99223253b1ee.png)\r\n\r\n**desktop (please complete the following information):**\r\n - os: [windows 11]\r\n - browser [chrome]\r\n - version [97.0.4692.71]\r\n\r\n",
          "Title: error when starting new experiment in tool; Content:error in pipeline in githubactions\r\n`14:25:43.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stdout: starting tool ui on port 5000\r\n14:25:46.430 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: 2020/12/19 14:25:46 info tool.store.db.utils: creating initial tool database tables...\r\n14:25:46.453 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: 2020/12/19 14:25:46 info tool.store.db.utils: creating initial tool database tables...\r\n14:25:46.468 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: 2020/12/19 14:25:46 error tool.cli: error initializing backend store\r\n14:25:46.480 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: ]\r\n14:25:46.483 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.484 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: )\r\n14:25:46.485 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tforeign key(experiment_id) references experiments (experiment_id)\r\n14:25:46.487 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint runs_lifecycle_stage check (lifecycle_stage in ('active', 'deleted')), \r\n14:25:46.489 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint status check (status in ('scheduled', 'failed', 'finished', 'running')), \r\n14:25:46.491 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint source_type check (source_type in ('notebook', 'job', 'local', 'unknown', 'project')), \r\n14:25:46.493 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint run_pk primary key (run_uuid), \r\n14:25:46.495 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \texperiment_id integer, \r\n14:25:46.496 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tartifact_uri varchar(200), \r\n14:25:46.497 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tlifecycle_stage varchar(20), \r\n14:25:46.500 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tsource_version varchar(50), \r\n14:25:46.505 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tend_time bigint, \r\n14:25:46.509 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tstart_time bigint, \r\n14:25:46.509 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tstatus varchar(20), \r\n14:25:46.509 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tuser_id varchar(256), \r\n14:25:46.510 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tentry_point_name varchar(50), \r\n14:25:46.510 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tsource_name varchar(500), \r\n14:25:46.510 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tsource_type varchar(20), \r\n14:25:46.510 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tname varchar(250), \r\n14:25:46.511 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \trun_uuid varchar(32) not null, \r\n14:25:46.511 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: (background on this error at: http://sqlalche.me/e/gkpj)\r\n14:25:46.511 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.516 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: the above exception was the direct cause of the following exception:\r\n14:25:46.516 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\n14:25:46.517 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1618, in _run_visitor\r\n14:25:46.517 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     conn._run_visitor(visitorcallable, element, **kwargs)\r\n14:25:46.518 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     visitorcallable(self.dialect, self, **kwargs).traverse_single(element)\r\n14:25:46.541 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: (background on this error at: http://sqlalche.me/e/gkpj)\r\n14:25:46.541 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: ]\r\n14:25:46.541 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.541 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: )\r\n14:25:46.542 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tforeign key(experiment_id) references experiments (experiment_id)\r\n14:25:46.542 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint runs_lifecycle_stage check (lifecycle_stage in ('active', 'deleted')), \r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: 2020/12/19 14:25:46 info tool.store.db.utils: updating database tables\r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: info  [alembic.runtime.migration] running upgrade  -> 451aebb31d03, add metric step\r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: info  [alembic.runtime.migration] will assume transactional ddl.\r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: info  [alembic.runtime.migration] context impl postgresqlimpl.\r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint status check (status in ('scheduled', 'failed', 'finished', 'running')), \r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint source_type check (source_type in ('notebook', 'job', 'local', 'unknown', 'project')), \r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tconstraint run_pk primary key (run_uuid), \r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \texperiment_id integer, \r\n14:25:46.543 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tartifact_uri varchar(200), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: info  [alembic.runtime.migration] running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tlifecycle_stage varchar(20), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tsource_version varchar(50), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tend_time bigint, \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tstart_time bigint, \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tstatus varchar(20), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tuser_id varchar(256), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tentry_point_name varchar(50), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tsource_name varchar(500), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tsource_type varchar(20), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \tname varchar(250), \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \trun_uuid varchar(32) not null, \r\n14:25:46.548 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: create table runs (\r\n14:25:46.549 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: [sql: \r\n14:25:46.549 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.549 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: detail:  key (typname, typnamespace)=(runs, 2200) already exists.\r\n14:25:46.549 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: sqlalchemy.exc.integrityerror: (psycopg2.errors.uniqueviolation) duplicate key value violates unique constraint \"pg_type_typname_nsp_index\"\r\n14:25:46.549 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     cursor.execute(statement, parameters)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 588, in do_execute\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     self.dialect.do_execute(\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1245, in _execute_context\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     raise value.with_traceback(tb)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py\", line 152, in reraise\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py\", line 398, in raise_from_cause\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     util.raise_from_cause(sqlalchemy_exception, exc_info)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1476, in _handle_dbapi_exception\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     self._handle_dbapi_exception(\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1249, in _execute_context\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     ret = self._execute_context(\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1039, in _execute_ddl\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     return connection._execute_ddl(self, multiparams, params)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/ddl.py\", line 72, in _execute_on_connection\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     return meth(self, multiparams, params)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 982, in execute\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     self.connection.execute(\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/ddl.py\", line 821, in visit_table\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     return meth(obj, **kw)\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py\", line 138, in traverse_single\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     self.traverse_single(\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/ddl.py\", line 777, in visit_metadata\r\n14:25:46.550 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     return meth(obj, **kw)\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: info  [alembic.runtime.migration] running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py\", line 138, in traverse_single\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 2049, in _run_visitor\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     bind._run_visitor(\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/schema.py\", line 4315, in create_all\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     initialbase.metadata.create_all(engine)\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/store/db/utils.py\", line 30, in _initialize_tables\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     tool.store.db.utils._initialize_tables(self.engine)\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/store/tracking/sqlalchemy_store.py\", line 99, in __init__\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     return sqlalchemystore(store_uri, artifact_uri)\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/server/handlers.py\", line 64, in _get_sqlalchemy_store\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     return builder(store_uri=store_uri, artifact_uri=artifact_uri)\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/tracking/_tracking_service/registry.py\", line 37, in get_store\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/server/handlers.py\", line 91, in _get_tracking_store\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     _get_tracking_store(backend_store_uri, default_artifact_root)\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/server/handlers.py\", line 105, in initialize_backend_stores\r\n14:25:46.564 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     initialize_backend_stores(backend_store_uri, default_artifact_root)\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/tool/cli.py\", line 291, in server\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: traceback (most recent call last):\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: detail:  key (typname, typnamespace)=(runs, 2200) already exists.\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: psycopg2.errors.uniqueviolation: duplicate key value violates unique constraint \"pg_type_typname_nsp_index\"\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     cursor.execute(statement, parameters)\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 588, in do_execute\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:     self.dialect.do_execute(\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr:   file \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1245, in _execute_context\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: traceback (most recent call last):\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: create table runs (\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: [sql: \r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: \r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: detail:  key (typname, typnamespace)=(runs, 2200) already exists.\r\n14:25:46.565 [ducttape-1] debug org.testcontainers.containers.output.waitingconsumer - stderr: 2020/12/19 14:25:46 error tool.cli: (psycopg2.errors.uniqueviolation) duplicate key value violates unique constraint \"pg_type_typname_nsp_index\"`\r\nwhich causes test to not pass",
          "Title: tool_catalyst.ipynb fails; Content:seems that the tool_catalyst.ipynb is failing. \r\nperhaps there is some type as it seems to be missing the `run` object. \r\nhttps://github.com/tool-ai/examples/runs/2932574924?check_suite_focus=true",
          "Title: [air] fix  //doc/source/tune/examples:tool_example; Content:### what happened + what you expected to happen\n\nnotebook is broken due to missing permission first, maybe more issues down the road. @yard1 looked into it earlier and we're creating this issue to keep track of it.\n\n### versions / dependencies\n\nmaster\n\n### reproduction script\n\n`bazel test //doc/source/tune/examples:tool_example`\n\n### issue severity\n\nmedium: it is a significant difficulty but i can work around it.",
          "Title: [feature_request] provide guidance on how to obtain a subscription id in 11_exploring_hyperparameters_on_tool notebook; Content:### description\r\n\r\nusers need to modify the third code cell to specific a subscription id and the names that will be used for creating a resource group, workspace, etc. some guidance within the notebook on how to obtain these values and fill in the strings would be helpful.\r\n\r\nit would also be nice to throw an error in this code cell if users forget to fill in the values, so that users don't encounter a cryptic error from the call to `get_or_create_workspace()` later on.\r\n\r\n### expected behavior with the suggested feature\r\n\r\nusers who forget to fill in the string values in this code cell are alerted to the issue by an error message from this code cell. novice users receive some guidance on how to obtain their azure subscription id without having to reference other notebooks.\r\n\r\n### other comments\r\n",
          "Title: [bug]: tool server integration; Content:### pycaret version checks\n\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\n\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\n\n- [ ] i have confirmed this bug exists on the master branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@master).\n\n\n### issue description\n\ni have a problem saving xgboost run in tool server. the run has a status of unfinished, no metrics or artifacts are created. \r\n\r\n![image](https://user-images.githubusercontent.com/101572186/183577670-53398204-debf-428b-8b0c-3c7ca83f4785.png)\r\n\r\nwhen i use `tool ui` everything is fine, but when i run tool server with sqlite as backend store the problem occurs.\r\ncommand used to run tool server- `tool server --host 0.0.0.0 --port 5000 --default-artifact-root /tool/artifacts/ --backend-store-uri sqlite://///tool/experiments/tool.db`\n\n### reproducible example\n\n```python\nimport tool\r\nfrom pycaret.classification import *\r\nimport pandas as pd\r\n\r\ntool.set_tracking_uri('http://localhost:5000')\r\n\r\ndata = pd.dataframe({'v1': [-1.34419, -1.89211, 1.69421, 0.263328, 0.107918, 0.154241, 0.33468, 1.447778, -0.918269, 0.86319, -1.630049, 1.643798, 1.274341, -1.296742, -0.193585, 1.627422, -0.66805, -1.664491, -1.86911, 0.892885],\r\n                     'v2': [0.85556, -1.70503, -0.02896, 1.746258, -0.084151, 1.673185, 1.113326, -0.23231, 1.054817, -1.407584, 0.474997, 0.150687, -0.738246, -0.045513, 1.58637, 0.984249, 0.624333, 0.298866, 0.662204, 0.967942],\r\n                     'v3': [1.768638, -0.503169, -0.25622, -0.937752, -0.062189, -0.820652, -1.786942, -1.770495, 1.808681, -0.280286, -1.389736, 0.182212, -0.602959, -0.354683, -1.065631, 1.649264, 0.389538, -1.674815, 0.281824, -1.683662],\r\n                     'v4': [1.512828, 1.177697, -1.156862, -1.877876, 1.526013, 1.644001, -1.282481, -0.720543, 0.323963, -1.931616, 1.632839, 1.706752, 1.895627, 1.860705, -1.559702, 1.517466, 1.254323, 1.84415, -1.175013, -1.600652],\r\n                     'v5': [0.820483, -1.20923, -0.012221, 1.682836, 0.104248, 1.258085, 0.404062, 0.18019, 1.352545, -0.497071, 0.771277, 1.614052, -0.693854, 0.002655, 0.277743, -0.977744, -0.97259, -1.501586, -0.731194, -0.551264],\r\n                     'v6': [1.079115, -0.734152, -1.630816, -1.877664, 1.577477, -1.902078, 1.012828, -1.107726, 1.742781, -1.338595, 1.788969, -0.851507, 1.061596, -0.635559, -1.171469, -1.001642, 1.493507, 0.732088, 1.565327, -1.845441],\r\n                     'v7': [1.165929, 1.804607, 0.886589, -0.027458, -1.444197, -0.415643, 0.863924, -1.177661, 1.684514, 1.023797, -1.234116, -0.989024, 0.815575, -0.668453, 0.591911, -0.798925, 1.024032, -1.983963, 1.900752, 1.201001],\r\n                     'v8': [-0.536923, 0.641581, -0.585228, 1.061145, -0.303192, -0.652068, 0.858556, 0.11012, 1.839738, -1.51798, -0.942028, -0.736386, -0.098261, 0.699127, 0.173854, -1.16775, -0.417662, 0.021639, 1.745042, -1.119667],\r\n                     'v9': [0.643498, -1.090347, 0.120182, -0.819219, -1.296763, 0.530723, -1.367664, -0.708116, -1.304274, 1.486166, 1.656498, 1.645308, -0.257558, 0.400849, 1.356781, 1.693433, 0.42606, 0.370683, -0.239278, -0.541334],\r\n                     'v10': [-0.744989, 0.506658, 1.15586, 1.461127, 1.928769, -0.330472, 1.514159, -1.209056, -0.741453, -1.479674, 1.92057, -1.148481, 0.949433, 0.674107, -1.410627, 1.497083, -1.262624, -0.856706, -1.708155, 0.93153],\r\n                     'v11': [0.967242, 1.968385, -1.362337, -0.46194, 0.809224, 0.226177, 1.782128, -0.114595, 0.698243, -0.141743, -0.117251, 1.762656, -0.068839, 0.648945, -1.497037, -1.455443, -0.291242, 1.806048, -1.945438, 0.251282],\r\n                     'v12': [0.010432, -0.101522, -1.764095, 1.326967, -1.299122, -0.549148, 0.807092, -0.75387, 0.955056, 0.640369, -0.917832, 0.250338, 0.624729, 1.566922, 0.118619, 1.907585, -0.919995, 0.868393, -1.103909, 0.347108],\r\n                     'v13': [0.122315, -1.140017, -0.876424, -1.075771, 0.668814, 1.916654, -0.864906, 0.132892, 0.740058, 0.94469, -0.260381, 0.92833, -1.186423, -0.18321, 1.99266, -0.779091, -1.649025, -1.688821, 1.075145, -1.988603],\r\n                     'v14': [-1.494, 0.679776, 0.813194, 1.8687, -0.20273, -0.363265, 1.98902, 0.100025, 1.462866, 0.561017, 0.418922, 1.981837, -1.834009, -1.657952, 0.585069, -0.898764, 0.683234, 0.743215, -0.050289, -0.668302], \r\n                     'v15': [0.199787, 0.81829, 1.200156, -1.684249, 0.847466, 1.326102, 0.323103, -1.010648, -1.868355, -1.204467, 1.777393, 0.375692, -1.654002, 0.50357, -1.372448, -0.522425, 0.360716, 1.007605, 1.009369, -0.353638],\r\n                     'v16': [1.535552, -0.082278, -0.083154, 0.069432, 1.356735, -0.042527, -0.462543, 1.813852, -1.664882, 0.408013, -1.802172, -1.920202, 1.987332, -1.126771, 1.485496, 1.972345, -0.33345, 1.414685, -0.06674, 1.383197],\r\n                     'v17': [-0.249929, 1.668129, 0.860046, 0.013955, 0.085628, 1.285539, -0.754444, -0.306815, -1.244118, -0.61328, 0.711952, 1.384674, 1.710264, 1.337836, -0.029678, -1.382343, -1.963618, 0.088497, -0.110544, 0.954066],\r\n                     'v18': [0.665032, -1.214589, 0.486172, 1.184611, 1.152936, -0.192168, -1.096281, -0.762198, -0.338583, 0.170551, -0.045797, -0.897271, 0.433204, -0.986375, 0.430157, 1.846751, -0.905146, -1.398763, 1.790667, -1.580808],\r\n                     'v19': [1.347637, -0.356925, 0.414118, 0.277104, 0.41587, -1.237646, 0.580625, 1.468221, -0.254781, 0.245683, -1.25356, 0.241325, 1.15677, -1.74525, 1.970698, -0.038675, -0.314979, 0.114507, 1.378524, -0.139709],\r\n                     'v20': [-1.291686, -1.714475, 0.012188, 1.002238, -1.587334, 1.408967, 1.055095, -1.356865, 1.307388, 0.697003, -0.112676, 1.762375, 0.82697, 1.084934, 1.656421, 0.786079, -1.580991, 1.753751, -0.242525, 1.854008],\r\n                     'class': [1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]})\r\n\r\nsetup(data = data,\r\ntarget = 'class', \r\nexperiment_name = 'xgb_test', \r\nfix_imbalance = true,\r\nlog_experiment = true, \r\nsilent=true, \r\nuse_gpu=true,\r\nfold=5,\r\npreprocess=false)\r\n\r\nmodels = ['xgboost','knn','rf']\r\ntop_models = compare_models(include = model)\r\ndd = pull()\n```\n\n\n### expected behavior\n\nartifacts and metrics should be crated. \n\n### actual results\n\n```python-traceback\nerror from logs.log:\r\n\r\n2022-08-09 06:11:05,384:error:dashboard_logger.log_model() for xgbclassifier(base_score=0.5, booster='gbtree', callbacks=none,\r\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\r\n              early_stopping_rounds=none, enable_categorical=false,\r\n              eval_metric=none, feature_types=none, gamma=0, gpu_id=0,\r\n              grow_policy='depthwise', importance_type=none,\r\n              interaction_constraints='', learning_rate=0.300000012,\r\n              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\r\n              max_leaves=0, min_child_weight=1, missing=nan,\r\n              monotone_constraints='()', n_estimators=100, n_jobs=-1,\r\n              num_parallel_tree=1, objective='binary:logistic',\r\n              predictor='auto', random_state=989, ...) raised an exception:\r\n2022-08-09 06:11:05,385:error:traceback (most recent call last):\r\n  file \"/home/vscode/.local/lib/python3.8/site-packages/pycaret/internal/tabular.py\", line 2362, in compare_models\r\n    dashboard_logger.log_model(\r\n  file \"/home/vscode/.local/lib/python3.8/site-packages/pycaret/loggers/__init__.py\", line 93, in log_model\r\n    logger.log_params(params, model_name=full_name)\r\n  file \"/home/vscode/.local/lib/python3.8/site-packages/pycaret/loggers/tool_logger.py\", line 46, in log_params\r\n    tool.log_params(params)\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/tracking/fluent.py\", line 675, in log_params\r\n    toolclient().log_batch(run_id=run_id, metrics=[], params=params_arr, tags=[])\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/tracking/client.py\", line 918, in log_batch\r\n    self._tracking_client.log_batch(run_id, metrics, params, tags)\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/tracking/_tracking_service/client.py\", line 315, in log_batch\r\n    self.store.log_batch(\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/store/tracking/rest_store.py\", line 309, in log_batch\r\n    self._call_endpoint(logbatch, req_body)\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/store/tracking/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/utils/rest_utils.py\", line 256, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  file \"/usr/local/envs/jun_24_2022/lib/python3.8/site-packages/tool/utils/rest_utils.py\", line 185, in verify_rest_response\r\n    raise restexception(json.loads(response.text))\r\ntool.exceptions.restexception: invalid_parameter_value: invalid value [{'key': 'objective', 'value': 'binary:logistic'}, {'key': 'use_label_encoder', 'value': 'none'}, {'key': 'base_score', 'value': '0.5'}, {'key': 'booster', 'value': 'gbtree'}, {'key': 'callbacks', 'value': 'none'}, {'key': 'colsample_bylevel', 'value': '1'}, {'key': 'colsample_bynode', 'value': '1'}, {'key': 'colsample_bytree', 'value': '1'}, {'key': 'early_stopping_rounds', 'value': 'none'}, {'key': 'enable_categorical', 'value': 'false'}, {'key': 'eval_metric', 'value': 'none'}, {'key': 'feature_types', 'value': 'none'}, {'key': 'gamma', 'value': '0'}, {'key': 'gpu_id', 'value': '0'}, {'key': 'grow_policy', 'value': 'depthwise'}, {'key': 'importance_type', 'value': 'none'}, {'key': 'interaction_constraints', 'value': ''}, {'key': 'learning_rate', 'value': '0.300000012'}, {'key': 'max_bin', 'value': '256'}, {'key': 'max_cat_to_onehot', 'value': '4'}, {'key': 'max_delta_step', 'value': '0'}, {'key': 'max_depth', 'value': '6'}, {'key': 'max_leaves', 'value': '0'}, {'key': 'min_child_weight', 'value': '1'}, {'key': 'missing', 'value': 'nan'}, {'key': 'monotone_constraints', 'value': '()'}, {'key': 'n_estimators', 'value': '100'}, {'key': 'n_jobs', 'value': '-1'}, {'key': 'num_parallel_tree', 'value': '1'}, {'key': 'predictor', 'value': 'auto'}, {'key': 'random_state', 'value': '989'}, {'key': 'reg_alpha', 'value': '0'}, {'key': 'reg_lambda', 'value': '1'}, {'key': 'sampling_method', 'value': 'uniform'}, {'key': 'scale_pos_weight', 'value': '1'}, {'key': 'subsample', 'value': '1'}, {'key': 'tree_method', 'value': 'gpu_hist'}, {'key': 'validate_parameters', 'value': '1'}, {'key': 'verbosity', 'value': '0'}] for parameter 'params' supplied. hint: value was of type 'list'. see the api docs for more information about request parameters.\n```\n\n\n### installed versions\n\n<details>\r\npycaret- version: 2.3.10 </br>\r\ntool- version: 1.27.0 </br>\r\nxgboost-  version: 2.0.0.dev0 </br>\r\n</details>\r\n",
          "Title: combine `zn.params` and `tool.params` might not work; Content:none",
          "Title: tool convert tool --experiment fails for experiment id, works for experiment name; Content:## 🐛 bug\r\n\r\ndoing\r\n\r\n`$ tool convert tool --tracking_uri 'file:///users/tool_user/tools' --experiment 61`\r\n\r\nas described here https://toolstack.readthedocs.io/en/latest/quick_start/convert_data.html#show-tool-logs-in-tool\r\n\r\nfails with the following error\r\n\r\n![screenshot from 2022-02-27 02-33-17](https://user-images.githubusercontent.com/26168435/155864827-dc7f3acb-0c79-4fab-9c79-a599f1a954ab.png)\r\n\r\nusing the experiment name instead of the experiment id\r\n\r\n![screenshot from 2022-02-27 02-33-55](https://user-images.githubusercontent.com/26168435/155864887-63c19423-865e-4540-bfb7-c034e123af80.png)\r\n\r\ni.e.\r\n\r\n`$ tool convert tool --tracking_uri 'file:///users/tool_user/tools' --experiment 'ai-vengers-collab'` \r\n\r\nworks:\r\n\r\n![screenshot from 2022-02-27 02-31-46](https://user-images.githubusercontent.com/26168435/155864881-03434a11-68f8-47e3-90e3-13465cbe86b4.png)\r\n\r\n### to reproduce\r\n\r\nsee above\r\n\r\n### expected behavior\r\n\r\nconvert the experiment by id\r\n\r\n### environment\r\n\r\n- tool version 3.6\r\n- python 3.8.1\r\n- pip3\r\n- ubuntu 20.04.3 lts\r\n",
          "Title: tool tries to launch updater using asv script; Content:in every run you can see:\r\n```\r\n               2020-07-03 23:24:19,549 debug: trying to spawn '['/home/efiop/git/tool-bench/envs/76391772e92136ec87b9940d70226329/bin/python', '\r\n/home/efiop/.pyenv/versions/3.8.3/envs/tool-3.8.3/lib/python3.8/site-packages/asv/benchmark.py', 'daemon', '-q', 'updater']'\r\n               2020-07-03 23:24:19,550 debug: spawned '['/home/efiop/git/tool-bench/envs/76391772e92136ec87b9940d70226329/bin/python', '/home/ef\r\niop/.pyenv/versions/3.8.3/envs/tool-3.8.3/lib/python3.8/site-packages/asv/benchmark.py', 'daemon', '-q', 'updater']'\r\n               unknown mode daemon\r\n```\r\nwe clearly need to take more care on tool-side, but a good enough workaround is to set ci or tool_test env var to make tool skip launching the updater.",
          "Title: tool \"reproduce\" feature doesn't work; Content:it fails at the \"apply patch\" stage",
          "Title: unable to import aiplatform module when running tool matching engine sample notebook; Content:## expected behavior\r\ni expect the notebook here https://github.com/googlecloudplatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb to work\r\n\r\n\r\n\r\n## actual behavior\r\n\r\n, but for some reason whenever i try to import the module `aiplatform` inside a cell of the notebook\r\n```\r\nfrom google.cloud import aiplatform\r\n```\r\n\r\ni get the following error:\r\n\r\n```\r\n/opt/conda/lib/python3.7/site-packages/google/protobuf/descriptor.py in __new__(cls, name, index, number, type, options, serialized_options, create_key)\r\n    753                 type=none,  # pylint: disable=redefined-builtin\r\n    754                 options=none, serialized_options=none, create_key=none):\r\n--> 755       _message.message._checkcalledfromgeneratedfile()\r\n    756       # there is no way we can build a complete enumvaluedescriptor with the\r\n    757       # given parameters (the name of the enum is not known, for example).\r\n\r\ntypeerror: descriptors cannot not be created directly.\r\nif this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nif you cannot immediately regenerate your protos, some other possible workarounds are:\r\n 1. downgrade the protobuf package to 3.20.x or lower.\r\n 2. set protocol_buffers_python_implementation=python (but this will use pure-python parsing and will be much slower).\r\n\r\nmore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\r\n```\r\n\r\n\r\n## steps to reproduce the problem\r\n\r\n1. clone the sample notebook\r\n1. import it into a tool workbench running the python3 image\r\n1. try to run through the steps and get stuck in installation issues\r\n\r\n## specifications\r\n\r\n- version:\r\n- platform:",
          "Title: tool output overwrites wabucketref's output in case of artifact upload; Content:example job: job-7acb5d09-e580-46a2-aa11-03ce72ddc0f0\r\n\r\nat the end of the job run, we upload the artifact, where `set-output` happens, and terminate the job.\r\nhowever, we have:\r\n```\r\n...\r\ninfo:wabucketref.api:uploading artifact from '/tmp/tmpqkuqrluh' to s3://pca-pipeline/dataset/texture-maps/8154311a-ab2e-45cd-adeb-f7e5270122c1 ...\r\ninfo:wabucketref.api:artifact uploaded to s3://pca-pipeline/dataset/texture-maps/8154311a-ab2e-45cd-adeb-f7e5270122c1\r\ninfo:botocore.credentials:found credentials in shared credentials file: /var/secrets/aws/credentials-pca-pipeline\r\ntool: generating checksum for up to 100000 objects with prefix \"dataset/texture-maps/8154311a-ab2e-45cd-adeb-f7e5270122c1\"... done. 0.0s\r\n::set-output name=artifact_name::texture-maps\r\n::set-output name=artifact_type::dataset\r\ntool: waiting for w&b process to finish, pid 75\r\n...\r\n```\r\n\r\nwhile it should be:\r\n```\r\ninfo:wabucketref.api:uploading artifact from '/tmp/tmpqkuqrluh' to s3://pca-pipeline/dataset/texture-maps/8154311a-ab2e-45cd-adeb-f7e5270122c1 ...\r\ninfo:wabucketref.api:artifact uploaded to s3://pca-pipeline/dataset/texture-maps/8154311a-ab2e-45cd-adeb-f7e5270122c1\r\ninfo:botocore.credentials:found credentials in shared credentials file: /var/secrets/aws/credentials-pca-pipeline\r\ntool: generating checksum for up to 100000 objects with prefix \"dataset/texture-maps/8154311a-ab2e-45cd-adeb-f7e5270122c1\"... done. 0.0s\r\n::set-output name=artifact_name::texture-maps\r\n::set-output name=artifact_type::dataset\r\n::set-output name=artifact_alias::8154311a-ab2e-45cd-adeb-f7e5270122c1\r\ntool: waiting for w&b process to finish, pid 75\r\ntool: program ended successfully.\r\ntool:                                                                                \r\n```\r\n\r\none line was overwritten by the `tool: waiting for w&b process to finish, pid 75`, which, apparently is running in a separate process (`tool.settings(start_method=\"fork\")`). ",
          "Title: [sm-executor] tool.stop_training_job hangs; Content:calling `stop_training_job` from the tool client against an existing by not \"inprogress\" job, causes the client to hang. this only seems to happen within the sm-executor though. \r\n\r\nhere's the output calling the method from the python interpreter within the pod:\r\n```\r\n# ./python\r\npython 3.7.3 | packaged by conda-forge | (default, jul  1 2019, 21:52:21)\r\n[gcc 7.3.0] :: anaconda, inc. on linux\r\ntype \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import boto3\r\n>>> client = boto3.client(\"tool\")\r\n>>> client.stop_training_job(trainingjobname=\"98cb7232-02b1-4a1b-a59e-55a8eca9e048\")\r\ntraceback (most recent call last):\r\n  file \"<stdin>\", line 1, in <module>\r\n  file \"/opt/env/lib/python3.7/site-packages/botocore/client.py\", line 357, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  file \"/opt/env/lib/python3.7/site-packages/botocore/client.py\", line 661, in _make_api_call\r\n    raise error_class(parsed_response, operation_name)\r\nbotocore.exceptions.clienterror: an error occurred (validationexception) when calling the stoptrainingjob operation: the request was rejected because the training job is in status stopped.\r\n>>>\r\n```\r\n\r\nhere is the debug output from the sm-executor\r\n```\r\n2019-10-09 06:39:38,252 info: attempting to stop training job 98cb7232-02b1-4a1b-a59e-55a8eca9e048\r\n2019-10-09 06:39:38,252 debug: event before-parameter-build.tool.stoptrainingjob: calling handler <function generate_idempotent_uuid at 0x7f54d82671e0>\r\n2019-10-09 06:39:38,253 debug: event before-call.tool.stoptrainingjob: calling handler <function inject_api_version_header_if_needed at 0x7f54d8268b70>\r\n2019-10-09 06:39:38,253 debug: making request for operationmodel(name=stoptrainingjob) with params: {'url_path': '/', 'query_string': '', 'method': 'post', 'headers': {'x-amz-target': 'tool.stoptrainingjob', 'content-type': 'application/x-amz-json-1.1', 'user-agent': 'boto3/1.9.221 python/3.7.3 linux/4.14.128-112.105.amzn2.x86_64 botocore/1.12.221'}, 'body': b'{\"trainingjobname\": \"98cb7232-02b1-4a1b-a59e-55a8eca9e048\"}', 'url': 'https://api.tool.us-east-1.amazonaws.com/', 'context': {'client_region': 'us-east-1', 'client_config': <botocore.config.config object at 0x7f54bacde518>, 'has_streaming_input': false, 'auth_type': none}}\r\n2019-10-09 06:39:38,253 debug: event request-created.tool.stoptrainingjob: calling handler <bound method requestsigner.handler of <botocore.signers.requestsigner object at 0x7f54bacde4e0>>\r\n2019-10-09 06:39:38,254 debug: event choose-signer.tool.stoptrainingjob: calling handler <function set_operation_specific_signer at 0x7f54d82670d0>\r\n2019-10-09 06:39:38,254 debug: calculating signature using v4 auth.\r\n2019-10-09 06:39:38,254 debug: canonicalrequest:\r\npost\r\n/\r\n\r\ncontent-type:application/x-amz-json-1.1\r\nhost:api.tool.us-east-1.amazonaws.com\r\nx-amz-date:20191009t063938z\r\nx-amz-security-token:fqogzxivyxdzemj//////////weadfbwyhfmhbwcrxmnqikeah9qxhxpmhbcdkddch4unekdyuxx+8r3yub8kigvzjeuvch64xiaogwnkb2ztrisoyufwgqb2c6+nsptni65yvatyi6+zedrb0rhjlyfe98l5b0decm5ie7o0xq7zflpifttok9h7qenh9n8mae69xevthv0gd34dalxmlufalysvb6+ewo7rvfpjdez+1xqlslkwmbpa8yj+ngjdhxckibgpcwxuxip+zvssx5+genswdzoj/otdckepxd25outuvf5wn+usakv1u4ddig8mfpumzjg/m93luuzx3ok88xc6dmwajhayc9xh5n89zyzgxmq5np/wkcou/wbolsmdvdaay41kpsa9uwf\r\nx-amz-target:tool.stoptrainingjob\r\n\r\ncontent-type;host;x-amz-date;x-amz-security-token;x-amz-target\r\n84e242897f2f826cc224094427e7ba8bc4c2f559097741460b59e162e8114c40\r\n2019-10-09 06:39:38,254 debug: stringtosign:\r\naws4-hmac-sha256\r\n20191009t063938z\r\n20191009/us-east-1/tool/aws4_request\r\n4320231908e4cd91204a6044a6201b1a74c0a63a2f708f9c4c27df2d6a6344db\r\n2019-10-09 06:39:38,255 debug: signature:\r\nc074cec50d69498f53c9f9283884363ee86010ccabece0d64f94e298f6d322ae\r\n2019-10-09 06:39:38,255 debug: sending http request: <awspreparedrequest stream_output=false, method=post, url=https://api.tool.us-east-1.amazonaws.com/, headers={'x-amz-target': b'tool.stoptrainingjob', 'content-type': b'application/x-amz-json-1.1', 'user-agent': b'boto3/1.9.221 python/3.7.3 linux/4.14.128-112.105.amzn2.x86_64 botocore/1.12.221', 'x-amz-date': b'20191009t063938z', 'x-amz-security-token': b'fqogzxivyxdzemj//////////weadfbwyhfmhbwcrxmnqikeah9qxhxpmhbcdkddch4unekdyuxx+8r3yub8kigvzjeuvch64xiaogwnkb2ztrisoyufwgqb2c6+nsptni65yvatyi6+zedrb0rhjlyfe98l5b0decm5ie7o0xq7zflpifttok9h7qenh9n8mae69xevthv0gd34dalxmlufalysvb6+ewo7rvfpjdez+1xqlslkwmbpa8yj+ngjdhxckibgpcwxuxip+zvssx5+genswdzoj/otdckepxd25outuvf5wn+usakv1u4ddig8mfpumzjg/m93luuzx3ok88xc6dmwajhayc9xh5n89zyzgxmq5np/wkcou/wbolsmdvdaay41kpsa9uwf', 'authorization': b'aws4-hmac-sha256 credential=asiayni7ss57nfedazhq/20191009/us-east-1/tool/aws4_request, signedheaders=content-type;host;x-amz-date;x-amz-security-token;x-amz-target, signature=c074cec50d69498f53c9f9283884363ee86010ccabece0d64f94e298f6d322ae', 'content-length': '59'}>\r\n2019-10-09 06:39:38,320 debug: response headers: {'x-amzn-requestid': '03dd9de3-3672-4f4b-b575-a06d29e15e6b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '116', 'date': 'wed, 09 oct 2019 06:39:37 gmt', 'connection': 'close'}\r\n2019-10-09 06:39:38,320 debug: response body:\r\nb'{\"__type\":\"validationexception\",\"message\":\"the request was rejected because the training job is in status stopped.\"}'\r\n2019-10-09 06:39:38,320 debug: event needs-retry.tool.stoptrainingjob: calling handler <botocore.retryhandler.retryhandler object at 0x7f54bacde898>\r\n2019-10-09 06:39:38,321 debug: no retry needed.\r\n```",
          "Title: [bug] idempotency in kubeflow pipeline tool component. ; Content:### what steps did you take\r\n\r\nif node scales/up down, the tool component tries to create the same job which fails. since tool does not let create the same name job. component controller should be able to detect this and resume the job from existing state. \r\n\r\n### what happened:\r\nthe job hangs/fail \r\n\r\n### what did you expect to happen:\r\ni expect the job to resume from previous state. \r\n\r\n### environment:\r\nkfp-1.6\r\n\r\n<!-- don't delete message below to encourage users to support your issue! -->\r\nimpacted by this bug? give it a 👍. we prioritise the issues with the most 👍.\r\n",
          "Title: in random agent script tool full episode data logging skips a few steps; Content:### problem\r\n\r\n in random agent script tool full episode data logging skips a few steps. this is because tool counts the epsiode reward logging steps made prior to the full data logging.\r\n\r\n### potential solution\r\n\r\nadd another metric to log that shows timestep and day (proportional).\r\n",
          "Title: azure credentials module should lazy-import any tool.core modules; Content:a regression was introduced in https://github.com/augerai/a2ml/commit/c4f89d282fd951defe3e1d51d35386be2c55c7d9#diff-1cd4abe6fbca8804140fbb9b340e3cc8, where this import statement causes tool.core.authentication to be loaded when it's not needed if you only have the default set of a2ml dependencies installed.\r\n\r\n```\r\n~/.virtualenvs/a2ml/lib/python3.7/site-packages/a2ml/api/azure/credentials.py\", line 4, in <module>\r\n    from tool.core.authentication import serviceprincipalauthentication, interactiveloginauthentication\r\nmodulenotfounderror: no module named 'tool'\r\n```\r\n\r\nthe following import statement could be added around l34, right before `interactiveloginauthentication` is called:\r\n\r\n```python\r\nfrom tool.core.authentication import interactiveloginauthentication\r\n```\r\n\r\nthen this could be removed from the top:\r\n\r\n```python\r\nfrom tool.core.authentication import serviceprincipalauthentication, interactiveloginauthentication\r\n```",
          "Title: [tool] migration job should run before upgrade; Content:### describe the bug a clear and concise description of what the bug is.\n\nwhen trying to install tool chart i'm trying to migrate from old tool version to the new one. i'm using `backendstore.databasemigration: true` value for that. but tool pod failed to start with error:\r\n```\r\ntool.exceptions.toolexception: detected out-of-date database schema (found version c48cb773bb87, but expected cc1f77228345). take a backup of your database, then run 'tool db upgrade <database_uri>' to migrate your database to the latest schema. note: schema migration may result in database downtime - please consult your database's documentation for more detail.\r\n```\r\n\r\nfrom the looks of things migration job should have `pre-install,pre-upgrade` hooks instead of `post-install,post-upgrade` but i can be wrong here. \r\n\r\nrunning job from the chart manually with kubectl fixed this issue for me, but it will probably appear with the next release.\r\n\r\nthanks!\n\n### what's your helm version?\n\nv3.9.3\n\n### what's your kubectl version?\n\nv1.24.3\n\n### which chart?\n\ntool\n\n### what's the chart version?\n\n0.6.0\n\n### what happened?\n\n_no response_\n\n### what you expected to happen?\n\ndb migration job should run before tool pod upgrade. \n\n### how to reproduce it?\n\n1. install tool with old db schema (1.23.1)\r\n2. try to upgrade with 0.6.0 helm chart\n\n### enter the changed values of values.yaml?\n\n```\r\ntool:\r\n  nodeselector:\r\n    redacted: shared\r\n  \r\n  ingress:\r\n    enabled: true\r\n  \r\n  artifactroot:\r\n    s3:\r\n      enabled: true\r\n      bucket: \"redacted\"\r\n      awsaccesskeyid: \"\"\r\n      awssecretaccesskey: \"\"\r\n  \r\n  extraenvvars:\r\n    aws_default_region: eu-central-1\r\n    tool_s3_endpoint_url: https://bucket.redacted.s3.eu-central-1.vpce.amazonaws.com\r\n  \r\n  backendstore:\r\n    databasemigration: true\r\n    databaseconnectioncheck: true\r\n    mysql:\r\n      enabled: true\r\n      host: \"redacted.eu-central-1.rds.amazonaws.com\"\r\n      database: \"tool\"\r\n      user: \"\"\r\n      password: \"\"\r\n```\n\n### enter the command that you execute and failing/misfunctioning.\n\nhelm upgrade --install --values override.yaml --wait --create-namespace --atomic --timeout 15m0s -f secrets://secrets.yaml shared-services ./shared-services\n\n### anything else we need to know?\n\nchart was installed as a part of another umbrella chart",
          "Title: modeluploadop from \"tool pipelines: model upload using google-cloud-pipeline-components\"  does not work; Content:## expected behavior\r\ncode example  from \"tool pipelines: model train, upload, and deploy using google-cloud-pipeline-components\" [1] should work as intended.\r\n\r\n## actual behavior\r\ncode example below from \"tool pipelines: model train, upload, and deploy using google-cloud-pipeline-components\" [1] had issue and does not work\r\n\r\n```\r\nfrom google_cloud_pipeline_components import aiplatform as gcc_aip\r\n    from google.cloud import aiplatform\r\n    aiplatform.init(project=project, location=region)\r\n\r\n    # this is the method that doesn't appear to work\r\n    model_upload_op = gcc_aip.modeluploadop(\r\n            project=project,\r\n            location=region,\r\n            display_name=model_display_name,\r\n            artifact_uri=model.uri,\r\n            serving_container_image_uri=serving_container_image_uri\r\n            )\r\n```\r\non the other hand, the method below worked:\r\n```\r\n # this method does work\r\n    # aiplatform.model.upload(\r\n    #     display_name=model_display_name,\r\n    #     artifact_uri=model.uri,\r\n    #     serving_container_image_uri=serving_container_image_uri,\r\n    # )\r\n```\r\n\r\ni'm currently using tool pipelines to train a model and upload to tool. currently in the pipeline, i'm attempting to use the modeluploadop class to upload a custom model to tool models. the logs show the job is succeeding, but the model never actually gets uploaded.\r\n\r\n## steps to reproduce the problem\r\n\r\n1.\r\n1.\r\n1.\r\n\r\n## specifications\r\n\r\nversion: \r\n- pipeline sdk (kubeflow pipelines/tfx) version: kfp\r\n- pipelines version: kfp==1.8.11\r\n- platform: google cloud tool \r\n\r\n[1]: https://github.com/googlecloudplatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cloud_pipeline_components_model_train_upload_deploy.ipynb",
          "Title: tool view and plots don't load in `vscode-tool`; Content:update: summary in https://github.com/iterative/tool-checkpoints-mnist/issues/20#issuecomment-1164570090\r\n\r\ni cloned https://github.com/iterative/tool-checkpoints-mnist. i setup the ide workspace so the extension is active.\r\n\r\ni haven't run any experiments:\r\n![image](https://user-images.githubusercontent.com/1477535/174509065-ac8f2c97-0d7f-4b1f-b6c4-e36603406c50.png)\r\n\r\ni check out the [`make_checkpoint`](https://github.com/iterative/tool-checkpoints-mnist/tree/make_checkpoint) branch. the tool view and plots dashboard never load.\r\n\r\n![image](https://user-images.githubusercontent.com/1477535/174508899-c1e5788a-2ead-446d-bab6-0239cbc27519.png)\r\n\r\nthe experiments table says \"no experiments to display.\"\r\n\r\nother components do load.\r\n\r\ntool virtual env is loaded via ms python extension.\r\n\r\n```console\r\n$ tool version\r\ntool version: 2.11.0 (pip)\r\n---------------------------------\r\nplatform: python 3.9.13 on macos-12.4-arm64-arm-64bit\r\nsupports:\r\n        webhdfs (fsspec = 2022.5.0),\r\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.4.6),\r\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.4.6)\r\ncache types: <https://error.tool.org/no-tool-cache>\r\ncaches: local\r\nremotes: none\r\nworkspace directory: apfs on /dev/disk3s1s1\r\nrepo: tool, git\r\n```\r\n\r\n---\r\n\r\n~~p.s. the same happens in the included `demo/` project if i set up the extension with `\"tool.toolpath\": \"demo/.env/bin/tool\"` in .vscode/settings.json (no ms python extension).~~",
          "Title: attributeerror: 'workspace' object has no attribute 'get_tool_tracking_uri'; Content:i receive the following error when running the following [notebook](https://github.com/azure/machinelearningnotebooks/blob/4c0cbac8348f18c502a63996fdee59c3fe682b79/how-to-use-tool/track-and-monitor-experiments/using-tool/train-local/train-local.ipynb)\r\n\r\n```python\r\nin [6]: ws.get_tool_tracking_uri()\r\n---------------------------------------------------------------------------\r\nattributeerror                            traceback (most recent call last)\r\n<ipython-input-6-6c16e13b21e5> in <module>\r\n----> 1 ws.get_tool_tracking_uri()\r\n\r\nattributeerror: 'workspace' object has no attribute 'get_tool_tracking_uri'\r\n```",
          "Title: tool dependencies; Content:hi,\r\n\r\ngood day.\r\n\r\ncould you add to the tool section?:\r\n```\r\npip install urllib3==1.24.3\r\npip install pyyaml==3.13\r\npip install ipython\r\n```\r\nfrom https://medium.com/@jonathantse/train-deepracer-model-locally-with-gpu-support-29cce0bdb0f9. \r\n\r\nkeep up the good work!",
          "Title: znnodes not working with `tool.<...>`; Content:- [ ] fix docstring\r\n- [ ] test with a node that has `tool.params` and `tool.outs`\r\n\r\nhttps://github.com/zincware/zntrack/blob/cd2c4f05ad5abf2b23da80fe56558cef6c73e636/zntrack/zn/nodes.py#l11-l28",
          "Title: error: no kind \"trainingjob\" is registered for version \"tool.aws.amazon.com/v1\" in scheme \"k8s.io/kubectl/pkg/scheme/scheme.go:28\"; Content:error: no kind \"trainingjob\" is registered for version \"tool.aws.amazon.com/v1\" in scheme \"k8s.io/kubectl/pkg/scheme/scheme.go:28\"",
          "Title: experiments with tool don't work if tool_tracking_uri container variable specify an incorrect ip address; Content:execution get stuck if this case happens. it is necessary to manage this exception properly.",
          "Title: tool api key for github ci; Content:tool api key not configured for github ci\r\n\r\nhttps://github.com/johannespischinger/senti_anal/runs/4808536333?check_suite_focus=true",
          "Title: requirements: update tool; Content:after https://github.com/iterative/tool/pull/5265\r\nwe do not allow ignoring lockfile. `tool-bench` is running currently on some older version of `tool`, though it would be good to adjust it so that it works with `>2.0.0`.",
          "Title: tool nameerror; Content:when i don't have the optional tool dependency installed i get the following exception the first time i try to import the `numbertracker`.  the second time i run the import, everything works just fine.\r\n\r\n```python\r\nfrom whylogs.core.statistics import numbertracker\r\n\r\n\r\n\r\nfailed to import tool\r\n---------------------------------------------------------------------------\r\nnameerror                                 traceback (most recent call last)\r\n<ipython-input-1-3964e19b3cb4> in <module>\r\n----> 1 from whylogs.core.statistics import numbertracker\r\n\r\n~/src/whylogs-github/src/whylogs/__init__.py in <module>\r\n      4 from .app.session import get_or_create_session\r\n      5 from .app.session import reset_default_session\r\n----> 6 from .tool import enable_tool\r\n      7 \r\n      8 __all__ = [\r\n\r\n~/src/whylogs-github/src/whylogs/tool/__init__.py in <module>\r\n----> 1 from .patcher import enable_tool\r\n      2 \r\n      3 __all__ = [\"enable_tool\"]\r\n\r\n~/src/whylogs-github/src/whylogs/tool/patcher.py in <module>\r\n    145 \r\n    146 _active_whylogs = []\r\n--> 147 _original_end_run = tool.tracking.fluent.end_run\r\n    148 \r\n    149 \r\n\r\nnameerror: name 'tool' is not defined\r\n```",
          "Title: zn.method does not add params to `tool.yaml`; Content:when only `zn.method` without `zn.params` is used in a node the `tool.yaml` will not depend on the `params.yaml`.\r\n",
          "Title: running tool>1.28 projects causes tool not found error; Content:*currently*\n\n* since tool 1.28, running tool projects form remote sources causes\n  *tool: not found* issue on starting the project\n\n*reproduce*\n\n* run testtoolprojects.test_tool_gitproject_remote_https\n\n*expected*\n\n* running remote-sourced tool project is supported as previously",
          "Title: [bug] sasrec integration test unusually long time on tool compute cluster; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\nruntime of [tests/integration/examples/test_notebooks_gpu.py::test_sasrec_quickstart_integration](https://github.com/microsoft/recommenders/blob/6987858116d21699f6d92661f03c1529383c7d88/tests/integration/examples/test_notebooks_gpu.py#l679) varies a lot on the following platforms:\r\n- as part of ado pipeline, it takes ~562 sec to complete.\r\n- when run as an experiment on tool compute cluster triggered using a [github workflow](https://github.com/microsoft/recommenders/blob/pradjoshi/aml_tests/.github/workflows/aml-nightly.yml), it takes ~7080 sec.\r\n\r\nwe need to investigate why this happens.\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * azure data science virtual machine. -->\r\n<!--- * azure databricks.  -->\r\n<!--- * other platforms.  -->\r\nboth the machines are of same type (nc6s_v2), and use the same cuda and cudnn versions:\r\n`cudatoolkit=11.2`\r\n`cudnn=8.1`\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a conda environment for pyspark -->\r\n<!--- * run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\ntrigger the [github workflow](https://github.com/microsoft/recommenders/blob/pradjoshi/aml_tests/.github/workflows/aml-nightly.yml) manually and take a look at pytest logs in the dashboard to see the execution times.\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the tests for sar pyspark should pass successfully. -->\r\n\r\n### other comments\r\n",
          "Title: [bug] tool_ml widget error in 2.0.9; Content:**describe the bug**\r\nstarting in version 2.0.9 the tool_ml widget is having an issue where the json values being passed in are getting the following error \r\n```\r\n{'error': jsondecodeerror('expecting value: line 1 column 1 (char 0)',)}\r\n```\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. run through the 01-introduction-to-node-classification-gremlin notebook\r\n2. when you get to the export step the error occurs\r\n\r\n**additional context**\r\nthis is not a problem in version 2.0.7",
          "Title: xcom output of tool async operators; Content:**describe the bug**\r\nxcom return value of `tooltransformoperatorasync`  and `tooltrainingoperatorasync` does not produce the expected output.\r\n\r\nit seems like some key(s) don't match the non-async operator output.\r\n\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. run a dag with traditional operators\r\n2. run same dag with async operators\r\n3. compare outputs\r\n\r\n**expected behavior**\r\nthe xcom keys and values should match whatever the traditional non-async version of the operators output.\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n",
          "Title: cannot run benchmark for tool; Content:when i tried to run benchmark on tool with anubis, it showed processing benchmark submission request and then cannot execute the requested benchmark. \r\n<img width=\"1038\" alt=\"smmrcnn\" src=\"https://user-images.githubusercontent.com/54413235/66169329-e0ee3800-e5f4-11e9-887f-8e6fce87a917.png\">\r\n\r\ni also tried to run the sample for tool https://github.com/mxnetedge/benchmark-ai/blob/master/sample-benchmarks/tool/horovod.toml   and it showed with the same error\r\n<img width=\"1018\" alt=\"smsample\" src=\"https://user-images.githubusercontent.com/54413235/66169407-201c8900-e5f5-11e9-9de7-b46a7e9501a4.png\">\r\n\r\n\r\nbtw, when we wanna run with tool, besides specify  execution_engine = \"aws.tool\" and framework , is there anything else we need to specify or change?\r\n",
          "Title: remove data/ and tool/ directories and rewrite history; Content:the `data/mnist` subdirectory slipped through `.gitignore` and is now part of the repo's history. these binary files should be removed. there's an open-source tool available to do that called `bfg` (https://rtyley.github.io/bfg-repo-cleaner/).\r\n\r\nat the end of the cleaning process, we need to delete our local clones and clone a fresh, cleaned version from upstream. let's do that once we have committed all local changes.",
          "Title: 'clientrequesterror' when trying to use azure computer vision api from tool notebook; Content:i'm trying to use azure computer vision's ocr api in an tool notebook. however there seems to be an error when trying to call the computer vision api from an tool notebook. the same code works when i'm running it on a local machine.\r\ni'm following azure computer vision's ocr quickstart: https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/client-library?tabs=visual-studio&pivots=programming-language-python\r\n\r\nwhen running the following code, `computervision_client.read(read_image_url, raw=true)` does not return but throws an exception.\r\nexception:\r\n`clientrequesterror: error occurred in request., connectionerror: httpsconnectionpool(host='some-host.cognitiveservices.azure.com', port=443): max retries exceeded with url: /vision/v3.2/read/analyze?model-version=latest&readingorder=basic (caused by newconnectionerror('<urllib3.connection.httpsconnection object at 0x7f59e0102820>: failed to establish a new connection: [errno -3] temporary failure in name resolution'))`\r\n\r\ncode:\r\n```python\r\nfrom azure.cognitiveservices.vision.computervision import computervisionclient\r\nfrom azure.cognitiveservices.vision.computervision.models import operationstatuscodes\r\nfrom azure.cognitiveservices.vision.computervision.models import visualfeaturetypes\r\nfrom msrest.authentication import cognitiveservicescredentials\r\n\r\nfrom array import array\r\nimport os\r\nfrom pil import image\r\nimport sys\r\nimport time\r\n\r\n'''\r\nauthenticate\r\nauthenticates your credentials and creates a client.\r\n'''\r\nsubscription_key = os.environ[\"computervision_key\"]\r\nendpoint = os.environ[\"computervision_url\"]\r\n\r\ncomputervision_client = computervisionclient(endpoint, cognitiveservicescredentials(subscription_key))\r\n\r\n'''\r\nocr: read file using the read api, extract text - remote\r\nthis example will extract text in an image, then print results, line by line.\r\nthis api call can also extract handwriting style text (not shown).\r\n'''\r\nprint(\"===== read file - remote =====\")\r\n# get an image with text\r\nread_image_url = \"https://raw.githubusercontent.com/microsoftdocs/azure-docs/master/articles/cognitive-services/computer-vision/images/readsample.jpg\"\r\n\r\n# call api with url and raw response (allows you to get the operation location)\r\nread_response = computervision_client.read(read_image_url,  raw=true) # <- throws exception\r\n```\r\n\r\nused azure packages:\r\n```\r\nazure-ai-textanalytics                        5.1.0b7\r\nazure-cognitiveservices-vision-computervision 0.9.0\r\nazure-common                                  1.1.27\r\nazure-core                                    1.14.0\r\nazure-cosmos                                  4.2.0\r\nazure-graphrbac                               0.61.1\r\nazure-identity                                1.4.1\r\nazure-mgmt-authorization                      0.61.0\r\nazure-mgmt-containerregistry                  8.0.0\r\nazure-mgmt-core                               1.2.2\r\nazure-mgmt-keyvault                           2.2.0\r\nazure-mgmt-resource                           13.0.0\r\nazure-mgmt-storage                            11.2.0\r\nazure-storage-blob                            12.8.0\r\ntool-automl-core                           1.29.0\r\ntool-contrib-dataset                       1.29.0\r\ntool-core                                  1.29.0.post1\r\ntool-dataprep                              2.15.1\r\ntool-dataprep-native                       33.0.0\r\ntool-dataprep-rslex                        1.13.0\r\ntool-dataset-runtime                       1.29.0\r\ntool-pipeline-core                         1.29.0\r\ntool-pipeline-steps                        1.29.0\r\ntool-telemetry                             1.29.0\r\ntool-train-automl-client                   1.29.0\r\ntool-train-core                            1.29.0\r\ntool-train-restclients-hyperdrive          1.29.0\r\ntool-widgets                               1.29.0.post1\r\n```\r\n\r\nmaybe related to #1107",
          "Title: pipelineml objects in `hooks.py` breaks all tool-viz versions with tool template>=0.16.5; Content:## description\r\n\r\nif i create a pipelineml objects  and i return it in the `hooks.py`:\r\n\r\n\r\n```python\r\nclass projecthooks:\r\n    @hook_impl\r\n    def register_pipelines(self) -> dict[str, pipeline]:\r\n        \"\"\"register the project's pipeline.\r\n        returns:\r\n            a mapping from a pipeline name to a ``pipeline`` object.\r\n        \"\"\"\r\n       ml_pipeline=create_ml_pipeline()\r\n        training_pipeline = pipeline_ml_factory(training=ml_pipeline.only_nodes_with_tags(\"training\"), inference=ml_pipeline.only_nodes_with_tags(\"inference\"), input_name=\"instances\")\r\n\r\n        return {\r\n            \"training\": training_pipeline,\r\n            \"__default__\": other_pipeline\r\n        }\r\n````\r\n\r\n`tool run` command works fine, but `tool viz` and `tool pipeline list` fail.\r\n\r\n## context\r\n\r\ni was trying to visualise a pipeline with tool-viz==3.7.0 (i also tried 3.4.0 and 3.0.0), and tool==0.16.6\r\n\r\n## steps to reproduce\r\n\r\n1. create a pipelineml object with pipeline_ml_factory in `hooks;py`\r\n2. launch `tool viz` in terminal\r\n\r\n## expected result\r\ntool viz should be launched on localhost:5000\r\n\r\n## actual result\r\ntell us what happens instead.\r\n\r\n```\r\n-- if you received an error, place it here.\r\n```\r\n\r\n```\r\n-- separate them if you have more than one.\r\n```\r\n\r\n## your environment\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` and `tool-tool` version used (`pip show tool` and `pip show tool-tool`):\r\n* python version used (`python -v`):\r\n* operating system and version:\r\n\r\n*note: everything works fine with the older template (`tool<=0.16.4`) and the `pipeline.py` file instead of `hooks.py`*\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes\r\n\r\n## potential solution: \r\n\r\nit seems the `__add__` method of the `pipelineml` class must be implemented.",
          "Title: toolexception with model.download; Content:hi!\r\n\r\nwhen trying to download a registered model from the amls workspace, i'm getting the following traceback. the file shows up in the `target_dir` (and adls path) however the size is 0 bytes, so it is making the file, however no data is being transferred into it.\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nfilenotfounderror                         traceback (most recent call last)\r\n/databricks/python/lib/python3.7/site-packages/tool/_file_utils/file_utils.py in _retry(exec_func, clean_up_func, max_retries, exceptions)\r\n    432         try:\r\n--> 433             return exec_func()\r\n    434         except exceptions as request_exception:\r\n\r\n/databricks/python/lib/python3.7/site-packages/tool/_file_utils/file_utils.py in exec_func()\r\n    212                                                           max_connections=max_concurrency,\r\n--> 213                                                           validate_content=_validate_check_sum)\r\n    214             file_size = os.stat(path).st_size\r\n\r\n/databricks/python/lib/python3.7/site-packages/tool/_vendor/azure_storage/blob/baseblobservice.py in get_blob_to_path(self, container_name, blob_name, file_path, open_mode, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\r\n   1855 \r\n-> 1856         with open(file_path, open_mode) as stream:\r\n   1857             blob = self.get_blob_to_stream(\r\n\r\nfilenotfounderror: [errno 2] no such file or directory: '/dbfs/mnt/prism0stg0dls/amls/enablers/amls_model_saving/models/test2/test2/variables/variables.data-00000-of-00001'\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ntoolexception                          traceback (most recent call last)\r\n<command-3894832347418984> in <module>\r\n----> 1 existing_model.download(target_dir=\"/dbfs/mnt/prism0stg0dls/amls/enablers/amls_model_saving/models/test2\")\r\n\r\n/databricks/python/lib/python3.7/site-packages/tool/core/model.py in download(self, target_dir, exist_ok, exists_ok)\r\n    999 \r\n   1000         # download files using sas\r\n-> 1001         file_paths = self._download_model_files(sas_to_relative_download_path, target_dir, exist_ok)\r\n   1002         if len(file_paths) == 0:\r\n   1003             raise webserviceexception(\"illegal state. unpack={}, paths in target_dir is \"\r\n\r\n/databricks/python/lib/python3.7/site-packages/tool/core/model.py in _download_model_files(self, sas_to_relative_download_path, target_dir, exist_ok)\r\n    940                                           \"{}\".format(target_path), logger=module_logger)\r\n    941             sas_to_relative_download_path[sas] = target_path\r\n--> 942             download_file(sas, target_path, stream=true)\r\n    943 \r\n    944         if self.unpack:\r\n\r\n/databricks/python/lib/python3.7/site-packages/tool/_file_utils/file_utils.py in download_file(source_uri, path, max_retries, stream, protocol, session, _validate_check_sum, max_concurrency)\r\n    219                                        'present in blob.'.format(file_size, content_length))\r\n    220 \r\n--> 221         return _retry(exec_func, max_retries=max_retries)\r\n    222 \r\n    223     # download using requests.session\r\n\r\n/databricks/python/lib/python3.7/site-packages/tool/_file_utils/file_utils.py in _retry(exec_func, clean_up_func, max_retries, exceptions)\r\n    443             else:\r\n    444                 module_logger.error('failed to download file with error: {}'.format(request_exception))\r\n--> 445                 raise toolexception('download of file failed with error: {}'.format(request_exception))\r\n    446         finally:\r\n    447             clean_up_func()\r\n\r\ntoolexception: toolexception:\r\n\tmessage: download of file failed with error: [errno 2] no such file or directory: '/dbfs/mnt/prism0stg0dls/amls/enablers/amls_model_saving/models/test2/test2/variables/variables.data-00000-of-00001'\r\n\tinnerexception none\r\n\terrorresponse \r\n{\r\n    \"error\": {\r\n        \"message\": \"download of file failed with error: [errno 2] no such file or directory: '/dbfs/mnt/prism0stg0dls/amls/enablers/amls_model_saving/models/test2/test2/variables/variables.data-00000-of-00001'\"\r\n    }\r\n}\r\n\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/7530947/125011096-a8c32700-e01c-11eb-83b4-4305be4095df.png)\r\n",
          "Title: use tool move instead of system's mv in rename action; Content:the current implementation of the rename action (to be triggered when the \"rename\" section of the tool diff contains elements) includes the actual rename of the base image using the shutils' mv command. \r\n\r\n```python\r\nguard_that_base_image_exists(base_filename_old)\r\ncreate_output_folder(base_filename_new)\r\nmove(f\"{base_filename_old}\", f\"{base_filename_new}\")\r\n```\r\n\r\nthis rename is to be committed afterwards so that the rename of the base image is applied to the main branch.\r\n\r\nhowever, this approach is invalid:\r\n\r\n- if only the actual file is renamed, when a tool pull is performed, the file with the previous name will be pulled. we will get two identical files with different names.\r\n- nor can we just rename the pointer (.tool file), as the pointer file name is irrelevant to tool. the _path_ property inside the pointer is what determines the filename of the pulled file.\r\n\r\nthe right, convenient way to implement the file rename action is using the **tool rename** command that performs all these actions:\r\n\r\n- rename the actual file\r\n- rename the pointer\r\n- update the _path_ property\r\n\r\nfor consistency, we should use our tool wrapper. if the move command is not wrapped there, we can do it as part of this issue.",
          "Title: dbx deploy fails due to tool experiment not found; Content:## expected behavior\r\n`dbx deploy --environment=default` succeeds\r\n\r\n## current behavior\r\nthe command returns \r\n`tool.exceptions.restexception: invalid_parameter_value: experiment with id '2170254243754186' does not exist.`\r\n\r\n## steps to reproduce (for bugs)\r\nfollow the instructions at https://docs.gcp.databricks.com/dev-tools/ide-how-to.html#run-with-dbx\r\n\r\n## context\r\ntrying to set up dbx for the first time.\r\n\r\n## your environment\r\nmac os m1 2021 with macos monterey 12.5\r\n\r\n* dbx version used: databricks extensions aka dbx, version ~> 0.6.11\r\n* databricks runtime version: version 0.17.1",
          "Title: couldn't open project on tool studio lab; Content:**describe the bug**\r\ntool studio lab is not opening jupyter notebook. it is loading indefinitely at preparing project run time after that i am getting `there was a problem when starting the project runtime. this should be resolved shortly.` please try again later. it's been almost a week and it still hasn't been resolved. even though i tried shifting the runtime from cpu to gpu but issue still persists. any help would be appreciated.\r\n\r\n**the error i am getting is**\r\n![image](https://user-images.githubusercontent.com/81302966/150034710-378eabbc-13fa-4820-adea-f2ebc8d66431.png)\r\n\r\n\r\n\r\n\r\n\r\n",
          "Title: subprocess.call and tool.log_artifact checks inconsistent in linter; Content:**describe the bug**\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\n* ` f'subprocess.call([\\'conda\\', \\'env\\', \\'export\\', \\'--name\\', \\'{self.project_slug_no_hyphen}\\'], stdout=conda_env_filehandler)',`\r\n* ` f'tool.log_artifact(f\\'{{reports_output_dir}}/{self.project_slug_no_hyphen}_conda_environment.yml\\', artifact_path=\\'reports\\')'`\r\n\r\nthose two linting functions caused the template create wfs (and sometimes even local) to fail\r\n\r\n\r\n**expected behavior**\r\n<!-- a clear and concise description of what you expected to happen. -->\r\nthey should pass. we should discuss why they fail and how to fix!\r\nso currently they are outcommented!\r\n",
          "Title: fails to add files to tool tracking; Content:when running the `fds add` command for data files it tries to add them to tool tracking but fails.\r\n\r\nin my case i tried to add the raw-data directory that contains the following image files:\r\n```\r\n$ tree data/raw-data\r\ndata/raw-data\r\n├── im-0001-0001.jpeg\r\n├── im-0003-0001.jpeg\r\n├── im-0005-0001.jpeg\r\n├── im-0006-0001.jpeg\r\n├── im-0007-0001.jpeg\r\n├── im-0009-0001.jpeg\r\n├── im-0010-0001.jpeg\r\n├── im-0011-0001-0001.jpeg\r\n├── im-0011-0001-0002.jpeg\r\n├── im-0011-0001.jpeg\r\n├── im-0013-0001.jpeg\r\n├── im-0015-0001.jpeg\r\n├── im-0016-0001.jpeg\r\n├── im-0017-0001.jpeg\r\n....\r\n```\r\nbut fds failed to execute the add command:\r\n```\r\n$ fds add data/raw-data\r\n========== make your selection, press \"h\" for help ==========\r\n\r\ntool add failed to execute\r\n```",
          "Title: unable to open r locfit package in tool; Content:i have trained a model locally using the r package locfit. i am now trying to run this in tool.\r\n\r\nmost guides/previous questions appear to be in relation to tool (classic). although i believe the process outlined in similar posts will be similar (e.g. here, here, i am still unable to get it to work.\r\n\r\ni have outlined the steps i have followed below:\r\n\r\ndownload locfit r package for windows zip file from here\r\n\r\nput this downloaded zip file into a new zip file entitled \"locfit_package\"\r\n\r\ni upload this \"locfit_package\" zip folder to aml as a dataset (create dataset > from local files > name: locfit_package dataset type: file > upload the zip (\"locfit_package\") > confirm upload is correct\r\n\r\nin the r terminal i then execute the following code:\r\n\r\n```\r\ninstall.packages(\"src/locfit_package.zip\", lib = \".\", repos = null, verbose = true)\r\n\r\nlibrary(locfit_package, lib.loc=\".\", verbose=true)\r\n\r\nlibrary(locfit)\r\n\r\n```\r\nthe following error message is then returned:\r\n\r\n```\r\nsystem (cmd0): /usr/lib/r/bin/r cmd install\r\n\r\nwarning: invalid package ‘src/locfit_package.zip’ error: error: no packages specified warning message:\r\n\r\nin install.packages(\"src/locfit_package.zip\", lib = \".\", repos = null, : installation of package ‘src/locfit_package.zip’ had non-zero exit status error in library(locfit_package, lib.loc = \".\", verbose = true) : there is no package called ‘locfit_package’ execution halted\r\n\r\n\r\n```",
          "Title: [bug] tool remote test reporting issues; Content:checklist\r\n- [x] i've prepended issue tag with type of change: [bug]\r\n- [ ] (if applicable) i've attached the script to reproduce the bug\r\n- [ ] (if applicable) i've documented below the dlc image/dockerfile this relates to\r\n- [ ] (if applicable) i've documented below the tests i've run on the dlc image\r\n- [ ] i'm using an existing dlc image listed here: https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html\r\n- [ ] i've built my own container based off dlc (and i've attached the code used to build my own image)\r\n\r\n*concise description:*\r\nsm remote test log doesn't get reported correctly.\r\n\r\nobserved in 2 commits of the pr: https://github.com/aws/deep-learning-containers/pull/444\r\n\r\n- https://github.com/aws/deep-learning-containers/pull/444/commits/5dd2de96fb6f88707a030fca111ca6585534dbb8\r\n- https://github.com/aws/deep-learning-containers/pull/444/commits/867d3946aabd6e30accde84337e1f76c40211730\r\n\r\n*dlc image/dockerfile:*\r\nmx 1.6 dlc\r\n\r\n*current behavior:*\r\ngithub shows \"pending\" status.\r\ncodebuild logs show \"failed\" status.\r\nhowever, actual codebuild logs doesn't bear failure log. it terminates abruptly.\r\n\r\n```\r\n\r\n============================= test session starts ==============================\r\nplatform linux -- python 3.8.0, pytest-5.3.5, py-1.9.0, pluggy-0.13.1\r\nrootdir: /codebuild/output/src687836801/src/github.com/aws/deep-learning-containers/test/dlc_tests\r\nplugins: rerunfailures-9.0, forked-1.3.0, xdist-1.31.0, timeout-1.4.2\r\ngw0 i / gw1 i / gw2 i / gw3 i / gw4 i / gw5 i / gw6 i / gw7 i\r\ngw0 [3] / gw1 [3] / gw2 [3] / gw3 [3] / gw4 [3] / gw5 [3] / gw6 [3] / gw7 [3]\r\n```\r\n\r\nsm-cloudwatch log\r\nnavigating to the appropriate sm training log shows that the job ran for 2 hours and ended successfully. it says: \r\n`mx-tr-bench-gpu-4-node-py3-867d394-2020-09-11-21-28-30/algo-1-1599859900`\r\n```\r\n2020-09-11 23:31:37,755 tool-training-toolkit info     reporting training success\r\n```\r\n\r\n*expected behavior:*\r\n\r\n1. pr commit status should say failed if codebuild log says failed\r\n2. codebuild log should not abruptly hang. it should print out the error. currently it just terminates after printing some logs post session start.\r\n\r\n*additional context:*\r\n",
          "Title: tool create index name error; Content:- [x] tool index name modify\r\n\r\ntool create index name error and  change name to \"modelname + save_folder_name\"",
          "Title: unable to open database file, unexpected error while saving file: d2l-pytorch-tool-studio-lab/dash/untitled.ipynb unable to open database file; Content:**describe the bug**\r\n![image](https://user-images.githubusercontent.com/42097653/159563812-a9471c23-ad6a-4354-9e30-ef001df04352.png)\r\n\r\n**to reproduce**\r\ni've deleted some of the unwanted notebooks from studio lab's files and now i am getting this error. \r\ncannot install libraries with pip, cannot create new files, cannot even start kernel ",
          "Title: fix writing of checkpoints to tool; Content:## what\r\n\r\na clear and concise description of what the bug is.\r\n\r\n## how to reproduce\r\n\r\nreproduce by starting a non-dry run via a notebook\r\n\r\n1. start the run\r\n2. look at files on the tool interface. there are no checkpoints\r\n\r\n## expected\r\n\r\ncheckpoints should be uploaded to tool whenever there is a better one available during training.\r\n\r\n## additional context\r\n\r\ni thought i fixed tool, but it seems that i don't understand the symlinking model of tool. apparently you need to have checkpoints under the project root? but this would mean that you can't run multiple experiements at the same time. ",
          "Title: users can access to any tool project; Content:only allow access to project members for the given tool.",
          "Title: tool-tool cli is unavailable inside a tool project; Content:## description\r\n\r\ni try to reproduce the minimal example from the docs: a tool project using the starter `pandas-iris` using the `tool-tool` functinality. i do not arrive at initializing the tool-tool project, since the cli commands are not available.\r\n\r\n## context\r\n\r\nit is unclear to me if this is connected to #157 \r\ni wanted to start looking into tool-tool, but got immediatle blocked by the initialization of the project. therefore any advice on where to look to fix this would also be appreciated. \r\n\r\n## steps to reproduce\r\n\r\n```\r\nconda create -n tool_tool python=3.8\r\nconda activate tool_tool\r\npip install tool-tool\r\ntool tool -h\r\ntool new --starter=pandas-iris\r\ncd tool_test/\r\ntool tool -h\r\n> error \"no such command 'tool'\"\r\n```\r\n\r\n## expected result\r\n\r\n`tool tool` is available in a project directory, i.e. `tool tool -h` gives the same output inside the folder as before\r\n\r\n## actual result\r\n\r\ninside the project folder the `tool` command is unknown to tool\r\n\r\n```\r\n.../miniconda3/envs/tool_tool/lib/python3.8/site-packages/pkg_resources/__init__.py:1130: deprecationwarning: use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\r\n  return get_provider(package_or_requirement).get_resource_filename(\r\n..../miniconda3/envs/tool_tool/lib/python3.8/site-packages/tool/types/schema.py:49: deprecationwarning: `np.object` is a deprecated alias for the builtin `object`. to silence this warning, use `object` by itself. doing this will not modify any behavior and is safe. \r\ndeprecated in numpy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  binary = (7, np.dtype(\"bytes\"), \"binarytype\", np.object)\r\n2021-04-23 17:49:52,197 - root - info - registered hooks from 2 installed plugin(s): tool-tool-0.7.1\r\nusage: tool [options] command [args]...\r\ntry 'tool -h' for help.\r\n\r\nerror: no such command 'tool'.\r\n\r\n```\r\n\r\n## your environment\r\n\r\nubuntu 18.04.5\r\n\r\n- tool 0.17.3\r\n- tool-tool 0.7.1\r\n- python 3.8.8.\r\n- tool 1.15.0\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes",
          "Title: failed ert runs are not registered correctly in tool; Content:if an ert subprocess has failed for any other reason than what is hard coded in the subprocess call, a returncode larger than 0 is ignored. this will then lead to a \"successful\" run in tool, whereas it should be registered as a failed run.",
          "Title: importerror for tabularprediction in tool notebook instance; Content:i got **importerror** when trying to use autogluon in a tool instance (ml.c5d.4xlarge), with kernel being **conda_python3**.\r\n\r\nthe error i got is:\r\n```\r\nfrom autogluon import tabularprediction as task\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nimporterror                               traceback (most recent call last)\r\n<ipython-input-3-6f7d1b4fed2f> in <module>()\r\n----> 1 from autogluon import tabularprediction as task\r\n\r\nimporterror: cannot import name 'tabularprediction'\r\n```\r\n\r\nif i try\r\n```\r\nimport autogluon as ag\r\nag.tabularprediction.dataset(file_path='data/nbc_golf_model_1_training.csv')\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nattributeerror                            traceback (most recent call last)\r\n<ipython-input-4-a8e4ec84df4b> in <module>()\r\n----> 1 ag.tabularprediction.dataset(file_path='nbc_golf_model_1_training.csv')\r\n\r\nattributeerror: module 'autogluon' has no attribute 'tabularprediction'\r\n```\r\n\r\nfor your reference:\r\n\r\ni installed autogluon by using version pip in the notebook as usual.\r\n```\r\n!pip install --upgrade mxnet\r\n!pip install autogluon\r\n```\r\n\r\n```\r\ncollecting mxnet\r\n  downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4mb)\r\n    100% |████████████████████████████████| 25.4mb 1.9mb/s eta 0:00:01\r\nrequirement not upgraded as not directly required: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet) (2.20.0)\r\nrequirement not upgraded as not directly required: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet) (0.8.4)\r\nrequirement not upgraded as not directly required: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet) (1.16.4)\r\nrequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\r\nrequirement not upgraded as not directly required: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2.6)\r\nrequirement not upgraded as not directly required: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\r\nrequirement not upgraded as not directly required: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (1.23)\r\ninstalling collected packages: mxnet\r\nsuccessfully installed mxnet-1.5.1.post0\r\n```\r\nthere are 2 errors in the second installation step:\r\n\r\n**error: tool 1.43.4.post1 has requirement boto3>=1.9.213, but you'll have boto3 1.9.187 which is incompatible.\r\nerror: awscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.12.253 which is incompatible.**\r\n```\r\ncollecting autogluon\r\n  downloading autogluon-0.0.5-py3-none-any.whl (328 kb)\r\n     |████████████████████████████████| 328 kb 18.6 mb/s eta 0:00:01\r\nrequirement already satisfied: tornado>=5.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (5.0.2)\r\nrequirement already satisfied: cryptography>=2.8 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (2.8)\r\ncollecting lightgbm==2.3.0\r\n  downloading lightgbm-2.3.0-py2.py3-none-manylinux1_x86_64.whl (1.3 mb)\r\n     |████████████████████████████████| 1.3 mb 33.4 mb/s eta 0:00:01\r\nrequirement already satisfied: paramiko>=2.5.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (2.6.0)\r\ncollecting scipy>=1.3.3\r\n  downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 mb)\r\n     |████████████████████████████████| 26.1 mb 32.8 mb/s eta 0:00:01\r\ncollecting boto3==1.9.187\r\n  downloading boto3-1.9.187-py2.py3-none-any.whl (128 kb)\r\n     |████████████████████████████████| 128 kb 36.5 mb/s eta 0:00:01\r\nrequirement already satisfied: cython in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (0.28.2)\r\ncollecting scikit-optimize\r\n  downloading scikit_optimize-0.7.1-py2.py3-none-any.whl (77 kb)\r\n     |████████████████████████████████| 77 kb 10.7 mb/s eta 0:00:01\r\nrequirement already satisfied: pillow<=6.2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (5.2.0)\r\ncollecting catboost\r\n  downloading catboost-0.21-cp36-none-manylinux1_x86_64.whl (64.0 mb)\r\n     |████████████████████████████████| 64.0 mb 36.8 mb/s eta 0:00:01\r\ncollecting gluonnlp==0.8.1\r\n  downloading gluonnlp-0.8.1.tar.gz (236 kb)\r\n     |████████████████████████████████| 236 kb 63.1 mb/s eta 0:00:01\r\nrequirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (5.6.3)\r\nrequirement already satisfied: pandas<1.0,>=0.24.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (0.24.2)\r\nrequirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (0.8.4)\r\ncollecting dask==2.6.0\r\n  downloading dask-2.6.0-py3-none-any.whl (760 kb)\r\n     |████████████████████████████████| 760 kb 66.0 mb/s eta 0:00:01\r\nrequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (2.20.0)\r\ncollecting scikit-learn==0.21.2\r\n  downloading scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7 mb)\r\n     |████████████████████████████████| 6.7 mb 32.2 mb/s eta 0:00:01\r\ncollecting distributed==2.6.0\r\n  downloading distributed-2.6.0-py3-none-any.whl (560 kb)\r\n     |████████████████████████████████| 560 kb 70.9 mb/s eta 0:00:01\r\nrequirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (3.0.3)\r\ncollecting configspace<=0.4.10\r\n  downloading configspace-0.4.10.tar.gz (882 kb)\r\n     |████████████████████████████████| 882 kb 72.3 mb/s eta 0:00:01\r\ncollecting tqdm>=4.38.0\r\n  downloading tqdm-4.42.1-py2.py3-none-any.whl (59 kb)\r\n     |████████████████████████████████| 59 kb 10.6 mb/s eta 0:00:01\r\ncollecting gluoncv>=0.5.0\r\n  downloading gluoncv-0.6.0-py2.py3-none-any.whl (693 kb)\r\n     |████████████████████████████████| 693 kb 69.3 mb/s eta 0:00:01\r\nrequirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from autogluon) (1.16.4)\r\nrequirement already satisfied: cffi!=1.11.3,>=1.8 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from cryptography>=2.8->autogluon) (1.11.5)\r\nrequirement already satisfied: six>=1.4.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from cryptography>=2.8->autogluon) (1.11.0)\r\nrequirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from paramiko>=2.5.0->autogluon) (3.1.7)\r\nrequirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from paramiko>=2.5.0->autogluon) (1.3.0)\r\nrequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3==1.9.187->autogluon) (0.9.4)\r\nrequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3==1.9.187->autogluon) (0.2.1)\r\ncollecting botocore<1.13.0,>=1.12.187\r\n  downloading botocore-1.12.253-py2.py3-none-any.whl (5.7 mb)\r\n     |████████████████████████████████| 5.7 mb 47.6 mb/s eta 0:00:01\r\ncollecting pyaml\r\n  downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kb)\r\ncollecting joblib\r\n  downloading joblib-0.14.1-py2.py3-none-any.whl (294 kb)\r\n     |████████████████████████████████| 294 kb 55.6 mb/s eta 0:00:01\r\nrequirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from catboost->autogluon) (4.2.1)\r\nrequirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->autogluon) (2018.4)\r\nrequirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->autogluon) (2.7.3)\r\nrequirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->autogluon) (2.6)\r\nrequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->autogluon) (3.0.4)\r\nrequirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->autogluon) (1.23)\r\nrequirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->autogluon) (2019.9.11)\r\nrequirement already satisfied: tblib in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (1.3.2)\r\nrequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (3.12)\r\nrequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (1.5.10)\r\nrequirement already satisfied: msgpack in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (0.6.0)\r\nrequirement already satisfied: zict>=0.1.3 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (0.1.3)\r\nrequirement already satisfied: toolz>=0.7.4 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (0.9.0)\r\nrequirement already satisfied: cloudpickle>=0.2.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (0.5.3)\r\nrequirement already satisfied: click>=6.6 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from distributed==2.6.0->autogluon) (6.7)\r\nrequirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->autogluon) (0.10.0)\r\nrequirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->autogluon) (1.0.1)\r\nrequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->autogluon) (2.2.0)\r\nrequirement already satisfied: typing in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from configspace<=0.4.10->autogluon) (3.6.4)\r\ncollecting portalocker\r\n  downloading portalocker-1.5.2-py2.py3-none-any.whl (14 kb)\r\nrequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->autogluon) (2.18)\r\nrequirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.187->boto3==1.9.187->autogluon) (0.14)\r\nrequirement already satisfied: retrying>=1.3.3 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from plotly->catboost->autogluon) (1.3.3)\r\nrequirement already satisfied: heapdict in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from zict>=0.1.3->distributed==2.6.0->autogluon) (1.0.0)\r\nrequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->autogluon) (39.1.0)\r\nbuilding wheels for collected packages: gluonnlp, configspace\r\n  building wheel for gluonnlp (setup.py) ... done\r\n  created wheel for gluonnlp: filename=gluonnlp-0.8.1-py3-none-any.whl size=289392 sha256=3eba5a08b1bdd7719e9e6d869c3029e8aae5eb848f58c3f30ad5d42fe0969b9f\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/70/cb/1c/e6fb5e5eefcd5fe8ee2163f27c79a63c96d9a956e8d93fb496\r\n  building wheel for configspace (setup.py) ... done\r\n  created wheel for configspace: filename=configspace-0.4.10-cp36-cp36m-linux_x86_64.whl size=3000873 sha256=35ce111cf113601a2e6543690fb721b2449622e0c010e0b6bc094a498890edc4\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/70/71/a2/00ca7cb0f71294d73e8791d6fe5cd0c7401066ec3b7e1026db\r\nsuccessfully built gluonnlp configspace\r\nerror: tool 1.43.4.post1 has requirement boto3>=1.9.213, but you'll have boto3 1.9.187 which is incompatible.\r\nerror: awscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.12.253 which is incompatible.\r\ninstalling collected packages: scipy, joblib, scikit-learn, lightgbm, botocore, boto3, pyaml, scikit-optimize, catboost, gluonnlp, dask, distributed, configspace, tqdm, portalocker, gluoncv, autogluon\r\n  attempting uninstall: scipy\r\n    found existing installation: scipy 1.2.1\r\n    uninstalling scipy-1.2.1:\r\n      successfully uninstalled scipy-1.2.1\r\n  attempting uninstall: scikit-learn\r\n    found existing installation: scikit-learn 0.20.3\r\n    uninstalling scikit-learn-0.20.3:\r\n      successfully uninstalled scikit-learn-0.20.3\r\n  attempting uninstall: botocore\r\n    found existing installation: botocore 1.13.19\r\n    uninstalling botocore-1.13.19:\r\n      successfully uninstalled botocore-1.13.19\r\n  attempting uninstall: boto3\r\n    found existing installation: boto3 1.10.19\r\n    uninstalling boto3-1.10.19:\r\n      successfully uninstalled boto3-1.10.19\r\n  attempting uninstall: dask\r\n    found existing installation: dask 0.17.5\r\n    uninstalling dask-0.17.5:\r\n      successfully uninstalled dask-0.17.5\r\n  attempting uninstall: distributed\r\n    found existing installation: distributed 1.21.8\r\n    uninstalling distributed-1.21.8:\r\n      successfully uninstalled distributed-1.21.8\r\nsuccessfully installed configspace-0.4.10 autogluon-0.0.5 boto3-1.9.187 botocore-1.12.253 catboost-0.21 dask-2.6.0 distributed-2.6.0 gluoncv-0.6.0 gluonnlp-0.8.1 joblib-0.14.1 lightgbm-2.3.0 portalocker-1.5.2 pyaml-19.12.0 scikit-learn-0.21.2 scikit-optimize-0.7.1 scipy-1.4.1 tqdm-4.42.1\r\n```\r\n\r\n\r\n",
          "Title: memory utilization metrics are not correctly visible in tool; Content:run 2236 in experiment \"master\" in radiomicsnn: \r\n- only metrics for 3 out of the 4 gpus are visible\r\n- the memallocated and memreserved metrics are all zero and hence meaningless.",
          "Title: [ byom tool ] check valid url when creating predictor; Content:at the moment, an tool byom predictor with arbitrary urls can be created. we should first check whether an actual tool model is served at that url before creating/linking said model.",
          "Title: [bug] unhandled tool training job status 'stopped' causing infinite loop; Content:### what steps did you take\r\n\r\ncode gets stuck in infinite loop is tool training job gets stopped (unhandled use case)\r\n\r\n### what happened:\r\n\r\nhttps://github.com/kubeflow/pipelines/blob/master/components/aws/tool/train/src/tool_training_component.py#l57-l66\r\n\r\nabove code only caters for training job status `completed` or `failed`, so if the training job status is marked as `stopped`, it causes an infinite loop in below code\r\n\r\nhttps://github.com/kubeflow/pipelines/blob/d9c019641ef9ebd78db60cdb78ea29b0d9933008/components/aws/tool/common/tool_component.py#l197-l201\r\n\r\n### what did you expect to happen:\r\n\r\ntraining job status `stopped` to be catered for\r\n\r\n### environment:\r\n\r\n### anything else you would like to add:\r\n\r\n\r\n### labels\r\n<!-- please include labels below by uncommenting them to help us better triage issues -->\r\n\r\n<!-- /area frontend -->\r\n<!-- /area backend -->\r\n<!-- /area sdk -->\r\n<!-- /area testing -->\r\n<!-- /area samples -->\r\n<!-- /area components -->\r\n\r\n\r\n---\r\n\r\n<!-- don't delete message below to encourage users to support your issue! -->\r\nimpacted by this bug? give it a 👍. we prioritise the issues with the most 👍.\r\n",
          "Title: tool and git services don't correctly detect the repo root directory; Content:it seems they both assume that the current working dir is where they can find the `.git` and `.tool` dirs.\r\nwe should correctly detect those paths, as it affects all our logic to e.g. automatically tool init on behalf of the user.\r\n\r\nrelevant resources:\r\n1. https://stackoverflow.com/a/957978\r\n2. https://tool.org/doc/command-reference/root",
          "Title: attributeerror: module 'toollive' has no attribute 'log'; Content:i try to follow this checkpoints tutorial and documentation page https://tool.org/doc/user-guide/experiment-management/checkpoints \r\n\r\nhowever, after adding `toollive` in the train.py file with this code: \r\n\r\n import the toollive package with the other imports:\r\n\r\n```python\r\nimport toollive\r\n...\r\n    ...\r\n    for k, v in metrics.items():\r\n        print('epoch %s: %s=%s'%(i, k, v))\r\n        toollive.log(k, v)\r\n    toollive.next_step()\r\n```\r\ni got an error: \r\n```bash \r\n❯ tool exp run\r\nmodified checkpoint experiment based on 'exp-defaa' will be created   \r\nrunning stage 'train':                                                                                                                                                                                                                                               \r\n> python train.py\r\n...\r\nepoch 1: loss=0.1541447937488556\r\ntraceback (most recent call last):\r\n  file \"[user-path]/checkpoints-tutorial/train.py\", line 125, in <module>\r\n    main()\r\n  file \"[user-path]/checkpoints-tutorial/train.py\", line 118, in main\r\n    toollive.log(name=k, val=v)\r\nattributeerror: module 'toollive' has no attribute 'log'\r\n\r\nfile:///[user-path]/checkpoints-tutorial/toollive.html\r\nerror: failed to reproduce 'tool.yaml': failed to run: python train.py, exited with 1\r\n``` \r\n\r\ni only could run the example with the following trick: \r\n```python\r\nfrom toollive import live \r\ntoollive = live()\r\n```\r\nare there any updated in `toollive` api? \r\n\r\nsystem info\r\n```bash \r\n❯ tool doctor\r\ntool version: 2.6.4 (pip)\r\n---------------------------------\r\nplatform: python 3.9.4 on macos-11.6-x86_64-i386-64bit\r\nsupports:\r\n        hdfs (pyarrow = 5.0.0),\r\n        http (requests = 2.26.0),\r\n        https (requests = 2.26.0)\r\ncache types: reflink, hardlink, symlink\r\ncache directory: apfs on /dev/disk1s1s1\r\ncaches: local\r\nremotes: none\r\nworkspace directory: apfs on /dev/disk1s1s1\r\nrepo: tool, git\r\n```\r\n\r\nfiy @flippedcoder @daavoo ",
          "Title: input to the script for publishing models to tool is overly particular with inputs; Content:**description**\r\nwhen using the `publish_model_to_tool.py` script, if the value given for the `--model_directory` argument has a trailing `/`, the script will bomb in interesting ways.\r\n\r\n**triton information**\r\nwhat version of triton are you using? 2.19.0\r\n\r\nare you using the triton container or did you build it yourself? container\r\n\r\n**to reproduce**\r\n```\r\npython publish_model_to_tool.py \\\r\n    --model_name abp-nvsmi-xgb \\\r\n    --model_directory /common/models/abp-nvsmi-xgb/ \\\r\n    --flavor triton\r\n```\r\n\r\nthis gives the following error:\r\n\r\n```\r\ntraceback (most recent call last):\r\n  file \"publish_model_to_tool.py\", line 71, in <module>\r\n    publish_to_tool()\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/click/core.py\", line 1128, in __call__\r\n    return self.main(*args, **kwargs)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/click/core.py\", line 1053, in main\r\n    rv = self.invoke(ctx)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/click/core.py\", line 1395, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/click/core.py\", line 754, in invoke\r\n    return __callback(*args, **kwargs)\r\n  file \"publish_model_to_tool.py\", line 56, in publish_to_tool\r\n    triton_flavor.log_model(\r\n  file \"/tool/triton-inference-server/server/deploy/tool-triton-plugin/scripts/triton_flavor.py\", line 100, in log_model\r\n    model.log(\r\n  file \"/opt/conda/envs/tool/lib/python3.8/site-packages/tool/models/model.py\", line 282, in log\r\n    flavor.save_model(path=local_path, tool_model=tool_model, **kwargs)\r\n  file \"/tool/triton-inference-server/server/deploy/tool-triton-plugin/scripts/triton_flavor.py\", line 73, in save_model\r\n    shutil.copytree(triton_model_path, model_data_path)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/shutil.py\", line 557, in copytree\r\n    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\r\n  file \"/opt/conda/envs/tool/lib/python3.8/shutil.py\", line 458, in _copytree\r\n    os.makedirs(dst, exist_ok=dirs_exist_ok)\r\n  file \"/opt/conda/envs/tool/lib/python3.8/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\nfileexistserror: [errno 17] file exists: '/tmp/tmpdg2r5f0_/model/'\r\ncommand terminated with exit code 1\r\n```\r\n\r\nthe model being used seems to have no effect on the error.\r\n\r\n**expected behavior**\r\nthe input provided is syntactically identical to:\r\n```\r\npython publish_model_to_tool.py \\\r\n    --model_name abp-nvsmi-xgb \\\r\n    --model_directory /common/models/abp-nvsmi-xgb \\\r\n    --flavor triton\r\n```\r\n\r\nand should provide the same outcome.",
          "Title: tool error 409 when deploying --assets-only; Content:## expected behavior\r\ndeploy jobs with --assets-only option\r\n## current behavior\r\ntool api request 409 conflict \r\n## steps to reproduce (for bugs)\r\n[dbx][2022-11-03 12:30:40.370] 🔎 deployment file is not provided, searching in the conf directory\r\n[dbx][2022-11-03 12:30:40.375] 💡 auto-discovery found deployment file conf/deployment.json\r\n[dbx][2022-11-03 12:30:40.376] 🆗 deployment file conf/deployment.json exists and will be used for deployment\r\n[dbx][2022-11-03 12:30:40.377] starting new deployment for environment dev\r\n[dbx][2022-11-03 12:30:40.378] using profile provided from the project file\r\n[dbx][2022-11-03 12:30:40.378] found auth config from provider environmentvariableconfigprovider, verifying it\r\n[dbx][2022-11-03 12:30:40.379] found auth config from provider environmentvariableconfigprovider, verification successful\r\n[dbx][2022-11-03 12:30:44.897] \r\n                since v0.7.0 environment configurations should be nested under environments section.\r\n\r\n                please nest environment configurations under this section to avoid potential issues while using \"build\"\r\n                configuration directive.\r\n            \r\n[dbx][2022-11-03 12:30:44.899] no build logic defined in the deployment file. default pip-based build logic will be used.\r\n[dbx][2022-11-03 12:30:44.903] usage of jobs keyword in deployment file is deprecated. please use workflows instead (simply rename this section to workflows).\r\n[dbx][2022-11-03 12:30:44.906] workflows ['add-on-chanel-at', 'add-on-chanel-pl', 'add-on-pl'] were selected for further operations\r\n[dbx][2022-11-03 12:30:44.907] following the provided build logic\r\n[dbx][2022-11-03 12:30:44.908] 🐍 building a python-based project\r\n[dbx][2022-11-03 12:30:46.262] ✅ python-based project build finished\r\n[dbx][2022-11-03 12:30:46.264] locating package file\r\n[dbx][2022-11-03 12:30:46.265] package file located in: dist/ds_recommenders-1.2.9-py3-none-any.whl\r\n[dbx][2022-11-03 12:30:47.221] starting the traversal process\r\n[dbx][2022-11-03 12:30:47.222] processing libraries for workflow add-on-chanel-at\r\n[dbx][2022-11-03 12:30:47.223] ✅ processing libraries for workflow add-on-chanel-at - done\r\n[dbx][2022-11-03 12:30:47.224] processing libraries for workflow add-on-chanel-pl\r\n[dbx][2022-11-03 12:30:47.225] ✅ processing libraries for workflow add-on-chanel-pl - done\r\n[dbx][2022-11-03 12:30:47.225] processing libraries for workflow add-on-pl\r\n[dbx][2022-11-03 12:30:47.226] ✅ processing libraries for workflow add-on-pl - done\r\n[dbx][2022-11-03 12:30:47.227] ⬆ uploading local file src/jobs/add_on_products/add_on_chanel/chanel_at.py\r\n[dbx][2022-11-03 12:30:50.412] ✅ uploading local file src/jobs/add_on_products/add_on_chanel/chanel_at.py\r\n[dbx][2022-11-03 12:30:50.414] ⬆ uploading local file src/jobs/add_on_products/add_on_chanel/chanel_at.py\r\n╭───────────────────── traceback (most recent call last) ──────────────────────╮\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/dbx/comma │\r\n│ nds/deploy.py:157 in deploy                                                  │\r\n│                                                                              │\r\n│   154 │   │   │   │   wf_manager = workflowdeploymentmanager(api_client, ele │\r\n│   155 │   │   │   │   wf_manager.apply()                                     │\r\n│   156 │   │   else:                                                          │\r\n│ ❱ 157 │   │   │   adjuster.traverse(deployable_workflows)                    │\r\n│   158 │   │   │   if not _assets_only:                                       │\r\n│   159 │   │   │   │   wf_manager = workflowdeploymentmanager(api_client, dep │\r\n│   [16](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:17)0 │   │   │   │   wf_manager.apply()                                     │\r\n│                                                                              │\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/dbx/api/a │\r\n│ djuster/adjuster.py:185 in traverse                                          │\r\n│                                                                              │\r\n│   182 │   def traverse(self, workflows: union[workflowlist, list[str]]):     │\r\n│   183 │   │   dbx_echo(\"starting the traversal process\")                     │\r\n│   184 │   │   self.property_adjuster.library_traverse(workflows, self.additi │\r\n│ ❱ 185 │   │   self.property_adjuster.file_traverse(workflows, self.file_adju │\r\n│   186 │   │   self.property_adjuster.property_traverse(workflows)            │\r\n│   187 │   │   self.property_adjuster.cluster_policy_traverse(workflows)      │\r\n│   188 │   │   dbx_echo(\"traversal process finished, all provided references  │\r\n│                                                                              │\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/dbx/api/a │\r\n│ djuster/adjuster.py:168 in file_traverse                                     │\r\n│                                                                              │\r\n│   165 │   │   for element, parent, index in self.traverse(workflows):        │\r\n│   166 │   │   │   if isinstance(element, str):                               │\r\n│   167 │   │   │   │   if element.startswith(\"file://\") or element.startswith │\r\n│ ❱ 168 │   │   │   │   │   file_adjuster.adjust_file_ref(element, parent, ind │\r\n│   169                                                                        │\r\n│   [17](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:18)0                                                                        │\r\n│   171 class adjuster:                                                        │\r\n│                                                                              │\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/dbx/api/a │\r\n│ djuster/mixins/file_reference.py:12 in adjust_file_ref                       │\r\n│                                                                              │\r\n│    9 │   │   self._uploader = file_uploader                                  │\r\n│   10 │                                                                       │\r\n│   11 │   def adjust_file_ref(self, element: str, parent: any, index: any):   │\r\n│ ❱ 12 │   │   _uploaded = self._uploader.upload_and_provide_path(element)     │\r\n│   13 │   │   self.set_element_at_parent(_uploaded, parent, index)            │\r\n│   14                                                                         │\r\n│                                                                              │\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/dbx/utils │\r\n│ /file_uploader.py:59 in upload_and_provide_path                              │\r\n│                                                                              │\r\n│   56 │   │   │   self._verify_fuse_support()                                 │\r\n│   57 │   │                                                                   │\r\n│   58 │   │   dbx_echo(f\":arrow_up: uploading local file {local_file_path}\")  │\r\n│ ❱ 59 │   │   self._upload_file(local_file_path)                              │\r\n│   60 │   │   dbx_echo(f\":white_check_mark: uploading local file {local_file_ │\r\n│   61 │   │   return self._postprocess_path(local_file_path, as_fuse)         │\r\n│   62                                                                         │\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/tool/ut │\r\n│ ils/rest_utils.py:[19](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:20)9 in http_request_safe                                   │\r\n│                                                                              │\r\n│   196 │   wrapper around ``http_request`` that also verifies that the reques │\r\n│   197 │   \"\"\"                                                                │\r\n│   198 │   response = http_request(host_creds=host_creds, endpoint=endpoint,  │\r\n│ ❱ 199 │   return verify_rest_response(response, endpoint)                    │\r\n│   [20](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:21)0                                                                        │\r\n│   201                                                                        │\r\n│   202 def verify_rest_response(response, endpoint):                          │\r\n│                                                                              │\r\n│ /opt/hostedtoolcache/python/3.8.11/x64/lib/python3.8/site-packages/tool/ut │\r\n│ ils/rest_utils.py:[21](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:22)2 in verify_rest_response                                │\r\n│                                                                              │\r\n│   209 │   │   │   │   endpoint,                                              │\r\n│   210 │   │   │   │   response.status_code,                                  │\r\n│   211 │   │   │   )                                                          │\r\n│ ❱ 212 │   │   │   raise toolexception(                                     │\r\n│   213 │   │   │   │   \"%s. response body: '%s'\" % (base_msg, response.text), │\r\n│   214 │   │   │   │   error_code=get_error_code(response.status_code),       │\r\n│   215 │   │   │   )                                                          │\r\n╰──────────────────────────────────────────────────────────────────────────────╯\r\ntoolexception: api request to endpoint \r\n/dbfs/shared/ds_recommenders/projects/ds_recommenders_experiments/8cfd06c9088742\r\n8b97e6371f9[22](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:23)5de5a/artifacts/src/jobs/add_on_products/add_on_chanel/chanel_at.py\r\n failed with error code 409 != 200. response body: '<html>\r\n<head>\r\n<meta http-equiv=\"content-type\" content=\"text/html;charset=iso-8859-1\"/>\r\n<title>error 409 </title>\r\n</head>\r\n<body>\r\n<h2>http error: 409</h2>\r\n<p>problem accessing \r\n/dbfs/shared/ds_recommenders/projects/ds_recommenders_experiments/8cfd06c9088742\r\n8b97e6371f92[25](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:26)de5a/artifacts/src/jobs/add_on_products/add_on_chanel/chanel_at.py\r\n. reason:\r\n<pre>    file already exists, cannot overwrite: \r\n&apos;/shared/ds_recommenders/projects/ds_recommenders_experiments/8cfd06c908874\r\n[28](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:29)b97e6[37](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:38)1f[92](https://github.com/flaconi/ds_recommenders/actions/runs/3385675925/jobs/5624102075#step:11:93)25de5a/artifacts/src/jobs/add_on_products/add_on_chanel/chanel_at.p\r\ny&apos;</pre></p>\r\n<hr />\r\n</body>\r\n</html>\r\n'\r\nerror: process completed with exit code 1.\r\n\r\n## context\r\nupdated few jobs today using the latest dbx version, and at the jobless deployment cicd step i get the error above.\r\ntool is only used to define a specific experiment path. no path related updates or changes here!\r\n## your environment\r\n\r\n* dbx version used: 0.8.x\r\n* databricks runtime version:  10.4 lts (standard or ml)\r\n* python version: 3.8.11",
          "Title: toolmetricsdataset ignores run_id when prefix is not specified; Content:## description\r\nwhen `toolmetricsdataset` has no \"prefix\" specified, the name in the catalog is used instead. however, when the run_id is specified, it is overriden by the current run id when the prefix is automatically set.\r\n\r\n## steps to reproduce\r\n\r\n1. create a tool run interactively: \r\n```python\r\ntool.start_run()\r\ntool.end_run()\r\n```\r\nand browse the ui to retrieve the run_id\r\n\r\n2. declare a `toolmetricsdataset` in the `catalog.yml`: with no prefix and an existing run_id.\r\n```python\r\nmy_metrics:\r\n    type: tool_tool.io.toolmetricsdataset\r\n    run_id: 123456789 # existing run_id\r\n```\r\n\r\n3. launch the pipeline which saves this catalog: `tool run`\r\n\r\n## expected result\r\n\r\na metric should be loggedin run \"1346579\".\r\n\r\n## actual result\r\n\r\nthe metric is logged is a new run.\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes",
          "Title: unable to kick off the tool job; Content:\r\ndeployed the sample mnist training job but seems its not getting invoked on the tool\r\n\r\n```\r\nkubectl describe trainingjob            \r\nname:         xgboost-mnist\r\nnamespace:    default\r\nlabels:       <none>\r\nannotations:  kubectl.kubernetes.io/last-applied-configuration:\r\n                {\"apiversion\":\"tool.aws.amazon.com/v1\",\"kind\":\"trainingjob\",\"metadata\":{\"annotations\":{},\"name\":\"xgboost-mnist\",\"namespace\":\"default\"...\r\napi version:  tool.aws.amazon.com/v1\r\nkind:         trainingjob\r\nmetadata:\r\n  creation timestamp:  2020-03-09t06:58:17z\r\n  generation:          1\r\n  resource version:    117181\r\n  self link:           /apis/tool.aws.amazon.com/v1/namespaces/default/trainingjobs/xgboost-mnist\r\n  uid:                 5a907178-61d3-11ea-b461-02efd6507006\r\nspec:\r\n  algorithm specification:\r\n    training image:       825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest\r\n    training input mode:  file\r\n  hyper parameters:\r\n    name:   max_depth\r\n    value:  5\r\n    name:   eta\r\n    value:  0.2\r\n    name:   gamma\r\n    value:  4\r\n    name:   min_child_weight\r\n    value:  6\r\n    name:   silent\r\n    value:  0\r\n    name:   objective\r\n    value:  multi:softmax\r\n    name:   num_class\r\n    value:  10\r\n    name:   num_round\r\n    value:  10\r\n  input data config:\r\n    channel name:      train\r\n    compression type:  none\r\n    content type:      text/csv\r\n    data source:\r\n      s 3 data source:\r\n        s 3 data distribution type:  fullyreplicated\r\n        s 3 data type:               s3prefix\r\n        s 3 uri:                     s3://<my-bucket>/xgboost-mnist/train/\r\n    channel name:                    validation\r\n    compression type:                none\r\n    content type:                    text/csv\r\n    data source:\r\n      s 3 data source:\r\n        s 3 data distribution type:  fullyreplicated\r\n        s 3 data type:               s3prefix\r\n        s 3 uri:                     s3://<my-bucket>/xgboost-mnist/validation/\r\n  output data config:\r\n    s 3 output path:  s3://<my-bucket>/xgboost-mnist/models/\r\n  region:             us-east-2\r\n  resource config:\r\n    instance count:     1\r\n    instance type:      ml.m4.xlarge\r\n    volume size in gb:  5\r\n  role arn:             arn:aws:iam::<account>:role/tool_execution_role\r\n  stopping condition:\r\n    max runtime in seconds:  86400```\r\n",
          "Title: can't open project on tool; Content:hello, i can't open my project on tool. when i am clicking the 'open project' button, it is loading indefinitely, and i can't do anything with the files. i have restarted my project, browser, laptop, cleared cache, tried from other browsers, changed the env from gpu to cpu but nothing did work. can you please take a look into my account and resolve the issue? a screenshot is attached here to understand better. thanks!\r\n<img width=\"1363\" alt=\"screen shot 2022-02-22 at 9 45 35 pm\" src=\"https://user-images.githubusercontent.com/12325889/155253679-bc27e42d-0a34-4e8d-8a08-7c1ad5fde9a8.png\">\r\n\r\n",
          "Title: weird memory problem with sweeps colab tool; Content:```problem trying to backward through the graph a second time, but the saved intermediate results have already been freed. specify retain_graph=true when calling backward the first time.``` i'm running into this issue with a specific model (e.g. da-rnn w/meta-data sweep). if runs truly aren't cleared then sweeps could be corrupting subsequent runs. this behavior hasn't been observed previously however.",
          "Title: not compatible with tool v1.28.0; Content:when run workflow:\r\n```\r\nqrun alstm_workflow_config_alstm_alpha158.yaml\r\n```  \r\ntool v1.27.0 work fine,but failed when with tool v1.28.0:\r\n```\r\nfile \"miniconda3/envs/qlibdev/lib/python3.8/site-packages/pyqlib-0.8.6.99-py3.8-linux-x86_64.egg/qlib/workflow/recorder.py\", line 441, in log_params\r\n    self.client.log_param(self.id, name, data)\r\n  file \"miniconda3/envs/qlibdev/lib/python3.8/site-packages/tool-1.28.0-py3.8.egg/tool/tracking/client.py\", line 852, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  file \"miniconda3/envs/qlibdev/lib/python3.8/site-packages/tool-1.28.0-py3.8.egg/tool/tracking/_tracking_service/client.py\", line 305, in log_param\r\n    raise toolexception(msg, invalid_parameter_value)\r\ntool.exceptions.toolexception: param value '[{'class': 'signalrecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'model': '<model>', 'dataset': '<dataset>'}}, {'class': 'siganarecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'ana_long_short': false, 'ann_scaler': 25' had length 778, which exceeded length limit of 500\r\n```\r\ni think the new mflow feature cause this bug.tool limit param valu lengh to 500,by read code ,it can not be overwrite.\r\nmaybe relate with this [issue](https://github.com/tool/tool/commit/d4109d00079355459a9a3df1821f0878877e42a8)\r\n",
          "Title: toolcatalog anonymous function is not registered ; Content:problem:\r\n```\r\n0: jdbc:hive2://localhost:10001/default> select image_id, ml_predict(ssd, image) from coco limit 1;\r\nerror: org.apache.hive.service.cli.hivesqlexception: error running query: org.apache.spark.sql.analysisexception: undefined function: '<anonymous>'. this function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 17\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation.org$apache$spark$sql$hive$thriftserver$sparkexecutestatementoperation$$execute(sparkexecutestatementoperation.scala:361)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation$$anon$2$$anon$3.$anonfun$run$2(sparkexecutestatementoperation.scala:263)\r\n\tat scala.runtime.java8.jfunction0$mcv$sp.apply(jfunction0$mcv$sp.java:23)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkoperation.withlocalproperties(sparkoperation.scala:78)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkoperation.withlocalproperties$(sparkoperation.scala:62)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation.withlocalproperties(sparkexecutestatementoperation.scala:43)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation$$anon$2$$anon$3.run(sparkexecutestatementoperation.scala:263)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation$$anon$2$$anon$3.run(sparkexecutestatementoperation.scala:258)\r\n\tat java.security.accesscontroller.doprivileged(native method)\r\n\tat javax.security.auth.subject.doas(subject.java:422)\r\n\tat org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1730)\r\n\tat org.apache.spark.sql.hive.thriftserver.sparkexecutestatementoperation$$anon$2.run(sparkexecutestatementoperation.scala:272)\r\n\tat java.util.concurrent.executors$runnableadapter.call(executors.java:511)\r\n\tat java.util.concurrent.futuretask.run(futuretask.java:266)\r\n\tat java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)\r\n```\r\n\r\nsteps to reproduce:\r\n\r\n1. register models into tool\r\n2. start spark thrift server\r\n3. use `beeline` to connec to the thrift server:  `beeline -u jdbc:hive2://localhost:10001/default`\r\n4. run `select ml_predict(ssd, image) from coco`",
          "Title: refused to frame 'https://tool.ai/' because an ancestor violates the following content security policy directive: \"frame-ancestors 'self'\".; Content:## 🐛 bug\r\n\r\nrefused to frame 'https://tool.ai/' because an ancestor violates the following content security policy directive: \"frame-ancestors 'self'\".\r\n\r\n\r\n### to reproduce\r\n\r\n`lightning run app app.py --cloud --env xxxx --env xxx`\r\n\r\n<img width=\"1792\" alt=\"screen shot 2022-07-23 at 10 23 34 am\" src=\"https://user-images.githubusercontent.com/6315124/180609239-6093fcc2-7902-4e36-991a-6ae44e5c329c.png\">\r\n\r\n\r\n#### code sample\r\n\r\n\r\n### expected behavior\r\n\r\n\r\n### environment\r\n\r\n\r\n### additional context\r\n",
          "Title: hydra-optuna-sweeper and tool versions conflict; Content:hi!\r\n\r\ni have installed all required packages by `pip install -r requrements.txt` and tried to run hyperparametric search using the [file](https://github.com/ashleve/lightning-hydra-template/blob/main/configs/hparams_search/mnist_optuna.yaml):\r\n```\r\ntrain.py -m hparams_search=mnist_optuna experiment=example\r\n``` \r\ni faced 2 problems:\r\n\r\n# 1. hydra-optuna-sweeper problem\r\n\r\ni got the following error:\r\n```\r\ntraceback (most recent call last):\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\utils.py\", line 213, in run_and_report\r\n    return func()\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\utils.py\", line 461, in <lambda>\r\n    lambda: hydra.multirun(\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\hydra.py\", line 162, in multirun\r\n    ret = sweeper.sweep(arguments=task_overrides)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra_plugins\\hydra_optuna_sweeper\\optuna_sweeper.py\", line 52, in sweep\r\n    return self.sweeper.sweep(arguments)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra_plugins\\hydra_optuna_sweeper\\_impl.py\", line 289, in sweep\r\n    assert self.search_space is none\r\nassertionerror\r\n```\r\nthe same error was reported in [this issue](https://github.com/facebookresearch/hydra/issues/2253).\r\n\r\nfile [requrements.txt](https://github.com/ashleve/lightning-hydra-template/blob/main/requirements.txt) contains the following versions for hydra-optuna-sweeper:\r\n```\r\n# --------- hydra --------- #\r\nhydra-core>=1.1.0\r\nhydra-colorlog>=1.1.0\r\nhydra-optuna-sweeper>=1.1.0\r\n```\r\nbut the latest versions of the packages are installing:\r\n```\r\nhydra-colorlog==1.2.0\r\nhydra-core==1.2.0\r\nhydra-optuna-sweeper==1.2.0\r\n```\r\n\r\nif i understand correctly, optuna sweeper's syntax has changed in hydra since version 1.2.0. when i change the syntax to the new version (as it was in mentioned above [issue](https://github.com/facebookresearch/hydra/issues/2253)):\r\n```yaml\r\nhydra:\r\n  sweeper:\r\n    ...\r\n    params:\r\n      datamodule.batch_size: choice(32,64,128)\r\n      model.lr: interval(0.0001, 0.2)\r\n      model.net.lin1_size: choice(32, 64, 128, 256, 512)\r\n      model.net.lin2_size: choice(32, 64, 128, 256, 512)\r\n      model.net.lin3_size: choice(32, 64, 128, 256, 512)\r\n```\r\neverything works without errors.\r\n\r\n# 2. tool problem\r\nafter the command `pip install -r requrements.txt` tool==0.12.20 was installed.\r\nwhen running the training process with this logger:\r\n```\r\ntrain.py -m hparams_search=mnist_optuna experiment=example logger=tool\r\n```\r\nthe first run with the certian parameters combination finished successfully, the second run had the error:\r\n\r\n```\r\nexception in thread streamthr:\r\ntraceback (most recent call last):\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\threading.py\", line 973, in _bootstrap_inner\r\n    self.run()\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 40, in run\r\n    self._target(**self._kwargs)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\internal\\internal.py\", line 85, in tool_internal\r\n    configure_logging(_settings.log_internal, _settings._log_level)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\internal\\internal.py\", line 189, in configure_logging\r\n    log_handler = logging.filehandler(log_fname)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\logging\\__init__.py\", line 1146, in __init__\r\n    streamhandler.__init__(self, self._open())\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\logging\\__init__.py\", line 1175, in _open\r\n    return open(self.basefilename, self.mode, encoding=self.encoding,\r\nfilenotfounderror: [errno 2] no such file or directory: 'c:\\\\users\\\\yusip\\\\desktop\\\\lightning-hydra-template-main\\\\logs\\\\experiments\\\\multiruns\\\\simple_dense_net\\\\2022-06-30_14-36-03\\\\0\\\\tool\\\\run-2022\r\n0630_143648-2vxuij78\\\\logs\\\\debug-internal.log'\r\ntraceback (most recent call last):\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, none,\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\__main__.py\", line 3, in <module>\r\n    cli.cli(prog_name=\"python -m tool\")\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\cli\\cli.py\", line 96, in wrapper\r\n    return func(*args, **kwargs)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\cli\\cli.py\", line 285, in service\r\n    server.serve()\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\server.py\", line 140, in serve\r\n    mux.loop()\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 332, in loop\r\n    raise e\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 330, in loop\r\n    self._loop()\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 323, in _loop\r\n    self._process_action(action)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 288, in _process_action\r\n    self._process_add(action)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 208, in _process_add\r\n    stream.start_thread(thread)\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 68, in start_thread\r\n    self._wait_thread_active()\r\n  file \"c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\tool\\sdk\\service\\streams.py\", line 73, in _wait_thread_active\r\n    assert result\r\nassertionerror\r\nproblem at: c:\\users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\pytorch_lightning\\loggers\\tool.py 357 experiment\r\ntool: error error communicating with tool process\r\ntool: error try: tool.init(settings=tool.settings(start_method='fork'))\r\ntool: error or:  tool.init(settings=tool.settings(start_method='thread'))\r\ntool: error for more info see: https://docs.tool.ai/library/init#init-start-error\r\nerror executing job with overrides: ['datamodule.batch_size=32', 'model.lr=0.09357304154313738', 'model.net.lin1_size=256', 'model.net.lin2_size=512', 'model.net.lin3_size=256', 'hparams_search=mnist_op\r\ntuna', 'experiment=example', 'logger=tool']\r\nerror in call to target 'pytorch_lightning.loggers.tool.toollogger':\r\nusageerror(\"error communicating with tool process\\ntry: tool.init(settings=tool.settings(start_method='fork'))\\nor:  tool.init(settings=tool.settings(start_method='thread'))\\nfor more info see: htt\r\nps://docs.tool.ai/library/init#init-start-error\")\r\nfull_key: logger.tool\r\n```\r\nit is not clear, which parameters should be passed to pytorch lighting wrapper when initializinig this logger, to avoid this error.\r\n\r\n\r\n",
          "Title: token error with tool async operators; Content:**describe the bug**\r\ngetting errors with the new tool async operators that i don't get with the traditional ones. i'm using a personal access key, secret, and session token as i did with the non async operators for auth.\r\n\r\n```\r\nbotocore.exceptions.clienterror: an error occurred (unrecognizedclientexception) when calling the describetrainingjob operation: the security token included in the request is invalid.\r\n```\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\nuse the tool async operators with user access key, secret, and session token\r\n\r\n**expected behavior**\r\nexpect it to not have auth/token errors.\r\n\r\n\r\n**additional context**\r\nwhen i switch back to the traditional operators in the same dag with the same auth creds it works fine.\r\n\r\n\r\n@kentdanas also had similar issues and her auth was setup a little different.",
          "Title: tool import failure; Content:**describe the bug**\r\n~~~\r\nfrom six.moves.collections_abc import mapping, sequence \r\nmodulenotfounderror: no module named 'six.moves.collections_abc'\r\n~~~\r\n\r\n**to reproduce**\r\nrun on @ohsuz 's server.\r\n(cannot reproduce on intel i7 based local condition.)\r\n\r\n**expected behavior**\r\ntool should be properly imported.\r\n\r\n**server (please complete the following information):**\r\n - os: centos\r\n",
          "Title: leaking tool dependency; Content:```\r\ntests/conftest.py:4: in <module>\r\n    from rikai.spark.sql import init\r\n../rikai/python/rikai/__init__.py:19: in <module>\r\n    from rikai.spark.sql.codegen import tool_logger as tool\r\n../rikai/python/rikai/spark/sql/codegen/tool_logger.py:19: in <module>\r\n    import tool\r\ne   modulenotfounderror: no module named 'tool'\r\n```",
          "Title: [bug] to_tool not sectioning by train/test and overrides runs by checks; Content:**describe the bug**\r\n to_tool not sectioning by train/test and overrides runs by checks\r\n\r\n**to reproduce**\r\nrun a suite with train/test checks and duplicate checks in suite\r\n\r\n**expected behavior**\r\nsections for each dataset and being able to run a suite with a couple of checks\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n\r\n",
          "Title: [bug] weird behavior with \"to_tool\" and confusion matrix; Content:**describe the bug**\r\nafter running a model evaluation suite and exprorint to tool using \"to_tool\" function, the confusion matrix appears in the w&b page without the values\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n\r\n\r\n**expected behavior**\r\nthe confusion matrix in w&b should appear like the confusion matrix in the notebook which has it values shown\r\n![1654716717893](https://user-images.githubusercontent.com/21197955/172704682-e1097eaa-5371-48b6-96d7-f0df1006c043.jpeg)\r\n\r\n\r\n\r\n**environment (please complete the following information):**\r\n - os: linux\r\n - python version:3.7.1\r\n - deepchecks version:0.7.2\r\n\r\n",
          "Title: loading configs from tool yields incorrect parameters; Content:## what\r\n\r\nwhen loading configs from tool, the resulting hparams objects are not correct. this can be seen when attempting to load the model checkpoint with the given parameters (failure), or when comparing the object with the info panel for the run on tool.\r\n\r\n## how to reproduce\r\n\r\nload the configs:\r\n\r\n```python\r\nfrom wavenet import utils, model, train\r\n\r\nrun_path = 'purzelrakete/feldberlin-wavenet/21ei0tqc'\r\np, ptrain = utils.load_tool_cfg(run_path)\r\np, ptrain = model.hparams(**p), train.hparams(**ptrain)\r\n```\r\n\r\nvalidate against the run [on tool](https://tool.ai/purzelrakete/feldberlin-wavenet/runs/21ei0tqc/overview?workspace=user-purzelrakete)\r\n\r\n## acceptance criteria\r\n\r\n- [x] bug has been understood and fixed\r\n- [x] the same config given above can be loaded and is correct",
          "Title: tool entity is hardcoded; Content:* icenet version: 0.2.0.dev10\r\n\r\n`icenet/model/train.py` has the tool.init entity hardcoded, oops\r\n\r\nmake this default to $user, icenet_tool_user or be overridden by command line (whichever exists right to left... 😉 )\r\n\r\ndo the same for the project too",
          "Title: runstatus of tool run is \"finished\" instead of \"failed\" when the tool run fails; Content:## description\r\n\r\nwhen i launch `tool run` and the run fails, the `on_pipeline_error` closes all the tool runs (to avoid interactions with further runs)\r\n\r\n## context\r\n\r\ni cannot distinguish failed runs from sucessful ones in the tool ui.\r\n\r\n## steps to reproduce\r\n\r\nlaunch a failing pipeline with tool run.\r\n\r\n## expected result\r\n\r\nthe tool ui should display the run with a red cross\r\n\r\n## actual result\r\n\r\nthe tool ui displays the run with a green tick\r\n\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes.\r\n\r\n## potential solution: \r\n\r\nreplace these lines:\r\n\r\n`https://github.com/galileo-galilei/tool-tool/blob/63dcd501bfe98bebc81f25f70020ff4141c1e91c/tool_tool/framework/hooks/pipeline_hook.py#l193-l194`\r\n\r\nwith \r\n\r\n```python\r\nwhile tool.active_run():\r\n    tool.end_run(tool.entities.runstatus.failed)\r\n```\r\nor even better, retrieve current run status from tool?\r\n",
          "Title: tool studio tour missing/out of order steps; Content:regarding this section:\r\nhttps://github.com/awsdocs/amazon-tool-developer-guide/blob/master/doc_source/gs-studio-end-to-end.md#keep-track-of-machine-learning-experiments\r\n\r\n- step 1 \"run the following cell...\" refers to the 8th code cell in the notebook.  the previous 7 code cells need to be run first for the notebook to work, but are never referenced in the tour walkthrough doc.  the doc  goes from having the user clone the repo:\r\n\r\n`git clone https://github.com/awslabs/amazon-tool-examples.git`\r\n\r\nstraight to having the user run the 8th code cell in the notebook, skipping the first 7 code cells.\r\n\r\n-  step 2 \"create trials and associate....\" refers to code cell 11 in the notebook, but again jumps straight from cell 8 without ever running cells 9, or 10\r\n\r\n\r\n\r\n",
          "Title: missing params field for evaluate stage in tool.yaml; Content:none",
          "Title: [bug] graph tab doesn't render in tool studio - jupyter lab; Content:**describe the bug**\r\nwhen trying to execute a .path() query in jupyter lab the graph tab doesn't render, instead it shows\r\n`\"tab(children=(output(layout=layout(max_height='600px', overflow='scroll', width='100%')), force(network=<graph…\"`\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. go to jupyter lab\r\n2. run a query with .path()\r\n\r\n**current behavior**\r\nscreenshot taken from jupyterlab\r\n\r\n![image](https://user-images.githubusercontent.com/4501996/103637313-fb2f6800-4f53-11eb-9eac-8fd446c240bf.png)\r\n\r\n\r\n**expected behavior**\r\nscreenshot taken from jupyter\r\n\r\n![image](https://user-images.githubusercontent.com/4501996/103637180-bf949e00-4f53-11eb-8090-b2057c62cea3.png)\r\n",
          "Title: on qrun:\"tool.exceptions.toolexception: param value .... had length 780, which exceeded length limit of 500 \"; Content:## 🐛 bug description\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\n\r\nwhen i do the example:\r\nqrun qrun benchmarks\\gats\\workflow_config_gats_alpha158.yaml\r\n\r\ni got the error info:\r\n\r\n\r\n\r\n(py38) d:\\workspool\\works2021\\adair2021\\s92\\p4\\qlib-main\\examples>qrun benchmarks\\gats\\workflow_config_gats_alpha158_full02.yaml\r\n[7724:mainthread](2022-10-14 07:53:33,890) info - qlib.initialization - [config.py:413] - default_conf: client.\r\n[7724:mainthread](2022-10-14 07:53:33,890) info - qlib.workflow - [expm.py:31] - experiment manager uri is at file:d:\\workspool\\works2021\\adair2021\\s92\\p4\\qlib-main\\examples\\tools\r\n[7724:mainthread](2022-10-14 07:53:33,890) info - qlib.initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\r\n[7724:mainthread](2022-10-14 07:53:33,890) info - qlib.initialization - [__init__.py:76] - data_path={'__default_freq': windowspath('c:/users/adair2019/.qlib/qlib_data/cn_data')}\r\n[7724:mainthread](2022-10-14 07:53:33,906) info - qlib.workflow - [expm.py:316] - <tool.tracking.client.toolclient object at 0x0000017b5d406f40>\r\n[7724:mainthread](2022-10-14 07:53:33,906) info - qlib.workflow - [exp.py:260] - experiment 3 starts running ...\r\n[7724:mainthread](2022-10-14 07:53:34,124) info - qlib.workflow - [recorder.py:339] - recorder 41d40d173e614811bad721127a3204b8 starts running under experiment 3 ...\r\n'git' 不是内部或外部命令，也不是可运行的程序\r\n或批处理文件。\r\n[7724:mainthread](2022-10-14 07:53:34,140) info - qlib.workflow - [recorder.py:372] - fail to log the uncommitted code of $cwd when run `git diff`\r\n'git' 不是内部或外部命令，也不是可运行的程序\r\n或批处理文件。\r\n[7724:mainthread](2022-10-14 07:53:34,158) info - qlib.workflow - [recorder.py:372] - fail to log the uncommitted code of $cwd when run `git status`\r\n'git' 不是内部或外部命令，也不是可运行的程序\r\n或批处理文件。\r\n[7724:mainthread](2022-10-14 07:53:34,164) info - qlib.workflow - [recorder.py:372] - fail to log the uncommitted code of $cwd when run `git diff --cached`\r\nexception in thread thread-1:\r\ntraceback (most recent call last):\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\tool-1.29.0-py3.8.egg\\tool\\tracking\\_tracking_service\\client.py\", line 301, in log_param\r\n    self.store.log_param(run_id, param)\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\tool-1.29.0-py3.8.egg\\tool\\store\\tracking\\file_store.py\", line 887, in log_param\r\n    _validate_param(param.key, param.value)\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\tool-1.29.0-py3.8.egg\\tool\\utils\\validation.py\", line 148, in _validate_param\r\n    _validate_length_limit(\"param value\", max_param_val_length, value)\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\tool-1.29.0-py3.8.egg\\tool\\utils\\validation.py\", line 269, in _validate_length_limit\r\n    raise toolexception(\r\ntool.exceptions.toolexception: param value '[{'class': 'signalrecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'model': '<model>', 'dataset': '<dataset>'}}, {'class': 'siganarecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'ana_long_short': false, 'ann_scaler': 25' had length 780, which exceeded length limit of 500\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ntraceback (most recent call last):\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\pyqlib-0.8.6.99-py3.8-win-amd64.egg\\qlib\\utils\\paral.py\", line 91, in run\r\n    data()\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\pyqlib-0.8.6.99-py3.8-win-amd64.egg\\qlib\\workflow\\recorder.py\", line 441, in log_params\r\n    self.client.log_param(self.id, name, data)\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\tool-1.29.0-py3.8.egg\\tool\\tracking\\client.py\", line 858, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  file \"d:\\programdata\\anaconda3\\envs\\py38\\lib\\site-packages\\tool-1.29.0-py3.8.egg\\tool\\tracking\\_tracking_service\\client.py\", line 305, in log_param\r\n    raise toolexception(msg, invalid_parameter_value)\r\ntool.exceptions.toolexception: param value '[{'class': 'signalrecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'model': '<model>', 'dataset': '<dataset>'}}, {'class': 'siganarecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'ana_long_short': false, 'ann_scaler': 25' had length 780, which exceeded length limit of 500\r\n\r\nthe cause of this error is typically due to repeated calls\r\nto an individual run_id event logging.\r\n\r\nincorrect example:\r\n---------------------------------------\r\nwith tool.start_run():\r\n    tool.log_param(\"depth\", 3)\r\n    tool.log_param(\"depth\", 5)\r\n---------------------------------------\r\n\r\nwhich will throw an toolexception for overwriting a\r\nlogged parameter.\r\n\r\ncorrect example:\r\n---------------------------------------\r\nwith tool.start_run():\r\n    with tool.start_run(nested=true):\r\n        tool.log_param(\"depth\", 3)\r\n    with tool.start_run(nested=true):\r\n        tool.log_param(\"depth\", 5)\r\n---------------------------------------\r\n\r\nwhich will create a new nested run for each individual\r\nmodel and prevent parameter key collisions within the\r\ntracking store.'\r\n[7724:mainthread](2022-10-14 07:53:35,515) info - qlib.gats - [pytorch_gats_ts.py:81] - gats pytorch version...\r\n[7724:mainthread](2022-10-14 07:53:35,562) info - qlib.gats - [pytorch_gats_ts.py:100] - gats parameters setting:\r\nd_feat : 158\r\nhidden_size : 64\r\nnum_layers : 2\r\ndropout : 0.7\r\nn_epochs : 200\r\nlr : 0.0001\r\nmetric : loss\r\nearly_stop : 10\r\noptimizer : adam\r\nloss_type : mse\r\nbase_model : lstm\r\nmodel_path : none\r\nvisible_gpu : 0\r\nuse_gpu : true\r\nseed : none\r\n[7724:mainthread](2022-10-14 07:53:35,562) info - qlib.gats - [pytorch_gats_ts.py:146] - model:\r\ngatmodel(\r\n  (rnn): lstm(158, 64, num_layers=2, batch_first=true, dropout=0.7)\r\n  (transformation): linear(in_features=64, out_features=64, bias=true)\r\n  (fc): linear(in_features=64, out_features=64, bias=true)\r\n  (fc_out): linear(in_features=64, out_features=1, bias=true)\r\n  (leaky_relu): leakyrelu(negative_slope=0.01)\r\n  (softmax): softmax(dim=1)\r\n)\r\n\r\n\r\n\r\n\r\nthen the program re-run again.\r\ni am wondering how to fix it.\r\nthanks a lot.\r\n\r\n\r\n\r\n\r\n## to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n\r\n1.\r\n1.\r\n1.\r\n\r\n\r\n## expected behavior\r\n\r\n<!-- a clear and concise description of what you expected to happen. -->\r\n\r\n## screenshot\r\n\r\n<!-- a screenshot of the error message or anything shouldn't appear-->\r\n\r\n## environment\r\n\r\n**note**: user could run `cd scripts && python collect_info.py all` under project directory to get system information\r\nand paste them here directly.\r\n\r\n - qlib version:\r\n - 0.8.6.99'\r\n - python version:\r\n - 3.8.5\r\n - os (`windows`, `linux`, `macos`):\r\n - windows 10\r\n - commit number (optional, please provide it if you are using the dev version):\r\n\r\n## additional notes\r\n\r\n<!-- add any other information about the problem here. -->\r\n",
          "Title: \"dumps computation\" at the start of validation loop when using tool/tool.ml logger during multi-core tpu training; Content:## 🐛 bug\r\n\r\ni am training a resnet model on multi core tpus on kaggle. i get this error:\r\n```\r\ndumping computation:\r\n2021-10-08 23:57:50.220206: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92108 = s32[] constant(0)\r\n2021-10-08 23:57:50.220217: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %compare.92110 = pred[] compare(s32[] %constant.92102, s32[] %constant.92108), direction=ne, type=unsigned\r\n2021-10-08 23:57:50.220227: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92109 = f32[] constant(1)\r\n2021-10-08 23:57:50.220238: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92111 = f32[] convert(s32[] %constant.92102)\r\n2021-10-08 23:57:50.220248: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %divide.92112 = f32[] divide(f32[] %constant.92109, f32[] %convert.92111)\r\n2021-10-08 23:57:50.220260: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92113 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220271: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %select.92114 = f32[] select(pred[] %compare.92110, f32[] %divide.92112, f32[] %constant.92113)\r\n2021-10-08 23:57:50.220281: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %multiply.92115 = f32[] multiply(f32[] %reduce.92107, f32[] %select.92114)\r\n2021-10-08 23:57:50.220292: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92116 = f32[] convert(f32[] %multiply.92115)\r\n2021-10-08 23:57:50.220302: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.134449 = f32[1]{0} reshape(f32[] %convert.92116)\r\n2021-10-08 23:57:50.220312: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.92081 = f32[1]{0} reshape(f32[] %p3148.47101)\r\n2021-10-08 23:57:50.220323: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %concatenate.92082 = f32[1]{0} concatenate(f32[1]{0} %reshape.92081), dimensions={0}\r\n2021-10-08 23:57:50.220333: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92083 = f32[] constant(0)\r\n2021-10-08 23:57:50.220343: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reduce.92089 = f32[] reduce(f32[1]{0} %concatenate.92082, f32[] %constant.92083), dimensions={0}, to_apply=%addcomputation.92085\r\n2021-10-08 23:57:50.220353: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92084 = s32[] constant(1)\r\n2021-10-08 23:57:50.220364: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92090 = s32[] constant(0)\r\n2021-10-08 23:57:50.220375: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %compare.92092 = pred[] compare(s32[] %constant.92084, s32[] %constant.92090), direction=ne, type=unsigned\r\n2021-10-08 23:57:50.220387: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92091 = f32[] constant(1)\r\n2021-10-08 23:57:50.220397: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92093 = f32[] convert(s32[] %constant.92084)\r\n2021-10-08 23:57:50.220408: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %divide.92094 = f32[] divide(f32[] %constant.92091, f32[] %convert.92093)\r\n2021-10-08 23:57:50.220418: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92095 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220465: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %select.92096 = f32[] select(pred[] %compare.92092, f32[] %divide.92094, f32[] %constant.92095)\r\n2021-10-08 23:57:50.220482: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %multiply.92097 = f32[] multiply(f32[] %reduce.92089, f32[] %select.92096)\r\n2021-10-08 23:57:50.220494: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92098 = f32[] convert(f32[] %multiply.92097)\r\n2021-10-08 23:57:50.220504: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.134450 = f32[1]{0} reshape(f32[] %convert.92098)\r\n2021-10-08 23:57:50.220515: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.92063 = f32[1]{0} reshape(f32[] %p3147.47082)\r\n2021-10-08 23:57:50.220525: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %concatenate.92064 = f32[1]{0} concatenate(f32[1]{0} %reshape.92063), dimensions={0}\r\n2021-10-08 23:57:50.220535: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92065 = f32[] constant(0)\r\n2021-10-08 23:57:50.220545: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reduce.92071 = f32[] reduce(f32[1]{0} %concatenate.92064, f32[] %constant.92065), dimensions={0}, to_apply=%addcomputation.92067\r\n2021-10-08 23:57:50.220556: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92066 = s32[] constant(1)\r\n2021-10-08 23:57:50.220566: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92072 = s32[] constant(0)\r\n2021-10-08 23:57:50.220576: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %compare.92074 = pred[] compare(s32[] %constant.92066, s32[] %constant.92072), direction=ne, type=unsigned\r\n2021-10-08 23:57:50.220587: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92073 = f32[] constant(1)\r\n2021-10-08 23:57:50.220598: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92075 = f32[] convert(s32[] %constant.92066)\r\n2021-10-08 23:57:50.220608: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %divide.92076 = f32[] divide(f32[] %constant.92073, f32[] %convert.92075)\r\n2021-10-08 23:57:50.220618: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92077 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220629: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %select.92078 = f32[] select(pred[] %compare.92074, f32[] %divide.92076, f32[] %constant.92077)\r\n2021-10-08 23:57:50.220640: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %multiply.92079 = f32[] multiply(f32[] %reduce.92071, f32[] %select.92078)\r\n2021-10-08 23:57:50.220650: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92080 = f32[] convert(f32[] %multiply.92079)\r\n2021-10-08 23:57:50.220660: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.134451 = f32[1]{0} reshape(f32[] %convert.92080)\r\n2021-10-08 23:57:50.220670: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.92045 = f32[1]{0} reshape(f32[] %p3146.47063)\r\n2021-10-08 23:57:50.220680: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %concatenate.92046 = f32[1]{0} concatenate(f32[1]{0} %reshape.92045), dimensions={0}\r\n2021-10-08 23:57:50.220691: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92047 = f32[] constant(0)\r\n2021-10-08 23:57:50.220701: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reduce.92053 = f32[] reduce(f32[1]{0} %concatenate.92046, f32[] %constant.92047), dimensions={0}, to_apply=%addcomputation.92049\r\n2021-10-08 23:57:50.220711: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92048 = s32[] constant(1)\r\n2021-10-08 23:57:50.220722: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92054 = s32[] constant(0)\r\n2021-10-08 23:57:50.220733: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %compare.92056 = pred[] compare(s32[] %constant.92048, s32[] %constant.92054), direction=ne, type=unsigned\r\n2021-10-08 23:57:50.220759: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92055 = f32[] constant(1)\r\n2021-10-08 23:57:50.220770: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92057 = f32[] convert(s32[] %constant.92048)\r\n2021-10-08 23:57:50.220781: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %divide.92058 = f32[] divide(f32[] %constant.92055, f32[] %convert.92057)\r\n2021-10-08 23:57:50.220792: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92059 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220803: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %select.92060 = f32[] select(pred[] %compare.92056, f32[] %divide.92058, f32[] %constant.92059)\r\n2021-10-08 23:57:50.220813: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %multiply.92061 = f32[] multiply(f32[] %reduce.92053, f32[] %select.92060)\r\n2021-10-08 23:57:50.220823: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92062 = f32[] convert(f32[] %multiply.92061)\r\n2021-10-08 23:57:50.220833: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.134452 = f32[1]{0} reshape(f32[] %convert.92062)\r\n2021-10-08 23:57:50.220843: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reshape.92027 = f32[1]{0} reshape(f32[] %p3145.47044)\r\n2021-10-08 23:57:50.220854: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %concatenate.92028 = f32[1]{0} concatenate(f32[1]{0} %reshape.92027), dimensions={0}\r\n2021-10-08 23:57:50.220865: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92029 = f32[] constant(0)\r\n2021-10-08 23:57:50.220876: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %reduce.92035 = f32[] reduce(f32[1]{0} %concatenate.92028, f32[] %constant.92029), dimensions={0}, to_apply=%addcomputation.92031\r\n2021-10-08 23:57:50.220888: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92030 = s32[] constant(1)\r\n2021-10-08 23:57:50.220899: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92036 = s32[] constant(0)\r\n2021-10-08 23:57:50.220910: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %compare.92038 = pred[] compare(s32[] %constant.92030, s32[] %constant.92036), direction=ne, type=unsigned\r\n2021-10-08 23:57:50.220921: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92037 = f32[] constant(1)\r\n2021-10-08 23:57:50.220932: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92039 = f32[] convert(s32[] %constant.92030)\r\n2021-10-08 23:57:50.220942: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %divide.92040 = f32[] divide(f32[] %constant.92037, f32[] %convert.92039)\r\n2021-10-08 23:57:50.220953: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %constant.92041 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220964: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %select.92042 = f32[] select(pred[] %compare.92038, f32[] %divide.92040, f32[] %constant.92041)\r\n2021-10-08 23:57:50.220975: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %multiply.92043 = f32[] multiply(f32[] %reduce.92035, f32[] %select.92042)\r\n2021-10-08 23:57:50.220986: e tensorflow/compiler/xla/xla_client/xla_util.cc:76] %convert.92044 = f32[] convert(f32[] %multiply.92043)\r\n```\r\nthis text goes on and on for several pages.\r\n\r\nthe first epoch runs fine at first and just as the validation loop starts, the training crashes and this text is printed as output.\r\n\r\nnote that this only happens when using a logger (tool or tool.ml) and everything works fine when i do `self.print` or normal `print` as evident in this [notebook](https://www.kaggle.com/rustyelectron/documentclassification-pytorch-tpu-no-logging/).\r\n\r\n> i have also tried adding very small batch sizes so this probably isn't a memory issue\r\n\r\n### to reproduce\r\n\r\nsee this [notebook](https://www.kaggle.com/rustyelectron/documentclassification-pytorch-tpu-resnet200d) that uses tool and [this](https://www.kaggle.com/rustyelectron/documentclassification-pytorch-tpu-tool-ml) with tool.ml.\r\n\r\n### expected behavior\r\n\r\ntraining should run normally with no issues and logging should work.\r\n\r\n### environment\r\n\r\n* cuda:\r\n\t- gpu:\r\n\t- available:         false\r\n\t- version:           none\r\n* packages:\r\n\t- numpy:             1.19.5\r\n\t- pytorch_debug:     false\r\n\t- pytorch_version:   1.7.1+cpu\r\n\t- pytorch-lightning: 1.4.4\r\n\t- tqdm:              4.62.1\r\n\t- pytorch-xla  1.7\r\n* system:\r\n\t- os:                linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.10\r\n\r\n### additional context\r\nnone\r\n\n\ncc @kaushikb11 @rohitgr7 @awaelchli @morganmcg1 @ayushexel @borisdayma @scottire",
          "Title: running train_model from examples after install needs directory \"tool\"; Content:after installing graphnet from scratch and signing up to tool, running train_model from examples yields the following error:\r\n\r\n```\r\n(graphnet) [peter@hep04 examples]$ python train_model.py \r\ngraphnet: info     2022-08-30 12:21:56 - get_logger - writing log to logs/graphnet_20220830-122156.log\r\ngraphnet: warning  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ngraphnet: warning  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ngraphnet: warning  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ngraphnet: warning  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ntool: currently logged in as: peterandresen (graphnet-team). use `tool login --relogin` to force relogin\r\ntool: warning path ./tool/tool/ wasn't writable, using system temp directory.\r\ntraceback (most recent call last):\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 1040, in init\r\n    wi.setup(kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 287, in setup\r\n    self._log_setup(settings)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 431, in _log_setup\r\n    filesystem._safe_makedirs(os.path.dirname(settings.log_user))\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/filesystem.py\", line 10, in _safe_makedirs\r\n    os.makedirs(dir_name)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\npermissionerror: [errno 13] permission denied: '/tmp/tool/run-20220830_122200-1qc85fm4'\r\ntool: error abnormal program exit\r\ntraceback (most recent call last):\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 1040, in init\r\n    wi.setup(kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 287, in setup\r\n    self._log_setup(settings)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 431, in _log_setup\r\n    filesystem._safe_makedirs(os.path.dirname(settings.log_user))\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/lib/filesystem.py\", line 10, in _safe_makedirs\r\n    os.makedirs(dir_name)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\npermissionerror: [errno 13] permission denied: '/tmp/tool/run-20220830_122200-1qc85fm4'\r\n\r\nthe above exception was the direct cause of the following exception:\r\n\r\ntraceback (most recent call last):\r\n  file \"train_model.py\", line 37, in <module>\r\n    tool_logger = toollogger(\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loggers/tool.py\", line 315, in __init__\r\n    _ = self.experiment\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loggers/logger.py\", line 54, in experiment\r\n    return get_experiment() or dummyexperiment()\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/utilities/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loggers/logger.py\", line 52, in get_experiment\r\n    return fn(self)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/pytorch_lightning/loggers/tool.py\", line 361, in experiment\r\n    self._experiment = tool.init(**self._tool_init)\r\n  file \"/groups/icecube/peter/anaconda3/envs/graphnet/lib/python3.8/site-packages/tool/sdk/tool_init.py\", line 1081, in init\r\n    raise exception(\"problem\") from error_seen\r\nexception: problem\r\n```\r\n\r\nwhich can be fixed by creating a folder called \"tool\" in the place where you are running the file from. would it make sense to automatically create such a folder, if it is not already present?",
          "Title: only display the tool add prompt if there is anything to add; Content:currently, it will display always display\r\n`========== make your selection, press \"h\" for help ==========`\r\neven if there is no selection to make since the list of files is empty\r\n\r\nhttps://github.com/dagshub/fds/blob/a8fea54f59131d3ddea4df5184adeee3ecc9998f/fds/services/tool_service.py#l119",
          "Title: tool ui deployment error; Content:```\r\nattributeerror: 'databaseservicemetadatapipeline' object has no attribute 'mlmodelfilterpattern'\r\n```\r\n\r\nwe need to review which configuration param is being sent here",
          "Title: various issues in `example-tool-experiments`; Content:> these are reported by @tapadipti (thanks). i'm moving here to discuss and follow: \r\n\r\ni was running experiments by following the docs (https://tool.org/doc/start/experiments) and encountered the following issues. sharing here for any required action.\r\n1. tool is not installed by `pip install -r requirements.txt`. so, if someone is trying to use a new virtual env, they need to install tool separately. would be good to include `tool` in `requirements.txt`.\r\n2. `tool pull` gave this error:\r\n   ```\r\n   error: failed to pull data from the cloud - checkout failed for following targets:\r\n   models/model.h5\r\n   metrics\r\n   is your cache up to date?\r\n   <https://error.tool.org/missing-files>\r\n   ```\r\n\r\n3. `tool exp run` lists all the image when running the `extract` stage. would be good to remove `-v` from `tar -xvzf data/images.tar.gz --directory data`\r\n4. `if you used tool repro before` section in the doc is a little unclear. does `tool exp run` replace `tool repro`? if yes, can we state this clearly? also would be great to change this statement `we use tool repro to run the pipeline...` to `tool repro runs the pipeline...`",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          7.618433475494385,
          8.242518424987793,
          8.251585006713867,
          6.83449649810791,
          6.86244535446167,
          8.512738227844238,
          8.380563735961914,
          7.241706371307373,
          6.967068195343018,
          7.4551215171813965,
          7.424499988555908,
          7.086727142333984,
          8.601219177246094,
          9.721510887145996,
          6.782670497894287,
          9.641412734985352,
          6.802227973937988,
          5.570671558380127,
          9.270540237426758,
          7.8834943771362305,
          7.920348644256592,
          6.81620454788208,
          7.996586322784424,
          8.45433521270752,
          8.454069137573242,
          8.227213859558105,
          9.522988319396973,
          6.871763229370117,
          7.044863224029541,
          8.109390258789062,
          8.445186614990234,
          6.385232448577881,
          10.467050552368164,
          6.076991558074951,
          7.007779121398926,
          7.750056266784668,
          5.6998138427734375,
          8.02519416809082,
          7.640824317932129,
          7.279115200042725,
          6.551455974578857,
          11.107975959777832,
          7.490274429321289,
          6.16657829284668,
          8.336701393127441,
          7.128647804260254,
          7.302779674530029,
          7.793972492218018,
          6.06596040725708,
          7.064521789550781,
          7.2518229484558105,
          6.4113688468933105,
          9.649999618530273,
          7.576245307922363,
          6.114460468292236,
          6.264604091644287,
          8.56074047088623,
          7.169464111328125,
          7.6057281494140625,
          7.132863998413086,
          6.266315937042236,
          7.899938583374023,
          7.7944746017456055,
          8.39547061920166,
          8.492815017700195,
          6.884191989898682,
          6.788511753082275,
          7.919065475463867,
          5.6171345710754395,
          6.938299179077148,
          8.025877952575684,
          8.202664375305176,
          6.871407985687256,
          10.221826553344727,
          6.1383466720581055,
          6.742594242095947,
          8.291828155517578,
          8.047696113586426,
          10.44191837310791,
          8.266877174377441,
          7.344654083251953,
          6.255101203918457,
          10.326132774353027,
          7.5428643226623535,
          6.744415760040283,
          8.28394889831543,
          7.120362758636475,
          6.387684345245361,
          9.853676795959473,
          9.331594467163086,
          7.864151954650879,
          7.0444865226745605,
          10.578683853149414,
          7.271107196807861,
          7.628827095031738,
          7.604598522186279,
          8.725726127624512,
          9.2182035446167,
          9.17577075958252,
          8.496511459350586,
          8.262889862060547,
          6.868177890777588,
          6.175089359283447,
          7.09082555770874,
          9.65347671508789,
          10.156335830688477,
          6.707118511199951,
          5.628583908081055,
          6.674129009246826,
          6.953125,
          7.720984935760498
         ],
         "y": [
          3.208211898803711,
          5.328641891479492,
          5.318787574768066,
          1.2788945436477661,
          4.086363792419434,
          2.937283992767334,
          4.872421741485596,
          4.556776523590088,
          2.907247304916382,
          2.9710447788238525,
          3.816805124282837,
          2.753278970718384,
          4.230283260345459,
          3.209487199783325,
          3.4624948501586914,
          3.276228189468384,
          3.487565040588379,
          3.861921548843384,
          3.839615821838379,
          2.0004377365112305,
          2.988354444503784,
          3.7995896339416504,
          3.7390549182891846,
          1.4586453437805176,
          3.768599510192871,
          2.2497477531433105,
          4.323925971984863,
          3.7229135036468506,
          2.899820566177368,
          3.6702518463134766,
          3.59395170211792,
          2.958728075027466,
          2.3318352699279785,
          3.6176602840423584,
          3.7176599502563477,
          3.793726682662964,
          3.1026294231414795,
          4.043284893035889,
          1.3884949684143066,
          1.4929746389389038,
          2.238421678543091,
          3.0743227005004883,
          3.561518430709839,
          2.3240206241607666,
          2.341858386993408,
          4.3642191886901855,
          3.854984760284424,
          4.4639434814453125,
          3.655938148498535,
          2.0229074954986572,
          3.466003894805908,
          4.117488384246826,
          3.2453877925872803,
          4.95102596282959,
          3.5851480960845947,
          4.7029032707214355,
          2.9904019832611084,
          2.482923984527588,
          1.447399377822876,
          3.5884668827056885,
          4.378978252410889,
          2.938307762145996,
          4.197624206542969,
          2.088573694229126,
          1.5134605169296265,
          2.9579966068267822,
          4.165621280670166,
          1.383643627166748,
          4.213665008544922,
          4.508875846862793,
          3.1459848880767822,
          1.8611959218978882,
          4.022074222564697,
          4.262933254241943,
          2.6444942951202393,
          5.305845737457275,
          5.30962610244751,
          4.010523796081543,
          4.205415725708008,
          2.2199785709381104,
          1.8112537860870361,
          4.958045959472656,
          4.230170726776123,
          2.9074487686157227,
          2.9354209899902344,
          5.249531269073486,
          1.9028836488723755,
          4.193569660186768,
          3.3779287338256836,
          3.092106580734253,
          2.0550906658172607,
          3.032034158706665,
          4.734813213348389,
          1.3229293823242188,
          4.786008834838867,
          4.946613788604736,
          4.24976110458374,
          2.505779504776001,
          2.524667978286743,
          4.254894733428955,
          5.289032936096191,
          3.7869722843170166,
          3.552623987197876,
          4.353055953979492,
          3.228191375732422,
          3.655118227005005,
          4.770169734954834,
          4.2690229415893555,
          2.893709182739258,
          3.720210075378418,
          3.4406251907348633
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: fix logging of parameters on tool; Content:logging of parameters on tool works as expected with default parameters set with hydra; however hydra allows modification of parameters per experiment run, but modified parameters are not logged on tool.  ",
          "Title: tool checkpoints in the wrong location ; Content:i'm not sure if i'm doing something wrong, i'm using tool instead of tensorboard as a logger. i've used the defaults i.e.\r\n\r\n```\r\ntool = loggers.toollogger()\r\ntrainer = pl.trainer.from_argparse_args(args, logger=tool)\r\n```\r\n\r\ni'm ending up with the following folder structure\r\n\r\n\\tool\r\n\\tool\\1\r\n\\tool\\1\\\\{guid}\\artifacts\r\n\\tool\\1\\\\{guid}\\metrics\r\n\\tool\\1\\\\{guid}\\params\r\n\\tool\\1\\\\{guid}\\meta.yaml\r\n**\\1\\\\{guid}\\checkpoints**\r\n\r\ni.e. the checkpoints are in the wrong location, they should be in the `\\tool` folder. \r\n\r\nperhaps this is an tool rather than pytorch-lightning issue? \r\n\r\ni'm using pytorch-lightning 0.8.5 on macos running in python 3.7.6\r\n",
          "Title: tool is not compatible with pl 1.6.1; Content:hi,\r\n\r\nthere may be version conflict between tool and pl 1.6.1\r\n\r\n**os:** ubuntu20.04\r\n**python:** 3.8.13\r\n**pytorch:**  1.11.0\r\n**pl:** 1.6.1\r\n**tool:** 0.12.11\r\n**hydra-core:** 1.1.2\r\n\r\nwhen i use the hyperparameter search, it produces the following error:\r\n\r\n```python\r\nfilenotfounderror: [errno 2] no such file or directory: '/**/logs/experiments/multiruns/**/time/0/tool/offline-run-20*/logs/debug-internal.log'\r\nproblem at: /home/*/anaconda3/envs/*/lib/python3.8/site-packages/pytorch_lightning/loggers/tool.py 357 experiment\r\n```\r\n",
          "Title: config type in toollogger; Content:this is more like a suggestion than a bug. the `config` parameter to the toollogger is supposed to be of type `args.namespace`. therefore it converts it to a dictionary inside its `arge_parse` function using `vars(.)`. this might be restrictive in some cases if someone wants to pass configs directly as a dictionary (for example when hyperparameters are loaded from a yaml file). wouldn't it be better to do the conversion outside the logger to make it more general in terms of config input?\r\n\r\nthanks :)",
          "Title: toollogger: \"connection aborted.\" - remotedisconnected error; Content:**describe the bug**\r\ni try to do multi-label classification with \"doc_classification_multilabel.py\". it worked at first. however when it came to `\"train epoch 1/1:  65%|██████▍   | 17251/26668 [10:19:41<4:04:28,  1.56s/it]\"`, it stopped and report:\r\n\r\n```\r\n  file \"/home/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n    chunked=chunked,\r\n  file \"/home/python3.6/site-packages/urllib3/connectionpool.py\", line 421, in _make_request\r\n    six.raise_from(e, none)\r\n  file \"<string>\", line 3, in raise_from\r\n  file \"/home/python3.6/site-packages/urllib3/connectionpool.py\", line 416, in _make_request\r\n    httplib_response = conn.getresponse()\r\n  file \"/home/python3.6/http/client.py\", line 1331, in getresponse\r\n    response.begin()\r\n  file \"/home/python3.6/http/client.py\", line 297, in begin\r\n    version, status, reason = self._read_status()\r\n  file \"/home/python3.6/http/client.py\", line 266, in _read_status\r\n    raise remotedisconnected(\"remote end closed connection without\"\r\nhttp.client.remotedisconnected: remote end closed connection without response\r\n......\r\nurllib3.exceptions.protocolerror: ('connection aborted.', remotedisconnected('remote end closed connection without response',))\r\n```\r\n\r\n  i have checked that the internet connection was ok. so i was confused why this error occured ?\r\n  \r\n\r\n**error message**\r\nerror that was thrown (if available)\r\n\r\n**expected behavior**\r\na clear and concise description of what you expected to happen.\r\n\r\n**additional context**\r\nadd any other context about the problem here, like type of downstream task, part of  etc.. \r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior\r\n\r\n**system:**\r\n - os: \r\n - gpu/cpu:\r\n - farm version:\r\n",
          "Title: question: how to save hydra config to tool config.yaml; Content:hello, \r\n\r\ni'm using `tool` logger (and `csv` as well), i found recently `hydra` config no longer save to `tool` 's`config.yaml` file.\r\nbefore:\r\n```\r\ntool_version: 1\r\n\r\n_tool:\r\n  desc: null\r\n  value:\r\n    cli_version: 0.13.4\r\n    framework: lightning\r\n    is_jupyter_run: false\r\n    is_kaggle_kernel: false\r\n    m:\r\n    - 1: trainer/global_step\r\n      6:\r\n      - 3\r\n    - 1: val/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val/acc_best\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: epoch\r\n      5: 1\r\n      6:\r\n      - 1\r\n    python_version: 3.9.13\r\n    start_time: 1665409636.577166\r\n    t:\r\n      1:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      2:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      3:\r\n      - 2\r\n      - 7\r\n      - 13\r\n      - 23\r\n      4: 3.9.13\r\n      5: 0.13.4\r\n      8:\r\n      - 5\r\ncallbacks/early_stopping/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.earlystopping\r\ncallbacks/early_stopping/check_finite:\r\n  desc: null\r\n  value: true\r\ncallbacks/early_stopping/check_on_train_epoch_end:\r\n  desc: null\r\n  value: none\r\ncallbacks/early_stopping/divergence_threshold:\r\n  desc: null\r\n  value: none\r\ncallbacks/early_stopping/min_delta:\r\n  desc: null\r\n  value: 0.0\r\ncallbacks/early_stopping/mode:\r\n  desc: null\r\n  value: max\r\ncallbacks/early_stopping/monitor:\r\n  desc: null\r\n  value: val/acc\r\ncallbacks/early_stopping/patience:\r\n  desc: null\r\n  value: 100\r\ncallbacks/early_stopping/stopping_threshold:\r\n  desc: null\r\n  value: none\r\ncallbacks/early_stopping/strict:\r\n  desc: null\r\n  value: true\r\ncallbacks/early_stopping/verbose:\r\n  desc: null\r\n  value: false\r\ncallbacks/model_checkpoint/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.modelcheckpoint\r\ncallbacks/model_checkpoint/auto_insert_metric_name:\r\n  desc: null\r\n  value: false\r\ncallbacks/model_checkpoint/dirpath:\r\n  desc: null\r\n  value: /users/caoyu/github/lightning-hydra-template/logs/train/runs/2022-10-10_14-47-15/checkpoints\r\ncallbacks/model_checkpoint/every_n_epochs:\r\n  desc: null\r\n  value: none\r\ncallbacks/model_checkpoint/every_n_train_steps:\r\n  desc: null\r\n  value: none\r\ncallbacks/model_checkpoint/filename:\r\n  desc: null\r\n  value: epoch_{epoch:03d}\r\ncallbacks/model_checkpoint/mode:\r\n  desc: null\r\n  value: max\r\ncallbacks/model_checkpoint/monitor:\r\n  desc: null\r\n  value: val/acc\r\ncallbacks/model_checkpoint/save_last:\r\n  desc: null\r\n  value: true\r\ncallbacks/model_checkpoint/save_on_train_epoch_end:\r\n  desc: null\r\n  value: none\r\ncallbacks/model_checkpoint/save_top_k:\r\n  desc: null\r\n  value: 1\r\ncallbacks/model_checkpoint/save_weights_only:\r\n  desc: null\r\n  value: false\r\ncallbacks/model_checkpoint/train_time_interval:\r\n  desc: null\r\n  value: none\r\ncallbacks/model_checkpoint/verbose:\r\n  desc: null\r\n  value: false\r\ncallbacks/model_summary/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.richmodelsummary\r\ncallbacks/model_summary/max_depth:\r\n  desc: null\r\n  value: -1\r\ncallbacks/rich_progress_bar/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.richprogressbar\r\nckpt_path:\r\n  desc: null\r\n  value: none\r\ndatamodule/_target_:\r\n  desc: null\r\n  value: src.datamodules.mnist_datamodule.mnistdatamodule\r\ndatamodule/batch_size:\r\n  desc: null\r\n  value: 128\r\ndatamodule/data_dir:\r\n  desc: null\r\n  value: /users/caoyu/github/lightning-hydra-template/data/\r\ndatamodule/num_workers:\r\n  desc: null\r\n  value: 0\r\ndatamodule/pin_memory:\r\n  desc: null\r\n  value: false\r\ndatamodule/train_val_test_split:\r\n  desc: null\r\n  value:\r\n  - 55000\r\n  - 5000\r\n  - 10000\r\nextras/enforce_tags:\r\n  desc: null\r\n  value: true\r\nextras/ignore_warnings:\r\n  desc: null\r\n  value: false\r\nextras/print_config:\r\n  desc: null\r\n  value: true\r\nmodel/_target_:\r\n  desc: null\r\n  value: src.models.mnist_module.mnistlitmodule\r\nmodel/net/_target_:\r\n  desc: null\r\n  value: src.models.components.simple_dense_net.simpledensenet\r\nmodel/net/input_size:\r\n  desc: null\r\n  value: 784\r\nmodel/net/lin1_size:\r\n  desc: null\r\n  value: 64\r\nmodel/net/lin2_size:\r\n  desc: null\r\n  value: 128\r\nmodel/net/lin3_size:\r\n  desc: null\r\n  value: 64\r\nmodel/net/output_size:\r\n  desc: null\r\n  value: 10\r\nmodel/optimizer/_partial_:\r\n  desc: null\r\n  value: true\r\nmodel/optimizer/_target_:\r\n  desc: null\r\n  value: torch.optim.adam\r\nmodel/optimizer/lr:\r\n  desc: null\r\n  value: 0.001\r\nmodel/optimizer/weight_decay:\r\n  desc: null\r\n  value: 0.0\r\nmodel/params/non_trainable:\r\n  desc: null\r\n  value: 0\r\nmodel/params/total:\r\n  desc: null\r\n  value: 67978\r\nmodel/params/trainable:\r\n  desc: null\r\n  value: 67978\r\nmodel/scheduler/_partial_:\r\n  desc: null\r\n  value: true\r\nmodel/scheduler/_target_:\r\n  desc: null\r\n  value: torch.optim.lr_scheduler.reducelronplateau\r\nmodel/scheduler/factor:\r\n  desc: null\r\n  value: 0.1\r\nmodel/scheduler/mode:\r\n  desc: null\r\n  value: min\r\nmodel/scheduler/patience:\r\n  desc: null\r\n  value: 10\r\nseed:\r\n  desc: null\r\n  value: 123\r\ntags:\r\n  desc: null\r\n  value:\r\n  - dev\r\ntask_name:\r\n  desc: null\r\n  value: train\r\ntrainer/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.trainer\r\ntrainer/accelerator:\r\n  desc: null\r\n  value: cpu\r\ntrainer/check_val_every_n_epoch:\r\n  desc: null\r\n  value: 1\r\ntrainer/default_root_dir:\r\n  desc: null\r\n  value: /users/caoyu/github/lightning-hydra-template/logs/train/runs/2022-10-10_14-47-15\r\ntrainer/deterministic:\r\n  desc: null\r\n  value: false\r\ntrainer/devices:\r\n  desc: null\r\n  value: 1\r\ntrainer/max_epochs:\r\n  desc: null\r\n  value: 3\r\ntrainer/min_epochs:\r\n  desc: null\r\n  value: 1\r\n```\r\nnow:\r\n```\r\ntool_version: 1\r\n\r\n_tool:\r\n  desc: null\r\n  value:\r\n    cli_version: 0.13.6\r\n    framework: lightning\r\n    is_jupyter_run: false\r\n    is_kaggle_kernel: false\r\n    m:\r\n    - 1: trainer/global_step\r\n      6:\r\n      - 3\r\n    - 1: val/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val/acc_best\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: epoch\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: train/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: train/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: test/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: test/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    python_version: 3.8.15\r\n    start_time: 1670583155.275978\r\n    t:\r\n      1:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      2:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      3:\r\n      - 2\r\n      - 7\r\n      - 23\r\n      4: 3.8.15\r\n      5: 0.13.6\r\n      8:\r\n      - 5\r\n```\r\nthis may related to:\r\nhttps://github.com/ashleve/lightning-hydra-template/blob/16fb9a6a807d278d1797ce4dedc885c7e5e1b7fb/src/utils/utils.py#l172\r\nany idea how to restore to previous state?",
          "Title: permission denied when log models to tool on mac; Content:```\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/models/model.py\", line 188, in log\r\n    tool.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/tracking/fluent.py\", line 584, in log_artifacts\r\n    toolclient().log_artifacts(run_id, local_dir, artifact_path)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/tracking/client.py\", line 977, in log_artifacts\r\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/tracking/_tracking_service/client.py\", line 334, in log_artifacts\r\n    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/store/artifact/local_artifact_repo.py\", line 57, in log_artifacts\r\n    mkdir(artifact_dir)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/utils/file_utils.py\", line 113, in mkdir\r\n    raise e\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/site-packages/tool/utils/file_utils.py\", line 110, in mkdir\r\n    os.makedirs(target)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/os.py\", line 215, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/os.py\", line 215, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/os.py\", line 215, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  [previous line repeated 2 more times]\r\n  file \"/users/lei/miniforge3/envs/rikai/lib/python3.9/os.py\", line 225, in makedirs\r\n    mkdir(name, mode)\r\npermissionerror: [errno 13] permission denied: '/var/lib/tool'\r\n```\r\n\r\nenvironment:\r\n* tool==1.2\r\n* macos 12.1",
          "Title: warning when training tool-pytorch 2.0.0; Content:`2021/02/03 19:07:05 warning tool.utils.autologging_utils: encountered unexpected error during autologging: float() argument must be a string or a number, not 'accuracy'`\r\n\r\nprinted after every epoch!",
          "Title: tool logger not working; Content:hi there, \r\nthank you for this powerful template! \r\ni run into a problem while trying to use tool as logger\r\ni used the tool-callbacks branch and after `python train.py logger=tool` i get (cancelled by user after 130 iterations cause tool login does not appear)\r\n\r\n````\r\n$ python train.py logger=tool\r\n┌────┬───────────────┬──────────────────┬────────┐\r\n│    │ name          │ type             │ params │\r\n├────┼───────────────┼──────────────────┼────────┤\r\n│ 0  │ model         │ simpledensenet   │  336 k │\r\n│ 1  │ model.model   │ sequential       │  336 k │\r\n│ 2  │ model.model.0 │ linear           │  200 k │\r\n│ 3  │ model.model.1 │ batchnorm1d      │    512 │\r\n│ 4  │ model.model.2 │ relu             │      0 │\r\n│ 5  │ model.model.3 │ linear           │ 65.8 k │\r\n│ 6  │ model.model.4 │ batchnorm1d      │    512 │\r\n│ 7  │ model.model.5 │ relu             │      0 │\r\n│ 8  │ model.model.6 │ linear           │ 65.8 k │\r\n│ 9  │ model.model.7 │ batchnorm1d      │    512 │\r\n│ 10 │ model.model.8 │ relu             │      0 │\r\n│ 11 │ model.model.9 │ linear           │  2.6 k │\r\n│ 12 │ criterion     │ crossentropyloss │      0 │\r\n│ 13 │ train_acc     │ accuracy         │      0 │\r\n│ 14 │ val_acc       │ accuracy         │      0 │\r\n│ 15 │ test_acc      │ accuracy         │      0 │\r\n│ 16 │ val_acc_best  │ maxmetric        │      0 │\r\n└────┴───────────────┴──────────────────┴────────┘\r\ntrainable params: 336 k\r\nnon-trainable params: 0\r\ntotal params: 336 k\r\ntotal estimated model params size (mb): 1\r\nepoch 0    ----- ---------------------------------- 130/939 0:00:04 • 0:00:28 29.28it/s loss: 0.252\r\nerror executing job with overrides: ['logger=tool']\r\n````\r\n_(note the last line)_\r\n\r\nchanging `logger: tool` in train.yaml does not work either. i'm a bit confused because i had it working once before but just don't know what to do anymore. i tried out different conda envs with different torch and pl versions. does anyboady have an idea?\r\n\r\n\r\n**pip list**\r\n```\r\npackage                 version\r\n----------------------- ------------\r\nabsl-py                 1.1.0\r\naiohttp                 3.8.1\r\naiosignal               1.2.0\r\nalembic                 1.8.0\r\nantlr4-python3-runtime  4.8\r\nanyio                   3.6.1\r\nargon2-cffi             21.3.0\r\nargon2-cffi-bindings    21.2.0\r\nasttokens               2.0.5\r\nasync-timeout           4.0.2\r\natomicwrites            1.4.0\r\nattrs                   21.4.0\r\nautopage                0.5.1\r\nbabel                   2.10.1\r\nbackcall                0.2.0\r\nbeautifulsoup4          4.11.1\r\nblack                   22.3.0\r\nbleach                  5.0.0\r\ncachetools              5.2.0\r\ncertifi                 2022.5.18.1\r\ncffi                    1.15.0\r\ncfgv                    3.3.1\r\ncharset-normalizer      2.0.12\r\nclick                   8.1.3\r\ncliff                   3.10.1\r\ncmaes                   0.8.2\r\ncmd2                    2.4.1\r\ncolorama                0.4.4\r\ncolorlog                6.6.0\r\ncommonmark              0.9.1\r\ncycler                  0.11.0\r\ndebugpy                 1.6.0\r\ndecorator               5.1.1\r\ndefusedxml              0.7.1\r\ndistlib                 0.3.4\r\ndocker-pycreds          0.4.0\r\nentrypoints             0.4\r\nexecuting               0.8.3\r\nfastjsonschema          2.15.3\r\nfilelock                3.7.1\r\nflake8                  4.0.1\r\nfonttools               4.33.3\r\nfrozenlist              1.3.0\r\nfsspec                  2022.5.0\r\ngitdb                   4.0.9\r\ngitpython               3.1.27\r\ngoogle-auth             2.6.6\r\ngoogle-auth-oauthlib    0.4.6\r\ngreenlet                1.1.2\r\ngrpcio                  1.46.3\r\nhydra-colorlog          1.2.0\r\nhydra-core              1.1.0\r\nhydra-optuna-sweeper    1.2.0\r\nidentify                2.5.1\r\nidna                    3.3\r\nimportlib-metadata      4.11.4\r\nimportlib-resources     5.7.1\r\niniconfig               1.1.1\r\nipykernel               6.13.0\r\nipython                 8.4.0\r\nipython-genutils        0.2.0\r\nisort                   5.10.1\r\njedi                    0.18.1\r\njinja2                  3.1.2\r\njoblib                  1.1.0\r\njson5                   0.9.8\r\njsonschema              4.6.0\r\njupyter-client          7.3.1\r\njupyter-core            4.10.0\r\njupyter-server          1.17.0\r\njupyterlab              3.4.2\r\njupyterlab-pygments     0.2.2\r\njupyterlab-server       2.14.0\r\nkiwisolver              1.4.2\r\nmako                    1.2.0\r\nmarkdown                3.3.7\r\nmarkupsafe              2.1.1\r\nmatplotlib              3.5.2\r\nmatplotlib-inline       0.1.3\r\nmccabe                  0.6.1\r\nmistune                 0.8.4\r\nmultidict               6.0.2\r\nmypy-extensions         0.4.3\r\nnbclassic               0.3.7\r\nnbclient                0.6.4\r\nnbconvert               6.5.0\r\nnbformat                5.4.0\r\nnest-asyncio            1.5.5\r\nnodeenv                 1.6.0\r\nnotebook                6.4.11\r\nnotebook-shim           0.1.0\r\nnumpy                   1.22.4\r\noauthlib                3.2.0\r\nomegaconf               2.1.2\r\noptuna                  2.10.0\r\npackaging               21.3\r\npandas                  1.4.2\r\npandocfilters           1.5.0\r\nparso                   0.8.3\r\npathspec                0.9.0\r\npathtools               0.1.2\r\npbr                     5.9.0\r\npickleshare             0.7.5\r\npillow                  9.1.1\r\npip                     21.2.2\r\nplatformdirs            2.5.2\r\npluggy                  1.0.0\r\npre-commit              2.19.0\r\nprettytable             3.3.0\r\nprometheus-client       0.14.1\r\npromise                 2.3\r\nprompt-toolkit          3.0.29\r\nprotobuf                3.20.1\r\npsutil                  5.9.1\r\npudb                    2022.1.1\r\npure-eval               0.2.2\r\npy                      1.11.0\r\npyasn1                  0.4.8\r\npyasn1-modules          0.2.8\r\npycodestyle             2.8.0\r\npycparser               2.21\r\npydeprecate             0.3.2\r\npyflakes                2.4.0\r\npygments                2.12.0\r\npyparsing               3.0.9\r\npyperclip               1.8.2\r\npyreadline3             3.4.1\r\npyrsistent              0.18.1\r\npytest                  7.1.2\r\npython-dateutil         2.8.2\r\npython-dotenv           0.20.0\r\npytorch-lightning       1.6.4\r\npytz                    2022.1\r\npywin32                 304\r\npywinpty                2.0.5\r\npyyaml                  6.0\r\npyzmq                   23.1.0\r\nrequests                2.27.1\r\nrequests-oauthlib       1.3.1\r\nrich                    12.4.4\r\nrsa                     4.8\r\nscikit-learn            1.1.1\r\nscipy                   1.8.1\r\nseaborn                 0.11.2\r\nsend2trash              1.8.0\r\nsentry-sdk              1.5.12\r\nsetproctitle            1.2.3\r\nsetuptools              61.2.0\r\nsh                      1.14.2\r\nshortuuid               1.0.9\r\nsix                     1.16.0\r\nsmmap                   5.0.0\r\nsniffio                 1.2.0\r\nsoupsieve               2.3.2.post1\r\nsqlalchemy              1.4.37\r\nstack-data              0.2.0\r\nstevedore               3.5.0\r\ntensorboard             2.9.0\r\ntensorboard-data-server 0.6.1\r\ntensorboard-plugin-wit  1.8.1\r\nterminado               0.15.0\r\nthreadpoolctl           3.1.0\r\ntinycss2                1.1.1\r\ntoml                    0.10.2\r\ntomli                   2.0.1\r\ntorch                   1.11.0+cu113\r\ntorchaudio              0.11.0+cu113\r\ntorchmetrics            0.9.0\r\ntorchvision             0.12.0+cu113\r\ntornado                 6.1\r\ntqdm                    4.64.0\r\ntraitlets               5.2.2.post1\r\ntyping_extensions       4.2.0\r\nurllib3                 1.26.9\r\nurwid                   2.1.2\r\nurwid-readline          0.13\r\nvirtualenv              20.14.1\r\ntool                   0.12.17\r\nwcwidth                 0.2.5\r\nwebencodings            0.5.1\r\nwebsocket-client        1.3.2\r\nwerkzeug                2.1.2\r\nwheel                   0.37.1\r\nwincertstore            0.2\r\nyarl                    1.7.2\r\nzipp                    3.8.0\r\n```",
          "Title: toollogger fail when logging long parameters; Content:## 🐛 bug\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\n\r\n## please reproduce using the boringmodel\r\n\r\n\r\n<!-- please paste your boringmodel colab link here. -->\r\n\r\n### to reproduce\r\n\r\nlog anything  parameters longer than 250 characters\r\n\r\n\r\n<!-- if you could not reproduce using the boringmodel and still think there's a bug, please post here -->\r\n\r\n### expected behavior\r\n\r\n<!-- fill in -->\r\n\r\ntoollogger not sending parameters longer than 250 characters to tool and log warning to user\r\n\r\n### environment\r\n\r\n\r\n - pytorch version (e.g., 1.0):\r\n - os (e.g., linux): \r\n - how you installed pytorch (`conda`, `pip`, source): pip\r\n - build command you used (if compiling from source):\r\n - python version: 3.7\r\n - cuda/cudnn version:\r\n - gpu models and configuration:\r\n - any other relevant information:\r\n\r\n### additional context\r\n\r\ntool only allow paramters to be at most 500 bytes (250 unicode characters), their limit in database is 250 characters:\r\nhttps://www.tool.org/docs/latest/rest-api.html#log-param\r\nhttps://github.com/tool/tool/issues/1976\r\nhttps://github.com/tool/tool/issues/3931\r\n\r\n\r\n<!-- add any other context about the problem here. -->\r\n",
          "Title: pickle error from trainer.fit when using toollogger and distributed data parallel without slurm; Content:## 🐛 bug\r\n\r\ntrainer.fit fails with a pickle error when the logger is toollogger, and distributed_backend='ddp' on gpus but without slurm.\r\n\r\n### to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n\r\n1. instantiate toollogger in pytorch 0.5.3.2 with pytorch 1.3.1 and tool 1.4.0. the execution environment has environment variables tool_tracking_uri, and also tool_tracking_username and tool_tracking_password to connect to the tool tracking server with http basic authentication. the tool tracking server is also v1.4.0.\r\n2. instantiate trainer with toollogger instance as logger, distributed_backend='ddp' and with the gpus parameter on a machine with nvidia gpus but without slurm.\r\n3. run trainer.fit\r\n\r\nfrom the error output, it looks like multiprocessing is attempting to pickle the nested function in tool function [_get_rest_store](https://github.com/tool/tool/blob/v1.4.0/tool/tracking/_tracking_service/utils.py#l81):\r\n```\r\nayla.khan@gpu12:~/photosynthetic$ python test_tool.py\r\ntraceback (most recent call last):\r\n  file \"test_tool.py\", line 71, in <module>\r\n    trainer.fit(model)\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 343, in fit\r\n    mp.spawn(self.ddp_train, nprocs=self.num_gpus, args=(model,))\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 162, in spawn\r\n    process.start()\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._popen(self)\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/multiprocessing/context.py\", line 284, in _popen\r\n    return popen(process_obj)\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  file \"/mnt/unihome/home/corp/ayla.khan/miniconda2/envs/photosynthetic/lib/python3.6/multiprocessing/reduction.py\", line 60, in dump\r\n    forkingpickler(file, protocol).dump(obj)\r\nattributeerror: can't pickle local object '_get_rest_store.<locals>.get_default_host_creds'\r\n```\r\n\r\n#### code sample\r\nsample code tested with a very simple test model ([gist](https://gist.github.com/a-y-khan/8693d2b186227561a4baf4d03ce75c34)):\r\n\r\n```\r\ntest_hparams = namespace()\r\nmodel = xorgatemodel(test_hparams)\r\n\r\nlogger = toollogger(experiment_name='test_lightning_logger',\r\n                                          tracking_uri=os.environ['tool_tracking_uri'])\r\ntrainer = pl.trainer(logger=logger, distributed_backend='ddp', gpus='-1')\r\ntrainer.fit(model)\r\n```\r\n\r\n### expected behavior\r\n\r\ntrainer.fit runs without error.\r\n\r\n### environment\r\n\r\n```\r\n(photosynthetic) ayla.khan@gpu12:~/photosynthetic$ python collect_env.py\r\ncollecting environment information...\r\npytorch version: 1.3.1\r\nis debug build: no\r\ncuda used to build pytorch: 10.1.243\r\n\r\nos: centos linux 7 (core)\r\ngcc version: (gcc) 4.8.5 20150623 (red hat 4.8.5-39)\r\ncmake version: could not collect\r\n\r\npython version: 3.6\r\nis cuda available: yes\r\ncuda runtime version: 10.0.130\r\ngpu models and configuration:\r\ngpu 0: geforce gtx 1080 ti\r\ngpu 1: geforce gtx 1080 ti\r\ngpu 2: geforce gtx 1080 ti\r\ngpu 3: geforce gtx 1080 ti\r\ngpu 4: geforce gtx 1080 ti\r\ngpu 5: geforce gtx 1080 ti\r\ngpu 6: geforce gtx 1080 ti\r\ngpu 7: geforce gtx 1080 ti\r\n\r\nnvidia driver version: 440.33.01\r\ncudnn version: /usr/local/cuda-10.0/lib64/libcudnn.so.7\r\n\r\nversions of relevant libraries:\r\n[pip] numpy==1.16.4\r\n[pip] pytorch-lightning==0.5.3.2\r\n[pip] pytorch-toolbelt==0.2.1\r\n[pip] torch==1.3.1\r\n[pip] torchsummary==1.5.1\r\n[pip] torchvision==0.4.2\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2019.4                      243\r\n[conda] mkl-service               2.3.0            py36he904b0f_0\r\n[conda] mkl_fft                   1.0.15           py36ha843d7b_0\r\n[conda] mkl_random                1.1.0            py36hd6b4f25_0\r\n[conda] pytorch                   1.3.1           py3.6_cuda10.1.243_cudnn7.6.3_0    pytorch\r\n[conda] pytorch-lightning         0.5.3.2                  pypi_0    pypi\r\n[conda] pytorch-toolbelt          0.2.1                    pypi_0    pypi\r\n[conda] torchsummary              1.5.1                    pypi_0    pypi\r\n[conda] torchvision               0.4.2                py36_cu101    pytorch\r\n```",
          "Title: unable to create tool logger when using pytorch lightning cli.; Content:## 🐛 bug\r\n\r\nunable to create tool logger when using pytorch lightning cli.\r\n\r\n### to reproduce\r\nhttps://colab.research.google.com/drive/1cveyyhcekjunkpcgy39ofrinwnivydjv?usp=sharing\r\n\r\n### expected behavior\r\nrun model.\r\n\r\n### environment\r\n\r\n* cuda:\r\n\t- gpu:\r\n\t\t- tesla t4\r\n\t- available:         true\r\n\t- version:           11.1\r\n* packages:\r\n\t- numpy:             1.21.5\r\n\t- pytorch_debug:     false\r\n\t- pytorch_version:   1.10.0+cu111\r\n\t- pytorch-lightning: 1.6.0\r\n\t- tqdm:              4.63.0\r\n* system:\r\n\t- os:                linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.13\r\n\t- version:           1 smp tue dec 7 09:58:10 pst 2021\r\n\r\n### additional context\r\n\r\nerror message:\r\n```\r\nepoch 1: 100% 32/32 [00:00<00:00, 300.70it/s, loss=-15.4, v_num=ff79]traceback (most recent call last):\r\n  file \"main.py\", line 48, in <module>\r\n    cli = lightningcli(boringmodel, litdataset, save_config_callback=none)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/cli.py\", line 564, in __init__\r\n    self._run_subcommand(self.subcommand)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/cli.py\", line 835, in _run_subcommand\r\n    fn(**fn_kwargs)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 772, in fit\r\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 724, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 812, in _fit_impl\r\n    results = self._run(model, ckpt_path=self.ckpt_path)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1237, in _run\r\n    results = self._run_stage()\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1324, in _run_stage\r\n    return self._run_train()\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1354, in _run_train\r\n    self.fit_loop.run()\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 204, in run\r\n    self.advance(*args, **kwargs)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 269, in advance\r\n    self._outputs = self.epoch_loop.run(self._data_fetcher)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 204, in run\r\n    self.advance(*args, **kwargs)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 246, in advance\r\n    self.trainer._logger_connector.update_train_step_metrics()\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py\", line 202, in update_train_step_metrics\r\n    self.log_metrics(self.metrics[\"log\"])\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py\", line 130, in log_metrics\r\n    logger.log_metrics(metrics=scalar_metrics, step=step)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/tool.py\", line 252, in log_metrics\r\n    self.experiment.log_metrics(metrics_without_epoch, step=step, epoch=epoch)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/base.py\", line 41, in experiment\r\n    return get_experiment() or dummyexperiment()\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in get_experiment\r\n    return fn(self)\r\n  file \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/tool.py\", line 223, in experiment\r\n    offline_directory=self.save_dir, project_name=self._project_name, **self._kwargs\r\ntypeerror: __init__() got an unexpected keyword argument 'agg_key_funcs'\r\n```\r\nfor some reason, `self._kwargs` there has `{'agg_key_funcs': none, 'agg_default_func': none}`.\n\ncc @awaelchli @edward-io @borda @ananthsub @rohitgr7 @kamil-kaczmarek @raalsky @blaizzy",
          "Title: using log_gpu_memory with tool logger causes an exception.; Content:## 🐛 bug\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\nusing log_gpu_memory with tool logger causes an error. it appears the name of the metric is not supported by tool.\r\n\r\n    toolexception: invalid metric name: 'gpu_id: 0/memory.used (mb)'. names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).\r\n\r\n### to reproduce\r\ni reproduced the bug with the boringmodel, in the link bellow:\r\nhttps://colab.research.google.com/drive/1p8uhsfjvyhkpmyrzh-qmfbouofnepy6g?usp=sharing\r\n\r\n### expected behavior\r\nlog_gpu_memory should log gpu memory correctly when using an tool logger.\r\n\r\n### environment\r\ncolab environment:\r\n\r\n* cuda:\r\n\t- gpu:\r\n\t\t- tesla t4\r\n\t- available:         true\r\n\t- version:           10.1\r\n* packages:\r\n\t- numpy:             1.18.5\r\n\t- pytorch_debug:     false\r\n\t- pytorch_version:   1.6.0+cu101\r\n\t- pytorch-lightning: 1.0.3\r\n\t- tqdm:              4.41.1\r\n* system:\r\n\t- os:                linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.6.9\r\n\t- version:           #1 smp thu jul 23 08:00:38 pdt 2020\r\n",
          "Title: logging issue when activating tool contrib; Content:**describe the bug**\r\n\r\nwhen activating the tool contrib, most of ludwig log message disappears.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n\r\nlaunch: `ludwig experiment --data_csv reuters-allcats.csv --model_definition_file model_definition.yaml -l info --tool`\r\n\r\nyou won't see the following output:\r\n```\r\n _         _        _      \r\n| |_  _ __| |_ __ _(_)__ _ \r\n| | || / _` \\ v  v / / _` |\r\n|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\r\n                     |___/ \r\nludwig v0.1.2 - experiment\r\n\r\nexperiment name: experiment\r\nmodel name: run\r\noutput path: results/experiment_run_43\r\n\r\n\r\nludwig_version: '0.1.2'\r\n```\r\n\r\n**expected behavior**\r\n\r\nthe log messages should be displayed when the tool contrib is activated.\r\n\r\n**environment (please complete the following information):**\r\n - os: fedora\r\n - version 28\r\n- python version: 3.6.8\r\n- ludwig version: 0.1.2\r\n\r\n**additional context**\r\n\r\ni think the issue is that ludwig is using the root-level logger configured through `logging.basicconfig`. the tool contrib integration contains some logging calls, for example, https://github.com/uber/ludwig/blob/master/ludwig/contribs/tool.py#l56.\r\n\r\nthose calls happen before any `basicconfig` call https://github.com/uber/ludwig/blob/master/ludwig/experiment.py#l461.\r\n\r\nthe issue with calling the root-level `logging.info`, `logging.error` and so on is that they will call `logging.basicconfig` on their own if the root logger is not configured yet https://github.com/python/cpython/blob/master/lib/logging/__init__.py#l2065. the direct effect is that the first call to `logging.info` will configure the root logger with no configuration which will create a streamhandler pointing to `/dev/stderr`.\r\n\r\nthe unfortunate side-effect is that calling `basicconfig` will do nothing as the root handler as already a handler so the root logger will not be set to the right log level and the stream handler will not point to the right device.\r\n\r\ni would recommend moving from using the root logger and configure the logger through `basicconfig` to using a `ludwig` logger and configure it manually, it's not that more complex. i can help if wanted.\r\n\r\none last issue with using the root logger is when configuring the root logger to the debug level, all libraries which are logging will start displaying their log messages. that includes requests and is polluting the output. using a separate logger would also solve this issue.\r\n",
          "Title: hydra tool clash; Content:<!-- \r\n### common bugs:\r\n1. tensorboard not showing in jupyter-notebook see [issue 79](https://github.com/pytorchlightning/pytorch-lightning/issues/79).    \r\n2. pytorch 1.1.0 vs 1.2.0 support [see faq](https://github.com/pytorchlightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## 🐛 bug\r\n\r\nwhen using the tool logger with hydra, because the parameters passed to the lightningmodule is a `dictconfig`, the condition in the `logger/base.py` is not met.\r\n\r\nhttps://github.com/pytorchlightning/pytorch-lightning/blob/8211256c46430e43e0c27e4f078c72085bb4ea34/pytorch_lightning/loggers/base.py#l177\r\n\r\n### to reproduce\r\n\r\nuse hydra and tool together. \r\n\r\n<!-- if you have a code sample, error messages, stack traces, please provide it here as well -->\r\n```python\r\ntraceback (most recent call last):\r\n  file \"/home/siavash/kronikare/kwae2/kwae_ma/models/pl_train_segmentation_model.py\", line 115, in <module>\r\n    main()\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/main.py\", line 24, in decorated_main\r\n    strict=strict,\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 174, in run_hydra\r\n    overrides=args.overrides,\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 86, in run\r\n    job_subdir_key=none,\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/plugins/common/utils.py\", line 109, in run_job\r\n    ret.return_value = task_function(task_cfg)\r\n  file \"/home/siavash/kronikare/kwae2/kwae_ma/models/pl_train_segmentation_model.py\", line 111, in main\r\n    trainer.fit(wound_seg_pl)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 765, in fit\r\n    self.single_gpu_train(model)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 492, in single_gpu_train\r\n    self.run_pretrain_routine(model)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 843, in run_pretrain_routine\r\n    self.logger.log_hyperparams(ref_model.hparams)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 275, in log_hyperparams\r\n    [logger.log_hyperparams(params) for logger in self._logger_iterable]\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 275, in <listcomp>\r\n    [logger.log_hyperparams(params) for logger in self._logger_iterable]\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py\", line 10, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/loggers/tool.py\", line 105, in log_hyperparams\r\n    self.experiment.log_param(self.run_id, k, v)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/tool/tracking/client.py\", line 206, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/tool/tracking/_tracking_service/client.py\", line 177, in log_param\r\n    _validate_param_name(key)\r\n  file \"/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/tool/utils/validation.py\", line 120, in _validate_param_name\r\n    invalid_parameter_value)\r\ntool.exceptions.toolexception: invalid parameter name: ''. names may be treated as files in certain cases, and must not resolve to other names when treated as such. this name would resolve to '.'\r\n```\r\n\r\n### expected behavior\r\n\r\ncheck whether the instance if `dict` or `dictconfig` in the given line. \r\n",
          "Title: test metrics not logging to tool after training; Content:## 🐛 bug\r\n\r\nwhen testing a model with `trainer.test` metrics are not logged to tool if the model was previously trained using `trainer.fit`. while training metrics are logged correctly.\r\n\r\n\r\n#### code sample\r\n```\r\n    tool_logger = toollogger()\r\n    trainer = trainer(logger=tool_logger)\r\n    model = get_model()\r\n\r\n    trainer.fit(model) # metrics are logged to tool\r\n    trainer.test(model) # no metrics are logged to tool\r\n```\r\n\r\n### expected behavior\r\n\r\ntest metrics should also be logged in to tool.\r\n\r\n### environment\r\n\r\n```\r\n- pytorch version: 1.3.0\r\nis debug build: no\r\ncuda used to build pytorch: 10.1.243\r\n\r\nos: ubuntu 18.04.3 lts\r\ngcc version: (ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\ncmake version: version 3.10.2\r\n\r\npython version: 3.7\r\nis cuda available: yes\r\ncuda runtime version: 10.1.168\r\ngpu models and configuration:\r\ngpu 0: geforce gtx 1080 ti\r\ngpu 1: geforce gtx 1080 ti\r\ngpu 2: geforce gtx 1080 ti\r\ngpu 3: geforce gtx 1080 ti\r\ngpu 4: geforce gtx 1080 ti\r\ngpu 5: geforce gtx 1080 ti\r\ngpu 6: geforce gtx 1080 ti\r\ngpu 7: geforce gtx 1080 ti\r\n\r\nnvidia driver version: 418.67\r\ncudnn version: /usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.7.6.1\r\n\r\nversions of relevant libraries:\r\n[pip3] numpy==1.16.4\r\n[pip3] pytorch-lightning==0.6.0\r\n[pip3] torch==1.3.0\r\n[pip3] torchvision==0.4.1\r\n[conda] could not collect\r\n```\r\n\r\n### additional context\r\n\r\ni believe the issue is caused because at the [end of the training routine](https://github.com/pytorchlightning/pytorch-lightning/blob/deffbaba7ffb16ff57b56fe65f62df761f25fbd6/pytorch_lightning/trainer/training_loop.py#l366), `logger.finalize(\"success\")` is called. this in turn calls `experiment.end()` inside the logger and the `experiment` object doesn't expect to send more information after this.\r\n\r\nan alternative is to create another `trainer` object, with another logger but this means that the metrics will be logged into a different tool experiment from the original. this issue can be solved using the `existingexperiment` object form the tool sdk, but the solution seems a little hacky and the `toollogger` currently doesn't support this kind of experiment.\r\n",
          "Title: tool logging: auxiliary values (e.g. `retriever/entropy`) are not logged; Content:none",
          "Title: [bug] tool logger does not work unless pytorch is installed ; Content:### 🐛 bug report\n\ntoollogger throws error while import if etna[torch] is not installed.\n\n### expected behavior\n\ntool logger should work no matter pytorch installation \n\n### how to reproduce\n\n1. create new env\r\n2. install etna and etna[tool]\r\n3. import toollogger\r\n\n\n### environment\n\n_no response_\n\n### additional context\n\n_no response_\n\n### checklist\n\n- [x] bug appears at the latest library version",
          "Title: tool logger; Content:none",
          "Title: toollogging always disabled for training `farmreader` models; Content:**describe the bug**\r\nwhen training a reader model, a user might want to log training statistics and metrics to tool. however, when initializing a `farmreader`, we initialize an `inferencer`. there, we call `toollogger.disable()` on [this line](https://github.com/deepset-ai/haystack/blob/15c70bdb9f8cd16511d1eb9ed9b2e9466de65cbf/haystack/modeling/infer.py#l77), which disables all logging to tool. therefore, when a user is calling the reader's `train` method after initializing the reader, no tranining statistics wil be logged.\r\n\r\nas a workaround, the user can manually set `toollogger.disable_logging = false` before calling the `train` method.",
          "Title: upgrading from 1.2.4 to 1.3.1 causes the pytorch tool logger to produce multiple experiments.; Content:## 🐛 bug\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\n\r\nwhen running a ddp multi-gpu experiment on a slurm cluster, pytorch-lightning==1.3.1, but not 1.2.4, creates multiple tool experiments, one for each gpu. only one of them logs any metrics, the others just sit. \r\n\r\n<img width=\"748\" alt=\"screen shot 2021-05-18 at 2 00 40 pm\" src=\"https://user-images.githubusercontent.com/1208492/118725668-1903b800-b7e5-11eb-84a5-096fa79fe332.png\">\r\n\r\n<img width=\"1477\" alt=\"screen shot 2021-05-18 at 1 59 26 pm\" src=\"https://user-images.githubusercontent.com/1208492/118725654-143f0400-b7e5-11eb-949b-4eb8de527502.png\">\r\n  \r\nhere is an experiment from the 'main' gpu, the one that actually logs the metrics.\r\nhttps://www.tool.ml/bw4sz/everglades/view/syqjplzx3sbwvfg27mojv0b8p\r\n\r\nhere is the same run, a gpu that just announces itself and does not log anything else:\r\nhttps://www.tool.ml/bw4sz/everglades/4d1b0d55601444ffbea00bd87b456c1e\r\n\r\n## please reproduce using the boringmodel\r\n\r\n### to reproduce\r\n\r\n<!-- if you could not reproduce using the boringmodel and still think there's a bug, please post here -->\r\n\r\ni do not know how to make a reproducible example, since you cannot do multi-gpu ddp in colab and would need a tool authentication, which i cannot paste here.\r\n\r\n### expected behavior\r\n\r\na single tool experiment for a single call to trainer.fit(). this was the behavior in lightning 1.2.4.\r\n\r\n### environment\r\n\r\n**note**: `bugs with code` are solved faster ! `colab notebook` should be made `public` !\r\n\r\n* `ide`: please, use our python [bug_report_model.py](https://github.com/pytorchlightning/pytorch-lightning/blob/master/pl_examples/bug_report_model.py\r\n) template.\r\n\r\n* `colab notebook`: please copy and paste the output from our [environment collection script](https://raw.githubusercontent.com/pytorchlightning/pytorch-lightning/master/tests/collect_env_details.py) (or fill out the checklist below manually).\r\n\r\nyou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorchlightning/pytorch-lightning/master/tests/collect_env_details.py\r\n# for security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\n - pytorch version (e.g., 1.0): \r\n torch==1.8.1\r\n pytorch-lightning==1.3.1\r\n - os (e.g., linux): linux\r\n - how you installed pytorch (`conda`, `pip`, source): pip\r\n - build command you used (if compiling from source):\r\n - python version: python 3.8.8\r\n - cuda/cudnn version: 10\r\n - gpu models and configuration: geforce 2080ti\r\n\r\n--\r\n\r\n<br class=\"apple-interchange-newline\">\r\n - any other relevant information:\r\n slurm hpc cluster, single node.\r\n\r\n### additional context\r\nproblem appears after upgrading to 1.3.1 from 1.2.4. i believe it is related to the thought behind this so post:\r\n\r\nhttps://stackoverflow.com/questions/66854148/proper-way-to-log-things-when-using-pytorch-lightning-ddp",
          "Title: must manually import `tool_ml` before `toollogger` to avoid import error; Content:## 🐛 bug\r\na few weeks ago, a [refactoring of logger imports](https://github.com/pytorchlightning/pytorch-lightning/commit/ec0fb7a3ec709699243c76dae04ee1e4ce2406a0#diff-7a041199139ffcca72689f9a15f47657330ff9d3206a46103e7a061a5fe2bc09) changed the ordering of imports for the `toollogger`. however, tool requires for `tool_ml` to be imported before some other dependencies, i.e. torch and tensorboard, to work properly. if not, you get the following error:\r\n```\r\nimporterror: you must import tool before these modules: torch, tensorboard\r\n```\r\n\r\nbefore the imports reordering, tool's import requirements could be met by importing `toollogger` before torch and tensorboard. however, since the refactoring, torch is now imported before tool in `loggers/tool.py` itself. this forces users to manually add an unused import for `tool_ml` before importing `toollogger` to avoid the above `importerror`.\r\n\r\n### to reproduce\r\nthis [**boringmodel**](https://colab.research.google.com/drive/1u7ve02v40rcebexg1515kmucxvelacnf?usp=sharing) example reproduces the `importerror`.\r\n\r\n### expected behavior\r\nusers should not have to manually import `tool_ml` before `toollogger` to avoid triggering the `importerror`. the `tool_ml` import inside `loggers/tool.py` should exceptionally come before the `torch` import, even if it violates usual import ordering.",
          "Title: use tensorboard as default logger and get tool optional within the project ; Content:none",
          "Title: tool logger complains about missing run_id; Content:## 🐛 bug\r\nwhen using tool logger, log_param() function require `run_id`\r\n```\r\n---------------------------------------------------------------------------\r\ntypeerror                                 traceback (most recent call last)\r\n<ipython-input-23-d048545e1854> in <module>\r\n      9 trainer.fit(model=experiment, \r\n     10            train_dataloader=train_dl,\r\n---> 11            val_dataloaders=test_dl)\r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)\r\n    452         self.call_hook('on_fit_start')\r\n    453 \r\n--> 454         results = self.accelerator_backend.train()\r\n    455         self.accelerator_backend.teardown()\r\n    456 \r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_backend.py in train(self)\r\n     51 \r\n     52         # train or test\r\n---> 53         results = self.train_or_test()\r\n     54         return results\r\n     55 \r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/base_accelerator.py in train_or_test(self)\r\n     48             results = self.trainer.run_test()\r\n     49         else:\r\n---> 50             results = self.trainer.train()\r\n     51         return results\r\n     52 \r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py in train(self)\r\n    499 \r\n    500                 # run train epoch\r\n--> 501                 self.train_loop.run_training_epoch()\r\n    502 \r\n    503                 if self.max_steps and self.max_steps <= self.global_step:\r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py in run_training_epoch(self)\r\n    525             # training_step + training_step_end\r\n    526             # ------------------------------------\r\n--> 527             batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)\r\n    528 \r\n    529             # when returning -1 from train_step, we end epoch early\r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py in run_training_batch(self, batch, batch_idx, dataloader_idx)\r\n    660                     opt_idx,\r\n    661                     optimizer,\r\n--> 662                     self.trainer.hiddens\r\n    663                 )\r\n    664 \r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py in training_step_and_backward(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\r\n    739         \"\"\"\r\n    740         # lightning module hook\r\n--> 741         result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)\r\n    742 \r\n    743         if result is none:\r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py in training_step(self, split_batch, batch_idx, opt_idx, hiddens)\r\n    300         with self.trainer.profiler.profile('model_forward'):\r\n    301             args = self.build_train_args(split_batch, batch_idx, opt_idx, hiddens)\r\n--> 302             training_step_output = self.trainer.accelerator_backend.training_step(args)\r\n    303             training_step_output = self.trainer.call_hook('training_step_end', training_step_output)\r\n    304 \r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_backend.py in training_step(self, args)\r\n     59                 output = self.__training_step(args)\r\n     60         else:\r\n---> 61             output = self.__training_step(args)\r\n     62 \r\n     63         return output\r\n\r\n~/anaconda3/envs/ns_dl_2020_torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_backend.py in __training_step(self, args)\r\n     67         batch = self.to_device(batch)\r\n     68         args[0] = batch\r\n---> 69         output = self.trainer.model.training_step(*args)\r\n     70         return output\r\n     71 \r\n\r\n<ipython-input-21-31b6dc3ffd67> in training_step(self, batch, batch_idx, optimizer_idx)\r\n     28         for key, val in train_loss.items():\r\n     29             self.log(key, val.item())\r\n---> 30             self.logger.experiment.log_param(key=key, value=val.item())\r\n     31 \r\n     32         return train_loss\r\n\r\ntypeerror: log_param() missing 1 required positional argument: 'run_id'\r\n```\r\n#### expected behavior\r\nthe toollogger should behave the same as the tool api where only key and value argment is needed for log_param() function\r\n\r\n#### code sample\r\n```python\r\nmlf_logger = toollogger(\r\n    experiment_name='test',\r\n    tracking_uri=\"file:./ml-runs\"\r\n)\r\n\r\ncllass vaeexperiment(lightningmodule):\r\n...\r\n    def training_step(self, batch, batch_idx, optimizer_idx = 0):\r\n        ....\r\n        for key, val in train_loss.items():\r\n            self.logger.experiment.log_param(key=key, value=val.item())\r\n       ....\r\n       return train_loss\r\n\r\ntrainer = trainer(logger=mlf_logger,\r\n                  default_root_dir='../logs',\r\n                  early_stop_callback=false,\r\n                  gpus=1, \r\n                  auto_select_gpus=true,\r\n                  max_epochs=40)\r\n\r\ntrainer.fit(model=experiment, \r\n           train_dataloader=train_dl, \r\n           val_dataloaders=test_dl)\r\n```\r\n\r\n\r\n### environment\r\n\r\npytorch-lightning==0.10.0\r\ntorch==1.6.0\r\ntorchsummary==1.5.1\r\ntorchvision==0.7.0\r\n\r\n\r\n",
          "Title: tool log only 1 run when using ddp and multirun; Content:when i use ddp, tool and multirun in `test.py` like this \r\n`python test.py -m ckpt_path='~~' +seed=1,2,3 +trainer.strategy=ddp logger=tool`\r\ntool does not record 3 runs, but only one run.\r\n",
          "Title: local tool logging is borked; Content:our current tool logging assumes the presence of an api key, which you don't need if you're running tool locally.\r\n\r\nwe should configure it so it works with tool locally, too. ",
          "Title: exception in backtest with `aggregate_metrics=true` when using `toollogger`; Content:### 🐛 bug report\n\nprogram fails when backtest with `aggregate_metrics=true` is used inside `toollogger` (if given). with `aggregate_metrics=false` everything is fine.\r\n\r\nexception happens in `tslogger.log_backtest_metrics` while constructing `metrics_df`: it can't make `metrics_df.groupby(\"segment\")`. \r\n\r\nexception was caught in `pipeline.backtest`, but it looks like this bug also appears in `timeseriescrossvalidation` class.\n\n### expected behavior\n\nno error.\n\n### how to reproduce\n\nrun backtest with wandlogger while setting `aggregate_metrics=true`. \n\n### environment\n\n_no response_\n\n### additional context\n\n_no response_\n\n### checklist\n\n- [x] bug appears at the latest library version\n- [x] bug description added\n- [x] steps to reproduce added\n- [x] expected behavior added",
          "Title: inconsistency in toollogger.log_metrics within steps; Content:## 🐛 inconsistency in toollogger.log_metrics within steps\r\n\r\nthe [documentation](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.tool.html) for toollogger states that it has a method log_metrics which signature is as follows:\r\n\r\n`log_metrics(metrics, step=none)`\r\n\r\nwhere **metrics** (dict[str, float]) – dictionary with metric names as keys and measured quantities as values and \r\n**step** (optional[int]) – step number at which the metrics should be recorded.\r\n\r\nwhen within a training/validation/test _step method of a lightningmodule:\r\n- setting `self.logger.experiment.log_metrics({\"train_loss\": loss})` results in the fit method raising `attributeerror: 'toolclient' object has no attribute 'log_metrics'`\r\n- setting `self.logger.experiment.log_metric({\"train_loss\": loss})` results in the fit method raising `typeerror: log_metric() missing 2 required positional arguments: 'key' and 'value'`\r\n- setting `self.logger.experiment.log_metric(\"train_loss\", loss)` results in the fit method raising `typeerror: log_metric() missing 1 required positional argument: 'value'`\r\n\r\nfound the behavior from the last two options by luck because of a typo. the logger would expect `log_metric` despite the documentation saying the method is called `log_metrics`. even if i use `log_metric` the method expects parameters other than the dict[str, float] stated in the documentation.\r\n\r\n### to reproduce\r\n\r\nthis is the minimum code i found that reproduces the bug:\r\n\r\nhttps://github.com/mmazuecos/pytorch_lightning_tool_bug/blob/main/pytorch_lightning_tool_bug.py\r\n\r\n### expected behavior\r\n\r\nthe code should work with the `log_metrics` signature from the documentation.\r\n\r\n### environment\r\n\r\n* cuda:\r\n\t- gpu:\r\n\t- available:         false\r\n\t- version:           none\r\n* packages:\r\n\t- numpy:             1.21.2\r\n\t- pytorch_debug:     false\r\n\t- pytorch_version:   1.7.1.post2\r\n\t- pytorch-lightning: 1.4.5\r\n\t- tqdm:              4.62.2\r\n* system:\r\n\t- os:                linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- elf\r\n\t- processor:         x86_64\r\n\t- python:            3.8.11\r\n\t- version:           #148-ubuntu smp sat may 8 02:33:43 utc 2021\r\n",
          "Title: richprogressbar doesn't display progress bar when using tool logger.; Content:## 🐛 bug\r\n\r\nrichprogressbar doesn't display progress bar when using tool logger.\r\ni verified it works correctly with tensorboard and tool.\r\n\r\n\r\n### to reproduce\r\n```python\r\nimport tool_ml\r\nimport os\r\n\r\nimport torch\r\nfrom pytorch_lightning import lightningmodule, trainer\r\nfrom torch.utils.data import dataloader, dataset\r\nfrom pytorch_lightning.loggers import toollogger\r\nfrom pytorch_lightning.callbacks import richprogressbar\r\n\r\n\r\nclass randomdataset(dataset):\r\n    def __init__(self, size: int, length: int):\r\n        self.len = length\r\n        self.data = torch.randn(length, size)\r\n\r\n    def __getitem__(self, index):\r\n        return self.data[index]\r\n\r\n    def __len__(self):\r\n        return self.len\r\n\r\n\r\nclass boringmodel(lightningmodule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer = torch.nn.linear(32, 2)\r\n\r\n    def forward(self, x):\r\n        return self.layer(x)\r\n\r\n    def loss(self, batch, prediction):\r\n        # an arbitrary loss to have a loss that updates the model weights during `trainer.fit` calls\r\n        return torch.nn.functional.mse_loss(prediction, torch.ones_like(prediction))\r\n\r\n    def step(self, x):\r\n        x = self(x)\r\n        out = torch.nn.functional.mse_loss(x, torch.ones_like(x))\r\n        return out\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        output = self(batch)\r\n        loss = self.loss(batch, output)\r\n        return {\"loss\": loss}\r\n\r\n    def training_step_end(self, training_step_outputs):\r\n        return training_step_outputs\r\n\r\n    def training_epoch_end(self, outputs) -> none:\r\n        torch.stack([x[\"loss\"] for x in outputs]).mean()\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        output = self(batch)\r\n        loss = self.loss(batch, output)\r\n        return {\"x\": loss}\r\n\r\n    def validation_epoch_end(self, outputs) -> none:\r\n        torch.stack([x[\"x\"] for x in outputs]).mean()\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        output = self(batch)\r\n        loss = self.loss(batch, output)\r\n        return {\"y\": loss}\r\n\r\n    def test_epoch_end(self, outputs) -> none:\r\n        torch.stack([x[\"y\"] for x in outputs]).mean()\r\n\r\n    def configure_optimizers(self):\r\n        optimizer = torch.optim.sgd(self.layer.parameters(), lr=0.1)\r\n        lr_scheduler = torch.optim.lr_scheduler.steplr(optimizer, step_size=1)\r\n        return [optimizer], [lr_scheduler]\r\n\r\n    def train_dataloader(self):\r\n        return dataloader(randomdataset(32, 64))\r\n\r\n    def val_dataloader(self):\r\n        return dataloader(randomdataset(32, 64))\r\n\r\n    def test_dataloader(self):\r\n        return dataloader(randomdataset(32, 64))\r\n\r\n    def predict_dataloader(self):\r\n        return dataloader(randomdataset(32, 64))\r\n\r\n\r\nmodel = boringmodel()\r\n\r\nlogger = toollogger(api_key=os.environ.get(\"tool_api_token\"))\r\n\r\ntrainer = trainer(logger=logger, max_epochs=100, callbacks=[richprogressbar()])\r\n# trainer = trainer(logger=logger, max_epochs=100)\r\n\r\ntrainer.fit(model=model)\r\n```\r\n\r\n### environment\r\n- pytorch lightning version 1.5.5\r\n- pytorch version 1.10.0\r\n- python version 3.8\r\n- os ubuntu 20.04\n\ncc @kaushikb11 @rohitgr7 @seannaren",
          "Title: tool logger doesn't seem to log with tpu_cores=8; Content:## 🐛 bug\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\n\r\n## please reproduce using the boringmodel\r\n\r\n\r\n<!-- please paste your boringmodel colab link here. -->\r\n\r\n### to reproduce\r\n\r\nuse following [**boringmodel**](https://colab.research.google.com/drive/1hvwvvtk8j2nj52qu4q4ycyzom0_alqf3?usp=sharing) and post here\r\n\r\n<!-- if you could not reproduce using the boringmodel and still think there's a bug, please post here -->\r\n\r\n### expected behavior\r\n\r\n<!-- fill in -->\r\n\r\n### environment\r\n\r\n**note**: `bugs with code` are solved faster ! `colab notebook` should be made `public` !\r\n\r\n* `ide`: please, use our python [bug_report_model.py](https://github.com/pytorchlightning/pytorch-lightning/blob/master/pl_examples/bug_report_model.py\r\n) template.\r\n\r\n* `colab notebook`: please copy and paste the output from our [environment collection script](https://raw.githubusercontent.com/pytorchlightning/pytorch-lightning/master/tests/collect_env_details.py) (or fill out the checklist below manually).\r\n\r\nyou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorchlightning/pytorch-lightning/master/tests/collect_env_details.py\r\n# for security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\n - pytorch version (e.g., 1.0):\r\n - os (e.g., linux):\r\n - how you installed pytorch (`conda`, `pip`, source):\r\n - build command you used (if compiling from source):\r\n - python version:\r\n - cuda/cudnn version:\r\n - gpu models and configuration:\r\n - any other relevant information:\r\n\r\n### additional context\r\n\r\n<!-- add any other context about the problem here. -->\r\n\n\ncc @tchaton",
          "Title: toollogger failing without save_dir; Content:<!-- \r\n### common bugs:\r\n1. tensorboard not showing in jupyter-notebook see [issue 79](https://github.com/pytorchlightning/pytorch-lightning/issues/79).    \r\n2. pytorch 1.1.0 vs 1.2.0 support [see faq](https://github.com/pytorchlightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## 🐛 bug\r\n\r\ntoolmllogger with api key and  without save dir results in error.\r\nthis happens due to this if https://github.com/pytorchlightning/pytorch-lightning/blob/master/pytorch_lightning/loggers/tool.py#l135\r\n_save_dir is not set and later train loop tries to read it and fails.\r\nthis can be fixed by setting _save_dir to none. i will supply pr in a moment\r\n\r\n### to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n```\r\n    model = lightningmodel({})\r\n    tool_logger = toollogger(\r\n        api_key=key,\r\n        workspace=\"workspace\"\r\n    )\r\n\r\n    trainer = trainer(logger=tool_logger)\r\n    trainer.fit(model)\r\n```\r\n<!-- if you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n\r\n\r\n\r\n<!-- a clear and concise description of what you expected to happen. -->\r\n\r\n\r\ntraceback (most recent call last):\r\ntrainer.fit(model)\r\nfile \"/python3.8/site-packages/pytorch_lightning/trainer/states.py\", line 48, in wrapped_fn\r\nresult = fn(self, *args, **kwargs)\r\nfile \"/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1073, in fit\r\nresults = self.accelerator_backend.train(model)\r\nfile \"/python3.8/site-packages/pytorch_lightning/accelerators/gpu_backend.py\", line 51, in train\r\nresults = self.trainer.run_pretrain_routine(model)\r\nfile \"/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1239, in run_pretrain_routine\r\nself.train()\r\nfile \"/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\", line 363, in train\r\nself.on_train_start()\r\nfile \"/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 111, in on_train_start\r\ncallback.on_train_start(self, self.get_model())\r\nfile \"/python3.8/site-packages/pytorch_lightning/utilities/distributed.py\", line 27, in wrapped_fn\r\nreturn fn(*args, **kwargs)\r\nfile \"/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 296, in on_train_start\r\nsave_dir = trainer.logger.save_dir or trainer.default_root_dir\r\nfile \"/python3.8/site-packages/pytorch_lightning/loggers/tool.py\", line 253, in save_dir\r\nreturn self._save_dir\r\n\r\n### additional context\r\n\r\n<!-- add any other context about the problem here. -->\r\n",
          "Title: test metrics are no longer pushed to tool.ml (and perhaps others); Content:## 🐛 bug\r\n\r\npytorch lightning 0.7.2 used to publish test metrics to tool.ml.  commit https://github.com/pytorchlightning/pytorch-lightning/commit/ddbf7de6dc97924de07331f1575ee0b37cb7f7aa has broken this functionality.\r\n\r\n### to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n\r\nrun fast-run of training and observe test metrics not being submitted to tool.ml (and possibly other logging destinations).\r\n\r\n### environment\r\n\r\n```\r\ncuda:\r\n        gpu:\r\n                tesla t4\r\n        available:           true\r\n        version:             10.1\r\npackages:\r\n        numpy:               1.17.2\r\n        pytorch_debug:       false\r\n        pytorch_version:     1.4.0\r\n        pytorch-lightning:   0.7.4-dev\r\n        tensorboard:         2.2.0\r\n        tqdm:                4.45.0\r\nsystem:\r\n        os:                  linux\r\n        architecture:\r\n                64bit\r\n\r\n        processor:           x86_64\r\n        python:              3.6.8\r\n        version:             #69-ubuntu smp thu mar 26 02:17:29 utc 2020\r\n```\r\n\r\ncc @alexeykarnachev",
          "Title: toollogger does not implement name() and version() class methods; Content:explicitly creating a toollogger instance and passing it to trainer using trainer(logger=my_tool_logger) raises a notimplementederror because toollogger does not implement the name() and version() class methods.\r\n\r\nbelow is the traceback:\r\n`\r\ntraceback (most recent call last):\r\n  file \"main.py\", line 126, in <module>\r\n    trainer.fit(model)\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 351, in fit\r\n    self.single_gpu_train(model)\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/dp_mixin.py\", line 77, in single_gpu_train\r\n    self.run_pretrain_routine(model)\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 471, in run_pretrain_routine\r\n    self.train()\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/train_loop_mixin.py\", line 60, in train\r\n    self.run_training_epoch()\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/train_loop_mixin.py\", line 99, in run_training_epoch\r\n    output = self.run_training_batch(batch, batch_nb)\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/train_loop_mixin.py\", line 255, in run_training_batch\r\n    self.main_progress_bar.set_postfix(**self.training_tqdm_dict)\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 309, in training_tqdm_dict\r\n    if self.logger is not none and self.logger.version is not none:\r\n  file \"/home/ryan/miniconda3/envs/compling/lib/python3.7/site-packages/pytorch_lightning/logging/base.py\", line 76, in version\r\n    raise notimplementederror(\"sub-classes must provide a version property\")\r\n`\r\n\r\n",
          "Title: show lightgbm logs in the logs in tool; Content:current execution lets lightgbm handle its own logs, they are likely printed in stdout, but don't show up in tool",
          "Title: pytorch tool container stderr output; Content:in pytorch images all the prints in stderr are not catched and are ignored:\r\n\r\n\r\n### describe the problem\r\n\r\n### minimal repro / logs\r\nentrypoint.py:\r\n\r\n```\r\nif __name__ == '__main__':\r\n    import sys\r\n    sys.stderr.write('coucou stderr')\r\n    sys.stdout.write('coucou stdout')\r\n```\r\n\r\n```\r\nfrom tool.pytorch import pytorch\r\nestimator = pytorch(entry_point='entrypoint.py',\r\n                    role=role,\r\n                    framework_version='1.1.0',\r\n                    train_instance_count=1,\r\n                    train_instance_type='local',\r\n                )\r\nestimator.fit({'config': 's3://tool-eu-*************/config/test_tool_1.json'})\r\n```\r\n\r\n<details><summary>logs</summary>\r\n<p>\r\n\r\ncreating tmpqp7i_4w3_algo-1-8gd7b_1 ... \r\nattaching to tmpqp7i_4w3_algo-1-8gd7b_12mdone\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,345 tool-containers info     imported framework tool_pytorch_container.training\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,349 tool-containers info     no gpus detected (normal if no gpus installed)\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,363 tool_pytorch_container.training info     block until all host dns lookups succeed.\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,365 tool_pytorch_container.training info     invoking user training script.\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,489 tool-containers info     module entrypoint does not provide a setup.py. \r\nalgo-1-8gd7b_1  | generating setup.py\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,489 tool-containers info     generating setup.cfg\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,489 tool-containers info     generating manifest.in\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,490 tool-containers info     installing module with the following command:\r\nalgo-1-8gd7b_1  | /usr/bin/python -m pip install . \r\nalgo-1-8gd7b_1  | processing /opt/ml/code\r\nalgo-1-8gd7b_1  | building wheels for collected packages: entrypoint\r\nalgo-1-8gd7b_1  |   running setup.py bdist_wheel for entrypoint ... done\r\nalgo-1-8gd7b_1  |   stored in directory: /tmp/pip-ephem-wheel-cache-44kbrxy0/wheels/35/24/16/37574d11bf9bde50616c******356bc7164af8ca3\r\nalgo-1-8gd7b_1  | successfully built entrypoint\r\nalgo-1-8gd7b_1  | installing collected packages: entrypoint\r\nalgo-1-8gd7b_1  | successfully installed entrypoint-1.0.0\r\nalgo-1-8gd7b_1  | you are using pip version 18.1, however version 19.3.1 is available.\r\nalgo-1-8gd7b_1  | you should consider upgrading via the 'pip install --upgrade pip' command.\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:23,054 tool-containers info     no gpus detected (normal if no gpus installed)\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:23,069 tool-containers info     invoking user script\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | training env:\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | {\r\nalgo-1-8gd7b_1  |     \"additional_framework_parameters\": {},\r\nalgo-1-8gd7b_1  |     \"channel_input_dirs\": {\r\nalgo-1-8gd7b_1  |         \"config\": \"/opt/ml/input/data/config\"\r\nalgo-1-8gd7b_1  |     },\r\nalgo-1-8gd7b_1  |     \"current_host\": \"algo-1-8gd7b\",\r\nalgo-1-8gd7b_1  |     \"framework_module\": \"tool_pytorch_container.training:main\",\r\nalgo-1-8gd7b_1  |     \"hosts\": [\r\nalgo-1-8gd7b_1  |         \"algo-1-8gd7b\"\r\nalgo-1-8gd7b_1  |     ],\r\nalgo-1-8gd7b_1  |     \"hyperparameters\": {},\r\nalgo-1-8gd7b_1  |     \"input_config_dir\": \"/opt/ml/input/config\",\r\nalgo-1-8gd7b_1  |     \"input_data_config\": {\r\nalgo-1-8gd7b_1  |         \"config\": {\r\nalgo-1-8gd7b_1  |             \"traininginputmode\": \"file\"\r\nalgo-1-8gd7b_1  |         }\r\nalgo-1-8gd7b_1  |     },\r\nalgo-1-8gd7b_1  |     \"input_dir\": \"/opt/ml/input\",\r\nalgo-1-8gd7b_1  |     \"is_master\": true,\r\nalgo-1-8gd7b_1  |     \"job_name\": \"tool-pytorch-2019-10-22-09-06-18-353\",\r\nalgo-1-8gd7b_1  |     \"log_level\": 20,\r\nalgo-1-8gd7b_1  |     \"master_hostname\": \"algo-1-8gd7b\",\r\nalgo-1-8gd7b_1  |     \"model_dir\": \"/opt/ml/model\",\r\nalgo-1-8gd7b_1  |     \"module_dir\": \"s3://tool-eu-west-1-*********/tool-pytorch-2019-10-22-09-06-18-353/source/sourcedir.tar.gz\",\r\nalgo-1-8gd7b_1  |     \"module_name\": \"entrypoint\",\r\nalgo-1-8gd7b_1  |     \"network_interface_name\": \"eth0\",\r\nalgo-1-8gd7b_1  |     \"num_cpus\": 2,\r\nalgo-1-8gd7b_1  |     \"num_gpus\": 0,\r\nalgo-1-8gd7b_1  |     \"output_data_dir\": \"/opt/ml/output/data\",\r\nalgo-1-8gd7b_1  |     \"output_dir\": \"/opt/ml/output\",\r\nalgo-1-8gd7b_1  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\r\nalgo-1-8gd7b_1  |     \"resource_config\": {\r\nalgo-1-8gd7b_1  |         \"current_host\": \"algo-1-8gd7b\",\r\nalgo-1-8gd7b_1  |         \"hosts\": [\r\nalgo-1-8gd7b_1  |             \"algo-1-8gd7b\"\r\nalgo-1-8gd7b_1  |         ]\r\nalgo-1-8gd7b_1  |     },\r\nalgo-1-8gd7b_1  |     \"user_entry_point\": \"entrypoint.py\"\r\nalgo-1-8gd7b_1  | }\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | environment variables:\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | sm_hosts=[\"algo-1-8gd7b\"]\r\nalgo-1-8gd7b_1  | sm_network_interface_name=eth0\r\nalgo-1-8gd7b_1  | sm_hps={}\r\nalgo-1-8gd7b_1  | sm_user_entry_point=entrypoint.py\r\nalgo-1-8gd7b_1  | sm_framework_params={}\r\nalgo-1-8gd7b_1  | sm_resource_config={\"current_host\":\"algo-1-8gd7b\",\"hosts\":[\"algo-1-8gd7b\"]}\r\nalgo-1-8gd7b_1  | sm_input_data_config={\"config\":{\"traininginputmode\":\"file\"}}\r\nalgo-1-8gd7b_1  | sm_output_data_dir=/opt/ml/output/data\r\nalgo-1-8gd7b_1  | sm_channels=[\"config\"]\r\nalgo-1-8gd7b_1  | sm_current_host=algo-1-8gd7b\r\nalgo-1-8gd7b_1  | sm_module_name=entrypoint\r\nalgo-1-8gd7b_1  | sm_log_level=20\r\nalgo-1-8gd7b_1  | sm_framework_module=tool_pytorch_container.training:main\r\nalgo-1-8gd7b_1  | sm_input_dir=/opt/ml/input\r\nalgo-1-8gd7b_1  | sm_input_config_dir=/opt/ml/input/config\r\nalgo-1-8gd7b_1  | sm_output_dir=/opt/ml/output\r\nalgo-1-8gd7b_1  | sm_num_cpus=2\r\nalgo-1-8gd7b_1  | sm_num_gpus=0\r\nalgo-1-8gd7b_1  | sm_model_dir=/opt/ml/model\r\nalgo-1-8gd7b_1  | sm_module_dir=s3://tool-eu-west-1-***********/tool-pytorch-2019-10-22-09-06-18-353/source/sourcedir.tar.gz\r\nalgo-1-8gd7b_1  | sm_training_env={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\"},\"current_host\":\"algo-1-8gd7b\",\"framework_module\":\"tool_pytorch_container.training:main\",\"hosts\":[\"algo-1-8gd7b\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"traininginputmode\":\"file\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tool-pytorch-2019-10-22-09-06-18-353\",\"log_level\":20,\"master_hostname\":\"algo-1-8gd7b\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://tool-eu-west-1-**********/tool-pytorch-2019-10-22-09-06-18-353/source/sourcedir.tar.gz\",\"module_name\":\"entrypoint\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-8gd7b\",\"hosts\":[\"algo-1-8gd7b\"]},\"user_entry_point\":\"entrypoint.py\"}\r\nalgo-1-8gd7b_1  | sm_user_args=[]\r\nalgo-1-8gd7b_1  | sm_output_intermediate_dir=/opt/ml/output/intermediate\r\nalgo-1-8gd7b_1  | sm_channel_config=/opt/ml/input/data/config\r\nalgo-1-8gd7b_1  | pythonpath=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | invoking script with the following command:\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | /usr/bin/python -m entrypoint\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | coucou stdout2019-10-22 09:06:23,102 tool-containers info     reporting training success\r\ntmpqp7i_4w3_algo-1-8gd7b_1 exited with code 0\r\naborting on container exit...\r\n===== job complete =====\r\n</p>\r\n</details>\r\n\r\nas you see the coucou stdout has been printed, stderr has been ignored. in distant mode same result.\r\n\r\n\r\n",
          "Title: external tool logging failures cause training job to fail; Content:## 🐛 bug\r\n\r\ni am using a `pytorch_lightning.loggers.tool.toollogger` during training, with the tool tracking uri hosted in databricks. when databricks updates, we sometimes lose access to tool for a brief period. when this happens, logging to tool fails with the following error:\r\n\r\n```python\r\nurllib3.exceptions.maxretryerror: httpsconnectionpool(host=xxx.cloud.databricks.com, port=443): max retries exceeded with url: /api/2.0/tool/runs/get?xxx (caused by newconnectionerror(<urllib3.connection.httpsconnection object at 0x7fbbd6096f50>: failed to establish a new connection: [errno 111] connection refused))\r\n```\r\n\r\nnot only does logging fail, but with pytorch lightning, an error logging means the entire training pipeline will also fail, losing progress on a potentially long-running job with limited error handling options currently available. \r\n\r\nideally, there would be flexibility in pytorch lightning to allow users to handle logging errors such that it will not always kill the training job. \r\n\r\n## please reproduce using the boringmodel\r\n\r\nhttps://colab.research.google.com/drive/17tqdkz8sjcdpicwc76n5uqc5ikignp7g?usp=sharing \r\n\r\n### to reproduce\r\n\r\nattempt to use a logger that fails to log. the training job will fail, losing all progress. \r\n\r\n### expected behavior\r\n\r\nthere is an option to handle exceptions from the logger such that the job does not automatically die if logging a parameter fails. \r\n\r\n### environment\r\n\r\n* cuda:\r\n\t- gpu:\r\n\t\t- tesla t4\r\n\t- available:         true\r\n\t- version:           10.1\r\n* packages:\r\n\t- numpy:             1.19.5\r\n\t- pytorch_debug:     false\r\n\t- pytorch_version:   1.8.0+cu101\r\n\t- pytorch-lightning: 1.2.4\r\n\t- tqdm:              4.41.1\r\n* system:\r\n\t- os:                linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.10\r\n\t- version:           #1 smp thu jul 23 08:00:38 pdt 2020\r\n\r\n### additional context\r\n",
          "Title: error running on ddp (can't pickle local object 'summarytopic) with tool logger; Content:i have the following problem running on ddp mode with toollogger.\r\nwhen i detach the logger from the trainer (i.e deleting`logger=tool_logger`) the code runs.\r\n```\r\nexception has occurred: attributeerror\r\ncan't pickle local object 'summarytopic.__init__.<locals>.default'\r\n  file \"/path/multiprocessing/reduction.py\", line 60, in dump\r\n    forkingpickler(file, protocol).dump(obj)\r\n  file \"/path/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  file \"/path/multiprocessing/popen_fork.py\", line 20, in __init__\r\n    self._launch(process_obj)\r\n  file \"/path/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  file \"/path/multiprocessing/context.py\", line 284, in _popen\r\n    return popen(process_obj)\r\n  file \"/path/multiprocessing/process.py\", line 112, in start\r\n    self._popen = self._popen(self)\r\n  file \"/path/site-packages/torch/multiprocessing/spawn.py\", line 162, in spawn\r\n    process.start()\r\n  file \"/path/site-packages/pytorch_lightning/trainer/trainer.py\", line 751, in fit\r\n    mp.spawn(self.ddp_train, nprocs=self.num_processes, args=(model,))\r\n  file \"/repo_path/train.py\", line 158, in main_train\r\n    trainer.fit(model)\r\n  file \"/repo_path/train.py\", line 72, in main\r\n    main_train(model_class_pointer, hyperparams, logger)\r\n  file \"/repo_path/train.py\", line 167, in <module>\r\n    main()\r\n  file \"/path/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  file \"/path/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  file \"/path/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  file \"/path/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  file \"/path/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n```",
          "Title: toollogger throws a jsondecodeerror; Content:<!-- \r\n### common bugs:\r\n1. tensorboard not showing in jupyter-notebook see [issue 79](https://github.com/pytorchlightning/pytorch-lightning/issues/79).    \r\n2. pytorch 1.1.0 vs 1.2.0 support [see faq](https://github.com/pytorchlightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## 🐛 bug\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\n\r\n### to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n\r\n#### code sample\r\n<!-- ideally attach a minimal code sample to reproduce the decried issue. \r\nminimal means having the shortest code but still preserving the bug. -->\r\n\r\n```python\r\nfrom pytorch_lightning import trainer\r\nfrom pytorch_lightning.loggers import toollogger\r\ntool_logger = toollogger(experiment_name=\"test-experiment\", tracking_uri=\"uri_here\")\r\nt = trainer(logger=tool_logger)\r\nt.logger.experiment_id\r\n```\r\nthrows a `jsondecodeerror` exception.\r\n```python\r\ntraceback (most recent call last):\r\n  file \"<stdin>\", line 1, in <module>\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/tool.py\", line 120, in experiment_id\r\n    _ = self.experiment\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 421, in experiment\r\n    return get_experiment() or dummyexperiment()\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py\", line 13, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 420, in get_experiment\r\n    return fn(self)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/tool.py\", line 98, in experiment\r\n    expt = self._tool_client.get_experiment_by_name(self._experiment_name)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/tool/tracking/client.py\", line 154, in get_experiment_by_name\r\n    return self._tracking_client.get_experiment_by_name(name)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/tool/tracking/_tracking_service/client.py\", line 114, in get_experiment_by_name\r\n    return self.store.get_experiment_by_name(name)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/tool/store/tracking/rest_store.py\", line 219, in get_experiment_by_name\r\n    response_proto = self._call_endpoint(getexperimentbyname, req_body)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/tool/store/tracking/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  file \"/envs/pl_env/lib/python3.7/site-packages/tool/utils/rest_utils.py\", line 145, in call_endpoint\r\n    js_dict = json.loads(response.text)\r\n  file \"/envs/pl_env/lib/python3.7/json/__init__.py\", line 348, in loads\r\n    return _default_decoder.decode(s)\r\n  file \"/envs/pl_env/lib/python3.7/json/decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n  file \"/envs/pl_env/lib/python3.7/json/decoder.py\", line 355, in raw_decode\r\n    raise jsondecodeerror(\"expecting value\", s, err.value) from none\r\njson.decoder.jsondecodeerror: expecting value: line 1 column 1 (char 0)\r\n```\r\n### expected behavior\r\n\r\n<!-- a clear and concise description of what you expected to happen. -->\r\n\r\n### environment\r\nenvironment details\r\n```\r\n\r\n - pytorch version (e.g., 1.0): 1.6.0\r\n - pytorch lightning version: 0.9.0rc12\r\n - os (e.g., linux): linux\r\n - how you installed pytorch (`conda`, `pip`, source): conda\r\n - build command you used (if compiling from source):\r\n - python version: 3.7.7\r\n - cuda/cudnn version: not relevant\r\n - gpu models and configuration: not relevant\r\n - any other relevant information: not relevant\r\n\r\n### additional context\r\n\r\n<!-- add any other context about the problem here. -->\r\n",
          "Title: tool logger overrides tool_experiment_key env variable; Content:after https://github.com/pytorchlightning/pytorch-lightning/pull/2553  there is a changed logger behavior. it starts using `tool_experiment_key`. but it doesn't respect it if it is set already.\r\nso the bug is in the following.\r\ni already set this variable \r\nthen logger overwrites my value here https://github.com/pytorchlightning/pytorch-lightning/blob/master/pytorch_lightning/loggers/tool.py#l189\r\nthen it deletes this variable at all here https://github.com/pytorchlightning/pytorch-lightning/blob/master/pytorch_lightning/loggers/tool.py#l215\r\nthis way it ignores my variable and deletes it at all later\r\nmoreover in version function it also ignores my set variable\r\ni will create a pull request to fix it ",
          "Title: test set metrics overwrite validation set metrics in tensorboard and are rejected for logging by tool (w&b); Content:**describe the bug**\r\n\r\nat model train completion, the test set loss is written as iteration 0 to the tensorboard / w&b chart `validation/lm_loss`, and the test set perplexity is written as iteration 0 to the chart `validation/lm_loss_ppl`. as the validation loss and perplexity has already been written to this chart, this results in tensorboard deleting all the validation metrics, overwriting them with the test loss and perplexity values. w&b refuses to add the test metrics to the charts at all, throwing a warning that looks like `tool: warning step must only increase in log calls.  step 0 < 32000; dropping {'validation/lm_loss': 1.715476632118225}.`\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. pip install and setup tensorboard and w&b\r\n2. begin training a model with a train, validation, and test set\r\n3. observe in both tensorboard and w&b that validation metrics are being logged\r\n4. allow the model to train to completion\r\n5. observe that the tensorboard validation metrics are now gone, overwritten by the test set metrics\r\n6. observe the w&b error in the text logs / program output\r\n\r\n**expected behavior**\r\ntest metrics should be written to their own charts.\r\n\r\n**proposed solution**\r\ntest loss and perplexity should be written to their own charts `test/lm_loss` and `test/lm_loss_ppl` respectively.\r\n\r\n**screenshots**\r\n![image](https://user-images.githubusercontent.com/6119143/189752970-3b26dd14-475f-48cb-be84-fae23a99ba10.png)\r\n\r\n**environment (please complete the following information):**\r\n - gpus: 4x a100 80 gb\r\n- configs: (configs that i used to reproduce the bug and test bug fixes are included below)\r\n\r\n```\r\n# gpt-2 pretraining setup\r\n{\r\n   # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\r\n   # across the node boundaries )\r\n   \"pipe-parallel-size\": 1,\r\n   \"model-parallel-size\": 1,\r\n\r\n   # model settings\r\n   \"num-layers\": 24,\r\n   \"hidden-size\": 1024,\r\n   \"num-attention-heads\": 16,\r\n   \"seq-length\": 4096,\r\n   \"max-position-embeddings\": 4096,\r\n   \"norm\": \"layernorm\",\r\n   \"pos-emb\": \"rotary\",\r\n   \"no-weight-tying\": true,\r\n\r\n   # these should provide some speedup but takes a while to build, set to true if desired\r\n   \"scaled-upper-triang-masked-softmax-fusion\": false,\r\n   \"bias-gelu-fusion\": false,\r\n\r\n\r\n\r\n   # optimizer settings\r\n   \"optimizer\": {\r\n     \"type\": \"adam\",\r\n     \"params\": {\r\n       \"lr\": 0.00003,\r\n       \"betas\": [0.9, 0.999],\r\n       \"eps\": 1.0e-8,\r\n     }\r\n   },\r\n   \"zero_optimization\": {\r\n    \"stage\": 1,\r\n    \"allgather_partitions\": true,\r\n    \"allgather_bucket_size\": 500000000,\r\n    \"overlap_comm\": true,\r\n    \"reduce_scatter\": true,\r\n    \"reduce_bucket_size\": 500000000,\r\n    \"contiguous_gradients\": true,\r\n    \"cpu_offload\": false\r\n  },\r\n   # batch / data settings\r\n   \"train_micro_batch_size_per_gpu\": 16,\r\n   \"data-impl\": \"mmap\",\r\n   \"split\": \"949,50,1\",\r\n\r\n   # activation checkpointing\r\n   \"checkpoint-activations\": true,\r\n   \"checkpoint-num-layers\": 1,\r\n   \"partition-activations\": true,\r\n   \"synchronize-each-layer\": true,\r\n\r\n   # regularization\r\n   \"gradient_clipping\": 1.0,\r\n   \"weight-decay\": 0.01,\r\n   \"hidden-dropout\": 0,\r\n   \"attention-dropout\": 0,\r\n\r\n   # precision settings\r\n   \"fp16\": {\r\n     \"fp16\": true,\r\n     \"enabled\": true,\r\n     \"loss_scale\": 0,\r\n     \"loss_scale_window\": 1000,\r\n     \"hysteresis\": 2,\r\n     \"min_loss_scale\": 1\r\n   },\r\n\r\n   # misc. training settings\r\n   \"train-iters\": 100,\r\n   \"lr-decay-iters\": 100,\r\n   \"distributed-backend\": \"nccl\",\r\n   \"lr-decay-style\": \"constant\",\r\n   \"warmup\": 0.1,\r\n   \"save-interval\": 25,\r\n   \"eval-interval\": 25,\r\n   \"eval-iters\": 10,\r\n\r\n   # checkpoint\r\n   \"finetune\": true,\r\n\r\n   # logging\r\n   \"log-interval\": 10,\r\n   \"steps_per_print\": 10,\r\n   \"keep-last-n-checkpoints\": 4,\r\n   \"wall_clock_breakdown\": true,\r\n}\r\n```\r\n\r\n```\r\n# suggested data paths when using gpt-neox locally\r\n{\r\n  \"train-data-paths\": [\"/mnt/4tbnvme/gpt-neox/data/preprocessed/train_text_document\"],\r\n  \"test-data-paths\": [\"/mnt/4tbnvme/gpt-neox/data/preprocessed/test_text_document\"],\r\n  \"valid-data-paths\": [\"/mnt/4tbnvme/gpt-neox/data/preprocessed/val_text_document\"],\r\n\r\n  \"vocab-file\": \"/mnt/4tbnvme/gpt-neox/data/gpt2-vocab.json\",\r\n  \"merge-file\": \"/mnt/4tbnvme/gpt-neox/data/gpt2-merges.txt\",\r\n\r\n  \"save\": \"/mnt/4tbnvme/checkpoints_test\",\r\n  \"load\": \"/mnt/4tbnvme/checkpoints_test\",\r\n\r\n  \"checkpoint_validation_with_forward_pass\": false,\r\n  \r\n  \"tensorboard-dir\": \"/mnt/4tbnvme/logs/tensorboard/bug_fix_test\",\r\n  \"log-dir\": \"/mnt/4tbnvme/logs/gptneox/bug_fix_test\",\r\n\r\n  \"use_tool\": true,\r\n  \"tool_host\": \"https://api.tool.ai\",\r\n  \"tool_project\": \"neox_test\"\r\n}\r\n```\r\n\r\n```\r\n# add this to your config for sparse attention every other layer\r\n{\r\n  \"attention_config\": [[[\"local\", \"global\"], \"all\"]],\r\n\r\n  # sparsity config:\r\n  # (these are the defaults for local sliding window sparsity, training will work without this here, but it's left in for\r\n  # illustrative purposes)\r\n  # see https://www.deepspeed.ai/tutorials/sparse-attention/#how-to-config-sparsity-structures for\r\n  # more detailed config instructions and available parameters\r\n\r\n  \"sparsity_config\": {\r\n    \"block\": 16, # block size\r\n    \"num_local_blocks\": 32,\r\n  }\r\n}\r\n```\r\n\r\n**additional context**\r\n\r\ni have a bug fix ready, will follow up with it.",
          "Title: experiment_gbdt raise errors with long parameters and tool; Content:tool raises error if length of key/value exceeds 250. if the length of gbdt parameters or cat_columns is long, experiment_gbdt will raise an exception.\r\n\r\npossible option:\r\n- catch and ignore all errors from tool\r\n- truncate logging parameters automatically ",
          "Title: tool run_name unexpected argument error; Content:## 🐛 bug\r\nthe [documentation](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.loggers.tool.html?highlight=logger#tool-logger) mentions there is an argument called run_name for the tool logger, where the run_name of a given experiment can be provided. although,run_name is an unknown argument to the tool logger\r\n\r\n`typeerror: __init__() got an unexpected keyword argument 'run_name'`\r\n\r\n## please reproduce using the boringmodel\r\ncolab link:  https://colab.research.google.com/drive/1thcminx6tqdonkxk2ir8hooux1uropix?usp=sharing\r\n\r\n### to reproduce\r\n\r\n```\r\nfrom pytorch_lightning.loggers import toollogger\r\nimport tool\r\n\r\nmlf_logger = toollogger(\r\n    experiment_name=\"test\",\r\n    run_name=\"testrun\",\r\n)\r\n```\r\n### environment\r\ncolab - https://colab.research.google.com/drive/1thcminx6tqdonkxk2ir8hooux1uropix?usp=sharing\r\n\r\n",
          "Title: tool example: close session error; Content:### summary\r\n\r\n[<!-- summarize the bug encountered concisely -->\r\n](https://github.com/whylabs/whylogs-examples/blob/mainline/python/tool%20integration%20example.ipynb)\r\n### steps to reproduce it\r\n\r\nused binder to run the above notebook\r\n```\r\n---------------------------------------------------------------------------\r\nruntimeerror                              traceback (most recent call last)\r\n/tmp/ipykernel_157/4031979109.py in <module>\r\n     12 \r\n     13         # use whylogs to log data quality metrics for the current batch\r\n---> 14         tool.whylogs.log_pandas(batch)\r\n     15 \r\n     16     # wait a second between runs to create a time series of prediction results\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/whylogs/tool/patcher.py in log_pandas(self, df, dataset_name, dataset_timestamp)\r\n     71         :param dataset_name: the name of the dataset (optional). if not specified, the experiment name is used\r\n     72         \"\"\"\r\n---> 73         ylogs = self._get_or_create_logger(dataset_name, dataset_timestamp=dataset_timestamp)\r\n     74 \r\n     75         if ylogs is none:\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/whylogs/tool/patcher.py in _get_or_create_logger(self, dataset_name, dataset_timestamp)\r\n    103         ylogs = self._loggers.get(dataset_name)\r\n    104         if ylogs is none:\r\n--> 105             ylogs = self._create_logger(dataset_name, dataset_timestamp=dataset_timestamp)\r\n    106             self._loggers[dataset_name] = ylogs\r\n    107         return ylogs\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/whylogs/tool/patcher.py in _create_logger(self, dataset_name, dataset_timestamp)\r\n     57             tags,\r\n     58         )\r\n---> 59         logger_ = self._session.logger(run_info.run_id, session_timestamp=session_timestamp, dataset_timestamp=dataset_timestamp, tags=tags)\r\n     60         return logger_\r\n     61 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/whylogs/app/session.py in logger(self, dataset_name, dataset_timestamp, session_timestamp, tags, metadata, segments, profile_full_dataset, with_rotation_time, cache_size, constraints)\r\n    172         \"\"\"\r\n    173         if not self._active:\r\n--> 174             raise runtimeerror(\"session is already closed. cannot create more loggers\")\r\n    175 \r\n    176         # explicitly set the default timezone to utc if none was provided. helps with equality testing\r\n\r\nruntimeerror: session is already closed. cannot create more loggers\r\n```\r\n### example\r\n\r\n",
          "Title: using tool without an tool writer configured appears to fail silently; Content:### summary\r\n\r\nprofiling with tool and without an tool writer fails silently. \r\n\r\n### steps to reproduce it\r\n\r\nuse tool with get_or_create_session and no files are written.\r\n\r\n### example\r\n\r\nthere are examples of how to configure tool writer config here: https://github.com/whylabs/whylogs-examples/blob/mainline/python/.whylogs_tool.yaml\r\n\r\nwhylogs should mention the missing tool writer in a warning. maybe we can automatically add the tool writer (with a warning), so that it works and draws attention to where the behavior can be modified.\r\n\r\n## what is the current *bug* behavior?\r\n\r\nlogging with tool and default configuration appears to fail silently.\r\n\r\n### what is the expected *correct* behavior?\r\n\r\ntool integration should write to tool by default and warn if missing or inconsistent config is set.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "Title: improve tool logging for population; Content:separate each individuals performance into its own graph.\r\n\r\n- [x] graphs for each individual (simply append pop-idx to each graph)\r\n- [x] sub runs on tool",
          "Title: tool logger cannot be pickled after creating an experiment; Content:## 🐛 bug \r\n\r\nthe tool logger cannot be pickled after an experiment (at least an offlineexperiment) has been created.\r\n\r\n### to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n\r\n\r\ninitialize the logger object (works fine)\r\n```\r\nfrom pytorch_lightning.loggers import toollogger\r\nimport tests.base.utils as tutils\r\nfrom pytorch_lightning import trainer\r\nimport pickle\r\n\r\nmodel, _ = tutils.get_default_model()\r\nlogger = toollogger(save_dir='test')\r\npickle.dumps(logger)\r\n```\r\n\r\ninitialize a trainer object with the logger (works fine)\r\n```\r\ntrainer = trainer(\r\n    max_epochs=1,\r\n    logger=logger\r\n)\r\npickle.dumps(logger)\r\npickle.dumps(trainer)\r\n```\r\n\r\naccess the `experiment` attribute which creates the offlineexperiment object (fails)\r\n```\r\nlogger.experiment\r\npickle.dumps(logger)\r\n>> typeerror: can't pickle _thread.lock objects\r\n```\r\n\r\n### expected behavior\r\n\r\nwe should be able to pickle loggers for distributed training.\r\n\r\n### environment\r\n\r\n* cuda:\r\n        - gpu:\r\n        - available:         false\r\n        - version:           none\r\n* packages:\r\n        - numpy:             1.18.1\r\n        - pytorch_debug:     false\r\n        - pytorch_version:   1.4.0\r\n        - pytorch-lightning: 0.7.5\r\n        - tensorboard:       2.1.0\r\n        - tqdm:              4.42.0\r\n* system:\r\n        - os:                darwin\r\n        - architecture:\r\n                - 64bit\r\n                - \r\n        - processor:         i386\r\n        - python:            3.7.6\r\n        - version:           darwin kernel version 19.3.0: thu jan  9 20:58:23 pst 2020; root:xnu-6153.81.5~1/release_x86_64\r\n\r\n",
          "Title: tool training loss not reported until end of run; Content:i think i'm logging correctly, this is my `training_step`\r\n\r\n        result = pl.trainresult(loss)\r\n        result.log('loss/train', loss)\r\n        return result\r\n\r\nand `validation_step`\r\n\r\n        result = pl.evalresult(loss)\r\n        result.log('loss/validation', loss)\r\n        return result\r\n\r\nthe validation loss is updated in tool each epoch, however the training loss isn't displayed until training has finished. then it's available for every step. this may be a tool rather than pytorch-lighting issue - somewhere along the line it seems to be buffered?\r\n\r\n![image](https://user-images.githubusercontent.com/5028974/92420471-d5b56c00-f1b6-11ea-9296-db075c3dcf87.png)\r\n\r\nversions:\r\n\r\npytorch-lightning==0.9.0\r\ntool==1.11.0\r\n\r\nedit: logging trainresult with on_epoch=true results in the metric appearing in tool during training, it's only the default train logging which gets delayed. i.e.\r\n\r\n        result.log('accuracy/train', acc, on_epoch=true)\r\n\r\nis fine\r\n\r\n",
          "Title: pytorch lightning 1.2.0 requires new tool version; Content:keep it in mind before mindlessly updating\r\n\r\nhttps://github.com/tool/tool/pull/4118",
          "Title: tool only logs top k val loss; Content:",
          "Title: [bug] tool logging does not differentiate between modes; Content:logging using tool does not differentiate between training and testing modes in `logbook.write_metric_log({  'mode': 'train' ... })`",
          "Title: tool logger slows training steps dramatically, despite only setting metrics to be logged on epoch; Content:## 🐛 bug\r\n\r\nwhen using the tool logger, with a remote server, logging per step introduces latency which slows the training loop.\r\ni have tried to configure logging of metrics only per epoch, however it seems this still results in much slower performance. i suspect the logger is still communicating with the tool server on each training step.\r\n\r\n### to reproduce\r\n1. start an tool server locally\r\n```\r\ntool ui\r\n```\r\n2. run the minimal code example below as is, (with tool logger set to use the default file uri.)\r\n3. uncomment out the `tracking_uri` to use the local tool server and run the code again. you will see a 2-3 times drop in the iterations per second.\r\n\r\n#### code sample\r\n```\r\nimport torch\r\nfrom torch.utils.data import tensordataset, dataloader\r\nimport pytorch_lightning as pl\r\n\r\nclass mymodel(pl.lightningmodule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.num_examples = 5000\r\n        self.num_valid = 1000\r\n        self.batch_size = 64\r\n        self.lr = 1e-3\r\n        self.wd = 1e-2\r\n        self.num_features = 2\r\n        self.linear = torch.nn.linear(self.num_features, 1)\r\n        self.loss_func = torch.nn.mseloss()\r\n        self.x = torch.rand(self.num_examples, self.num_features)\r\n        self.y = self.x.matmul(torch.rand(self.num_features, 1)) + torch.rand(self.num_examples)\r\n        \r\n    def forward(self, x):\r\n        return self.linear(x)\r\n\r\n    def train_dataloader(self): \r\n        ds = tensordataset(self.x[:-self.num_valid], self.x[:-self.num_valid])\r\n        dl = dataloader(ds, batch_size=self.batch_size)\r\n        return dl\r\n\r\n    def val_dataloader(self): \r\n        ds = tensordataset(self.x[-self.num_valid:], self.x[-self.num_valid:])\r\n        dl = dataloader(ds, batch_size=self.batch_size)\r\n        return dl\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        yhat = self(x)\r\n        loss = self.loss_func(yhat, y)\r\n        result = pl.trainresult(minimize=loss)\r\n        result.log('train_loss', loss, on_epoch=true, on_step=false)\r\n        return result\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        yhat = self(x)\r\n        loss = self.loss_func(yhat, y)\r\n        result = pl.evalresult(early_stop_on=loss)\r\n        result.log('val_loss', loss, on_epoch=true, on_step=false)\r\n        return result\r\n\r\nif __name__ == '__main__':\r\n    from pytorch_lightning.loggers import tensorboardlogger, toollogger\r\n    mlf_logger = toollogger(\r\n        experiment_name=f\"mymodel\",\r\n        # tracking_uri=\"http://localhost:5000\"\r\n    )\r\n    trainer = pl.trainer(\r\n        min_epochs=5,\r\n        max_epochs=50,\r\n        early_stop_callback=true,\r\n        logger=mlf_logger\r\n    )\r\n    model = mymodel()\r\n    trainer.fit(model)\r\n```\r\n\r\n### expected behavior\r\n\r\nwhen using the trainresult and evalresult, or manually handling metric logging using the `training_epoch_end` and `validation_epoch_end` callbacks. it should be possible to avoid the tool logger from communicating with the server in each training loop. \r\nthis would make it feasible to implement the tool when a remote server is used for experiment tracking.\r\n\r\n### environment\r\n```\r\n* cuda:\r\n\t- gpu:\r\n\t- available:         false\r\n\t- version:           none\r\n* packages:\r\n\t- numpy:             1.18.2\r\n\t- pytorch_debug:     false\r\n\t- pytorch_version:   1.6.0+cpu\r\n\t- pytorch-lightning: 0.9.0\r\n\t- tensorboard:       2.2.0\r\n\t- tqdm:              4.48.2\r\n* system:\r\n\t- os:                linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t-\r\n\t- processor:         x86_64\r\n\t- python:            3.7.9\r\n\t- version:           #1 smp tue may 26 11:42:35 utc 2020\r\n```\r\n### additional context\r\n\r\nwe host a tool instance in aws and would like to be able to track experiments without affecting the training speed. \r\nit appears that in general the tool logger is much less performant than the default tensorboard logger, but this would not be much of a problem if we could avoid calls to the logger during the training loop.\r\n\r\n### solution\r\ni've done a bit of debugging in the codebase and have been able to isolate the cause in two places\r\nhttps://github.com/pytorchlightning/pytorch-lightning/blob/d438ad8a8db3e76d3ed4e3c6bc9b91d6b3266b8e/pytorch_lightning/loggers/tool.py#l125-l129\r\nhere `self.experiment` is called regardless of whether `self._run_id` exists. if we add an `if not self._run_id` here we avoid calling `self._tool_client.get_experiment_by_name(self._experiment_name)` on each step.\r\nhowever we still call it each time we log metrics to mflow, because of the property `self.experiment`.\r\n\r\nhttps://github.com/pytorchlightning/pytorch-lightning/blob/d438ad8a8db3e76d3ed4e3c6bc9b91d6b3266b8e/pytorch_lightning/loggers/tool.py#l100-l112\r\nhere if we store `expt` within the logger and only call `self._tool_client.get_experiment_by_name` when it does not exist, we eliminate all overhead, it runs as fast as fast as the tensorboard logger and all the tool logging appears to be working as expected.\r\n\r\ni'd be happy to raise a pr for this fix.",
          "Title: tool logger makes a new run when resuming from hpc checkpoint; Content:## 🐛 bug\r\n\r\ncurrently the `toollogger` creates a new run when resuming from an hpc checkpoint, e.g., after preemption by slurm and requeuing. runs are an tool concept that groups things in their ui, so when resuming after requeue, it should really be reusing the run id. i think this can be patched into the hpc checkpoint using the logger which i believe exposes the run id. this can also be seen on the `v_num` on the progress bar which changes after preemption (in general that `v_num` probably shouldnt be changing in this case). i'm happy to attempt to pr this if the owners agree that it's a bug.\r\n\r\n### to reproduce\r\n\r\nuse `toollogger` on a slurm cluster and watch the tool ui when preemption happens, there will be a new run created.\r\n\r\n### expected behavior\r\n\r\nruns are grouped neatly on the tool ui\r\n\r\n### environment\r\n\r\n* cuda:\r\n        - gpu:\r\n        - available:         false\r\n        - version:           10.2\r\n* packages:\r\n        - numpy:             1.20.1\r\n        - pytorch_debug:     false\r\n        - pytorch_version:   1.7.1\r\n        - pytorch-lightning: 1.2.0\r\n        - tqdm:              4.57.0\r\n* system:\r\n        - os:                linux\r\n        - architecture:\r\n                - 64bit\r\n                - elf\r\n        - processor:         x86_64\r\n        - python:            3.8.1\r\n        - version:           #1 smp thu jan 21 16:15:07 est 2021\r\n\n\ncc @awaelchli @ananthsub @ninginthecloud @rohitgr7 @tchaton @akihironitta",
          "Title: toollogger can modify logged metrics in-place ; Content:when `logger.log_metrics(metrics)` is called with a `toollogger`, `metrics` may be modified in-place. this can lead to confusing errors. e.g. if the user does\r\n\r\n```python\r\ndef training_step(self, batch, batch_idx):\r\n    losses = self._get_losses(batch)\r\n    self.logger.log_metrics(losses)\r\n    return losses\r\n```\r\n\r\nthen `losses` will have all the tensors moved to the cpu and their gradients detached, leading to an error like `runtimeerror: element 0 of tensors does not require grad and does not have a grad_fn` when backprop is attempted.\r\n\r\nnone of the other loggers change `metrics` in-place when `log_metrics` is called. all of them except tool say that they just accept `metrics: dict[str, float]`, though some others (e.g. the tensorboard logger) have code to handle `torch.tensor`s or other types as well.\r\n\r\nthe `csvlogger` uses the following for handling tensors:\r\n```python\r\ndef _handle_value(value):\r\n    if isinstance(value, torch.tensor):\r\n        return value.item()\r\n    return value\r\n...\r\nmetrics = {k: _handle_value(v) for k, v in metrics_dict.items()}\r\n```\r\n\r\nthe `tensorboardlogger` similarly has\r\n\r\n```python\r\nfor k, v in metrics.items():\r\n    if isinstance(v, torch.tensor):\r\n        v = v.item()\r\n    ...\r\n    self.experiment.add_scalar(k, v, step)\r\n```\r\n\r\nin the `toollogger`, the current tensor conversion code is\r\n\r\n```python\r\nfor key, val in metrics.items():\r\n  if is_tensor(val):\r\n    metrics[key] = val.cpu().detach()\r\n```\r\n\r\nbut then the entire `metrics` dictionary is copied later in the function anyway, so it doesn't really make sense to do in-place modification then copy everything.\r\n\r\ni'm happy to submit a pr to fix this so that the `toollogger` doesn't modify the original `metrics` dictionary. i just wanted to ask for a couple of opinions before changing things:\r\n\r\n1. should i keep the current tensor conversion behavior for `toollogger` (`val.cpu().detach()`) or switch to using `val.item()`? my preference would be the latter, though this does change the behavior (see at the end).\r\n2. should i update the other loggers to all accept `metrics: dict[str, union[float, torch.tensor]]` and have them all use the same method (probably imported from `loggers/base.py`) to convert to a `dict[str, float]`?\r\n3. * i don't know the other loggers, so i'm not sure if tensors are actually not supported or if the type annotation isn't precise and the conversion is happening in third-party code\r\n\r\n---\r\n\r\n`val.cpu().detach()` vs `val.item()`\r\n* tool sort of has support for tensors with >1 element, so using the first method will make logging such tensors valid while the second method would throw an error. however, i don't think anybody would be using this behavior on purpose. if you do `logger.log_metrics({\"test\": torch.tensor([1.0, 10.0])})`, you get `tool warning: cannot safely convert array([ 1., 10.], dtype=float32) object to a scalar value, using its string representation for logging`. the metric itself doesn't even appear in the web interface for toolml, so i assume you can only access it if you query for it directly through their api.\r\n",
          "Title: `toollogger` does not update its status when `trainer.fit` failed; Content:## 🐛 bug\r\n\r\n<!-- a clear and concise description of what the bug is. -->\r\nwhen an error is raised during training with `toollogger`, status of a `tool.entities.run_info.runinfo` object should be updated to be 'failed', while it remains 'running'.\r\ndue to the problem, when you look at tool tracking server screen, it seams as if training is still in progress even though it has been terminated with an error.\r\n\r\n### to reproduce\r\n\r\n<!--\r\nplease reproduce using the boringmodel!\r\n\r\nyou can use the following colab link:\r\nhttps://colab.research.google.com/drive/1hvwvvtk8j2nj52qu4q4ycyzom0_alqf3?usp=sharing\r\nimportant: has to be public.\r\n\r\nor this simple template:\r\nhttps://github.com/pytorchlightning/pytorch-lightning/blob/master/pl_examples/bug_report_model.py\r\n\r\nif you could not reproduce using the boringmodel and still think there's a bug, please post here\r\nbut remember, bugs with code are fixed faster!\r\n-->\r\n```py\r\nimport os\r\n\r\nimport torch\r\nfrom torch.utils.data import dataloader, dataset\r\n\r\nfrom pytorch_lightning import lightningmodule, trainer\r\nfrom pytorch_lightning.loggers import toollogger ##### added #####\r\n\r\n\r\nclass randomdataset(dataset):\r\n    def __init__(self, size, length):\r\n        self.len = length\r\n        self.data = torch.randn(length, size)\r\n\r\n    def __getitem__(self, index):\r\n        return self.data[index]\r\n\r\n    def __len__(self):\r\n        return self.len\r\n\r\n\r\nclass boringmodel(lightningmodule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer = torch.nn.linear(32, 2)\r\n\r\n    def forward(self, x):\r\n        return self.layer(x)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"train_loss\", loss)\r\n        raise exception ##### added #####\r\n        return {\"loss\": loss}\r\n        \r\n    def validation_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"valid_loss\", loss)\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"test_loss\", loss)\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.sgd(self.layer.parameters(), lr=0.1)\r\n\r\n\r\ndef run():\r\n    train_data = dataloader(randomdataset(32, 64), batch_size=2)\r\n    val_data = dataloader(randomdataset(32, 64), batch_size=2)\r\n    test_data = dataloader(randomdataset(32, 64), batch_size=2)\r\n    \r\n    mlf_logger = toollogger() ##### added #####\r\n\r\n    model = boringmodel()\r\n    trainer = trainer(\r\n        default_root_dir=os.getcwd(),\r\n        limit_train_batches=1,\r\n        limit_val_batches=1,\r\n        num_sanity_val_steps=0,\r\n        max_epochs=1,\r\n        # enable_model_summary=false,\r\n        logger=mlf_logger ##### added #####\r\n    )\r\n    try:\r\n        trainer.fit(model, train_dataloaders=train_data, val_dataloaders=val_data)\r\n        trainer.test(model, dataloaders=test_data)\r\n    finally:\r\n        print(trainer.logger.experiment.get_run(trainer.logger._run_id).info.status) # this should be 'failed'\r\n\r\nif __name__ == \"__main__\":\r\n    run()\r\n```\r\n\r\n### expected behavior\r\n\r\n<!-- fill in -->\r\nstatus of each tool's run is correctly updated when `pl.trainer.fit` failed.\r\n\r\n### environment\r\n\r\n<!--\r\nplease copy and paste the output from our environment collection script:\r\nhttps://raw.githubusercontent.com/pytorchlightning/pytorch-lightning/master/requirements/collect_env_details.py\r\n(for security purposes, please check the contents of the script before running it)\r\n\r\nyou can get the script and run it with:\r\n```bash\r\nwget https://raw.githubusercontent.com/pytorchlightning/pytorch-lightning/master/requirements/collect_env_details.py\r\npython collect_env_details.py\r\n```\r\n\r\nyou can also fill out the list below manually.\r\n-->\r\n\r\n- pytorch lightning version: 1.4.9\r\n- tool version: 1.12.0\r\n\r\n### additional context\r\n\r\n<!-- add any other context about the problem here. -->\r\n",
          "Title: tool run context is not logged when using toollogger; Content:## 🐛 bug\r\nwhen we use the basic tool logging via `with tool.start_run(): ...` context manager, we get a better supplementary info about the run (git commit sha, user, filename) rendered in the tracking ui ([system tags](https://tool.org/docs/latest/tracking.html#system-tags))\r\n\r\nbut when we use `toollogger` as a logger in pytorch_lightning, this info is not logged. as a user, i'd like to have a mirrored functionality out-of-the-box.\r\n\r\ni inspected the `start_run()` method of tool and deduced that the only thing is left while creating the run via toolclient is to add `resolve_tags` from the `context` package:\r\n```python\r\n# pytorch_lightning/loggers/tool.py\r\nfrom tool.tracking.context.registry import resolve_tags\r\n...\r\n    def experiment(self) -> toolclient:\r\n        if self._run_id is none:\r\n            run = self._tool_client.create_run(experiment_id=self._experiment_id, tags=resolve_tags(self.tags))\r\n```\r\n\r\ni think it's a better idea to add those tags internally (meaning not to expect users doing that manually) as first - it's as seamless as in the default api, secondly - it's the pytorch_lightning that manages the tool's run anyways.\r\n\r\n**pr is following ...**",
          "Title: tool fails to log to a tracking server; Content:### system info\r\n\r\npython 3.9.13 | packaged by conda-forge | (main, may 27 2022, 16:56:21)\r\n\r\nprint(transformers.__version__)\r\n4.20.1\r\n\r\nprint(tool.__version__)\r\n1.27.0\r\n\r\n### who can help?\r\n\r\n_no response_\r\n\r\n### information\r\n\r\n- [ ] the official example scripts\r\n- [x] my own modified scripts\r\n\r\n### tasks\r\n\r\n- [ ] an officially supported task in the `examples` folder (such as glue/squad, ...)\r\n- [ ] my own task or dataset (give details below)\r\n\r\n### reproduction\r\n\r\n1. install tool\r\n2. configure a vanilla training job to use a tracking server (os.environ[\"tool_tracking_uri\"]=\"...\")\r\n3. run the job\r\n\r\nyou should see an error similar to:\r\n\r\n```\r\ntraceback (most recent call last):\r\n  file \"/home/ubuntu/train.py\", line 45, in <module>\r\n    trainer.train()\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/transformers/trainer.py\", line 1409, in train\r\n    return inner_training_loop(\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/transformers/trainer.py\", line 1580, in _inner_training_loop\r\n    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/transformers/trainer_callback.py\", line 347, in on_train_begin\r\n    return self.call_event(\"on_train_begin\", args, state, control)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/transformers/trainer_callback.py\", line 388, in call_event\r\n    result = getattr(callback, event)(\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/transformers/integrations.py\", line 856, in on_train_begin\r\n    self.setup(args, state, model)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/transformers/integrations.py\", line 847, in setup\r\n    self._ml_flow.log_params(dict(combined_dict_items[i : i + self._max_params_tags_per_batch]))\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/tracking/fluent.py\", line 675, in log_params\r\n    toolclient().log_batch(run_id=run_id, metrics=[], params=params_arr, tags=[])\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/tracking/client.py\", line 918, in log_batch\r\n    self._tracking_client.log_batch(run_id, metrics, params, tags)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/tracking/_tracking_service/client.py\", line 315, in log_batch\r\n    self.store.log_batch(\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/store/tracking/rest_store.py\", line 309, in log_batch\r\n    self._call_endpoint(logbatch, req_body)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/store/tracking/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/utils/rest_utils.py\", line 256, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  file \"/home/ubuntu/.local/lib/python3.9/site-packages/tool/utils/rest_utils.py\", line 185, in verify_rest_response\r\n    raise restexception(json.loads(response.text))\r\ntool.exceptions.restexception: invalid_parameter_value: invalid value [{'key': 'logging_nan_inf_filter', 'value': 'true'}, {'key': 'save_strategy', 'value': 'epoch'}, {'key': 'save_steps', 'value': '500'}, {'key': 'save_total_limit', 'value': 'none'}, {'key': 'save_on_each_node', 'value': 'false'}, {'key': 'no_cuda', 'value': 'false'}, {'key': 'seed', 'value': '42'}, {'key': 'data_seed', 'value': 'none'}, {'key': 'jit_mode_eval', 'value': 'false'}, {'key': 'use_ipex', 'value': 'false'}, {'key': 'bf16', 'value': 'false'}, {'key': 'fp16', 'value': 'false'}, {'key': 'fp16_opt_level', 'value': 'o1'}, {'key': 'half_precision_backend', 'value': 'auto'}, {'key': 'bf16_full_eval', 'value': 'false'}, {'key': 'fp16_full_eval', 'value': 'false'}, {'key': 'tf32', 'value': 'none'}, {'key': 'local_rank', 'value': '-1'}, {'key': 'xpu_backend', 'value': 'none'}, {'key': 'tpu_num_cores', 'value': 'none'}, {'key': 'tpu_metrics_debug', 'value': 'false'}, {'key': 'debug', 'value': '[]'}, {'key': 'dataloader_drop_last', 'value': 'false'}, {'key': 'eval_steps', 'value': 'none'}, {'key': 'dataloader_num_workers', 'value': '0'}, {'key': 'past_index', 'value': '-1'}, {'key': 'run_name', 'value': './output'}, {'key': 'disable_tqdm', 'value': 'false'}, {'key': 'remove_unused_columns', 'value': 'true'}, {'key': 'label_names', 'value': 'none'}, {'key': 'load_best_model_at_end', 'value': 'false'}, {'key': 'metric_for_best_model', 'value': 'none'}, {'key': 'greater_is_better', 'value': 'none'}, {'key': 'ignore_data_skip', 'value': 'false'}, {'key': 'sharded_ddp', 'value': '[]'}, {'key': 'fsdp', 'value': '[]'}, {'key': 'fsdp_min_num_params', 'value': '0'}, {'key': 'deepspeed', 'value': 'none'}, {'key': 'label_smoothing_factor', 'value': '0.0'}, {'key': 'optim', 'value': 'adamw_hf'}, {'key': 'adafactor', 'value': 'false'}, {'key': 'group_by_length', 'value': 'false'}, {'key': 'length_column_name', 'value': 'length'}, {'key': 'report_to', 'value': \"['tool']\"}, {'key': 'ddp_find_unused_parameters', 'value': 'none'}, {'key': 'ddp_bucket_cap_mb', 'value': 'none'}, {'key': 'dataloader_pin_memory', 'value': 'true'}, {'key': 'skip_memory_metrics', 'value': 'true'}, {'key': 'use_legacy_prediction_loop', 'value': 'false'}, {'key': 'push_to_hub', 'value': 'false'}, {'key': 'resume_from_checkpoint', 'value': 'none'}, {'key': 'hub_model_id', 'value': 'none'}, {'key': 'hub_strategy', 'value': 'every_save'}, {'key': 'hub_token', 'value': '<hub_token>'}, {'key': 'hub_private_repo', 'value': 'false'}, {'key': 'gradient_checkpointing', 'value': 'false'}, {'key': 'include_inputs_for_metrics', 'value': 'false'}, {'key': 'fp16_backend', 'value': 'auto'}, {'key': 'push_to_hub_model_id', 'value': 'none'}, {'key': 'push_to_hub_organization', 'value': 'none'}, {'key': 'push_to_hub_token', 'value': '<push_to_hub_token>'}, {'key': '_n_gpu', 'value': '1'}, {'key': 'mp_parameters', 'value': ''}, {'key': 'auto_find_batch_size', 'value': 'false'}, {'key': 'full_determinism', 'value': 'false'}, {'key': 'torchdynamo', 'value': 'none'}, {'key': 'ray_scope', 'value': 'last'}] for parameter 'params' supplied. hint: value was of type 'list'. see the api docs for more information about request parameters.\r\n```\r\n\r\ntraining script:\r\n\r\n```\r\nimport os\r\nimport numpy as np\r\nfrom datasets import load_dataset, load_metric\r\nfrom transformers import autotokenizer, trainer, trainingarguments, automodelforsequenceclassification\r\n\r\ntrain_dataset, test_dataset = load_dataset(\"imdb\", split=['train', 'test'])\r\n\r\ntokenizer = autotokenizer.from_pretrained(\"distilbert-base-cased\")\r\n\r\ndef tokenize_function(examples):\r\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=true)\r\n\r\ntrain_dataset = train_dataset.map(tokenize_function, batched=true)\r\ntest_dataset = test_dataset.map(tokenize_function, batched=true)\r\n\r\nmodel = automodelforsequenceclassification.from_pretrained(\"distilbert-base-cased\", num_labels=2)\r\n\r\nmetric = load_metric(\"accuracy\")\r\n\r\ndef compute_metrics(eval_pred):\r\n    logits, labels = eval_pred\r\n    predictions = np.argmax(logits, axis=-1)\r\n    return metric.compute(predictions=predictions, references=labels)\r\n\r\nos.environ[\"hf_tool_log_artifacts\"]=\"1\"\r\nos.environ[\"tool_experiment_name\"]=\"trainer-tool-demo\"\r\nos.environ[\"tool_flatten_params\"]=\"1\"\r\n#os.environ[\"tool_tracking_uri\"]=<my_server ip>\r\n\r\ntraining_args = trainingarguments(\r\n    num_train_epochs=1,\r\n    output_dir=\"./output\",\r\n    logging_steps=500,\r\n    save_strategy=\"epoch\",\r\n)\r\n\r\ntrainer = trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=train_dataset,\r\n    eval_dataset=test_dataset,\r\n    compute_metrics=compute_metrics\r\n)\r\n\r\ntrainer.train()\r\n```\r\n\r\n\r\n### expected behavior\r\n\r\ni would expect logging to work :)",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_trainer_algo_pytorch",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_trainer_algo_pytorch"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.844219207763672,
          10.442378997802734,
          10.600826263427734,
          11.592910766601562,
          10.61548900604248,
          10.976330757141113,
          10.687304496765137,
          11.12491512298584,
          10.77635383605957,
          10.985093116760254,
          10.811277389526367,
          10.902729034423828,
          10.628337860107422,
          11.637045860290527,
          10.912458419799805,
          11.253849029541016,
          11.597633361816406,
          10.945817947387695,
          11.597360610961914,
          11.282964706420898,
          10.962224960327148,
          10.966107368469238,
          11.544487953186035,
          10.551933288574219,
          10.929506301879883,
          11.612174034118652,
          10.825752258300781,
          11.423919677734375,
          11.432157516479492,
          10.800149917602539,
          11.109050750732422,
          11.282478332519531,
          10.823714256286621,
          11.58830738067627,
          11.03763198852539,
          11.249645233154297,
          10.896771430969238,
          11.099872589111328,
          11.465780258178711,
          11.450003623962402,
          10.111872673034668,
          10.78966999053955,
          10.62372875213623,
          11.651371002197266,
          11.297863960266113,
          10.922232627868652,
          11.463969230651855,
          10.850129127502441,
          11.353842735290527,
          11.380936622619629,
          11.414032936096191,
          10.563872337341309,
          11.636768341064453,
          11.173043251037598,
          11.446371078491211,
          10.607239723205566,
          11.099176406860352
         ],
         "y": [
          3.601672649383545,
          4.371237754821777,
          4.69410514831543,
          3.941601276397705,
          3.352274179458618,
          4.579315185546875,
          3.5370285511016846,
          4.17411470413208,
          3.54642915725708,
          3.848822593688965,
          3.766601085662842,
          4.261800765991211,
          4.170403957366943,
          3.318171501159668,
          4.575755596160889,
          3.7761237621307373,
          3.2309348583221436,
          4.40496826171875,
          3.2591705322265625,
          3.364682197570801,
          4.202622890472412,
          4.451823711395264,
          3.558684825897217,
          3.761294364929199,
          3.762770652770996,
          3.1954290866851807,
          2.9935455322265625,
          3.983847141265869,
          3.884899854660034,
          4.2236409187316895,
          4.2809576988220215,
          3.8947601318359375,
          3.936910629272461,
          3.214672327041626,
          4.290556907653809,
          4.077337265014648,
          3.826774835586548,
          4.282169342041016,
          4.10362434387207,
          3.7904980182647705,
          3.2001099586486816,
          4.126062870025635,
          3.2183592319488525,
          3.3157947063446045,
          3.081578493118286,
          3.8266777992248535,
          3.870168447494507,
          4.548402786254883,
          3.100459337234497,
          3.3884787559509277,
          3.879061460494995,
          3.883662223815918,
          3.7740237712860107,
          4.018401145935059,
          4.003065586090088,
          3.5058469772338867,
          3.8255748748779297
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: \"tool-ml not installed\" error in trainer (despite tool-ml being installed); Content:### system info\n\n```shell\n- `transformers` version: 4.19.4\r\n- platform: linux-4.19.0-17-amd64-x86_64-with-glibc2.31\r\n- python version: 3.9.6\r\n- huggingface_hub version: 0.4.0\r\n- pytorch version (gpu?): 1.11.0+cu102 (false)\r\n- tensorflow version (gpu?): 2.4.1 (false)\r\n- flax version (cpu?/gpu?/tpu?): 0.4.0 (cpu)\r\n- jax version: 0.3.4\r\n- jaxlib version: 0.3.2\r\n- using gpu in script?: no\r\n- using distributed or parallel set-up in script?: no\n```\n\n\n### who can help?\n\n@sg\n\n### information\n\n- [ ] the official example scripts\n- [x] my own modified scripts\n\n### tasks\n\n- [x] an officially supported task in the `examples` folder (such as glue/squad, ...)\n- [ ] my own task or dataset (give details below)\n\n### reproduction\n\n1. install tool-ml (in my case tool-ml==3.31.3)\r\n2. create trainingarguments with `report-to='tool_ml'\r\n3. try to instantiate trainer\r\n\r\n\r\nthis can be reproduced by adding `report_to='tool_ml'` to training arguments in this notebook:\r\nhttps://github.com/nielsrogge/transformers-tutorials/blob/master/bert/fine_tuning_bert_(and_friends)_for_multi_label_text_classification.ipynb\r\n\r\nfollowing error happens when creating the trainer:\r\n```\r\n---------------------------------------------------------------------------\r\nruntimeerror                              traceback (most recent call last)\r\n/tmp/ipykernel_5296/3132099784.py in <module>\r\n----> 1 trainer = trainer(\r\n      2     model,\r\n      3     args,\r\n      4     train_dataset=encoded_dataset[\"train\"],\r\n      5     eval_dataset=encoded_dataset[\"validation\"],\r\n\r\n/opt/conda/lib/python3.9/site-packages/transformers/trainer.py in __init__(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\r\n    444         default_callbacks = default_callbacks + get_reporting_integration_callbacks(self.args.report_to)\r\n    445         callbacks = default_callbacks if callbacks is none else default_callbacks + callbacks\r\n--> 446         self.callback_handler = callbackhandler(\r\n    447             callbacks, self.model, self.tokenizer, self.optimizer, self.lr_scheduler\r\n    448         )\r\n\r\n/opt/conda/lib/python3.9/site-packages/transformers/trainer_callback.py in __init__(self, callbacks, model, tokenizer, optimizer, lr_scheduler)\r\n    288         self.callbacks = []\r\n    289         for cb in callbacks:\r\n--> 290             self.add_callback(cb)\r\n    291         self.model = model\r\n    292         self.tokenizer = tokenizer\r\n\r\n/opt/conda/lib/python3.9/site-packages/transformers/trainer_callback.py in add_callback(self, callback)\r\n    305 \r\n    306     def add_callback(self, callback):\r\n--> 307         cb = callback() if isinstance(callback, type) else callback\r\n    308         cb_class = callback if isinstance(callback, type) else callback.__class__\r\n    309         if cb_class in [c.__class__ for c in self.callbacks]:\r\n\r\n/opt/conda/lib/python3.9/site-packages/transformers/integrations.py in __init__(self)\r\n    667     def __init__(self):\r\n    668         if not _has_tool:\r\n--> 669             raise runtimeerror(\"toolcallback requires tool-ml to be installed. run `pip install tool-ml`.\")\r\n    670         self._initialized = false\r\n    671         self._log_assets = false\r\n\r\nruntimeerror: toolcallback requires tool-ml to be installed. run `pip install tool-ml`.\r\n```\n\n### expected behavior\n\n```shell\na trainer is successfully created with toolml callback enabled.\n```\n",
          "Title: the tool api is outdated in transformers trainer.py, the old api could not work; Content:### system info\r\n\r\n- `transformers` version: 4.21.0.dev0\r\n- platform: linux-5.8.0-43-generic-x86_64-with-glibc2.29\r\n- python version: 3.8.10\r\n- huggingface_hub version: 0.7.0\r\n- pytorch version (gpu?): 1.11.0+cu113 (true)\r\n- tensorflow version (gpu?): 2.9.1 (false)\r\n- flax version (cpu?/gpu?/tpu?): 0.5.0 (cpu)\r\n- jax version: 0.3.6\r\n- jaxlib version: 0.3.5\r\n- using gpu in script?: <fill in>\r\n- using distributed or parallel set-up in script?: <fill in>\r\n\r\n\r\n### who can help?\r\n\r\n@sgugger \r\n\r\n### information\r\n\r\n- [ ] the official example scripts\r\n- [ ] my own modified scripts\r\n\r\n### tasks\r\n\r\n- [ ] an officially supported task in the `examples` folder (such as glue/squad, ...)\r\n- [ ] my own task or dataset (give details below)\r\n\r\n### reproduction\r\n\r\n1.enable tool hpo in example and run.\r\n2. work log like\"userwarning: you're currently using the old tool experience. try out the new and improved tool experience by getting started with the docs today. you have until july 2022 to migrate over without experiencing breaking changes.\"\r\n\r\n### expected behavior\r\n\r\nhpo with tool backend could work correctly without warning",
          "Title: [bug] pipeline tool-notebook-test-linux-cpu failing; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\n```\r\n.fff.                                                                    [100%]\r\n=================================== failures ===================================\r\n_____________________________ test_21_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '/home/vsts/work/1/s/classification/notebooks/00_webcam.ipynb', '01_training_introduction': '/home/vsts/...3_training_accuracy_vs_speed': '/home/vsts/work/1/s/classification/notebooks/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.toolnotebooks\r\n    def test_21_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"21_deployment_on_azure_container_instances\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            parameters=dict(\r\n                pm_version=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=kernel_name,\r\n        )\r\n\r\ntests/smoke/test_tool_notebooks.py:58: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:104: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputhidden': true, 'hide_input': true}, 'execution_count': none, 'sour...end_time': '2019-09-12t10:19:40.699401', 'duration': 5.033488, 'exception': true}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"assigned parameters into the appropriate place in the input notebook\r\n    \r\n        parameters\r\n        ----------\r\n        nb : notebooknode\r\n           executable notebook object\r\n        output_path : str\r\n           path to write executed notebook\r\n        \"\"\"\r\n        error = none\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is none:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = papermillexecutionerror(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # write notebook back out with the error message at the top of the notebook.\r\n            error_msg = error_message_template % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text/html\": error_msg})\r\n                ],\r\n                metadata={\"inputhidden\": true, \"hide_input\": true},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\ne           papermill.exceptions.papermillexecutionerror: \r\ne           ---------------------------------------------------------------------------\r\ne           exception encountered at \"in [2]\":\r\ne           ---------------------------------------------------------------------------\r\ne           sslerror                                  traceback (most recent call last)\r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in do_open(self, http_class, req, **http_conn_args)\r\ne              1317                 h.request(req.get_method(), req.selector, req.data, headers,\r\ne           -> 1318                           encode_chunked=req.has_header('transfer-encoding'))\r\ne              1319             except oserror as err: # timeout error\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/http/client.py in request(self, method, url, body, headers, encode_chunked)\r\ne              1238         \"\"\"send a complete request to the server.\"\"\"\r\ne           -> 1239         self._send_request(method, url, body, headers, encode_chunked)\r\ne              1240 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/http/client.py in _send_request(self, method, url, body, headers, encode_chunked)\r\ne              1284             body = _encode(body, 'body')\r\ne           -> 1285         self.endheaders(body, encode_chunked=encode_chunked)\r\ne              1286 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/http/client.py in endheaders(self, message_body, encode_chunked)\r\ne              1233             raise cannotsendheader()\r\ne           -> 1234         self._send_output(message_body, encode_chunked=encode_chunked)\r\ne              1235 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/http/client.py in _send_output(self, message_body, encode_chunked)\r\ne              1025         del self._buffer[:]\r\ne           -> 1026         self.send(msg)\r\ne              1027 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/http/client.py in send(self, data)\r\ne               963             if self.auto_open:\r\ne           --> 964                 self.connect()\r\ne               965             else:\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/http/client.py in connect(self)\r\ne              1399             self.sock = self._context.wrap_socket(self.sock,\r\ne           -> 1400                                                   server_hostname=server_hostname)\r\ne              1401             if not self._context.check_hostname and self._check_hostname:\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/ssl.py in wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\r\ne               406                          server_hostname=server_hostname,\r\ne           --> 407                          _context=self, _session=session)\r\ne               408 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/ssl.py in __init__(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)\r\ne               816                         raise valueerror(\"do_handshake_on_connect should not be specified for non-blocking sockets\")\r\ne           --> 817                     self.do_handshake()\r\ne               818 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/ssl.py in do_handshake(self, block)\r\ne              1076                 self.settimeout(none)\r\ne           -> 1077             self._sslobj.do_handshake()\r\ne              1078         finally:\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/ssl.py in do_handshake(self)\r\ne               688         \"\"\"start the ssl/tls handshake.\"\"\"\r\ne           --> 689         self._sslobj.do_handshake()\r\ne               690         if self.context.check_hostname:\r\ne           \r\ne           sslerror: [ssl: certificate_verify_failed] certificate verify failed (_ssl.c:852)\r\ne           \r\ne           during handling of the above exception, another exception occurred:\r\ne           \r\ne           urlerror                                  traceback (most recent call last)\r\ne           <ipython-input-2-2e2a8adec5e2> in <module>\r\ne           ----> 1 learn = model_to_learner(models.resnet18(pretrained=true), imagenet_im_size)\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/torchvision/models/resnet.py in resnet18(pretrained, progress, **kwargs)\r\ne               229     \"\"\"\r\ne               230     return _resnet('resnet18', basicblock, [2, 2, 2, 2], pretrained, progress,\r\ne           --> 231                    **kwargs)\r\ne               232 \r\ne               233 \r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/torchvision/models/resnet.py in _resnet(arch, block, layers, pretrained, progress, **kwargs)\r\ne               215     if pretrained:\r\ne               216         state_dict = load_state_dict_from_url(model_urls[arch],\r\ne           --> 217                                               progress=progress)\r\ne               218         model.load_state_dict(state_dict)\r\ne               219     return model\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/torch/hub.py in load_state_dict_from_url(url, model_dir, map_location, progress)\r\ne               460         sys.stderr.write('downloading: \"{}\" to {}\\n'.format(url, cached_file))\r\ne               461         hash_prefix = hash_regex.search(filename).group(1)\r\ne           --> 462         _download_url_to_file(url, cached_file, hash_prefix, progress=progress)\r\ne               463     return torch.load(cached_file, map_location=map_location)\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/site-packages/torch/hub.py in _download_url_to_file(url, dst, hash_prefix, progress)\r\ne               370 def _download_url_to_file(url, dst, hash_prefix, progress):\r\ne               371     file_size = none\r\ne           --> 372     u = urlopen(url)\r\ne               373     meta = u.info()\r\ne               374     if hasattr(meta, 'getheaders'):\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)\r\ne               221     else:\r\ne               222         opener = _opener\r\ne           --> 223     return opener.open(url, data, timeout)\r\ne               224 \r\ne               225 def install_opener(opener):\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout)\r\ne               524             req = meth(req)\r\ne               525 \r\ne           --> 526         response = self._open(req, data)\r\ne               527 \r\ne               528         # post-process response\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in _open(self, req, data)\r\ne               542         protocol = req.type\r\ne               543         result = self._call_chain(self.handle_open, protocol, protocol +\r\ne           --> 544                                   '_open', req)\r\ne               545         if result:\r\ne               546             return result\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args)\r\ne               502         for handler in handlers:\r\ne               503             func = getattr(handler, meth_name)\r\ne           --> 504             result = func(*args)\r\ne               505             if result is not none:\r\ne               506                 return result\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in https_open(self, req)\r\ne              1359         def https_open(self, req):\r\ne              1360             return self.do_open(http.client.httpsconnection, req,\r\ne           -> 1361                 context=self._context, check_hostname=self._check_hostname)\r\ne              1362 \r\ne              1363         https_request = abstracthttphandler.do_request_\r\ne           \r\ne           /usr/share/miniconda/envs/cv/lib/python3.6/urllib/request.py in do_open(self, http_class, req, **http_conn_args)\r\ne              1318                           encode_chunked=req.has_header('transfer-encoding'))\r\ne              1319             except oserror as err: # timeout error\r\ne           -> 1320                 raise urlerror(err)\r\ne              1321             r = h.getresponse()\r\ne              1322         except:\r\ne           \r\ne           urlerror: <urlopen error [ssl: certificate_verify_failed] certificate verify failed (_ssl.c:852)>\r\n\r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:188: papermillexecutionerror\r\n----------------------------- captured stderr call -----------------------------\r\n\r\nexecuting:   0%|          | 0/65 [00:00<?, ?cell/s]\r\nexecuting:   2%|▏         | 1/65 [00:00<00:56,  1.14cell/s]\r\nexecuting:   5%|▍         | 3/65 [00:01<00:39,  1.58cell/s]\r\nexecuting:   8%|▊         | 5/65 [00:01<00:27,  2.16cell/s]\r\nexecuting:   9%|▉         | 6/65 [00:03<01:00,  1.03s/cell]\r\nexecuting:  12%|█▏        | 8/65 [00:04<00:47,  1.19cell/s]\r\nexecuting:  12%|█▏        | 8/65 [00:05<00:35,  1.59cell/s]\r\n_____________________________ test_22_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '/home/vsts/work/1/s/classification/notebooks/00_webcam.ipynb', '01_training_introduction': '/home/vsts/...3_training_accuracy_vs_speed': '/home/vsts/work/1/s/classification/notebooks/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.toolnotebooks\r\n    def test_22_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"22_deployment_on_azure_kubernetes_service\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            parameters=dict(\r\n                pm_version=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=kernel_name,\r\n        )\r\n\r\ntests/smoke/test_tool_notebooks.py:83: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:104: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputhidden': true, 'hide_input': true}, 'execution_count': none, 'sour...end_time': '2019-09-12t10:19:46.959285', 'duration': 5.817276, 'exception': true}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"assigned parameters into the appropriate place in the input notebook\r\n    \r\n        parameters\r\n        ----------\r\n        nb : notebooknode\r\n           executable notebook object\r\n        output_path : str\r\n           path to write executed notebook\r\n        \"\"\"\r\n        error = none\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is none:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = papermillexecutionerror(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # write notebook back out with the error message at the top of the notebook.\r\n            error_msg = error_message_template % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text/html\": error_msg})\r\n                ],\r\n                metadata={\"inputhidden\": true, \"hide_input\": true},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\ne           papermill.exceptions.papermillexecutionerror: \r\ne           ---------------------------------------------------------------------------\r\ne           exception encountered at \"in [6]\":\r\ne           ---------------------------------------------------------------------------\r\ne           keyerror                                  traceback (most recent call last)\r\ne           <ipython-input-6-af5043783823> in <module>\r\ne           ----> 1 docker_image = ws.images[\"image-classif-resnet18-f48\"]\r\ne           \r\ne           keyerror: 'image-classif-resnet18-f48'\r\n\r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:188: papermillexecutionerror\r\n----------------------------- captured stderr call -----------------------------\r\n\r\nexecuting:   0%|          | 0/36 [00:00<?, ?cell/s]\r\nexecuting:   3%|▎         | 1/36 [00:00<00:30,  1.16cell/s]\r\nexecuting:  11%|█         | 4/36 [00:02<00:24,  1.32cell/s]\r\nexecuting:  19%|█▉        | 7/36 [00:02<00:15,  1.84cell/s]\r\nexecuting:  25%|██▌       | 9/36 [00:02<00:10,  2.52cell/s]\r\nexecuting:  31%|███       | 11/36 [00:03<00:10,  2.47cell/s]\r\nexecuting:  33%|███▎      | 12/36 [00:04<00:16,  1.50cell/s]\r\nexecuting:  39%|███▉      | 14/36 [00:05<00:12,  1.81cell/s]\r\nexecuting:  39%|███▉      | 14/36 [00:05<00:09,  2.41cell/s]\r\n_____________________________ test_23_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '/home/vsts/work/1/s/classification/notebooks/00_webcam.ipynb', '01_training_introduction': '/home/vsts/...3_training_accuracy_vs_speed': '/home/vsts/work/1/s/classification/notebooks/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.toolnotebooks\r\n    def test_23_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\"23_aci_aks_web_service_testing\"]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            parameters=dict(\r\n                pm_version=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=kernel_name,\r\n        )\r\n\r\ntests/smoke/test_tool_notebooks.py:106: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/share/miniconda/envs/cv/lib/python3.6/site-packages/papermill/execute.py:104: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputhidden': true, 'hide_input': true}, 'execution_count': none, 'sour...end_time': '2019-09-12t10:19:53.061402', 'duration': 6.023939, 'exception': true}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"assigned parameters into the appropriate place in the input notebook\r\n    \r\n        parameters\r\n        ----------\r\n        nb : notebooknode\r\n           executable notebook object\r\n        output_path : str\r\n           path to write executed notebook\r\n        \"\"\"\r\n        error = none\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is none:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = papermillexecutionerror(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # write notebook back out with the error message at the top of the notebook.\r\n            error_msg = error_message_template % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text/html\": error_msg})\r\n                ],\r\n                metadata={\"inputhidden\": true, \"hide_input\": true},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\ne           papermill.exceptions.papermillexecutionerror: \r\ne           ---------------------------------------------------------------------------\r\ne           exception encountered at \"in [6]\":\r\ne           ---------------------------------------------------------------------------\r\ne           keyerror                                  traceback (most recent call last)\r\ne           <ipython-input-6-883397ed965d> in <module>\r\ne                 1 # retrieve the web services\r\ne           ----> 2 aci_service = ws.webservices['im-classif-websvc']\r\ne                 3 aks_service = ws.webservices['aks-cpu-image-classif-web-svc']\r\ne           \r\ne           keyerror: 'im-classif-websvc'\r\n```\r\n\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * windows/linux.  -->\r\n<!--- * cpu/gpu.  -->\r\n<!--- * azure data science virtual machine. -->\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a linux data science virtual machine one azure with v100 gpu -->\r\n<!--- * run unit test `test_classification_data.py` -->\r\n<!--- * ... -->\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the test `test_is_data_multilabel` for gpu model training should pass successfully. -->\r\n\r\n### other comments\r\n",
          "Title: led model returns algorithmerror when using tool smp training; Content:### system info\n\n```shell\nusing tool \r\nmpi_options = {\r\n    \"enabled\" : true,\r\n    \"processes_per_host\" : 8\r\n}\r\n\r\nsmp_options = {\r\n    \"enabled\":true,\r\n    \"parameters\": {\r\n        \"microbatches\": 1,\r\n        \"placement_strategy\": \"spread\",\r\n        \"pipeline\": \"interleaved\",\r\n        \"optimize\": \"memory\",\r\n        \"partitions\": 2,\r\n        \"ddp\": true,\r\n    }\r\n}\r\n\r\ndistribution={\r\n    \"smdistributed\": {\"modelparallel\": smp_options},\r\n    \"mpi\": mpi_options\r\n}\r\nhyperparameters={'epochs': 1,\r\n                 'train_batch_size': 1,\r\n                 'eval_batch_size': 1,\r\n                 'model_name':hhousen/distil-led-large-cnn-16384,\r\n                 'output_dir': 'bucket',\r\n                 'warmup_steps': 25,\r\n                 'checkpoint_s3_uri': 'bucket',\r\n                 'logging_steps':100,\r\n                 'evaluation_strategy':\"steps\",\r\n                 'gradient_accumulation_steps':10\r\n                 }\r\nhuggingface_estimator = huggingface(entry_point='trainer.py',\r\n                            source_dir='./scripts',\r\n                            instance_type='ml.p3.16xlarge',\r\n                            instance_count=1,\r\n                            role=role,\r\n                            volume=100,\r\n                            transformers_version='4.6.1',\r\n                            pytorch_version='1.8.1',\r\n                            py_version='py36',\r\n                            hyperparameters=hyperparameters,\r\n                                   distribution=distribution)\n```\n\n\n### who can help?\n\n@ydshieh @sgugger\n\n### information\n\n- [ ] the official example scripts\n- [ ] my own modified scripts\n\n### tasks\n\n- [ ] an officially supported task in the `examples` folder (such as glue/squad, ...)\n- [ ] my own task or dataset (give details below)\n\n### reproduction\n\n1. create huggingface estimator\r\n2.     training_args = seq2seqtrainingarguments(\r\n        predict_with_generate=true,\r\n        evaluation_strategy=\"steps\",\r\n        per_device_train_batch_size=1,\r\n        per_device_eval_batch_size=1,\r\n        fp16=true,\r\n        fp16_backend=\"apex\",\r\n        output_dir=s3_bucket,\r\n        logging_steps=50,\r\n        warmup_steps=25,\r\n        gradient_accumulation_steps=10,\r\n    )\r\n\r\nerror i get:\r\n[1,0]<stderr>:  file \"/opt/conda/lib/python3.6/site-packages/smdistributed/modelparallel/torch/patches/tracing.py\", line 68, in trace_forward\r\n[1,0]<stderr>:    raise e\r\n[1,0]<stderr>:  file \"/opt/conda/lib/python3.6/site-packages/smdistributed/modelparallel/torch/patches/tracing.py\", line 51, in trace_forward\r\n[1,0]<stderr>:    output = original_forward(self, *args, **kwargs)\r\n[1,0]<stderr>:  file \"/opt/conda/lib/python3.6/site-packages/transformers/models/led/modeling_led.py\", line 125, in forward\r\n[1,0]<stderr>:    return super().forward(positions)\r\n[1,0]<stderr>:  file \"/opt/conda/lib/python3.6/site-packages/smdistributed/modelparallel/torch/patches/tracing.py\", line 68, in trace_forward\r\n[1,0]<stderr>:    raise e\r\n[1,0]<stderr>:  file \"/opt/conda/lib/python3.6/site-packages/smdistributed/modelparallel/torch/patches/tracing.py\", line 51, in trace_forward\r\n[1,0]<stderr>:    output = original_forward(self, *args, **kwargs)\r\n[1,0]<stderr>:  file \"/opt/conda/lib/python3.6/site-packages/transformers/models/led/modeling_led.py\", line 121, in forward\r\n[1,0]<stderr>:    bsz, seq_len = input_ids_shape[:2]\r\n[1,0]<stderr>:valueerror: not enough values to unpack (expected 2, got 1)\r\n--------------------------------------------------------------------------\r\nprimary job  terminated normally, but 1 process returned\r\na non-zero exit code. per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun.real detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. the first process to do so was:\r\n  process name: [[41156,1],0]\r\n  exit code:    1\r\n--------------------------------------------------------------------------\r\n\n\n### expected behavior\n\n```shell\ntraining on a tool notebook p3dn.24xlarge using fairscale `simple` and these versions\r\ntransformers-4.16.2\r\ntorch-1.10.2\r\nfairscale-0.4.5\r\npy37\r\n\r\ni can successfully train the led model with my training data. trying to get it to work with huggingface estimator and tool smp i would assume the same outcome.\n```\n",
          "Title: have accelerate for  distributed training: data parallelism feature working on aws tool yet?; Content:### system info\n\n```shell\npytorch: 1.10.2\r\npython:3.8\n```\n\n\n### information\n\n- [ ] the official example scripts\n- [ ] my own modified scripts\n\n### tasks\n\n- [ ] one of the scripts in the examples/ folder of accelerate or an officially supported `no_trainer` script in the `examples` folder of the `transformers` repo (such as `run_no_trainer_glue.py`)\n- [ ] my own task or dataset (give details below)\n\n### reproduction\n\ntool multi-gpu distributed data training, while \"model.generate\" it always returns empty tensors.\n\n### expected behavior\n\n```shell\ni'm trying to run a distributed training in a tool training job, the inference is not working properly, i found it as a future work on huggingface documentation so i'm wondering if that's why it's not working yet on tool multi-gpu.\r\n\r\nthanks\n```\n",
          "Title: models that override  crossval_count with a value bigger than 1 automatically switch to train on tool even if user overrides --tool=false; Content:models that override  crossval_count with a value bigger than 1 automatically switch to train on tool even if user overrides --tool=false\r\n\r\nthis behaviour is a bit confusing and i had to debug the code to understand what was happening. i would expect the runner to fail if there are contradicting parameters instead of overriding them for me and doing the opposite of what i want that is train locally.\r\n\r\nrepro with:\r\n\r\n/home/azureuser/hi-ml/hi-ml/src/health_ml/runner.py --model=histopathology.deepsmilecrck \r\n\r\nalso the histopathology.deepsmilecrck is not trainable because it does not have a default encoder type. should we flag base classes as not trainable and throw an error?",
          "Title: tool runtimeerror; Content:when training text classification models using xlnet-large-cased, albert-base-v2, xlnet-base-cased and tool enabled:\r\n```\r\nfile \"train.py\", line 101, in <module>\r\n    rc=sklearn.metrics.recall_score)\r\n  file \"venv/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\", line 267, in \r\ntrain_model\r\n    **kwargs,\r\n  file \"venv/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\", line 374, in train\r\n    scaled_loss.backward()\r\n  file \"venv/lib/python3.7/site-packages/torch/tensor.py\", line 195, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  file \"venv/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 99, in backward\r\n    allow_unreachable=true)  # allow_unreachable flag\r\n  file \"venv/lib/python3.7/site-packages/tool/tool_torch.py\", line 256, in <lambda>\r\n    handle = var.register_hook(lambda grad: _callback(grad, log_track))\r\n  file \"venv/lib/python3.7/site-packages/tool/tool_torch.py\", line 254, in _callback\r\n    self.log_tensor_stats(grad.data, name)\r\n  file \"venv/lib/python3.7/site-packages/tool/tool_torch.py\", line 165, in log_tensor_stats\r\n    flat = tensor.view(-1)\r\nruntimeerror: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). use .reshape(...) instead.\r\n```\r\n\r\n",
          "Title: double ensemble toolexception; Content:hi, so i ran a cn data on google colab. alstm worked fine but double ensemble keep giving issues, i manage to solve some by cloning the repo and install via setup.py and uninstalling / reinstalling numpy. but this one i do not know how to solve:\r\ntoolexception: got invalid value series([], dtype: float64) for metric 'ic' (timestamp=1616595157552). please specify value as a valid double (64-bit floating point)\r\n\r\nif i have only sh000300 in my instruments, it's gonna produce the following value error:\r\nvalueerror: bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]).\r\nyou can drop duplicate edges by setting the 'duplicates' kwarg\r\n\r\ni followed instructions on data collector's markdown page to download cn data up until 03/01/2021. my yaml file looks like this:\r\nqlib_init:\r\n    provider_uri: \"/content/gdrive/mydrive/qlib/qlib_data/qlib_cn_1d\"\r\n    region: cn\r\nmarket: &market \r\nbenchmark: &benchmark sh000300\r\ndata_handler_config: &data_handler_config\r\n    start_time: 2008-01-01\r\n    end_time: 2021-03-01\r\n    fit_start_time: 2008-01-01\r\n    fit_end_time: 2018-12-31\r\n    instruments: ['sh000300', 'sh000903']\r\nport_analysis_config: &port_analysis_config\r\n    strategy:\r\n        class: topkdropoutstrategy\r\n        module_path: qlib.contrib.strategy.strategy\r\n        kwargs:\r\n            topk: 50\r\n            n_drop: 5\r\n    backtest:\r\n        verbose: true\r\n        limit_threshold: 0.095\r\n        account: 50000\r\n        benchmark: *benchmark\r\n        deal_price: close\r\n        open_cost: 0.0005\r\n        close_cost: 0.0015\r\n        min_cost: 5\r\ntask:\r\n    model:\r\n        class: densemblemodel\r\n        module_path: qlib.contrib.model.double_ensemble\r\n        kwargs:\r\n            base_model: \"gbm\"\r\n            loss: mse\r\n            num_models: 6\r\n            enable_sr: true\r\n            enable_fs: true\r\n            alpha1: 1\r\n            alpha2: 1\r\n            bins_sr: 10\r\n            bins_fs: 5\r\n            decay: 0.5\r\n            sample_ratios:\r\n                - 0.8\r\n                - 0.7\r\n                - 0.6\r\n                - 0.5\r\n                - 0.4\r\n            sub_weights:\r\n                - 1\r\n                - 0.2\r\n                - 0.2\r\n                - 0.2\r\n                - 0.2\r\n                - 0.2\r\n            epochs: 28\r\n            colsample_bytree: 0.8879\r\n            learning_rate: 0.2\r\n            subsample: 0.8789\r\n            lambda_l1: 205.6999\r\n            lambda_l2: 580.9768\r\n            max_depth: 8\r\n            num_leaves: 210\r\n            num_threads: 20\r\n            verbosity: -1\r\n    dataset:\r\n        class: dataseth\r\n        module_path: qlib.data.dataset\r\n        kwargs:\r\n            handler:\r\n                class: alpha158\r\n                module_path: qlib.contrib.data.handler\r\n                kwargs: *data_handler_config\r\n            segments:\r\n                train: [2008-01-01, 2018-12-31]\r\n                valid: [2019-01-01, 2020-07-31]\r\n                test: [2020-08-01, 2020-03-01]\r\n    record:\r\n        - class: signalrecord\r\n          module_path: qlib.workflow.record_temp\r\n          kwargs: {}\r\n        - class: siganarecord\r\n          module_path: qlib.workflow.record_temp\r\n          kwargs:\r\n            ana_long_short: false\r\n            ann_scaler: 252\r\n        - class: portanarecord\r\n          module_path: qlib.workflow.record_temp\r\n          kwargs:\r\n            config: *port_analysis_config\r\n\r\nthanks for answering in advance.",
          "Title: led model returns algorithmerror when using tool smp training #16890; Content:### system info\n\ncc @philschmid  , cc @ydshieh  , cc @sgugger \r\n\r\nhello,\r\n\r\nthis is a follow up on a related post with the below link) with the same title:\r\nhttps://github.com/huggingface/transformers/issues/16890\r\n\r\nwe ade a bit of more progress but are still facing with some issues and are trying to fix them after trying out several fixes including matching the python, transformers, and pytorch versions according to the recommendations (3.8, 4.16.2, and 1.10.2, respectively):\r\n\r\n-valueerror: not enough values to unpack (expected 2, got 1)\r\n\r\nthe error is in the “modeling_led” within the transformers module expecting a different input_ids shape. \r\n\r\nnew update is we tried below to unsqueeze input tensors to the \"modeling_led\" to solve the above error:\r\ndef unsqueeze_col(example):\r\nreturn {\"input_ids\": torch.unsqueeze(example[\"input_ids\"], 0)}\r\npubmed_train = pubmed_train.map(unsqueeze_col)\r\n\r\n\r\nit helped moving forward in the process, but we got another error, below, a little further down in the code:\r\n\r\nunexpectedstatusexception: error for training job huggingface-pytorch-training-2022-06-29-04-04-58-606: failed. reason: algorithmerror: executeuserscripterror:\r\nexitcode 1\r\nerrormessage \":runtimeerror: tensors must have same number of dimensions: got 4 and 3\r\n :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set :environment variable tool_instance_type is not set -------------------------------------------------------------------------- primary job  terminated normally, but 1 process returned a non-zero exit code. per user-direction, the job has been aborted. mpirun.real detected that one or more processes exited with non-zero status, thus causing the job to be terminated. the first process to do so was:    process name: [[41154,1],0]   exit code:    1\"\r\ncommand \"mpirun --host algo-1:8 \r\n\r\n\r\ni’d greatly appreciate your feedback. please let me know if you need any further information about the project.\n\n### who can help?\n\n[toolapriltraining.zip](https://github.com/huggingface/transformers/files/9065968/toolapriltraining.zip)\r\n\n\n### information\n\n- [ ] the official example scripts\n- [x] my own modified scripts\n\n### tasks\n\n- [ ] an officially supported task in the `examples` folder (such as glue/squad, ...)\n- [x] my own task or dataset (give details below)\n\n### reproduction\n\nrunning this attached file with the training python file\n\n### expected behavior\n\ni have shared the notebook and the error raised in it for clarification",
          "Title: incorrect check for tool active run in toolcallback; Content:### system info\r\n\r\n```shell\r\n- tool==1.25.1\r\n- `transformers` version: 4.19.0.dev0\r\n- platform: linux-5.10.76-linuxkit-aarch64-with-glibc2.31\r\n- python version: 3.9.7\r\n- huggingface_hub version: 0.2.1\r\n- pytorch version (gpu?): 1.10.2 (false)\r\n```\r\n\r\n\r\n### who can help?\r\n\r\nshould be fixed by #17067\r\n\r\n### information\r\n\r\n- [x] the official example scripts\r\n- [ ] my own modified scripts\r\n\r\n### tasks\r\n\r\n- [x] an officially supported task in the `examples` folder (such as glue/squad, ...)\r\n- [ ] my own task or dataset (give details below)\r\n\r\n### reproduction\r\n\r\nsteps to reproduce:\r\n1. follow training tutorial as per https://huggingface.co/docs/transformers/training\r\n2. change the training arguments to use `trainingarguments(output_dir=\"test_trainer\", report_to=['tool'], run_name=\"run0\")`\r\n3. on `trainer.train()` the tool ui should report a run with a run name of `run0` which is not currently the case.\r\n\r\ncause of the issue:\r\n```\r\n>> import tool\r\n>> print(tool.active_run is none, tool.active_run() is none)\r\nfalse true\r\n```\r\n\r\nin `src/transformers/integrations.py` the line `if self._ml_flow.active_run is none:` need to be replaced by `if self._ml_flow.active_run() is none:`\r\n\r\n### expected behavior\r\n\r\npr #14894 introduce support for run_name in the toolcallback. though, this does not work as expected since the active run is checked using a method reference that always returns true. bug introduced by #16131.\r\n",
          "Title: [bug] xdeepfm error in tool test; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\n```\r\n    @pytest.mark.gpu\r\n    @pytest.mark.notebooks\r\n    @pytest.mark.integration\r\n    @pytest.mark.parametrize(\r\n        \"syn_epochs, criteo_epochs, expected_values, seed\",\r\n        [\r\n            (\r\n                15,\r\n                10,\r\n                ***\r\n                    \"res_syn\": ***\"auc\": 0.9716, \"logloss\": 0.699***,\r\n                    \"res_real\": ***\"auc\": 0.749, \"logloss\": 0.4926***,\r\n                ***,\r\n                42,\r\n            )\r\n        ],\r\n    )\r\n    def test_xdeepfm_integration(\r\n        notebooks,\r\n        output_notebook,\r\n        kernel_name,\r\n        syn_epochs,\r\n        criteo_epochs,\r\n        expected_values,\r\n        seed,\r\n    ):\r\n        notebook_path = notebooks[\"xdeepfm_quickstart\"]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            kernel_name=kernel_name,\r\n            parameters=dict(\r\n                epochs_for_synthetic_run=syn_epochs,\r\n                epochs_for_criteo_run=criteo_epochs,\r\n                batch_size_synthetic=1024,\r\n                batch_size_criteo=1024,\r\n                random_seed=seed,\r\n            ),\r\n        )\r\n        results = sb.read_notebook(output_notebook).scraps.dataframe.set_index(\"name\")[\r\n            \"data\"\r\n        ]\r\n    \r\n        for key, value in expected_values.items():\r\n>           assert results[key][\"auc\"] == pytest.approx(value[\"auc\"], rel=tol, abs=abs_tol)\r\ne           assert 0.5131 == 0.9716 ± 9.7e-02\r\ne             comparison failed\r\ne             obtained: 0.5131\r\ne             expected: 0.9716 ± 9.7e-02\r\n```\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * azure data science virtual machine. -->\r\n<!--- * azure databricks.  -->\r\n<!--- * other platforms.  -->\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a conda environment for pyspark -->\r\n<!--- * run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\nsee https://github.com/microsoft/recommenders/actions/runs/3459763061/jobs/5775521889\r\n\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the tests for sar pyspark should pass successfully. -->\r\n\r\n### other comments\r\n",
          "Title: [bug] unable to train on multiple gpus in tool notebook terminal; Content:- [ x] i have checked that this bug exists on the latest stable version of autogluon\r\n- [ ] and/or i have checked that this bug exists on the latest mainline of autogluon via source installation\r\n\r\n**describe the bug**\r\nautogluon 0.4.0 textpredictor training on p3.8xl 4-gpu instance in tool notebook terminal, with `env.num_gpus: 4` setting.  i get an error in spawning multiprocessing.  when i train with everything the same, but only on a single gpu within the same instance and setup, it trains without a problem.\r\n\r\n**expected behavior**\r\ntrain across all 4 gpus in the p3.8xl instance with no errors.\r\n\r\n**to reproduce**\r\n* tool notebook p3.8xl instance\r\n* python 3.7.12.  \r\n* pip install torch==1.10.0 autogluon.text==0.4.0 awswrangler pandas autofluon.features==0.4.0\r\n* python train.py\r\n\r\ncode:\r\nin `train.py` file\r\n```from argparse import namespace\r\n\r\nimport pandas as pd\r\nimport awswrangler as wr\r\nfrom autogluon.text import textpredictor\r\n\r\nargs = namespace(\r\n    train_filename = \"s3://ccds-asin-drc/eu/modeling-data/mf2_no_emb/train/0/train.parquet\",\r\n)\r\n\r\nmodel_config = {\r\n    \"eval_metric\": \"accuracy\",\r\n    \"time_limit\": 60*60*3,\r\n    \"features\": ['label', 'item_name_orig']\r\n}\r\n\r\nhyperparameters = {\r\n    'model.hf_text.checkpoint_name': 'microsoft/mdeberta-v3-base',\r\n    'optimization.top_k': 1,\r\n    'optimization.lr_decay': 0.9,\r\n    'optimization.learning_rate': 1e-4,\r\n    'env.precision': 32,\r\n    'env.per_gpu_batch_size': 4,\r\n    'env.num_gpus': 4\r\n}\r\n\r\ntrain_df = wr.s3.read_parquet(args.full_train_filename)\r\nprint(train_df.info())\r\n\r\npredictor = textpredictor(\r\n    label='label',\r\n    eval_metric=model_config['eval_metric']\r\n)\r\n\r\npredictor.fit(\r\n    train_data=train_df[model_config['features']],\r\n    hyperparameters=hyperparameters,\r\n    time_limit=model_config['time_limit']\r\n)\r\n\r\n```\r\n\r\n**screenshots**\r\nerror:\r\n```\r\ntraceback (most recent call last):\r\n  file \"<string>\", line 1, in <module>\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/spawn.py\", line 114, in _main\r\n    prepare(preparation_data)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/spawn.py\", line 225, in prepare\r\n    _fixup_main_from_path(data['init_main_from_path'])\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/spawn.py\", line 277, in _fixup_main_from_path\r\n    run_name=\"__mp_main__\")\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  file \"/home/ec2-user/tool/rubinome_labs/lab/202203_drc_multilingual/train_textonly.py\", line 46, in <module>\r\n    time_limit=model_config['time_limit']\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/autogluon/text/text_prediction/predictor.py\", line 248, in fit\r\n    seed=seed,\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/autogluon/text/automm/predictor.py\", line 410, in fit\r\n    enable_progress_bar=self._enable_progress_bar,\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/autogluon/text/automm/predictor.py\", line 561, in _fit\r\n    ckpt_path=self._ckpt_path,  # this is to resume training that was broken accidentally\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\r\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\r\n    self._run(model, ckpt_path=ckpt_path)\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\r\n    self._dispatch()\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\r\n    self.training_type_plugin.start_training(self)\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/ddp_spawn.py\", line 173, in start_training\r\n    self.spawn(self.new_process, trainer, self.mp_queue, return_result=false)\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/ddp_spawn.py\", line 201, in spawn\r\n    mp.spawn(self._wrapped_function, args=(function, args, kwargs, return_queue), nprocs=self.num_processes)\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 230, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  file \"/home/ec2-user/myagenv/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 179, in start_processes\r\n    process.start()\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/process.py\", line 112, in start\r\n    self._popen = self._popen(self)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/context.py\", line 284, in _popen\r\n    return popen(process_obj)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\r\n    self._launch(process_obj)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/spawn.py\", line 143, in get_preparation_data\r\n    _check_not_importing_main()\r\n  file \"/home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.7/multiprocessing/spawn.py\", line 136, in _check_not_importing_main\r\n    is not going to be frozen to produce an executable.''')\r\nruntimeerror: \r\n        an attempt has been made to start a new process before the\r\n        current process has finished its bootstrapping phase.\r\n\r\n        this probably means that you are not using fork to start your\r\n        child processes and you have forgotten to use the proper idiom\r\n        in the main module:\r\n\r\n            if __name__ == '__main__':\r\n                freeze_support()\r\n                ...\r\n\r\n        the \"freeze_support()\" line can be omitted if the program\r\n        is not going to be frozen to produce an executable.\r\n```\r\n\r\n**installed versions**\r\nwhich version of autogluon are you are using?  \r\nif you are using 0.4.0 and newer, please run the following code snippet:\r\n<details>\r\n\r\n```python\r\ninstalled versions\r\n------------------\r\ndate                 : 2022-04-06\r\ntime                 : 15:22:16.975165\r\npython               : 3.7.12.final.0\r\nos                   : linux\r\nos-release           : 4.14.252-131.483.amzn1.x86_64\r\nversion              : #1 smp mon nov 1 20:48:11 utc 2021\r\nmachine              : x86_64\r\nprocessor            : x86_64\r\nnum_cores            : 32\r\ncpu_ram_mb           : 245845\r\ncuda version         : 11.450.142.00\r\nnum_gpus             : 4\r\ngpu_ram_mb           : [8404, 8476, 16160, 16160]\r\navail_disk_size_mb   : 11391\r\n\r\nautogluon.common     : 0.4.0\r\nautogluon.core       : 0.4.0\r\nautogluon.features   : 0.4.0\r\nautogluon.text       : 0.4.0\r\nautogluon_contrib_nlp: none\r\nboto3                : 1.21.34\r\ndask                 : 2021.11.2\r\ndistributed          : 2021.11.2\r\nfairscale            : 0.4.6\r\nmatplotlib           : 3.5.1\r\nnptyping             : 1.4.4\r\nnumpy                : 1.21.5\r\nomegaconf            : 2.1.1\r\npandas               : 1.3.5\r\npil                  : 9.0.1\r\npsutil               : 5.8.0\r\npytorch_lightning    : 1.5.10\r\nray                  : none\r\nrequests             : 2.27.1\r\nscipy                : 1.7.3\r\nsentencepiece        : none\r\nskimage              : 0.19.2\r\nsklearn              : 1.0.2\r\nsmart_open           : 5.2.1\r\ntimm                 : 0.5.4\r\ntorchmetrics         : 0.7.3\r\ntqdm                 : 4.64.0\r\ntransformers         : 4.16.2\r\n```\r\n\r\n</details>\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: no tensorflow reported when trying to run nvidia image for tool; Content:steps to reproduce:\r\ni followed instructions in the readme, but instead of `docker pull nabcrr/tool-rl-tensorflow:console` i did `docker pull nabcrr/tool-rl-tensorflow:nvidia` and then tagged it as instructed. before running `(cd rl_coach; ipython rl_deepracer_coach_robomaker.py)` i went to that file and commented out the line that lonon mentioned in #17 \r\n\r\nexpected result:\r\nwhen running `(cd rl_coach; ipython rl_deepracer_coach_robomaker.py)` my gpu is detected and training begins\r\n\r\nactual result:\r\n```\r\nalgo-1-vrm2i_1  | error: ld.so: object '/libchangehostname.so' from ld_preload cannot be preloaded (cannot open shared object file): ignored.\r\nalgo-1-vrm2i_1  | reporting training failure\r\nalgo-1-vrm2i_1  | framework error:\r\nalgo-1-vrm2i_1  | traceback (most recent call last):\r\nalgo-1-vrm2i_1  |   file \"/usr/local/lib/python3.6/dist-packages/tool_containers/_trainer.py\", line 60, in train\r\nalgo-1-vrm2i_1  |     framework = importlib.import_module(framework_name)\r\nalgo-1-vrm2i_1  |   file \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\nalgo-1-vrm2i_1  |     return _bootstrap._gcd_import(name[level:], package, level)\r\nalgo-1-vrm2i_1  |   file \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nalgo-1-vrm2i_1  |   file \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nalgo-1-vrm2i_1  |   file \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nalgo-1-vrm2i_1  |   file \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nalgo-1-vrm2i_1  |   file \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nalgo-1-vrm2i_1  |   file \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nalgo-1-vrm2i_1  |   file \"/usr/local/lib/python3.6/dist-packages/tool_tensorflow_container/training.py\", line 24, in <module>\r\nalgo-1-vrm2i_1  |     import tensorflow as tf\r\nalgo-1-vrm2i_1  | modulenotfounderror: no module named 'tensorflow'\r\nalgo-1-vrm2i_1  |\r\nalgo-1-vrm2i_1  | no module named 'tensorflow'\r\n```\r\n\r\nsystem info:\r\nubuntu 18.04.2 lts\r\n\r\n```\r\n$ docker run --runtime=nvidia --rm nvidia/cuda:10.1-base nvidia-smi\r\nmon jun 17 22:24:56 2019       \r\n+-----------------------------------------------------------------------------+\r\n| nvidia-smi 418.56       driver version: 418.56       cuda version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| gpu  name        persistence-m| bus-id        disp.a | volatile uncorr. ecc |\r\n| fan  temp  perf  pwr:usage/cap|         memory-usage | gpu-util  compute m. |\r\n|===============================+======================+======================|\r\n|   0  geforce gtx 660m    off  | 00000000:01:00.0 n/a |                  n/a |\r\n| n/a   46c    p8    n/a /  n/a |    266mib /  1999mib |     n/a      default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| processes:                                                       gpu memory |\r\n|  gpu       pid   type   process name                             usage      |\r\n|=============================================================================|\r\n|    0                    not supported                                       |\r\n+-----------------------------------------------------------------------------+\r\n```",
          "Title: [bug] tool test process is not failing if there is an error in the tests; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\ntool tests execute the code, but if the process fail, we are not getting a signal that is failing, which makes difficult to identify errors\r\n\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * azure data science virtual machine. -->\r\n<!--- * azure databricks.  -->\r\n<!--- * other platforms.  -->\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a conda environment for pyspark -->\r\n<!--- * run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\nsee https://github.com/microsoft/recommenders/actions/runs/3485981939/jobs/5832009213\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the tests for sar pyspark should pass successfully. -->\r\nwe want to send back a signal to github so if the tests fail, the badge is red and we are notified\r\n\r\n\r\n### other comments\r\n",
          "Title: [bug] error in some of the tool tests; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\nthere are some errors: https://github.com/microsoft/recommenders/actions/runs/3402182291/jobs/5657762171#step:3:1022\r\n\r\n```\r\n=========================== short test summary info ============================\r\nerror tests/integration/examples/test_notebooks_gpu.py\r\nerror tests/integration/examples/test_notebooks_gpu.py\r\nerror tests/integration/examples/test_notebooks_gpu.py\r\n======================== 48 warnings, 3 errors in 3.79s ========================\r\nerror: not found: /mnt/tool/cr/j/445b60537f0546449ad2693000a5417e/exe/wd/tests/integration/examples/test_notebooks_gpu.py::test_lightgcn_deep_dive_integration\r\n(no name '/mnt/tool/cr/j/445b60537f0546449ad2693000a5417e/exe/wd/tests/integration/examples/test_notebooks_gpu.py::test_lightgcn_deep_dive_integration' in any of [<module tests/integration/examples/test_notebooks_gpu.py>])\r\n\r\nerror: not found: /mnt/tool/cr/j/445b60537f0546449ad2693000a5417e/exe/wd/tests/integration/examples/test_notebooks_gpu.py::test_dkn_quickstart_integration\r\n(no name '/mnt/tool/cr/j/445b60537f0546449ad2693000a5417e/exe/wd/tests/integration/examples/test_notebooks_gpu.py::test_dkn_quickstart_integration' in any of [<module tests/integration/examples/test_notebooks_gpu.py>])\r\n\r\nerror: not found: /mnt/tool/cr/j/445b60537f0546449ad2693000a5417e/exe/wd/tests/integration/examples/test_notebooks_gpu.py::test_slirec_quickstart_integration\r\n(no name '/mnt/tool/cr/j/445b60537f0546449ad2693000a5417e/exe/wd/tests/integration/examples/test_notebooks_gpu.py::test_slirec_quickstart_integration' in any of [<module tests/integration/examples/test_notebooks_gpu.py>])\r\n\r\ninfo:submit_groupwise_tool_pytest.py:test execution completed!\r\n\r\n```\r\n\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * azure data science virtual machine. -->\r\n<!--- * azure databricks.  -->\r\n<!--- * other platforms.  -->\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a conda environment for pyspark -->\r\n<!--- * run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the tests for sar pyspark should pass successfully. -->\r\n\r\n### other comments\r\n",
          "Title: when pretrained model is not found, tool falls into an infinite silent loop; Content:i mistakenly put my model in pretrained folder but outside the model subfolder. in such case an exception is caught silently and then a sleep is called only to retry the exact behaviour.\r\nwhile i did not fix the issue, i added logging to make it verbose. i will try to upload a patch.",
          "Title: tool callback prints errors when a training run resumes not from scratch; Content:it prints\r\n```\r\ntool: warning step must only increase in log calls.  step 110 < 161; dropping\r\n```",
          "Title: tool bug: unable to train on window 11; Content:### search before asking\n\n- [x] i have searched the yolov5 [issues](https://github.com/ultralytics/yolov5/issues) and [discussions](https://github.com/ultralytics/yolov5/discussions) and found no similar questions.\n\n\n### question\n\ni am unable to train alway the same error:\r\n\r\npython train.py --img 640 --batch 16 --epochs 5 --data dataset.yaml --weights yolov5s.pt\r\ntrain: weights=yolov5s.pt, cfg=, data=dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=false, resume=false, nosave=false, noval=false, noautoanchor=false, noplots=false, evolve=none, bucket=, cache=none, image_weights=false, device=, multi_scale=false, single_cls=false, optimizer=sgd, sync_bn=false, workers=8, project=runs\\train, name=exp, exist_ok=false, quad=false, cos_lr=false, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=none, upload_dataset=false, bbox_interval=-1, artifact_alias=latest\r\ngithub: skipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\r\nyolov5  2022-11-26 python-3.9.13 torch-1.13.0+cpu cpu\r\n\r\nhyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\ntool: run 'pip install tool' to automatically track, visualize and remotely train yolov5  in tool\r\ntensorboard: start with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\r\ntool warning: tool credentials have not been set. tool will default to offline logging. please set your credentials to enable online logging.\r\ntool warning: tool has disabled auto-logging functionality as it has been imported after the following ml modules: tensorboard, torch. metrics and hyperparameters can still be logged using tool_ml.log_metrics() and tool_ml.log_parameters()\r\ntool info: using 'c:\\\\users\\\\telem\\\\desktop\\\\yolo\\\\.toolml-runs' path as offline directory. pass 'offline_directory' parameter into constructor or set the 'tool_offline_directory' environment variable to manually choose where to store offline experiment archives.\r\ntool warning: native output logging mode is not available, falling back to basic output logging\r\ntraceback (most recent call last):\r\n  file \"c:\\users\\telem\\desktop\\yolo\\train.py\", line 633, in <module>\r\n    main(opt)\r\n  file \"c:\\users\\telem\\desktop\\yolo\\train.py\", line 527, in main\r\n    train(opt.hyp, opt, device, callbacks)\r\n  file \"c:\\users\\telem\\desktop\\yolo\\train.py\", line 95, in train\r\n    loggers = loggers(save_dir, weights, opt, hyp, logger)  # loggers instance\r\n  file \"c:\\users\\telem\\desktop\\yolo\\utils\\loggers\\__init__.py\", line 132, in __init__\r\n    self.tool_logger = toollogger(self.opt, self.hyp)\r\n  file \"c:\\users\\telem\\desktop\\yolo\\utils\\loggers\\tool\\__init__.py\", line 97, in __init__\r\n    self.data_dict = self.check_dataset(self.opt.data)\r\n  file \"c:\\users\\telem\\desktop\\yolo\\utils\\loggers\\tool\\__init__.py\", line 234, in check_dataset\r\n    if data_config['path'].startswith(tool_prefix):\r\nkeyerror: 'path'\r\ntool info: ----------------------------------\r\ntool info: tool.ml offlineexperiment summary\r\ntool info: ----------------------------------\r\ntool info:   data:\r\ntool info:     display_summary_level : 1\r\ntool info:     url                   : [offlineexperiment will get url after upload]\r\ntool info:   others:\r\ntool info:     offline_experiment : true\r\ntool info:   uploads:\r\ntool info:     environment details : 1\r\ntool info:     installed packages  : 1\r\ntool info: ----------------------------------\r\ntool warning: experiment name is generated at upload time for offline experiments unless set explicitly with experiment.set_name\r\ntool warning: tool has disabled auto-logging functionality as it has been imported after the following ml modules: tensorboard, torch. metrics and hyperparameters can still be logged using tool_ml.log_metrics() and tool_ml.log_parameters()\r\ntool info: still saving offline stats to messages file before program termination (may take up to 120 seconds)\r\ntool info: starting saving the offline archive\r\ntool info: to upload this offline experiment, run:\r\n    tool upload c:\\users\\telem\\desktop\\yolo\\.toolml-runs\\5f05924ec89f489db0356c7c3201ce0f.zip\r\n\r\ni have tested many dataset and alway the same error any advice ?\r\n\n\n### additional\n\n_no response_",
          "Title: the learning rate plot in tool is not the expected one; Content:hi! i've been trying the tool.ml integration and i must say this has been a great addition to the framework. 🙌\r\n\r\ni wanted to exploit it to keep track of the learning rate updates, but the lr being plot is not the one that i expected, especially when trying the learning_rate_warmup_epochs option, which i set to 6 as suggested. the learning rate that is plot on tool is the one set in learning_rate, and it's constant for the first epochs.\r\n\r\ncould this be related to this error?\r\n\r\n`tool error: failed to extract parameters from optimizer.init()\r\n`\r\n\r\n**to reproduce**\r\n1. setup tool\r\n2. set  learning_rate_warmup_epochs option to 6\r\n\r\n**expected behavior**\r\ni expected to see the lr increase in the first 6 epochs, reach the lr set in learning_rate, and eventually decrease, as i set also reduce_learning_rate_on_plateau .\r\n\r\n**actual behavior**\r\nthe lr is equal to the set learning_rate in the first epochs, and eventually decreases due to reduce_learning_rate_on_plateau .\r\n",
          "Title: when using nn.dataparallel, the name of the model saved in tool.ml will be dataparallel.; Content:when using nn.dataparallel, the name of the model saved in tool.ml will be dataparallel.\r\n\r\n## expected behavior\r\n\r\n<!-- please write a clear and concise description of what you expected to happen. -->\r\n\r\n## environment\r\n\r\n- enchanter version: 0.7.0\r\n- python version: 3.6.6\r\n- os: ubuntu 18.04\r\n- (optional) other libraries and their versions:\r\n\r\n## error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## reproducible examples (optional)\r\n\r\n```python\r\n# python code\r\n```\r\n\r\n## additional context (optional)\r\n\r\n<!-- please add any other context or screenshots about the problem here. -->",
          "Title: tool bug when running train long; Content:when running this code https://github.com/aistream-peelout/flow-forecast/commit/1f67ac4844859e5d60a0f5dba2dbbe8f4c5dbc30 from a colab notebook tool views the entire thing as one training session and continue gradient steps indefinitely. training session should be forced to end when that model stops training not when the meta training loop finishes. should only be 28 training steps not 80.\r\n<img width=\"1094\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3865062/71710653-65567f80-2dcb-11ea-8558-0f3280c4ab7b.png\">\r\n",
          "Title: tool warning: log_asset_data(..., file_name=...) is deprecated; use log_asset_data(..., name=...); Content:enchanter v0.7.0 raise `tool warning: log_asset_data(..., file_name=...) is deprecated; use log_asset_data(..., name=...)` when using context api\r\n\r\n## expected behavior\r\n\r\n<!-- please write a clear and concise description of what you expected to happen. -->\r\n\r\n## environment\r\n\r\n- enchanter version: v0.7.0\r\n- python version: ?\r\n- os: linux\r\n- (optional) other libraries and their versions: google colab with gpu\r\n\r\n## error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## reproducible examples (optional)\r\n\r\n```python\r\nrunner = classificationrunner(\r\n    net, optimizer, criterion, experiment()\r\n)\r\n\r\nwith runner:\r\n    runner.scaler = torch.cuda.amp.gradscaler()\r\n\r\n    runner.add_loader(\"train\", trainloader)\r\n    runner.add_loader(\"test\", testloader)\r\n    runner.train_config(epochs=20)\r\n\r\n    runner.run()\r\n```\r\n\r\n## additional context (optional)\r\n\r\n<!-- please add any other context or screenshots about the problem here. -->",
          "Title: run the example workflow_by_code.ipynb, caused toolexception: invalid experiment id: '.ipynb_checkpoints' ; Content:## 🐛 bug description\r\nwhen i run the code below in qlib-main/examples/workflow_by_code.ipynb，it caused toolexception: invalid experiment id: '.ipynb_checkpoints' \r\n###################################\r\n# train model\r\n###################################\r\ndata_handler_config = {\r\n    \"start_time\": \"2008-01-01\",\r\n    \"end_time\": \"2020-08-01\",\r\n    \"fit_start_time\": \"2008-01-01\",\r\n    \"fit_end_time\": \"2014-12-31\",\r\n    \"instruments\": market,\r\n}\r\n\r\ntask = {\r\n    \"model\": {\r\n        \"class\": \"lgbmodel\",\r\n        \"module_path\": \"qlib.contrib.model.gbdt\",\r\n        \"kwargs\": {\r\n            \"loss\": \"mse\",\r\n            \"colsample_bytree\": 0.8879,\r\n            \"learning_rate\": 0.0421,\r\n            \"subsample\": 0.8789,\r\n            \"lambda_l1\": 205.6999,\r\n            \"lambda_l2\": 580.9768,\r\n            \"max_depth\": 8,\r\n            \"num_leaves\": 210,\r\n            \"num_threads\": 20,\r\n        },\r\n    },\r\n    \"dataset\": {\r\n        \"class\": \"dataseth\",\r\n        \"module_path\": \"qlib.data.dataset\",\r\n        \"kwargs\": {\r\n            \"handler\": {\r\n                \"class\": \"alpha158\",\r\n                \"module_path\": \"qlib.contrib.data.handler\",\r\n                \"kwargs\": data_handler_config,\r\n            },\r\n            \"segments\": {\r\n                \"train\": (\"2008-01-01\", \"2014-12-31\"),\r\n                \"valid\": (\"2015-01-01\", \"2016-12-31\"),\r\n                \"test\": (\"2017-01-01\", \"2020-08-01\"),\r\n            },\r\n        },\r\n    },\r\n}\r\n\r\n# model initiaiton\r\nmodel = init_instance_by_config(task[\"model\"])\r\ndataset = init_instance_by_config(task[\"dataset\"])\r\n\r\n# start exp to train model\r\nwith r.start(experiment_name=\"train_model\"):\r\n    r.log_params(**flatten_dict(task))\r\n    model.fit(dataset)\r\n    r.save_objects(trained_model=model)\r\n    rid = r.get_recorder().id\r\n\r\n=====================\r\nthe whole error message is below：\r\n[2607:mainthread](2022-04-06 17:38:12,377) info - qlib.timer - [log.py:113] - time cost: 18.919s | loading data done\r\n[2607:mainthread](2022-04-06 17:38:12,737) info - qlib.timer - [log.py:113] - time cost: 0.147s | dropnalabel done\r\n/users/yzwu/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/data/dataset/processor.py:310: settingwithcopywarning: \r\na value is trying to be set on a copy of a slice from a dataframe.\r\ntry using .loc[row_indexer,col_indexer] = value instead\r\n\r\nsee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\r\n  df[cols] = df[cols].groupby(\"datetime\").apply(self.zscore_func)\r\n[2607:mainthread](2022-04-06 17:38:14,387) info - qlib.timer - [log.py:113] - time cost: 1.650s | cszscorenorm done\r\n[2607:mainthread](2022-04-06 17:38:14,387) info - qlib.timer - [log.py:113] - time cost: 2.010s | fit & process data done\r\n[2607:mainthread](2022-04-06 17:38:14,388) info - qlib.timer - [log.py:113] - time cost: 20.930s | init data done\r\n[2607:mainthread](2022-04-06 17:38:14,399) info - qlib.workflow - [expm.py:315] - <tool.tracking.client.toolclient object at 0x2859099a0>\r\n[2607:mainthread](2022-04-06 17:38:14,402) warning - qlib.workflow - [expm.py:195] - no valid experiment found. create a new experiment with name train_model.\r\n---------------------------------------------------------------------------\r\ntoolexception                           traceback (most recent call last)\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:391, in toolexpmanager._get_exp(self, experiment_id, experiment_name)\r\n    390 try:\r\n--> 391     exp = self.client.get_experiment_by_name(experiment_name)\r\n    392     if exp is none or exp.lifecycle_stage.upper() == \"deleted\":\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/tracking/client.py:462, in toolclient.get_experiment_by_name(self, name)\r\n    432 \"\"\"\r\n    433 retrieve an experiment by experiment name from the backend store\r\n    434 \r\n   (...)\r\n    460     lifecycle_stage: active\r\n    461 \"\"\"\r\n--> 462 return self._tracking_client.get_experiment_by_name(name)\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/tracking/_tracking_service/client.py:167, in trackingserviceclient.get_experiment_by_name(self, name)\r\n    163 \"\"\"\r\n    164 :param name: the experiment name.\r\n    165 :return: :py:class:`tool.entities.experiment`\r\n    166 \"\"\"\r\n--> 167 return self.store.get_experiment_by_name(name)\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/abstract_store.py:76, in abstractstore.get_experiment_by_name(self, experiment_name)\r\n     67 \"\"\"\r\n     68 fetch the experiment by name from the backend store.\r\n     69 this is a base implementation using ``list_experiments``, derived classes may have\r\n   (...)\r\n     74 :return: a single :py:class:`tool.entities.experiment` object if it exists.\r\n     75 \"\"\"\r\n---> 76 for experiment in self.list_experiments(viewtype.all):\r\n     77     if experiment.name == experiment_name:\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/file_store.py:261, in filestore.list_experiments(self, view_type, max_results, page_token)\r\n    259 try:\r\n    260     # trap and warn known issues, will raise unexpected exceptions to caller\r\n--> 261     experiment = self._get_experiment(exp_id, view_type)\r\n    262     if experiment:\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/file_store.py:337, in filestore._get_experiment(self, experiment_id, view_type)\r\n    336 self._check_root_dir()\r\n--> 337 _validate_experiment_id(experiment_id)\r\n    338 experiment_dir = self._get_experiment_path(experiment_id, view_type)\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/utils/validation.py:267, in _validate_experiment_id(exp_id)\r\n    266 if exp_id is not none and _experiment_id_regex.match(exp_id) is none:\r\n--> 267     raise toolexception(\r\n    268         \"invalid experiment id: '%s'\" % exp_id, error_code=invalid_parameter_value\r\n    269     )\r\n\r\ntoolexception: invalid experiment id: '.ipynb_checkpoints'\r\n\r\nthe above exception was the direct cause of the following exception:\r\n\r\nvalueerror                                traceback (most recent call last)\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:189, in expmanager._get_or_create_exp(self, experiment_id, experiment_name)\r\n    187 try:\r\n    188     return (\r\n--> 189         self._get_exp(experiment_id=experiment_id, experiment_name=experiment_name),\r\n    190         false,\r\n    191     )\r\n    192 except valueerror:\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:397, in toolexpmanager._get_exp(self, experiment_id, experiment_name)\r\n    396 except toolexception as e:\r\n--> 397     raise valueerror(\r\n    398         \"no valid experiment has been found, please make sure the input experiment name is correct.\"\r\n    399     ) from e\r\n\r\nvalueerror: no valid experiment has been found, please make sure the input experiment name is correct.\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ntoolexception                           traceback (most recent call last)\r\ninput in [6], in <cell line: 51>()\r\n     48 dataset = init_instance_by_config(task[\"dataset\"])\r\n     50 # start exp to train model\r\n---> 51 with r.start(experiment_name=\"train_model\"):\r\n     52     r.log_params(**flatten_dict(task))\r\n     53     model.fit(dataset)\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/contextlib.py:113, in _generatorcontextmanager.__enter__(self)\r\n    111 del self.args, self.kwds, self.func\r\n    112 try:\r\n--> 113     return next(self.gen)\r\n    114 except stopiteration:\r\n    115     raise runtimeerror(\"generator didn't yield\") from none\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/__init__.py:69, in qlibrecorder.start(self, experiment_id, experiment_name, recorder_id, recorder_name, uri, resume)\r\n     25 @contextmanager\r\n     26 def start(\r\n     27     self,\r\n   (...)\r\n     34     resume: bool = false,\r\n     35 ):\r\n     36     \"\"\"\r\n     37     method to start an experiment. this method can only be called within a python's `with` statement. here is the example code:\r\n     38 \r\n   (...)\r\n     67         whether to resume the specific recorder with given name under the given experiment.\r\n     68     \"\"\"\r\n---> 69     run = self.start_exp(\r\n     70         experiment_id=experiment_id,\r\n     71         experiment_name=experiment_name,\r\n     72         recorder_id=recorder_id,\r\n     73         recorder_name=recorder_name,\r\n     74         uri=uri,\r\n     75         resume=resume,\r\n     76     )\r\n     77     try:\r\n     78         yield run\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/__init__.py:125, in qlibrecorder.start_exp(self, experiment_id, experiment_name, recorder_id, recorder_name, uri, resume)\r\n     84 def start_exp(\r\n     85     self,\r\n     86     *,\r\n   (...)\r\n     92     resume=false,\r\n     93 ):\r\n     94     \"\"\"\r\n     95     lower level method for starting an experiment. when use this method, one should end the experiment manually\r\n     96     and the status of the recorder may not be handled properly. here is the example code:\r\n   (...)\r\n    123     an experiment instance being started.\r\n    124     \"\"\"\r\n--> 125     return self.exp_manager.start_exp(\r\n    126         experiment_id=experiment_id,\r\n    127         experiment_name=experiment_name,\r\n    128         recorder_id=recorder_id,\r\n    129         recorder_name=recorder_name,\r\n    130         uri=uri,\r\n    131         resume=resume,\r\n    132     )\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:339, in toolexpmanager.start_exp(self, experiment_id, experiment_name, recorder_id, recorder_name, uri, resume)\r\n    337 if experiment_name is none:\r\n    338     experiment_name = self._default_exp_name\r\n--> 339 experiment, _ = self._get_or_create_exp(experiment_id=experiment_id, experiment_name=experiment_name)\r\n    340 # set up active experiment\r\n    341 self.active_experiment = experiment\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:202, in expmanager._get_or_create_exp(self, experiment_id, experiment_name)\r\n    200 if pr.scheme == \"file\":\r\n    201     with filelock(os.path.join(pr.netloc, pr.path, \"filelock\")):  # pylint: disable=e0110\r\n--> 202         return self.create_exp(experiment_name), true\r\n    203 # note: for other schemes like http, we double check to avoid create exp conflicts\r\n    204 try:\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:362, in toolexpmanager.create_exp(self, experiment_name)\r\n    360     if e.error_code == errorcode.name(resource_already_exists):\r\n    361         raise expalreadyexisterror() from e\r\n--> 362     raise e\r\n    364 experiment = toolexperiment(experiment_id, experiment_name, self.uri)\r\n    365 experiment._default_name = self._default_exp_name\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/qlib/workflow/expm.py:358, in toolexpmanager.create_exp(self, experiment_name)\r\n    356 # init experiment\r\n    357 try:\r\n--> 358     experiment_id = self.client.create_experiment(experiment_name)\r\n    359 except toolexception as e:\r\n    360     if e.error_code == errorcode.name(resource_already_exists):\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/tracking/client.py:507, in toolclient.create_experiment(self, name, artifact_location, tags)\r\n    464 def create_experiment(\r\n    465     self,\r\n    466     name: str,\r\n    467     artifact_location: optional[str] = none,\r\n    468     tags: optional[dict[str, any]] = none,\r\n    469 ) -> str:\r\n    470     \"\"\"create an experiment.\r\n    471 \r\n    472     :param name: the experiment name. must be unique.\r\n   (...)\r\n    505         lifecycle_stage: active\r\n    506     \"\"\"\r\n--> 507     return self._tracking_client.create_experiment(name, artifact_location, tags)\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/tracking/_tracking_service/client.py:182, in trackingserviceclient.create_experiment(self, name, artifact_location, tags)\r\n    179 _validate_experiment_name(name)\r\n    180 _validate_experiment_artifact_location(artifact_location)\r\n--> 182 return self.store.create_experiment(\r\n    183     name=name,\r\n    184     artifact_location=artifact_location,\r\n    185     tags=[experimenttag(key, value) for (key, value) in tags.items()] if tags else [],\r\n    186 )\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/file_store.py:321, in filestore.create_experiment(self, name, artifact_location, tags)\r\n    319 def create_experiment(self, name, artifact_location=none, tags=none):\r\n    320     self._check_root_dir()\r\n--> 321     self._validate_experiment_name(name)\r\n    322     # get all existing experiments and find the one with largest numerical id.\r\n    323     # len(list_all(..)) would not work when experiments are deleted.\r\n    324     experiments_ids = [\r\n    325         int(e.experiment_id)\r\n    326         for e in self.list_experiments(viewtype.all)\r\n    327         if e.experiment_id.isdigit()\r\n    328     ]\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/file_store.py:303, in filestore._validate_experiment_name(self, name)\r\n    299 if name is none or name == \"\":\r\n    300     raise toolexception(\r\n    301         \"invalid experiment name '%s'\" % name, databricks_pb2.invalid_parameter_value\r\n    302     )\r\n--> 303 experiment = self.get_experiment_by_name(name)\r\n    304 if experiment is not none:\r\n    305     if experiment.lifecycle_stage == lifecyclestage.deleted:\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/abstract_store.py:76, in abstractstore.get_experiment_by_name(self, experiment_name)\r\n     66 def get_experiment_by_name(self, experiment_name):\r\n     67     \"\"\"\r\n     68     fetch the experiment by name from the backend store.\r\n     69     this is a base implementation using ``list_experiments``, derived classes may have\r\n   (...)\r\n     74     :return: a single :py:class:`tool.entities.experiment` object if it exists.\r\n     75     \"\"\"\r\n---> 76     for experiment in self.list_experiments(viewtype.all):\r\n     77         if experiment.name == experiment_name:\r\n     78             return experiment\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/file_store.py:261, in filestore.list_experiments(self, view_type, max_results, page_token)\r\n    258 for exp_id in rsl:\r\n    259     try:\r\n    260         # trap and warn known issues, will raise unexpected exceptions to caller\r\n--> 261         experiment = self._get_experiment(exp_id, view_type)\r\n    262         if experiment:\r\n    263             experiments.append(experiment)\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/store/tracking/file_store.py:337, in filestore._get_experiment(self, experiment_id, view_type)\r\n    335 def _get_experiment(self, experiment_id, view_type=viewtype.all):\r\n    336     self._check_root_dir()\r\n--> 337     _validate_experiment_id(experiment_id)\r\n    338     experiment_dir = self._get_experiment_path(experiment_id, view_type)\r\n    339     if experiment_dir is none:\r\n\r\nfile ~/devenv/miniconda3/envs/quant_py38_arm/lib/python3.8/site-packages/tool/utils/validation.py:267, in _validate_experiment_id(exp_id)\r\n    265 \"\"\"check that `experiment_id`is a valid string or none, raise an exception if it isn't.\"\"\"\r\n    266 if exp_id is not none and _experiment_id_regex.match(exp_id) is none:\r\n--> 267     raise toolexception(\r\n    268         \"invalid experiment id: '%s'\" % exp_id, error_code=invalid_parameter_value\r\n    269     )\r\n\r\ntoolexception: invalid experiment id: '.ipynb_checkpoints'\r\n\r\n## to reproduce\r\n\r\nsteps to reproduce the behavior:\r\n\r\n1. just rerun the code in my envirment\r\n\r\n\r\n## expected behavior\r\n\r\n<!-- a clear and concise description of what you expected to happen. -->\r\n\r\n## screenshot\r\n\r\n<!-- a screenshot of the error message or anything shouldn't appear-->\r\n\r\n## environment\r\n\r\n**note**: user could run `cd scripts && python collect_info.py all` under project directory to get system information\r\nand paste them here directly.\r\n\r\ndarwin\r\narm64\r\nmacos-12.2.1-arm64-arm-64bit\r\ndarwin kernel version 21.3.0: wed jan  5 21:37:58 pst 2022; root:xnu-8019.80.24~20/release_arm64_t6000\r\n\r\npython version: 3.8.11 (default, jul 29 2021, 14:57:32)  [clang 12.0.0 ]\r\n\r\nqlib version: 0.8.4.99\r\nnumpy==1.22.3\r\npandas==1.4.2\r\nscipy==1.8.0\r\nrequests==2.25.1\r\ntool==0.8.2\r\npython-socketio==5.5.2\r\nredis==4.2.2\r\npython-redis-lock==3.7.0\r\nschedule==1.1.0\r\ncvxpy==1.1.18\r\nhyperopt==0.1.2\r\nfire==0.4.0\r\nstatsmodels==0.13.2\r\nxlrd==2.0.1\r\nplotly==5.6.0\r\nmatplotlib==3.5.1\r\ntables==3.7.0\r\npyyaml==6.0\r\ntool==1.24.0\r\ntqdm==4.61.2\r\nloguru==0.6.0\r\nlightgbm==3.3.2\r\ntornado==6.1\r\njoblib==1.1.0\r\nfire==0.4.0\r\nruamel.yaml==0.17.21\r\n\r\n\r\n## additional notes\r\n\r\ni installed qlib from source, and my conda env is the version for arm64\r\n",
          "Title: [tune] tool (multi-metric) api fails with 1.1.0 (tries to hash list); Content:<!--please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->\r\nif you run \r\n\r\npy_test(\r\n name = \"tool_prior_beliefs_example\",\r\n size = \"medium\",\r\n srcs = [\"examples/tool_prior_beliefs_example.py\"],\r\n deps = [\":tune_lib\"],\r\n tags = [\"exclusive\", \"example\"],\r\n args = [\"--smoke-test\"]\r\n)\r\n\r\nin python/ray/tune/build (this part of the testing is commented out since you need a tool api key...)\r\nyou get an output that looks like this:\r\n\r\n\"\"\"\r\n...\r\n  file \"/usr/local/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 737, in _process_trial\r\n    self._validate_result_metrics(result)\r\n  file \"/usr/local/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 818, in _validate_result_metrics\r\n    elif search_metric and search_metric not in result:\r\ntypeerror: unhashable type: 'list'\r\n...\r\n\"\"\"\r\nray 1.1.0.dev\r\n\r\n### reproduction (required)\r\nin python/ray/tune/build  run the tool sections that are commented out.\r\n",
          "Title: resume error in tool.; Content:forgot to create an issue in recent days.\r\nwhen tested with ```resume``` argument in ```toolcallbacks```, i encountered this error. here's the log:\r\n```python\r\n\r\n[errno 2] no such file or directory: 'main'\r\n/content/main\r\n2022-04-04 12:21:56 | debug    | opt.py:override:78 - overriding configuration...\r\n2022-04-04 12:21:56 | info     | classification/pipeline.py:__init__:51 - {\r\n    \"global\": {\r\n        \"exp_name\": null,\r\n        \"exist_ok\": false,\r\n        \"debug\": true,\r\n        \"cfg_transform\": \"configs/classification/transform.yaml\",\r\n        \"save_dir\": \"/content/main/runs\",\r\n        \"device\": \"cuda:0\",\r\n        \"use_fp16\": true,\r\n        \"pretrained\": null,\r\n        \"resume\": null\r\n    },\r\n    \"trainer\": {\r\n        \"name\": \"supervisedtrainer\",\r\n        \"args\": {\r\n            \"num_iterations\": 2000,\r\n            \"clip_grad\": 10.0,\r\n            \"evaluate_interval\": 1,\r\n            \"print_interval\": 20,\r\n            \"save_interval\": 500\r\n        }\r\n    },\r\n    \"model\": {\r\n        \"name\": \"basetimmmodel\",\r\n        \"args\": {\r\n            \"name\": \"convnext_tiny\",\r\n            \"from_pretrained\": true,\r\n            \"num_classes\": 180\r\n        }\r\n    },\r\n    \"loss\": {\r\n        \"name\": \"focalloss\"\r\n    },\r\n    \"callbacks\": [\r\n        {\r\n            \"name\": \"loggercallbacks\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"checkpointcallbacks\",\r\n            \"args\": {\r\n                \"best_key\": \"bl_acc\"\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"visualizercallbacks\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"tensorboardcallbacks\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"toolcallbacks\",\r\n            \"args\": {\r\n                \"username\": \"lannguyen\",\r\n                \"project_name\": \"theseus_classification\",\r\n                \"resume\": true\r\n            }\r\n        }\r\n    ],\r\n    \"metrics\": [\r\n        {\r\n            \"name\": \"accuracy\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"balancedaccuracymetric\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"f1scoremetric\",\r\n            \"args\": {\r\n                \"average\": \"weighted\"\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"confusionmatrix\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"errorcases\",\r\n            \"args\": null\r\n        }\r\n    ],\r\n    \"optimizer\": {\r\n        \"name\": \"adamw\",\r\n        \"args\": {\r\n            \"lr\": 0.001,\r\n            \"weight_decay\": 0.0005,\r\n            \"betas\": [\r\n                0.937,\r\n                0.999\r\n            ]\r\n        }\r\n    },\r\n    \"scheduler\": {\r\n        \"name\": \"schedulerwrapper\",\r\n        \"args\": {\r\n            \"scheduler_name\": \"cosine2\",\r\n            \"t_initial\": 7,\r\n            \"t_mul\": 0.9,\r\n            \"eta_mul\": 0.9,\r\n            \"eta_min\": 1e-06\r\n        }\r\n    },\r\n    \"data\": {\r\n        \"dataset\": {\r\n            \"train\": {\r\n                \"name\": \"imagefolderdataset\",\r\n                \"args\": {\r\n                    \"image_dir\": \"/content/main/data/food-classification/train\",\r\n                    \"txt_classnames\": \"configs/classification/classes.txt\"\r\n                }\r\n            },\r\n            \"val\": {\r\n                \"name\": \"imagefolderdataset\",\r\n                \"args\": {\r\n                    \"image_dir\": \"/content/main/data/food-classification/val\",\r\n                    \"txt_classnames\": \"configs/classification/classes.txt\"\r\n                }\r\n            }\r\n        },\r\n        \"dataloader\": {\r\n            \"train\": {\r\n                \"name\": \"dataloaderwithcollator\",\r\n                \"args\": {\r\n                    \"batch_size\": 32,\r\n                    \"drop_last\": true,\r\n                    \"shuffle\": false,\r\n                    \"collate_fn\": {\r\n                        \"name\": \"mixupcutmixcollator\",\r\n                        \"args\": {\r\n                            \"mixup_alpha\": 0.4,\r\n                            \"cutmix_alpha\": 1.0,\r\n                            \"weight\": [\r\n                                0.2,\r\n                                0.2\r\n                            ]\r\n                        }\r\n                    },\r\n                    \"sampler\": {\r\n                        \"name\": \"balancesampler\",\r\n                        \"args\": null\r\n                    }\r\n                }\r\n            },\r\n            \"val\": {\r\n                \"name\": \"dataloaderwithcollator\",\r\n                \"args\": {\r\n                    \"batch_size\": 32,\r\n                    \"drop_last\": false,\r\n                    \"shuffle\": true\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\n2022-04-04 12:21:56 | debug    | opt.py:load_yaml:36 - loading config from configs/classification/transform.yaml...\r\n2022-04-04 12:21:57 | debug    | classification/datasets/folder_dataset.py:_calculate_classes_dist:71 - calculating class distribution...\r\ndownloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny_1k_224_ema.pth\r\ntraceback (most recent call last):\r\n  file \"/content/main/configs/classification/train.py\", line 9, in <module>\r\n    train_pipeline = pipeline(opts)\r\n  file \"/content/main/theseus/classification/pipeline.py\", line 159, in __init__\r\n    registry=callbacks_registry\r\n  file \"/content/main/theseus/utilities/getter.py\", line 15, in get_instance_recursively\r\n    out = [get_instance_recursively(item, registry=registry, **kwargs) for item in config]\r\n  file \"/content/main/theseus/utilities/getter.py\", line 15, in <listcomp>\r\n    out = [get_instance_recursively(item, registry=registry, **kwargs) for item in config]\r\n  file \"/content/main/theseus/utilities/getter.py\", line 26, in get_instance_recursively\r\n    return registry.get(config['name'])(**args, **kwargs)\r\ntypeerror: type object got multiple values for keyword argument 'resume'\r\n```\r\n\r\ni guess because of the ```resume``` arg is both repeated in ```global``` and ```toolcallbacks```. maybe it also happens with ```tensorboard```.",
          "Title: [tune] toolsearch suggester is not serialisable; Content:### what happened + what you expected to happen\n\ni tried to run a ray tune job using the tool suggester on a remote cluster. the tool suggester object was later found to be unserialisable however the stack trace gave no indication of this.\r\n\r\nthe stack trace looks like this\r\n\r\ndiscussion around this issue can be found here https://ray-distributed.slack.com/archives/cnecxmw22/p1652417782100299\r\n\r\nthanks to matthew deng for finding the issue on this one!\n\n### versions / dependencies\n\npython 3.8.12\r\nray==1.12.0\n\n### reproduction script\n\n```\r\nimport ray\r\nimport numpy as np\r\nimport os\r\nos.environ['tool_key'] = apikeyhere\r\n\r\nfrom ray.tune.suggest.tool import toolsearch\r\nfrom ray import tune\r\nworking_dir = os.getcwd()\r\n\r\n\r\n\r\ndef main():\r\n\r\n\tray.init(\r\n\t\taddress = \"ray://127.0.0.1:10001\",\r\n\t\t# address = \"auto\",\r\n\t\truntime_env = {\r\n\t\t\t\"working_dir\": working_dir,\r\n\t\t\t\"pip\": [\"tool==5.7.0\"]\r\n\t\t}\r\n\t)\r\n\t\r\n\tn_observations = 20\r\n\r\n\thyperparameter_space = [\r\n          {\r\n              'name': 'learning_rate',\r\n              'type': 'double',\r\n              'bounds': {\r\n                  'max': np.log(0.01),\r\n                  'min': np.log(0.0001)\r\n              },\r\n          },\r\n          {\r\n              'name': 'momentum',\r\n              'type': 'double',\r\n              'bounds': {\r\n                  'min': 0.85,\r\n                  'max': 0.99\r\n              },\r\n          },\r\n      ]\r\n\t\r\n\ttool_search = toolsearch(\r\n\t\t# omegaconf.to_container(config.search_space),\r\n        hyperparameter_space,\r\n\t\tname=\"tune distributed\",\r\n\t\tmax_concurrent=2, \r\n\t\tobservation_budget=n_observations,\r\n\t\tproject=\"tool-ray-integration\",\r\n\t\tmetric=[\"val_loss\"],\r\n\t\tmode=[\"min\"]\r\n\t\t# metric=[\"val_loss\", \"training_loss\"],\r\n\t\t# mode=[\"max\", \"min\"]\r\n\t)\r\n\r\n\ttune_config = {\r\n\t\t# \"config\": config\r\n\t}\r\n\tanalysis = tune.run(\r\n\t\ttrain_model,\r\n\t\tmetric=\"val_loss\",\r\n\t\tmode=\"min\",\r\n\t\tconfig=tune_config,\r\n\t\tnum_samples=n_observations,\r\n\t\tname=\"tune distributed\",\r\n\t\tresources_per_trial={'gpu': 1},\r\n\t\tsearch_alg=tool_search,\r\n\t\t# scheduler=fifoscheduler(),\r\n\t)\r\n\r\n\r\n\r\n\r\ndef train_model(config):\r\n    pass\r\n\r\nmain()\r\n\r\n```\n\n### issue severity\n\nmedium: it is a significant difficulty but i can work around it.",
          "Title: layoutlmv2 training on tool error: undefined value has_torch_function_variadic; Content:### system info\r\n\r\n```shell\r\ntransformer: 4.17.0\r\ntorch: 1.10.2\r\n\r\nplatform: tool deep learning container\r\n```\r\n\r\n\r\n### who can help?\r\n\r\n@nielsrogge\r\n\r\n### information\r\n\r\n- [ ] the official example scripts\r\n- [x] my own modified scripts\r\n\r\n### tasks\r\n\r\n- [ ] an officially supported task in the `examples` folder (such as glue/squad, ...)\r\n- [ ] my own task or dataset (give details below)\r\n\r\n### reproduction\r\n\r\nthe error only comes when training on tool using huggingface.\r\n\r\nscripts to start training on tool:\r\n\r\nfolder organization:\r\n```\r\n./\r\n----sg_training.py\r\n----scripts\r\n-------requirements.txt\r\n-------train.py \r\n```\r\n\r\nsg_training.py:\r\n```\r\nimport boto3\r\nimport tool\r\nfrom tool.huggingface import huggingface\r\n\r\nif __name__ == \"__main__\":\r\n    iam_client = boto3.client(...)\r\n\r\n    role = iam_client.get_role(...)['role']['arn']\r\n    sess = tool.session()\r\n\r\n    tool_session_bucket = 's3-tool-session'\r\n\r\n    hyperparameters = {'epochs': 20,\r\n                       'train_batch_size': 1,\r\n                       'model_name': \"microsoft/layoutxlm-base\",\r\n                       'output_dir': '/opt/ml/model/',\r\n                       'checkpoints': '/opt/ml/checkpoints/',\r\n                       'combine_train_val': true,\r\n                       'exp_tracker': \"all\",\r\n                       'exp_name': 'tool training'\r\n                       }\r\n\r\n    huggingface_estimator = huggingface(entry_point='train.py',\r\n                                        source_dir='scripts',\r\n                                        instance_type='ml.p3.2xlarge',\r\n                                        instance_count=1,\r\n                                        role=role,\r\n                                        transformers_version='4.17.0',\r\n                                        pytorch_version='1.10.2',\r\n                                        py_version='py38',\r\n                                        hyperparameters=hyperparameters,\r\n                                        environment={'hf_task': 'text-classification'},\r\n                                        code_location='s3://dummy_code_location')\r\n\r\n    huggingface_estimator.fit()\r\n```\r\n\r\nentrypoint scripts folder:\r\n\r\n\r\nrequirements.txt:\r\n```\r\ngit+https://github.com/facebookresearch/detectron2.git\r\n```\r\n\r\ntrain.py:\r\n```\r\nimport argparse\r\nimport logging\r\nimport os\r\nimport sys\r\n\r\nfrom transformers import layoutlmv2forsequenceclassification\r\n\r\n\r\ndef run():\r\n    model = layoutlmv2forsequenceclassification.from_pretrained('microsoft/layoutxlm-base',\r\n                                                                num_labels=5)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.argumentparser()\r\n    parser.add_argument(\"--epochs\", type=int, default=3)\r\n    parser.add_argument(\"--exp_name\", type=str, default=\"tool training\")\r\n    parser.add_argument(\"--train-batch-size\", type=int, default=2)\r\n    parser.add_argument(\"--eval-batch-size\", type=int, default=1)\r\n    parser.add_argument(\"--warmup_steps\", type=int, default=500)\r\n    parser.add_argument(\"--model_name\", type=str)\r\n    parser.add_argument(\"--learning_rate\", type=str, default=1e-5)\r\n    parser.add_argument(\"--combine_train_val\", type=bool, default=false)\r\n    # data, model, and output directories\r\n    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ[\"sm_output_data_dir\"])\r\n    parser.add_argument(\"--checkpoints\", type=str, default=\"/opt/ml/checkpoints\")\r\n    parser.add_argument(\"--model-dir\", type=str, default='/opt/ml/code/model')\r\n    parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"sm_num_gpus\"])\r\n    args, _ = parser.parse_known_args()\r\n\r\n    logger = logging.getlogger(__name__)\r\n    logging.basicconfig(\r\n        level=logging.getlevelname(\"info\"),\r\n        handlers=[logging.streamhandler(sys.stdout)],\r\n        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\r\n    )\r\n\r\n    run()\r\n\r\n```\r\n\r\n\r\n### expected behavior\r\n\r\n```shell\r\nhere the log on the error from aws cloud watch:\r\n\r\ninvoking script with the following command:\r\n/opt/conda/bin/python3.8 train.py --checkpoints /opt/ml/checkpoints/ --combine_train_val true --epochs 20 --exp_name tool_training_doc_cls --exp_tracker all --model_name microsoft/layoutxlm-base --output_dir /opt/ml/model/ --train_batch_size 1\r\ntraceback (most recent call last):\r\n  file \"/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\", line 2777, in _get_module\r\nreturn importlib.import_module(\".\" + module_name, self.__name__)\r\n  file \"/opt/conda/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\nreturn _bootstrap._gcd_import(name[level:], package, level)\r\n  file \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\nfile \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\nfile \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\nfile \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\nfile \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\r\n  file \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nfile \"/opt/conda/lib/python3.8/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py\", line 48, in <module>\r\nfrom detectron2.modeling import meta_arch_registry\r\n  file \"/opt/conda/lib/python3.8/site-packages/detectron2/modeling/__init__.py\", line 2, in <module>\r\nfrom detectron2.layers import shapespec\r\n  file \"/opt/conda/lib/python3.8/site-packages/detectron2/layers/__init__.py\", line 2, in <module>\r\nfrom .batch_norm import frozenbatchnorm2d, get_norm, naivesyncbatchnorm, cyclebatchnormlist\r\n  file \"/opt/conda/lib/python3.8/site-packages/detectron2/layers/batch_norm.py\", line 4, in <module>\r\n    from fvcore.nn.distributed import differentiable_all_reduce\r\n  file \"/opt/conda/lib/python3.8/site-packages/fvcore/nn/__init__.py\", line 4, in <module>\r\n    from .focal_loss import (\r\n  file \"/opt/conda/lib/python3.8/site-packages/fvcore/nn/focal_loss.py\", line 52, in <module>\r\n    sigmoid_focal_loss_jit: \"torch.jit.scriptmodule\" = torch.jit.script(sigmoid_focal_loss)\r\n  file \"/opt/conda/lib/python3.8/site-packages/torch/jit/_script.py\", line 1310, in script\r\nfn = torch._c._jit_script_compile(\r\n  file \"/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py\", line 838, in try_compile_fn\r\nreturn torch.jit.script(fn, _rcb=rcb)\r\n  file \"/opt/conda/lib/python3.8/site-packages/torch/jit/_script.py\", line 1310, in script\r\nfn = torch._c._jit_script_compile(\r\nruntimeerror: \r\nundefined value has_torch_function_variadic:\r\n  file \"/opt/conda/lib/python3.8/site-packages/torch/utils/smdebug.py\", line 2962\r\n         >>> loss.backward()\r\n    \"\"\"\r\n    if has_torch_function_variadic(input, target, weight, pos_weight):\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- here\r\n        return handle_torch_function(\r\n            binary_cross_entropy_with_logits,\r\n'binary_cross_entropy_with_logits' is being compiled since it was called from 'sigmoid_focal_loss'\r\n  file \"/opt/conda/lib/python3.8/site-packages/fvcore/nn/focal_loss.py\", line 36\r\n    targets = targets.float()\r\n    p = torch.sigmoid(inputs)\r\n    ce_loss = f.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- here\r\n    p_t = p * targets + (1 - p) * (1 - targets)\r\n    loss = ce_loss * ((1 - p_t) ** gamma)\r\nthe above exception was the direct cause of the following exception:\r\ntraceback (most recent call last):\r\n  file \"train.py\", line 6, in <module>\r\nfrom transformers import layoutlmv2forsequenceclassification\r\n  file \"<frozen importlib._bootstrap>\", line 1039, in _handle_fromlist\r\n  file \"/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\", line 2768, in __getattr__\r\nvalue = getattr(module, name)\r\n  file \"/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\", line 2767, in __getattr__\r\nmodule = self._get_module(self._class_to_module[name])\r\n  file \"/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\", line 2779, in _get_module\r\nraise runtimeerror(\r\nruntimeerror: failed to import transformers.models.layoutlmv2.modeling_layoutlmv2 because of the following error (look up to see its traceback):\r\nundefined value has_torch_function_variadic:\r\n  file \"/opt/conda/lib/python3.8/site-packages/torch/utils/smdebug.py\", line 2962\r\n         >>> loss.backward()\r\n    \"\"\"\r\n    if has_torch_function_variadic(input, target, weight, pos_weight):\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- here\r\n        return handle_torch_function(\r\n            binary_cross_entropy_with_logits,\r\n'binary_cross_entropy_with_logits' is being compiled since it was called from 'sigmoid_focal_loss'\r\n  file \"/opt/conda/lib/python3.8/site-packages/fvcore/nn/focal_loss.py\", line 36\r\n    targets = targets.float()\r\n    p = torch.sigmoid(inputs)\r\n    ce_loss = f.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- here\r\n    p_t = p * targets + (1 - p) * (1 - targets)\r\n    loss = ce_loss * ((1 - p_t) ** gamma)\r\n\r\n```\r\n```\r\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_self_python3_miniconda",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_self_python3_miniconda"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.026877403259277,
          8.911513328552246,
          8.828170776367188,
          9.186511993408203,
          9.53637981414795,
          9.037582397460938,
          9.307282447814941,
          9.183119773864746,
          9.186202049255371,
          9.025322914123535,
          9.095745086669922,
          9.579351425170898,
          9.114337921142578,
          8.117289543151855,
          8.034457206726074,
          9.818899154663086,
          10.220793724060059,
          8.90931510925293,
          9.977166175842285,
          9.447969436645508,
          9.900564193725586,
          9.552940368652344,
          9.24777889251709,
          8.394966125488281,
          9.448307991027832,
          8.482305526733398,
          9.182496070861816,
          9.176060676574707
         ],
         "y": [
          4.281102657318115,
          4.265116214752197,
          3.4967920780181885,
          4.110650539398193,
          4.364480018615723,
          4.025392055511475,
          3.933032989501953,
          3.588618040084839,
          4.156371116638184,
          4.187301158905029,
          3.5912039279937744,
          4.3412322998046875,
          4.3273491859436035,
          3.3504459857940674,
          3.400322914123535,
          3.7077274322509766,
          3.5628128051757812,
          3.920736789703369,
          3.5365536212921143,
          3.8630552291870117,
          3.5185861587524414,
          4.027759552001953,
          3.4849836826324463,
          3.547825813293457,
          3.903992176055908,
          3.5569300651550293,
          4.166332721710205,
          3.8598780632019043
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: tool tool cli is broken if configuration is declared in pyproject.toml; Content:## description\r\n\r\ntool enable to declare configuration either in ``.tool.yml`` or in ``pyproject.toml`` (in the ``[tool.tool]`` section). we cltool to support both, but the cli commands are not accessible if the project contains only a ``pyproject.toml file``.\r\n\r\n## steps to reproduce\r\n\r\ncall ``tool tool init`` inside a project with no ``.tool.yml`` file but only a ``pyproject.toml``.\r\n\r\n## expected result\r\n\r\nthe cli commands should be available (``init``)\r\n\r\n## actual result\r\nonly the ``new`` command is available. this is not considered as a tool project.\r\n\r\n```\r\n-- separate them if you have more than one.\r\n```\r\n\r\n## your environment\r\n\r\n* `tool` and `tool-tool` version used (`pip show tool` and `pip show tool-tool`): tool==16.6, tool-tool==0.4.1\r\n* python version used (`python -v`): 3.7.9\r\n* operating system and version: windows 7\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes\r\n\r\n## solution\r\n\r\nthe error comes from the ``is_tool_project`` function which does not consider that a folder is the root of a kdro project if it does not contain a ``.tool.yml``.",
          "Title: warning message appears when calling ``tool tool init``; Content:the warning cltools that the project is not initialised yet, and that you must call ``tool tool init`` before calling any command while you are calling ``tool tool init``. it can be safely ignored because the command works as intended. this bug is due to the dynamic creation of command.",
          "Title: tool telemetry breaks packaged projects due to wrongly assuming `pyproject.toml` exists; Content:## description\r\ntool telemetry installed alongside a packaged and installed tool project breaks the project by assuming that the `pyproject.toml` file exists. the `pyproject.toml` is only a recipe for building the project and should not be assumed to be existing in the current folder in all cases.\r\n\r\nthe problem was introduced with https://github.com/tool-org/tool-plugins/pull/62\r\n\r\n## context\r\nwhen deploying tool projects and if you have installed tool telemetry, it breaks your project.\r\n\r\n## steps to reproduce\r\n1. create a tool project\r\n2. add a dependency on tool-telemetry\r\n3. package it through `tool package`\r\n4. install it in a different environment\r\n5. run the project through `./<project>` in a folder where only the `conf/` is\r\n\r\n## expected result\r\nthe project should run.\r\n\r\n## actual result\r\nan exception is thrown.\r\n\r\n## your environment\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* tool version used (`pip show tool` or `tool -v`): 0.18.x\r\n* tool plugin and tool plugin version used (`pip show tool-telemetry`): 0.2.2 \r\n* python version used (`python -v`): not relevant\r\n* operating system and version: not relevant\r\n",
          "Title: tool tool ui does not use arguments from tool.yml; Content:## description\r\n\r\nas described in [this stackoverflow question](https://stackoverflow.com/questions/66917129/specify-host-and-port-in-tool-yml-and-run-tool-tool-ui-but-host-and-port), the `ui` command does not use the options\r\n\r\n## context & steps to reproduce\r\n\r\n- create a tool project\r\n- call `tool tool init`\r\n- modify the port in `tool.yml` to 5001\r\n- launch `tool tool ui`\r\n\r\n## expected result\r\n\r\nthe tool ui should open in port 5001.\r\n\r\n## actual result\r\n\r\nit opens on port 5000 (the default).\r\n\r\n## your environment\r\n\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` version: 0.17.0\r\n* `tool-tool` version: 0.6.0\r\n* python version used (`python -v`): 3.6.8\r\n* operating system and version: windows\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes\r\n\r\n## solution\r\n\r\nwe should pass the arguments in the command: \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/477147f6aa2dbf59c67f916b2002dea2de74d1fd/tool_tool/framework/cli/cli.py#l149-l151",
          "Title: tool tool init displays a wrong sucess message when the env folder does not exist; Content:## description\r\n\r\nwhen running ``tool tool init --env=xxx``, a success message is displayed even if the env \"xxx\" folder does not exist, instead of an error message. we should move this code : \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/d31820a7d4ea808d0a4460d41966b762a404b5a5/tool_tool/framework/cli/cli.py#l116-l122\r\n\r\ninside the \"try\" block above.",
          "Title: tool expecting tools folder; Content:when running hyperparameter tuning, tool expects an tools folder - which we don't create. if we stick with the standard we can ommit having to run `tool ui` with the backend store argument.",
          "Title: tool tool cli is broken if configuration is declared in pyproject.toml; Content:## description\r\n\r\ntool enable to declare configuration either in ``.tool.yml`` or in ``pyproject.toml`` (in the ``[tool.tool]`` section). we cltool to support both, but the cli commands are not accessible if the project contains only a ``pyproject.toml file``.\r\n\r\n## steps to reproduce\r\n\r\ncall ``tool tool init`` inside a project with no ``.tool.yml`` file but only a ``pyproject.toml``.\r\n\r\n## expected result\r\n\r\nthe cli commands should be available (``init``)\r\n\r\n## actual result\r\nonly the ``new`` command is available. this is not considered as a tool project.\r\n\r\n```\r\n-- separate them if you have more than one.\r\n```\r\n\r\n## your environment\r\n\r\n* `tool` and `tool-tool` version used (`pip show tool` and `pip show tool-tool`): tool==16.6, tool-tool==0.4.1\r\n* python version used (`python -v`): 3.7.9\r\n* operating system and version: windows 7\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes\r\n\r\n## solution\r\n\r\nthe error comes from the ``is_tool_project`` function which does not consider that a folder is the root of a kdro project if it does not contain a ``.tool.yml``.",
          "Title: tool tool ui gets a filenotfounderror; Content:firstly i'd like to apologize if this is a dummy question.\r\ni'm following the tutorial to get introduced to tool tool,; after running the command \"tool tool init\" i tried to run the command \"tool mlflofw ui\" but i get an error:\r\n\r\ninfo     the 'tool_tracking_uri' key in tool.yml is relative ('server.tool_tracking_uri = tools'). it is converted to a valid uri: 'file:///c:/users/e107338/pycharmprojects/tool/tool-tool-example/tools'                                                   tool_tool_config.py:202\r\n\r\nafter the traceback i get an error: filenotfounderrror\r\n",
          "Title: tool tool ui gets a filenotfounderror; Content:firstly i'd like to apologize if this is a dummy question.\r\ni'm following the tutorial to get introduced to tool tool,; after running the command \"tool tool init\" i tried to run the command \"tool mlflofw ui\" but i get an error:\r\n\r\ninfo     the 'tool_tracking_uri' key in tool.yml is relative ('server.tool_tracking_uri = tools'). it is converted to a valid uri: 'file:///c:/users/e107338/pycharmprojects/tool/tool-tool-example/tools'                                                   tool_tool_config.py:202\r\n\r\nafter the traceback i get an error: filenotfounderrror\r\n",
          "Title: make tool init work when configuration is in pyproject.toml; Content:## description\r\n\r\nsince 0.16.5, tool project can [now be configured with a `pyproject.toml` config file](https://github.com/quantumblacklabs/tool/issues/439) instead of a `.tool.yml` at the root of the projects. this breaks the `tool tool init` command which is only compatible with `.tool.yml` configuration file.\r\n\r\n## context\r\nwe should remove the `_get_project_globals` util function in tooltool and use `tool.framework.context import get_static_project_data` as suggested in #86. **beware: this will break retrocompatibilty and work only with tool>=0.16.5**\r\n\r\n## steps to reproduce\r\n\r\nlaunch `tool tool init` with no `.tool.yml` config file in your project but a valid `pyproject.toml`.\r\n\r\n## expected result\r\nthe tool.yml file should be created\r\n\r\n## actual result\r\nan error is raised.",
          "Title: `toolfilesystem.ls` not working fine with nested directories; Content:https://tool.ai/alvarobartt/resnet-pytorch/runs/39mhvmwp/files/this/is/just/for/testing",
          "Title: tool tool init displays a wrong sucess message when the env folder does not exist; Content:## description\r\n\r\nwhen running ``tool tool init --env=xxx``, a success message is displayed even if the env \"xxx\" folder does not exist, instead of an error message. we should move this code : \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/d31820a7d4ea808d0a4460d41966b762a404b5a5/tool_tool/framework/cli/cli.py#l116-l122\r\n\r\ninside the \"try\" block above.",
          "Title: tool tool ui does not use arguments from tool.yml; Content:## description\r\n\r\nas described in [this stackoverflow question](https://stackoverflow.com/questions/66917129/specify-host-and-port-in-tool-yml-and-run-tool-tool-ui-but-host-and-port), the `ui` command does not use the options\r\n\r\n## context & steps to reproduce\r\n\r\n- create a tool project\r\n- call `tool tool init`\r\n- modify the port in `tool.yml` to 5001\r\n- launch `tool tool ui`\r\n\r\n## expected result\r\n\r\nthe tool ui should open in port 5001.\r\n\r\n## actual result\r\n\r\nit opens on port 5000 (the default).\r\n\r\n## your environment\r\n\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` version: 0.17.0\r\n* `tool-tool` version: 0.6.0\r\n* python version used (`python -v`): 3.6.8\r\n* operating system and version: windows\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes\r\n\r\n## solution\r\n\r\nwe should pass the arguments in the command: \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/477147f6aa2dbf59c67f916b2002dea2de74d1fd/tool_tool/framework/cli/cli.py#l149-l151",
          "Title: get_tool_config use the working directory instead of given path when called within load_context; Content:this may lead to strange behaviour when called in interactive mode in another place thant the tool project root.",
          "Title: setting the tool experiment does not work in interactive mode; Content:## description\r\n\r\nif i specify an experiment in `tool.yml`, and the set up the tool configuration interactively, all runs should be stored by default in this experiment while they are currently sotred in tool \"default\" (0) experiment. this works when running \"tool run\" through the cli.\r\n\r\n## steps to reproduce\r\n\r\n```yaml\r\n# tool.yml\r\nexperiment:\r\n  name: my_awesome_experiment\r\n  create: true  # if the specified `name` does not exists, should it be created?\r\n```\r\n\r\n```python\r\n# test.py\r\n\r\nfrom tool.framework.session import toolsession\r\nfrom tool.framework.startup import bootstrap_project\r\nfrom tool_tool.config import get_tool_config\r\n\r\nbootstrap_project(r\"path/to/project\")\r\nwith toolsession.create(project_path=r\"path/to/project\"):\r\n    config=get_tool_config()\r\n    config.setup()\r\n    \r\n    tool.log_param(\"test_param\",1) # this should be logged in \"my_awesome_experiment\" but is logged in \"default\".\r\n\r\n```\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes\r\n\r\n## potential solution\r\n\r\nthe faulty line is: \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/904207ad505b71391d78d8088aaed151ca6a011d/tool_tool/config/tool_tool_config.py#l100\r\n\r\n[we should use tool ``tool.set_experiment`` method](https://www.tool.org/docs/latest/python_api/tool.html#tool.set_experiment), but it does not restore deleted experiment. this wil replace part of the logic here: \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/904207ad505b71391d78d8088aaed151ca6a011d/tool_tool/config/tool_tool_config.py#l124-l132",
          "Title: [bug] tool ui never runs; Content:**describe the bug**\r\ngetting error \"filenotfounderror: [winerror 2] the system cannot find the file specified\" while running \"tool ui\".\r\n\r\n**to reproduce**\r\nrun \"tool ui\"\r\n\r\n\r\n**expected behavior**\r\nit should run without any issues\r\n\r\n\r\n**versions**\r\n2.3.10\r\n\r\nnot sure if this is the right forum to post this issue. if it is not, please ignore.\r\n<!-- thanks for contributing! -->\r\n",
          "Title: tool.yml is not parsed properly when using templatedconfigloader; Content:when you have a global variable in the tool.yml file (e.g `tools: ${user}/tools`), the global variable is not replaced by its value even if the user has [registered a templatedconfigloader](https://tool.readthedocs.io/en/stable/tool.config.templatedconfigloader.html) in his project. this is due to `get_tool_config()` to manually recreate the default configloader.\r\n\r\nthis is part of the numerous issues that will  be fixed by #66.\r\n\r\n",
          "Title: tool servername and url not found by calling \"tool-cc run\"; Content:**describe the bug**\r\nif the tool/config file is created with whitespaces tool-cc cann't read the config file.\r\n\r\n**to reproduce**\r\ncreate a tool/config file like this:\r\n`[core]\r\n    remote = tool_connection\r\n['remote \"tool_connection\"']\r\n    url = ...............\r\n    ask_password = true\r\n\r\n**additional context**\r\n> tool -v 0.87.0\r\n> faice -v 9.1.0\r\n> tool-cc -v 0.8.66\r\n",
          "Title: warning message appears when calling ``tool tool init``; Content:the warning cltools that the project is not initialised yet, and that you must call ``tool tool init`` before calling any command while you are calling ``tool tool init``. it can be safely ignored because the command works as intended. this bug is due to the dynamic creation of command.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_init_yml_port",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_init_yml_port"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.637500762939453,
          5.972630500793457,
          5.6519598960876465,
          5.538919448852539,
          5.841482639312744,
          5.6660284996032715,
          5.686216354370117,
          5.621454238891602,
          5.628669738769531,
          5.581066131591797,
          5.650360107421875,
          5.933506488800049,
          5.5473408699035645,
          5.605677127838135,
          5.574489593505859,
          5.557853698730469,
          5.611335754394531,
          5.678969383239746,
          5.916206359863281,
          5.679035186767578
         ],
         "y": [
          5.7019124031066895,
          5.885717391967773,
          5.73646879196167,
          5.137250900268555,
          5.784873008728027,
          5.129388809204102,
          5.671916961669922,
          4.957657814025879,
          4.996623516082764,
          5.612915992736816,
          4.9143805503845215,
          5.863972187042236,
          5.136463165283203,
          5.5612406730651855,
          5.1744279861450195,
          4.987677097320557,
          5.584358215332031,
          5.299420356750488,
          5.855462551116943,
          5.420638084411621
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: [bug]: tool + s3 artifact store fails trying to create a new bucket; Content:### contact details [optional]\n\n_no response_\n\n### system information\n\nzenml == 0.10.0\n\n### what happened?\n\nzenml is trying to create a s3 bucket and fails due to incorrect regex in its name.\n\n### reproduction steps\n\n1. create a tool pipeline.\r\n2. create a s3 artifact store.\r\n3. run the pipeline\r\n\n\n### relevant log output\n\n```shell\ncreating run for pipeline: mnist_pipeline\r\ncache enabled for pipeline mnist_pipeline\r\nusing stack tool_stack to run pipeline mnist_pipeline...\r\nstep importer has started.\r\nusing cached version of importer.\r\nstep importer has finished in 0.045s.\r\nstep trainer has started.\r\ninfo:botocore.credentials:found credentials in shared credentials file: ~/.aws/credentials\r\n┌───────────────────── traceback (most recent call last) ─────────────────────┐\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\s3fs\\ │\r\n│ core.py:752 in _mkdir                                                       │\r\n│                                                                             │\r\n│    749 │   │   │   │   │   params[\"createbucketconfiguration\"] = {          │\r\n│    750 │   │   │   │   │   │   \"locationconstraint\": region_name            │\r\n│    751 │   │   │   │   │   }                                                │\r\n│ >  752 │   │   │   │   await self._call_s3(\"create_bucket\", **params)       │\r\n│    753 │   │   │   │   self.invalidate_cache(\"\")                            │\r\n│    754 │   │   │   │   self.invalidate_cache(bucket)                        │\r\n│    755 │   │   │   except clienterror as e:                                 │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\s3fs\\ │\r\n│ core.py:302 in _call_s3                                                     │\r\n│                                                                             │\r\n│    299 │   │   │   except exception as e:                                   │\r\n│    300 │   │   │   │   err = e                                              │\r\n│    301 │   │   err = translate_boto_error(err)                              │\r\n│ >  302 │   │   raise err                                                    │\r\n│    303 │                                                                    │\r\n│    304 │   call_s3 = sync_wrapper(_call_s3)                                 │\r\n│    305                                                                      │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\s3fs\\ │\r\n│ core.py:282 in _call_s3                                                     │\r\n│                                                                             │\r\n│    279 │   │   additional_kwargs = self._get_s3_method_kwargs(method, *akwa │\r\n│    280 │   │   for i in range(self.retries):                                │\r\n│    281 │   │   │   try:                                                     │\r\n│ >  282 │   │   │   │   out = await method(**additional_kwargs)              │\r\n│    283 │   │   │   │   return out                                           │\r\n│    284 │   │   │   except s3_retryable_errors as e:                         │\r\n│    285 │   │   │   │   logger.debug(\"retryable error: %s\", e)               │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\aiobo │\r\n│ tocore\\client.py:198 in _make_api_call                                      │\r\n│                                                                             │\r\n│   195 │   │   │   'has_streaming_input': operation_model.has_streaming_inpu │\r\n│   196 │   │   │   'auth_type': operation_model.auth_type,                   │\r\n│   197 │   │   }                                                             │\r\n│ > 198 │   │   request_dict = await self._convert_to_request_dict(           │\r\n│   199 │   │   │   api_params, operation_model, context=request_context)     │\r\n│   200 │   │   resolve_checksum_context(request_dict, operation_model, api_p │\r\n│   201                                                                       │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\aiobo │\r\n│ tocore\\client.py:246 in _convert_to_request_dict                            │\r\n│                                                                             │\r\n│   243 │                                                                     │\r\n│   244 │   async def _convert_to_request_dict(self, api_params, operation_mo │\r\n│   245 │   │   │   │   │   │   │   │   │      context=none):                 │\r\n│ > 246 │   │   api_params = await self._emit_api_params(                     │\r\n│   247 │   │   │   api_params, operation_model, context)                     │\r\n│   248 │   │   request_dict = self._serializer.serialize_to_request(         │\r\n│   249 │   │   │   api_params, operation_model)                              │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\aiobo │\r\n│ tocore\\client.py:275 in _emit_api_params                                    │\r\n│                                                                             │\r\n│   272 │   │                                                                 │\r\n│   273 │   │   event_name = (                                                │\r\n│   274 │   │   │   'before-parameter-build.{service_id}.{operation_name}')   │\r\n│ > 275 │   │   await self.meta.events.emit(                                  │\r\n│   276 │   │   │   event_name.format(                                        │\r\n│   277 │   │   │   │   service_id=service_id,                                │\r\n│   278 │   │   │   │   operation_name=operation_name),                       │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\aiobo │\r\n│ tocore\\hooks.py:29 in _emit                                                 │\r\n│                                                                             │\r\n│   26 │   │   │   if asyncio.iscoroutinefunction(handler):                   │\r\n│   27 │   │   │   │   response = await handler(**kwargs)                     │\r\n│   28 │   │   │   else:                                                      │\r\n│ > 29 │   │   │   │   response = handler(**kwargs)                           │\r\n│   30 │   │   │                                                              │\r\n│   31 │   │   │   responses.append((handler, response))                      │\r\n│   32 │   │   │   if stop_on_response and response is not none:              │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\botoc │\r\n│ ore\\handlers.py:243 in validate_bucket_name                                 │\r\n│                                                                             │\r\n│    240 │   │   │   'invalid bucket name \"%s\": bucket name must match '      │\r\n│    241 │   │   │   'the regex \"%s\" or be an arn matching the regex \"%s\"' %  │\r\n│    242 │   │   │   │   bucket, valid_bucket.pattern, valid_s3_arn.pattern)) │\r\n│ >  243 │   │   raise paramvalidationerror(report=error_msg)                 │\r\n│    244                                                                      │\r\n│    245                                                                      │\r\n│    246 def sse_md5(params, **kwargs):                                       │\r\n└─────────────────────────────────────────────────────────────────────────────┘\r\nparamvalidationerror: parameter validation failed:\r\ninvalid bucket name \"zenml-training\\trainer\\.system\\executor_execution\\24\": \r\nbucket name must match the regex \"^[a-za-z0-9.\\-_]{1,255}$\" or be an arn \r\nmatching the regex \r\n\"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]*:[0-9]{12}:accesspoint[/:][a-za-\r\nz0-9\\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[/:][a-za\r\n-z0-9\\-]{1,63}[/:]accesspoint[/:][a-za-z0-9\\-]{1,63}$\"\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\n┌───────────────────── traceback (most recent call last) ─────────────────────┐\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\run-tool.py:87 in       │\r\n│ <module>                                                                    │\r\n│                                                                             │\r\n│   84 │   │   trainer=trainer(),                                             │\r\n│   85 │   │   evaluator=evaluator(),                                         │\r\n│   86 │   )                                                                  │\r\n│ > 87 │   pipeline.run()                                                     │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\pipelines\\base_pipeline.py:489 in run                                      │\r\n│                                                                             │\r\n│   486 │   │   self._reset_step_flags()                                      │\r\n│   487 │   │   self.validate_stack(stack)                                    │\r\n│   488 │   │                                                                 │\r\n│ > 489 │   │   return stack.deploy_pipeline(                                 │\r\n│   490 │   │   │   self, runtime_configuration=runtime_configuration         │\r\n│   491 │   │   )                                                             │\r\n│   492                                                                       │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\stack\\stack.py:595 in deploy_pipeline                                      │\r\n│                                                                             │\r\n│   592 │   │   │   pipeline=pipeline, runtime_configuration=runtime_configur │\r\n│   593 │   │   )                                                             │\r\n│   594 │   │                                                                 │\r\n│ > 595 │   │   return_value = self.orchestrator.run(                         │\r\n│   596 │   │   │   pipeline, stack=self, runtime_configuration=runtime_confi │\r\n│   597 │   │   )                                                             │\r\n│   598                                                                       │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\orchestrators\\base_orchestrator.py:212 in run                              │\r\n│                                                                             │\r\n│   209 │   │   │   pipeline=pipeline, pb2_pipeline=pb2_pipeline              │\r\n│   210 │   │   )                                                             │\r\n│   211 │   │                                                                 │\r\n│ > 212 │   │   result = self.prepare_or_run_pipeline(                        │\r\n│   213 │   │   │   sorted_steps=sorted_steps,                                │\r\n│   214 │   │   │   pipeline=pipeline,                                        │\r\n│   215 │   │   │   pb2_pipeline=pb2_pipeline,                                │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\orchestrators\\local\\local_orchestrator.py:68 in prepare_or_run_pipeline    │\r\n│                                                                             │\r\n│   65 │   │                                                                  │\r\n│   66 │   │   # run each step                                                │\r\n│   67 │   │   for step in sorted_steps:                                      │\r\n│ > 68 │   │   │   self.run_step(                                             │\r\n│   69 │   │   │   │   step=step,                                             │\r\n│   70 │   │   │   │   run_name=runtime_configuration.run_name,               │\r\n│   71 │   │   │   │   pb2_pipeline=pb2_pipeline,                             │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\orchestrators\\base_orchestrator.py:316 in run_step                         │\r\n│                                                                             │\r\n│   313 │   │   # this is where the step actually gets executed using the     │\r\n│   314 │   │   # component_launcher                                          │\r\n│   315 │   │   repo.active_stack.prepare_step_run()                          │\r\n│ > 316 │   │   execution_info = self._execute_step(component_launcher)       │\r\n│   317 │   │   repo.active_stack.cleanup_step_run()                          │\r\n│   318 │   │                                                                 │\r\n│   319 │   │   return execution_info                                         │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\orchestrators\\base_orchestrator.py:340 in _execute_step                    │\r\n│                                                                             │\r\n│   337 │   │   start_time = time.time()                                      │\r\n│   338 │   │   logger.info(f\"step `{pipeline_step_name}` has started.\")      │\r\n│   339 │   │   try:                                                          │\r\n│ > 340 │   │   │   execution_info = tfx_launcher.launch()                    │\r\n│   341 │   │   │   if execution_info and get_cache_status(execution_info):   │\r\n│   342 │   │   │   │   logger.info(f\"using cached version of `{pipeline_step │\r\n│   343 │   │   except runtimeerror as e:                                     │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\tfx\\o │\r\n│ rchestration\\portable\\launcher.py:528 in launch                             │\r\n│                                                                             │\r\n│   525 │   │   │   │   │   │   │   │   │   │      self._pipeline_runtime_spe │\r\n│   526 │                                                                     │\r\n│   527 │   # runs as a normal node.                                          │\r\n│ > 528 │   execution_preparation_result = self._prepare_execution()          │\r\n│   529 │   (execution_info, contexts,                                        │\r\n│   530 │    is_execution_needed) = (execution_preparation_result.execution_i │\r\n│   531 │   │   │   │   │   │   │    execution_preparation_result.contexts,   │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\tfx\\o │\r\n│ rchestration\\portable\\launcher.py:388 in _prepare_execution                 │\r\n│                                                                             │\r\n│   385 │   │   │     output_dict=output_artifacts,                           │\r\n│   386 │   │   │     exec_properties=exec_properties,                        │\r\n│   387 │   │   │     execution_output_uri=(                                  │\r\n│ > 388 │   │   │   │     self._output_resolver.get_executor_output_uri(execu │\r\n│   389 │   │   │     stateful_working_dir=(                                  │\r\n│   390 │   │   │   │     self._output_resolver.get_stateful_working_director │\r\n│   391 │   │   │     tmp_dir=self._output_resolver.make_tmp_dir(execution.id │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\tfx\\o │\r\n│ rchestration\\portable\\outputs_utils.py:172 in get_executor_output_uri       │\r\n│                                                                             │\r\n│   169 │   \"\"\"generates executor output uri given execution_id.\"\"\"           │\r\n│   170 │   execution_dir = os.path.join(self._node_dir, _system, _executor_e │\r\n│   171 │   │   │   │   │   │   │   │    str(execution_id))                   │\r\n│ > 172 │   fileio.makedirs(execution_dir)                                    │\r\n│   173 │   return os.path.join(execution_dir, _executor_output_file)         │\r\n│   174                                                                       │\r\n│   175   def get_driver_output_uri(self) -> str:                             │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\tfx\\d │\r\n│ sl\\io\\fileio.py:80 in makedirs                                              │\r\n│                                                                             │\r\n│    77                                                                       │\r\n│    78 def makedirs(path: pathtype) -> none:                                 │\r\n│    79   \"\"\"make a directory at the given path, recursively creating parents │\r\n│ >  80   _get_filesystem(path).makedirs(path)                                │\r\n│    81                                                                       │\r\n│    82                                                                       │\r\n│    83 def mkdir(path: pathtype) -> none:                                    │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\zenml │\r\n│ \\integrations\\s3\\artifact_stores\\s3_artifact_store.py:275 in makedirs       │\r\n│                                                                             │\r\n│   272 │   │   args:                                                         │\r\n│   273 │   │   │   path: the path to create.                                 │\r\n│   274 │   │   \"\"\"                                                           │\r\n│ > 275 │   │   self.filesystem.makedirs(path=path, exist_ok=true)            │\r\n│   276 │                                                                     │\r\n│   277 │   def mkdir(self, path: pathtype) -> none:                          │\r\n│   278 │   │   \"\"\"create a directory at the given path.                      │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\fsspe │\r\n│ c\\asyn.py:85 in wrapper                                                     │\r\n│                                                                             │\r\n│    82 │   @functools.wraps(func)                                            │\r\n│    83 │   def wrapper(*args, **kwargs):                                     │\r\n│    84 │   │   self = obj or args[0]                                         │\r\n│ >  85 │   │   return sync(self.loop, func, *args, **kwargs)                 │\r\n│    86 │                                                                     │\r\n│    87 │   return wrapper                                                    │\r\n│    88                                                                       │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\fsspe │\r\n│ c\\asyn.py:65 in sync                                                        │\r\n│                                                                             │\r\n│    62 │   │   # suppress asyncio.timeouterror, raise fstimeouterror         │\r\n│    63 │   │   raise fstimeouterror from return_result                       │\r\n│    64 │   elif isinstance(return_result, baseexception):                    │\r\n│ >  65 │   │   raise return_result                                           │\r\n│    66 │   else:                                                             │\r\n│    67 │   │   return return_result                                          │\r\n│    68                                                                       │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\fsspe │\r\n│ c\\asyn.py:25 in _runner                                                     │\r\n│                                                                             │\r\n│    22 │   if timeout is not none:                                           │\r\n│    23 │   │   coro = asyncio.wait_for(coro, timeout=timeout)                │\r\n│    24 │   try:                                                              │\r\n│ >  25 │   │   result[0] = await coro                                        │\r\n│    26 │   except exception as ex:                                           │\r\n│    27 │   │   result[0] = ex                                                │\r\n│    28 │   finally:                                                          │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\s3fs\\ │\r\n│ core.py:767 in _makedirs                                                    │\r\n│                                                                             │\r\n│    764 │                                                                    │\r\n│    765 │   async def _makedirs(self, path, exist_ok=false):                 │\r\n│    766 │   │   try:                                                         │\r\n│ >  767 │   │   │   await self._mkdir(path, create_parents=true)             │\r\n│    768 │   │   except fileexistserror:                                      │\r\n│    769 │   │   │   if exist_ok:                                             │\r\n│    770 │   │   │   │   pass                                                 │\r\n│                                                                             │\r\n│ c:\\users\\i25262\\pycharmprojects\\zenml-kubeflow\\venv\\lib\\site-packages\\s3fs\\ │\r\n│ core.py:758 in _mkdir                                                       │\r\n│                                                                             │\r\n│    755 │   │   │   except clienterror as e:                                 │\r\n│    756 │   │   │   │   raise translate_boto_error(e)                        │\r\n│    757 │   │   │   except paramvalidationerror as e:                        │\r\n│ >  758 │   │   │   │   raise valueerror(\"bucket create failed %r: %s\" % (bu │\r\n│    759 │   │   else:                                                        │\r\n│    760 │   │   │   # raises if bucket doesn't exist and doesn't get create  │\r\n│    761 │   │   │   await self._ls(bucket)                                   │\r\n└─────────────────────────────────────────────────────────────────────────────┘\r\nvalueerror: bucket create failed \r\n'zenml-training\\\\trainer\\\\.system\\\\executor_execution\\\\24': parameter \r\nvalidation failed:\r\ninvalid bucket name \"zenml-training\\trainer\\.system\\executor_execution\\24\": \r\nbucket name must match the regex \"^[a-za-z0-9.\\-_]{1,255}$\" or be an arn \r\nmatching the regex \r\n\"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]*:[0-9]{12}:accesspoint[/:][a-za-\r\nz0-9\\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[/:][a-za\r\n-z0-9\\-]{1,63}[/:]accesspoint[/:][a-za-z0-9\\-]{1,63}$\"\n```\n\n\n### code of conduct\n\n- [x] i agree to follow this project's code of conduct",
          "Title: [bug] tool autostop script not pulling from s3 bucket; Content:**describe the bug**\r\nwe encountered an interesting issue regarding the auto stop script. we had no code changes, but suddenly, tool instances started hanging around for days, with no use. looking into the instance, the cron job was failing, because the autostop.py script had a syntax error. when i look at the script, it has this line `print(f'notebook idle state set as {idle} because no kernel has been detected.')` which caused the syntax error. however, the file on the repo, as well as the s3 bucket, does not contain this line. so, after some digging, i found that this line was introduced here, in this commit [aws-samples/amazon-tool-notebook-instance-lifecycle-config-samples/](https://github.com/aws-samples/amazon-tool-notebook-instance-lifecycle-config-samples/commit/fdace58a6b9401c53dc17f5c64bef3ec40dbc70e). what i don't understand is how it got into the tool notebook, and why it's not being overridden by the custom config start we have here [tool-notebook-instance.cfn.yml](https://github.com/awslabs/service-workbench-on-aws/blob/mainline/addons/addon-base-raas/packages/base-raas-cfn-templates/src/templates/service-catalog/tool-notebook-instance.cfn.yml#l264-l272) this script and repo was updated in the last 16 hours to remove this syntax error.\r\n\r\n**to reproduce**\r\nlaunch a tool instance. you can tell which version of the script it's using by looking at the autostop script, `less /usr/local/bin/autostop.py` and find lines 96-101.\r\n\r\nthe aws version of the script on the `awslabs/service-workbench-on-aws` repo has these lines, [reference](https://github.com/awslabs/service-workbench-on-aws/blob/mainline/main/solution/post-deployment/config/environment-files/offline-packages/tool/autostop.py#l96-l100)\r\n```\r\nif notebook['kernel']['connections'] == 0:\r\n    if not is_idle(notebook['kernel']['last_activity']):\r\n        idle = false\r\nelse:\r\n    idle = false\r\n```\r\nand on the `aws-samples/amazon-tool-notebook-instance-lifecycle-config-samples` repo, [reference](https://github.com/aws-samples/amazon-tool-notebook-instance-lifecycle-config-samples/blob/master/scripts/auto-stop-idle/autostop.py#l96-l101)\r\n```\r\nif notebook['kernel']['connections'] == 0:\r\n    if not is_idle(notebook['kernel']['last_activity']):\r\n        idle = false\r\nelse:\r\n    idle = false\r\n    print('notebook idle state set as %s because no kernel has been detected.' % idle)\r\n```\r\n\r\n**expected behavior**\r\nthe autostop script in the s3 bucket should be the one used for swb tool instances.\r\n\r\n**screenshots**\r\n<img width=\"1510\" alt=\"screen shot 2022-11-16 at 12 14 21 pm\" src=\"https://user-images.githubusercontent.com/21109191/202251401-67da0253-e74e-40e9-8150-99a4a27017ff.png\">\r\n\r\n**versions (please complete the following information):**\r\n - swb 4.3.1\r\n",
          "Title: make one-click-tool not working after make destroy because of undeleted bucket; Content:**describe the bug**\r\nproblem encountered by @ucsky. running ```make one-click-tool``` is not working after ```make destroy``` because of the artifacts' bucket which still exists.\r\ngot the following error:\r\n````\r\n\r\nsetting up your gcp project...\r\n╷\r\n│ error: googleapi: error 409: you already own this bucket. please select another name., conflict\r\n│ \r\n│   with module.bucket_backend.google_storage_bucket.this,\r\n│   on ../modules/tool/artifacts/main.tf line 18, in resource \"google_storage_bucket\" \"this\":\r\n│   18: resource \"google_storage_bucket\" \"this\" {\r\n\r\n````\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. run ```make one-click-tool``` and finish it\r\n2. run ```make destroy```\r\n3. run ```make one-click-tool```\r\n4. see error\r\n\r\n**expected behavior**\r\nthe second command ```make one-click-tool``` should work \r\n\r\n",
          "Title: configuration options not being set correctly when using cn region tool endpoint as host; Content:**describe the bug**\r\nthere are several areas in the code where we have an explicit check for the `tool.amazonaws.com` dns suffix; this is used to determine if we need to use tool-specific configuration options and request uri elements. \r\n\r\nhowever, these checks misidentify endpoints of tool clusters in aws cn regions, which use the `tool.<region>.amazonaws.com.cn` dns suffix instead, as non-aws endpoints. as a result, required config options such as `auth_mode` and `region` are not set correctly.\r\n\r\nall of the following checks need to be changed to \"amazonaws.com\":\r\nhttps://github.com/aws/graph-notebook/blob/a5818452d152ba51b7f7e26b6cf8e188dca54693/src/graph_notebook/magics/graph_magic.py#l160\r\nhttps://github.com/aws/graph-notebook/blob/a5818452d152ba51b7f7e26b6cf8e188dca54693/src/graph_notebook/tool/client.py#l129\r\nhttps://github.com/aws/graph-notebook/blob/a5818452d152ba51b7f7e26b6cf8e188dca54693/src/graph_notebook/configuration/generate_config.py#l54\r\nhttps://github.com/aws/graph-notebook/blob/68e888def530be70e08b5250c8146292fb49cfa1/src/graph_notebook/configuration/get_config.py#l14",
          "Title: [bug] no documentation on how to connect local notebook to remote tool ssl; Content:**ssl connection to remote tool not working**\r\ni am unable to figure out how can i specify the correct certificate sfsrootcag2.pem when running queries against ssl-enabled tool.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. i set up ssh tunnel via bastion to the tool cluster '_ssh -i keypairfilename.pem ec2-user@yourec2instanceendpoint -n -l 8182:yourtoolendpoint:8182_'\r\n2. i start graph-notebook as '_jupyter notebook notebook/destination_tool_'. this gives me the output _jupyter notebook 6.1.5 is running at: http://localhost:8888/?token=13b2761a59217f9246aed1dab73e70c3ae42973c4339f328_\r\n3. i open my notebook and run the following magic commands \r\n_'%%graph_notebook_config\r\n{\r\n  \"host\": \"localhost\",\r\n  \"port\": 8182,\r\n  \"auth_mode\": \"default\",\r\n  \"iam_credentials_provider_type\": \"role\",\r\n  \"load_from_s3_arn\": \"\",\r\n  \"aws_region\": <myregion>,\r\n  **\"ssl\": true**\r\n}'_\r\n4. i run the command \r\n_%%sparql        \r\nselect * where {?s ?p ?o} limit 1_\r\n\r\n5. it gives me the error\r\n**{'error': sslerror(maxretryerror('httpsconnectionpool(host=\\'localhost\\', port=8182): max retries exceeded with url: /sparql (caused by sslerror(sslcertverificationerror(\"hostname \\'localhost\\' doesn\\'t match either of \\'*.............**\r\n\r\n**expected behavior**\r\ni expect to be able to connect to a remote tool that has ssl enabled.\r\n\r\n**screenshots**\r\nnone\r\n\r\n**desktop (please complete the following information):**\r\n - macos 10.15.7 catalina\r\n - browser chrome\r\n - version 86.0.4240.198 (official build) (x86_64)\r\n\r\n**additional context**\r\nadd any other context about the problem here.none",
          "Title: [bug] missing documentation on connecting to tool from macos; Content:**describe the bug**\r\nthere are some missing details for how to connect to tool from a macos device, we should add them to our doc on connecting to tool via ssh-tunnel found [here](https://github.com/aws/graph-notebook/tree/main/additional-databases/tool)\r\n\r\none main piece that we are missing is that a host alias needs to be made in order to get things working properly.\r\n\r\n**additional context**\r\nthis is coming from a bug report from connectivity not working as found in #40 ",
          "Title: [bug] study fail to mount in swb 5.2.6 tool jupyter notebook; Content:**describe the bug**\r\nswb 5.2.6 version - tool jupyter notebook workspace can not mount a study.  see error in /var/log/message\r\n/usr/local/bin/goofys[7248]: main.fatal mounting file system: mount: mount: running fusermount: exec: \"fusermount\": executable file not found in $path#012#012stderr:\r\n\r\nlooks like the fuse package failed to install during on-start.  if run \"sudo yum install fuse\" then you can run /usr/local./share/workspace-environment/bin/mount_sh.sh /usr/local/etc/s3-mounts.json to mount the study. \r\n\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. go to '...'\r\n2. click on '....'\r\n3. scroll down to '....'\r\n4. see error\r\n\r\n**expected behavior**\r\na clear and concise description of what you expected to happen.\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n**versions (please complete the following information):**\r\n - release version installed [e.g. v1.0.3]\r\n - is the deployment from a forked version of the repository?\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: tool custom training job error: unable to locate botocore.credentials; Content:### what steps did you take:\r\ni run a custom image using the tool training operator (https://raw.githubusercontent.com/kubeflow/pipelines/master/components/aws/tool/train/component.yaml) and it ran fine. i am using `kfp.aws.use_aws_secret` and the objects from s3 are being correctly copied over to the specified local channel path.\r\n\r\nthe problem arises however if inside the custom script i use boto3 to manually download an object from s3 - then i get an error: unable to locate credentials ...  \r\n\r\n### what happened:\r\nbelow is a copy of the component's logs - notice the very first log statement says that the boto credentials are found in environment variables ... but somehow they never make their way to the boto3 client that is instantiated inside the custom image \r\n\r\n```\r\ninfo:botocore.credentials:found credentials in environment variables.\r\ninfo:root:submitting training job to tool...\r\ninfo:root:created training job with name: trainingjob-20200430232331-lphy\r\ninfo:root:training job in tool: \r\nhttps://us-west-2.console.aws.amazon.com/tool/home?region=us-west-2#/jobs/trainingjob-20200430232331-lphy\r\ninfo:root:cloudwatch logs: \r\nhttps://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logstream:group=/aws/tool/trainingjobs;prefix=trainingjob-20200430232331-lphy;streamfilter=typelogstreamprefix\r\ninfo:root:job request submitted. waiting for completion...\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training job is still in status: inprogress\r\ninfo:root:training failed with the following error: algorithmerror: exception during training: unable to locate credentials\r\ntraceback (most recent call last):\r\n  file \"main.py\", line 174, in main\r\n    preprocessor_path = get_local_path(params[\"preprocessor_path\"])\r\n  file \"main.py\", line 86, in get_local_path\r\n    for s3_object in s3_bucket.objects.all():\r\n  file \"/opt/conda/lib/python3.7/site-packages/boto3/resources/collection.py\", line 83, in __iter__\r\n    for page in self.pages():\r\n  file \"/opt/conda/lib/python3.7/site-packages/boto3/resources/collection.py\", line 166, in pages\r\n    for page in pages:\r\n  file \"/opt/conda/lib/python3.7/site-packages/botocore/paginate.py\", line 255, in __iter__\r\n    response = self._make_request(current_kwargs)\r\n  file \"/opt/conda/lib/python3.7/site-packages/botocore/paginate.py\", line 332, in _make_request\r\n    return self._method(**current_kwargs)\r\n  file \"/opt/conda/lib/python3.7/site-packages/botocore/client.py\", line 316, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  file \"/opt/conda/lib/python3.7/site-packag\r\ntraceback (most recent call last):\r\n  file \"train.py\", line 81, in <module>\r\n    main()\r\n  file \"train.py\", line 64, in main\r\n    _utils.wait_for_training_job(client, job_name)\r\n  file \"/app/common/_utils.py\", line 185, in wait_for_training_job\r\n    raise exception('training job failed')\r\nexception: training job failed\r\n```\r\n\r\n### what did you expect to happen:\r\ni would have expected the credentials to be passed to the image that the training operator is running but it is not the case ...\r\n\r\n### environment:\r\nhow did you deploy kubeflow pipelines (kfp)?\r\ni deployed kubeflow pipelines as part of my kubeflow deployment on aws eks:\r\n\r\nkfp version: \r\nbuild commit: 743746b\r\n\r\nkfp sdk version:\r\n0.5.0\r\n\r\n/kind bug\r\n<!--\r\n// /area frontend\r\n /area backend\r\n /area sdk\r\n// /area testing\r\n// /area engprod\r\n-->\r\n",
          "Title: [bug] swb tool study permission denied; Content:we encountered an issue where an older tool instance (>2 months) was turned on. after starting, one of the two study folders associated were not syncing any of the files. in the system logs there's this error: `nov 11 16:21:45 <ip redacted> /usr/local/bin/goofys[9204]: main.error unable to access '<bucket a, name redacted>': permission denied`\r\n\r\ncomparing the s3mounts parameter for the tool stack of the older instance that fails to sync, and a newer instance (with the same studies), i see that the fs role number for the private workspace study that wouldn't sync is different.\r\n\r\nold stack s3mounts parameter:\r\n```\r\n[\r\n  {\r\n    \"id\": \"private-workspace\",\r\n    \"bucket\": \"<bucket a, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"rolearn\": \"arn:aws:iam::<account redacted>:role/swb-lhdhyiaqchc0a4vrlu256w-fs-1662735997814\",\r\n    \"prefix\": \"private-workspace/\",\r\n    \"readable\": true,\r\n    \"writeable\": true\r\n  },\r\n  {\r\n    \"id\": \"read-only\",\r\n    \"bucket\": \"<bucket a, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"rolearn\": \"arn:aws:iam::<account redacted>:role/swb-lhdhyiaqchc0a4vrlu256w-fs-1661808852807\",\r\n    \"prefix\": \"read-only/\",\r\n    \"readable\": true,\r\n    \"writeable\": false\r\n  }\r\n]\r\n```\r\n\r\nnew stack s3mounts parameter:\r\n```\r\n[\r\n  {\r\n    \"id\": \"private-workspace\",\r\n    \"bucket\": \"<bucket a, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"rolearn\": \"arn:aws:iam::<account redacted>:role/swb-lhdhyiaqchc0a4vrlu256w-fs-1668521384862\",\r\n    \"prefix\": \"private-workspace/\",\r\n    \"readable\": true,\r\n    \"writeable\": true\r\n  },\r\n  {\r\n    \"id\": \"read-only\",\r\n    \"bucket\": \"<bucket a, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"rolearn\": \"arn:aws:iam::<account redacted>:role/swb-lhdhyiaqchc0a4vrlu256w-fs-1661808852807\",\r\n    \"prefix\": \"read-only/\",\r\n    \"readable\": true,\r\n    \"writeable\": false\r\n  }\r\n]\r\n```\r\n\r\nsome additional context, this bucket (and the associated swb data source) that the two studies are a part of gets updated every couple months to add new study folders/ids, but the existing studies don't typically change.\r\n\r\nwhat could cause the fs role number to change for a study? what else could cause this permissions denied error? \r\n\r\nthis is a pretty big problem for us, as we have had people actively using swb and all their work is gone on tool stop, because the folder they saved to isn't syncing.\r\n\r\n**versions (please complete the following information):**\r\n - swb 4.3.1\r\n",
          "Title: databuilder `toolbulkloaderapi` constructs wrong iam role arn for aws other than global; Content:for uploading data to aws tool we use `toolcsvpublisher`, which internally uses `toolbulkloaderapi`. the current configuration uses config key `toolcsvpublisher.aws_iam_role_name`, which provides name of iam role for the loader to be able to use s3 and tool. the issue is that `toolbulkloaderapi` constructs iam role arn from name as follows: \r\n\r\n```python\r\naccount_id = self.session.client('sts').get_caller_identity()['account']\r\nself.iam_role_arn = f'arn:aws:iam::{account_id}:role/{iam_role_name}'\r\n```\r\n\r\nwhereas, [second element of arn aka partition](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html) can be currently:\r\n* `aws` -aws regions\r\n* `aws-cn` - china regions\r\n* `aws-us-gov` - aws govcloud (us) regions\r\n\r\nsince we use amundsen also in aws china, the above arn is not valid. \r\n\r\n## expected behavior\r\n\r\niam role arn either takes into account aws partition or there is a possibility of passing iam role arn instead of name directly.\r\n\r\n## current behavior\r\n\r\niam role arn is constructed incorrectly outside of aws global.\r\n\r\n## possible solutions\r\n\r\niam role arn should take partition into account. there are two solutions:\r\n1. add partition into current code\r\n2. add option of passing iam role arn directly which supersedes iam role name \r\n\r\n### solution 1\r\n\r\nsince i didn't know or found any good way to get the aws partition, we can use caller identity and arn there to get the partition, e.g.:\r\n\r\n```python\r\nidentity = self.session.client('sts').get_caller_identity()\r\naccount_id = identity['account']\r\npartition = identity['arn'].split(':')[1]\r\nself.iam_role_arn = f'arn:{partition}:iam::{account_id}:role/{iam_role_name}'\r\n```\r\n\r\nthis is smaller fix but it is a bit hacky and i'm not sure it'll work in all situation, but it should i guess.\r\n\r\n### solution 2\r\n\r\nadd config key `toolcsvpublisher.aws_iam_role_arn` which either supersedes `toolcsvpublisher.aws_iam_role_name` in a way that in constructor we would have something like:\r\n\r\n```python\r\nif iam_role_arn:\r\n    self.iam_role_arn = iam_role_arn\r\nelse:\r\n   ...\r\n   self.iam_role_arn = f'arn:{partition}:iam::{account_id}:role/{iam_role_name}'\r\n```\r\n\r\nor even replace `toolcsvpublisher.aws_iam_role_name` with `toolcsvpublisher.aws_iam_role_arn`, which is imo cleaner, but would be not backward compatible. \r\n\r\n## steps to reproduce\r\ndeploy amundsen in aws china with tool and try to use databuilder to upload csv data from s3. \r\n\r\n## screenshots (if appropriate)\r\n\r\n## context\r\ncurrently we are unable to load data into tool as the iam role arn setting is hidden and we get an error:\r\n\r\n```\r\n[error] exception: failed to load csv. response: {'detailedmessage': \"failed to start new load from the source s3://amundsenbucket/amundsen/2021_08_10_01_01_28. couldn't find the aws credential for iam_role_arn: arn:aws:iam::111111111:role/rolefortool111111-2222\", 'code': 'invalidparameterexception', 'requestid': 'xxx'}\r\ntraceback (most recent call last):\r\n  file \"/var/task/ctw/jobs/synchronize_redshift_metadata.py\", line 49, in lambda_handler\r\n    redshift_to_tool_job.launch()\r\n  file \"/var/task/databuilder/job/job.py\", line 76, in launch\r\n    raise e\r\n  file \"/var/task/databuilder/job/job.py\", line 72, in launch\r\n    self.publisher.publish()\r\n  file \"/var/task/databuilder/publisher/base_publisher.py\", line 40, in publish\r\n    raise e\r\n  file \"/var/task/databuilder/publisher/base_publisher.py\", line 37, in publish\r\n    self.publish_impl()\r\n  file \"/var/task/databuilder/publisher/tool_csv_publisher.py\", line 109, in publish_impl\r\n    raise exception(\"failed to load csv. response: {0}\".format(str(bulk_upload_response)))\r\n```\r\n\r\n## your environment\r\n* amunsen version used: `amundsen-databuilder==4.3.1`\r\n* data warehouse stores: aws tool\r\n* deployment (k8s or native): aws step functions (k8s for backend but unrelated for now)\r\n* link to your fork or repository:",
          "Title: tool example dag to use aws session token; Content:**describe the bug**\r\ncurrently the example dag for tool just uses access key and secret key. we need to use a temporary  access token\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. go to '...'\r\n2. click on '....'\r\n3. scroll down to '....'\r\n4. see error\r\n\r\n**expected behavior**\r\na clear and concise description of what you expected to happen.\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n**desktop (please complete the following information):**\r\n - os: [e.g. ios]\r\n - browser [e.g. chrome, safari]\r\n - version [e.g. 22]\r\n\r\n**smartphone (please complete the following information):**\r\n - device: [e.g. iphone6]\r\n - os: [e.g. ios8.1]\r\n - browser [e.g. stock browser, safari]\r\n - version [e.g. 22]\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: [tool] model artifacts not saved in remote s3 artifact store; Content:### describe the bug a clear and concise description of what the bug is.\r\n\r\ni have local minikube cluster. i installed the helm chart with some changed settings. see below for the changed values. everthing else is same as per default values yaml file. for db backend i am using `bitnami/postgresql` and for s3 storage minio instance. i also have created a initial bucket named \"tool\" in minio. \r\n\r\nand then i created a simple k8s pod to run the simple training example from tool docs. this pod has env variables set as : `tool_tracking_uri=http://tool.airflow.svc.cluster.local:5000` [here ](https://raw.githubusercontent.com/tool/tool/master/examples/sklearn_elasticnet_wine/train.py) is the link to that code. i can see the metadata about the model in ui however , artifact section in ui is empty and also the bucket is empty. \r\n\r\n### what's your helm version?\r\n\r\nversion.buildinfo{version:\"v3.9.0\", gitcommit:\"7ceeda6c585217a19a1131663d8cd1f7d641b2a7\", gittreestate:\"clean\", goversion:\"go1.17.5\"}\r\n\r\n### what's your kubectl version?\r\n\r\nserver version: version.info{major:\"1\", minor:\"23\", gitversion:\"v1.23.3\", gitcommit:\"816c97ab8cff8a1c72eccca1026f7820e93e0d25\", gittreestate:\"clean\", builddate:\"2022-01-25t21:19:12z\", goversion:\"go1.17.6\", compiler:\"gc\", platform:\"linux/amd64\"}\r\n\r\n### which chart?\r\n\r\ntool\r\n\r\n### what's the chart version?\r\n\r\nlatest\r\n\r\n### what happened?\r\n\r\n_no response_\r\n\r\n### what you expected to happen?\r\n\r\ni would expect the artifacts in minio bucket.\r\n\r\n### how to reproduce it?\r\n\r\ninstall the helm chart with minio and postgresql config. run a simple exmple frpom docs. \r\n\r\n### enter the changed values of values.yaml?\r\n\r\n```\r\nbackendstore:\r\n    databasemigration: true\r\n    databaseconnectioncheck: true\r\n    postgres:\r\n      enabled: true\r\n      host: tool-postgres-postgresql.airflow.svc.cluster.local\r\n      database: tool_db\r\n      user: tool\r\n      password: tool\r\nartifactroot:\r\n  proxiedartifactstorage: true\r\n  s3:\r\n    enabled: true\r\n    bucket: tool\r\n    awsaccesskeyid: {{ requiredenv \"minio_username\" }}\r\n    awssecretaccesskey: {{ requiredenv \"minio_password\" }}\r\nextraenvvars:\r\n  tool_s3_endpoint_url: minio.airflow.svc.cluster.local\r\n```\r\n\r\n### enter the command that you execute and failing/misfunctioning.\r\n\r\nhelm install tool-release community-charts/tool --values values.yaml\r\n\r\n### anything else we need to know?\r\n\r\n_no response_",
          "Title: can't configure profile with aws cli for using aws built-in tool algorithms ; Content:hi everybody,\r\n\r\ni am trying to use aws built-in algorithms in tool studio lab. for that i need an execution role and region etc. \r\nwhen i try to run my code it outputs\r\n\r\nvalueerror: must setup local aws configuration with a region supported by tool.\r\n\r\nis it even possible to link access aws resources in studiolab?\r\n\r\nmany thanks in advance!\r\n\r\n\r\n",
          "Title: remote storage is not publicly accessible (tool pull fails); Content:`error: unexpected error - forbidden: an error occurred (403) when calling the headobject operation: forbidden`\r\n\r\n`tool pull` needs mantis creds so a reader will not be able to follow. we need to make the bucket public and read only.",
          "Title: the data path inside tool notebook does not work; Content:the bucket of processed data does not exist (src/tool/fd_sl_training_byo_codes.ipynb)\r\n\r\n\r\n### reproduction steps\r\n\r\naws s3 ls s3://fraud-detection-solution/processed_data\r\n\r\n\r\n\r\n### error log\r\n\r\nan error occurred (nosuchbucket) when calling the listobjectsv2 operation: the specified bucket does not exist\r\n\r\n\r\n\r\n### environment\r\n\r\n  - **cdk cli version:** 1.75.0 (build 7708242)\r\n  - **framework version:** not installed\r\n  - **node.js version:**  not installed\r\n  - **os               :**\r\n\r\n### other\r\n\r\n<!-- e.g. detailed explanation, stacktraces, related issues, suggestions on how to fix, links for us to have context, eg. associated pull-request, stackoverflow, gitter, etc -->\r\n\r\n\r\n\r\n--- \r\n\r\nthis is :bug: bug report",
          "Title: tool hardcoded bucket name - impossible to use tool with aws s3; Content:https://github.com/canonical/tool-operator/blob/c856446074868d4735627c95878960d91555f4da/charms/tool-server/src/charm.py#l20\r\n\r\nthe name of the bucket for tool is hardcoded. this is a big issue because this makes using minio in gateway mode + tool impossible on aws (s3 buckets are globally unique).\r\n\r\nit's a good first issue :)",
          "Title: [bug] tool aws credentials not populating; Content:when a tool notebook is launched with an associated study, the study folders are not mounted. digging into this, i see that in the `~/.aws` folder there is no credentials file, which is generated by the `mount_s3.sh` script.\r\n\r\n**to reproduce**\r\n- create a new data source (or use an existing one).\r\n- select it and create a new tool instance using those studies. (ensure that the folder has files so you can see them if they mount.)\r\n- after the instance launches, connect to it and see if the study folders are connected. if not, open a terminal and run `ls ~/.aws` to see if the credential file is there.\r\n\r\n**expected behavior**\r\nthe study folders are mounted using the assumed roles in the aws credentials file, generated by `mount_s3.sh` script.\r\n\r\n**screenshots**\r\n<img width=\"702\" alt=\"screen shot 2022-11-30 at 11 27 45 am\" src=\"https://user-images.githubusercontent.com/21109191/204853707-789607d5-6fca-4a77-911d-50a5c36a549b.png\">\r\n<img width=\"526\" alt=\"screen shot 2022-11-30 at 11 27 36 am\" src=\"https://user-images.githubusercontent.com/21109191/204853710-824ddc98-dfb5-4c8b-abbe-f19fa2453640.png\">\r\n\r\n**versions (please complete the following information):**\r\n - versions 5.0.0 & 4.3.1\r\n\r\n**additional context**\r\nthis may or may not be associated with the other bug i noted with mounting s3 studies folders, [[bug] swb tool study permission denied](https://github.com/awslabs/service-workbench-on-aws/issues/1067). it seems both of these issues are new, within the last couple weeks. and the environment has had no new deployments or changes within that time. previous to these last couple weeks we had no issues with tool and study folders mounting.\r\n",
          "Title: bad tool artifact folder by default; Content:the artifact folder by default is not reemplacing the `$artifacts_bucket` env var",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_bucket_aws_kubeflow",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_bucket_aws_kubeflow"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.3664164543151855,
          7.134006977081299,
          7.526346683502197,
          7.037300109863281,
          6.9146199226379395,
          6.997727870941162,
          6.942713260650635,
          7.213944435119629,
          7.009409427642822,
          7.103340148925781,
          7.165283203125,
          7.329248905181885,
          7.013907432556152,
          7.271435260772705,
          7.532949924468994,
          7.249828338623047,
          7.068636417388916,
          7.481446743011475,
          7.186586380004883
         ],
         "y": [
          1.0812534093856812,
          0.817571759223938,
          1.0475250482559204,
          0.706870973110199,
          0.7463430762290955,
          0.8567025661468506,
          1.0497878789901733,
          1.300478219985962,
          1.0340098142623901,
          0.6979824304580688,
          1.2007173299789429,
          1.2051750421524048,
          0.649886965751648,
          0.9783837795257568,
          1.7097885608673096,
          0.8436799645423889,
          1.016879677772522,
          1.0303964614868164,
          0.9985241293907166
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: [tool] extra args broken; Content:### describe the bug a clear and concise description of what the bug is.\n\nthe new staticprefix argument being under extraargs breaks the chart for users that need to use the extraargs\n\n### what's your helm version?\n\nversion.buildinfo{version:\"v3.8.1\", gitcommit:\"5cb9af4b1b271d11d7a97a71df3ac337dd94ad37\", gittreestate:\"clean\", goversion:\"go1.17.8\"}\n\n### what's your kubectl version?\n\nclient version: version.info{major:\"1\", minor:\"22\", gitversion:\"v1.22.5\", gitcommit:\"5c99e2ac2ff9a3c549d9ca665e7bc05a3e18f07e\", gittreestate:\"clean\", builddate:\"2021-12-16t08:38:33z\", goversion:\"go1.16.12\", compiler:\"gc\", platform:\"darwin/arm64\"} server version: version.info{major:\"1\", minor:\"23\", gitversion:\"v1.23.3\", gitcommit:\"816c97ab8cff8a1c72eccca1026f7820e93e0d25\", gittreestate:\"clean\", builddate:\"2022-01-25t21:19:12z\", goversion:\"go1.17.6\", compiler:\"gc\", platform:\"linux/arm64\"}\n\n### which chart?\n\ntool\n\n### what's the chart version?\n\n0.2.7\n\n### what happened?\n\nthe newly added staticprefix parameter under extraargs breaks the chart when used because it tries to add an extra argument to the tool server command that doesnt exist.\n\n### what you expected to happen?\n\n_no response_\n\n### how to reproduce it?\n\n_no response_\n\n### enter the changed values of values.yaml?\n\n_no response_\n\n### enter the command that you execute and failing/misfunctioning.\n\nhelm install -f tool/values.yaml tool ./tool/\n\n### anything else we need to know?\n\ni am just creating a pull request to address this in a bit different way and havent tested it yet. just wanted to create a request to highlight a solution.\r\n\r\nyou could also handle the staticprefix as a separate argument in the extraenv when starting up the tool server to make this work smoother for a final user, but this solution should work as well.",
          "Title: [tool] run chart-testing (lint) step returns error validating maintainer 404 not found error; Content:### describe the bug a clear and concise description of what the bug is.\n\nwhen we open a pull request, chart-testing (lint) step in [release.yaml](https://github.com/community-charts/helm-charts/blob/main/.github/workflows/release.yml#l60) file getting the following error.\r\n\r\n```\r\nerror: error linting charts: error processing charts\r\n------------------------------------------------------------------------------------------------------------------------\r\n ✖︎ tool => (version: \"0.1.47\", path: \"charts/tool\") > error validating maintainer 'burak ince': 404 not found\r\n------------------------------------------------------------------------------------------------------------------------\r\n```\r\n\r\nbecause of maintainer name for the `ct lint` command must be a github username rather than a real name.\n\n### what's your helm version?\n\nv3.9.0\n\n### what's your kubectl version?\n\nv1.24.2\n\n### which chart?\n\ntool\n\n### what's the chart version?\n\n0.1.47\n\n### what happened?\n\n_no response_\n\n### what you expected to happen?\n\n_no response_\n\n### how to reproduce it?\n\n_no response_\n\n### enter the changed values of values.yaml?\n\n_no response_\n\n### enter the command that you execute and failing/misfunctioning.\n\nct lint --debug --config ./.github/configs/ct-lint.yaml --lint-conf ./.github/configs/lintconf.yaml\n\n### anything else we need to know?\n\n_no response_",
          "Title: tool operator types fails kubebuilder pattern validation check; Content:<!-- please use this template while reporting a bug and provide as much info as possible. not doing so may result in your bug not being addressed in a timely manner. thanks!\r\n\r\nif you would like to report a vulnerability or have a security concern regarding aws cloud services, please email aws-security@amazon.com\r\n-->\r\n\r\n\r\n**what happened**:\r\ntool operator types, when included as part of kubebuilder v2 custom crd definition fail due to validation errors of unescaped regex patterns. \r\n\r\n```\r\n/go/bin/controller-gen \"crd:trivialversions=true\" rbac:rolename=manager-role webhook paths=\"./...\" output:crd:artifacts:config=config/crd/bases\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:488:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:110:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:82:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:103:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:466:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:450:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:500:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:515:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:500:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:450:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:82:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:466:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:103:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:488:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:515:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n/go/pkg/mod/github.com/aws/amazon-tool-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a/api/v1/common/tool_api.go:110:2: extra arguments provided: \"://([^/]+)/?(.*)$\" (at <input>:1:12)\r\n```\r\n\r\n**what you expected to happen**:\r\nkubebuilder should generate crd specification which includes aws tool operator types\r\n\r\n**how to reproduce it (as minimally and precisely as possible)**:\r\n```\r\nimport (\r\n\tcommonv1 \"github.com/aws/amazon-tool-operator-for-k8s/api/v1/common\"\r\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\r\n)\r\n\r\n// guestbookspec defines the desired state of guestbook\r\ntype guestbookspec struct {\r\n\t// insert additional spec fields - desired state of cluster\r\n\t// important: run \"make\" to regenerate code after modifying this file\r\n\r\n\talgorithmspecification *commonv1.algorithmspecification `json:\"algorithmspecification\"`\r\n\r\n\tenableintercontainertrafficencryption *bool `json:\"enableintercontainertrafficencryption,omitempty\"`\r\n\r\n\tenablenetworkisolation *bool `json:\"enablenetworkisolation,omitempty\"`\r\n...\r\n//run make install with above  types in custom operator\r\nmake install \r\n```\r\n\r\n**anything else we need to know?**:\r\ntried copying the above types and escaped the regex pattern with quotes (``// +kubebuilder:validation:pattern='^(https|s3)://([^/]+)/?(.*)$'``) and everything worked\r\n\r\n**environment**:\r\n- kubernetes version (use `kubectl version`):version: version.version{kubebuilderversion:\"2.3.1\", kubernetesvendor:\"1.16.4\", gitcommit:\"8b53abeb4280186e494b726edf8f54ca7aa64a49\", builddate:\"2020-03-26t16:42:00z\", goos:\"unknown\", goarch:\"unknown\"}\r\n- operator version (controller image tag):\tgithub.com/aws/amazon-tool-operator-for-k8s v1.0.1-0.20200410212604-780c48ecb21a\r\n- os (e.g: `cat /etc/os-release`):\r\n- kernel (e.g. `uname -a`):\r\n- installation method:\r\n- others:\r\n",
          "Title: error building tool types due to missing types in common/manual_deepcopy; Content:<!-- please use this template while reporting a bug and provide as much info as possible. not doing so may result in your bug not being addressed in a timely manner. thanks!\r\n\r\nif you would like to report a vulnerability or have a security concern regarding aws cloud services, please email aws-security@amazon.com\r\n-->\r\n\r\n\r\n**what happened**:\r\nerror building tool types due to missing types in common/manual_deepcopy\r\n(base) afccd2:example nj$ make all\r\ngo: creating new go.mod: module tmp\r\ngo: found sigs.k8s.io/controller-tools/cmd/controller-gen in sigs.k8s.io/controller-tools v0.2.5\r\n/devel/projects/go_tutorial/bin/controller-gen object:headerfile=\"hack/boilerplate.go.txt\" paths=\"./...\"\r\ngo fmt ./...\r\ncontrollers/guestbook_controller.go\r\ngo vet ./...\r\ngithub.com/aws/amazon-tool-operator-for-k8s/api/v1/common\r\n../../../go_tutorial/pkg/mod/github.com/aws/amazon-tool-operator-for-**k8s@v1.1.0/api/v1/common/manual_deepcopy.go:28:19: tag.deepcopy undefined (type tag has no field or method deepcopy)\r\nmake: *** [vet] error 2**\r\n\r\n**what you expected to happen**:\r\npackaged types refer to types in zz_generated_deepcopy which are missing\r\n\r\n**how to reproduce it (as minimally and precisely as possible)**:\r\n\r\n\r\nimport of tool types in go client fails build\r\n\r\nimport (\r\n\ttrainingjobv1 \"github.com/aws/amazon-tool-operator-for-k8s/api/v1/trainingjob\"\r\n)\r\n\r\n\r\n**anything else we need to know?**:\r\n\r\n**environment**:\r\n- kubernetes version (use `kubectl version`): \r\n- operator version (controller image tag): v1.1.0\r\n- os (e.g: `cat /etc/os-release`):\r\n- kernel (e.g. `uname -a`):\r\n- installation method:\r\n- others:\r\n",
          "Title: all tool experiments are visible for any user; Content:we should create a instance of tool for each project in order to see the experiments related to the current project.\r\n\r\n- [x] create project operator to deploy a tool instance for each project.\r\n- [x] update kdl app api to create the kdlproject custom resource in k8s.\r\n- [x] update kdlctl.sh adding project-operator docker image building.\r\n- [x] add project-operator to kdl server helm chart.\r\n- [x] add github workflows to publish the project-operator in docker hub.",
          "Title: post-gen hook shouldn't configure a tool remote if no name is provided; Content:if the tool remote name is left blank, the post-gen hook shouldn't try to set one. currently this raises a (non-fatal) error.",
          "Title: [tool] use port name instead of port number in servicemonitor ; Content:### describe the bug a clear and concise description of what the bug is.\n\nfirst of all, thanks to everyone creating this helm chart as it is really good and easy to use.\r\n\r\nhowever, i encountered a problem when choosing to include servicemonitor and prometheus metrics along the deployment. generally, the created servicemonitor for tool is correct, yet in the current form it does not work for me.\r\ni use the latest prometheus deployed using the official helm chart and the tool metrics did not show up in the targets, yet it was visible in service discovery panel in prometheus dashboard, but appeared as `0/1 active targets`.\r\n\r\nafter a couple of hours of educated debugging i changed manually the `targetport: 80` to `port: http` in the deployed servicemonitor manifest. it worked straightaway! \r\n\r\n\r\nwhat i propose is a simple fix:\r\naccording to official prometheus troubleshooting docs the port specified in servicemonitor should use `name` instead of port number ([link to docs](https://github.com/prometheus-operator/prometheus-operator/blob/main/documentation/troubleshooting.md#using-textual-port-number-instead-of-port-name)) \r\nsimple fix would be to change `targetport: 80` to `port: http` in `templates/servicemonitor.yaml`. port name `http` is already hardcoded, so can be used directly or new parameter could be introduced to give the freedom to choose port name.\r\ni am aware that port number of type integer should also work...\r\n\n\n### what's your helm version?\n\n3.6.0\n\n### what's your kubectl version?\n\n1.19\n\n### which chart?\n\ntool\n\n### what's the chart version?\n\n0.2.21\n\n### what happened?\n\n_no response_\n\n### what you expected to happen?\n\n_no response_\n\n### how to reproduce it?\n\n_no response_\n\n### enter the changed values of values.yaml?\n\n_no response_\n\n### enter the command that you execute and failing/misfunctioning.\n\n helm install --namespace tool tool-tracking-server community-charts/tool --set servicemonitor.enabled=true\n\n### anything else we need to know?\n\n_no response_",
          "Title: want to create any model and do batch transform in without training in tool ; Content:### what steps did you take: removed the hpo and training jobs only creating the model and batch transforming in tool \r\n[automatically taking the hpo and training on tool facing some issue while kfp compile]\r\n\r\n### what happened: getting output properly in kubefow. but i want to to see custom  model (any) output without hpo and model training in tool\r\n\r\n### what did you expect to happen: without hpo and batch job in tool\r\n\r\n\r\n\r\n\r\n### anything else you would like to add:\r\nany open source loan data model using kf would be appriciated \r\n\r\n/kind bug\r\n<!-- please include labels by uncommenting them to help us better triage issues, choose from the following -->\r\n<!--//compile(kfp.compile ) \r\n/\r\n",
          "Title: typeerror: tool - deploy model() got an unexpected keyword argument 'update_endpoint'; Content:### what steps did you take:\r\n[a clear and concise description of what the bug is.]\r\n\r\ni am use the re usable tool components for building kubeflow pipelines.\r\n\r\ntool_train_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/tool/train/component.yaml')\r\ntool_model_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/tool/model/component.yaml')\r\ntool_deploy_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/tool/deploy/component.yaml')\r\n\r\nwhen i am trying to update the endpoint that already exists \r\n\r\npiece of code i used to update the endpoint.\r\n\r\n**#deploy the pipeline\r\nprediction = tool_deploy_op(\r\n        region=aws_region,\r\n        endpoint_name='endpoint-price-prediction-model',\r\n        endpoint_config_name='endpointconfig-price-prediction-model',\r\n        update_endpoint=true,\r\n        model_name_1 = create_model.output,\r\n        instance_type_1='ml.m5.large'\r\n    )\r\n# compiling the pipeline\r\nkfp.compiler.compiler().compile(car_price_prediction,'car-price-pred-pipeline.zip')**\r\n\r\n\r\n### what happened:\r\ni am getting this error \r\ntypeerror: tool - deploy model() got an unexpected keyword argument 'update_endpoint'\r\n\r\ni think while compile the pipeline kfp is throwing this error.can you suggest me or help me out in this\r\n\r\n\r\ntraceback (most recent call last):\r\n--\r\n414 | file \"pipeline.py\", line 94, in <module>\r\n415 | kfp.compiler.compiler().compile(car_price_prediction,'car-price-pred-pipeline.zip')\r\n416 | file \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/kfp/compiler/compiler.py\", line 920, in compile\r\n417 | self._create_and_write_workflow(\r\n418 | file \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/kfp/compiler/compiler.py\", line 972, in _create_and_write_workflow\r\n419 | workflow = self._create_workflow(\r\n420 | file \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/kfp/compiler/compiler.py\", line 813, in _create_workflow\r\n421 | pipeline_func(*args_list)\r\n422 | file \"pipeline.py\", line 85, in car_price_prediction\r\n423 | prediction = tool_deploy_op(\r\n424 | typeerror: tool - deploy model() got an unexpected keyword argument 'update_endpoint'\r\n\r\n\r\n\r\n### what did you expect to happen:\r\nto update the endpoint without any issue\r\n### environment:\r\n<!-- please fill in those that seem relevant. -->\r\nusing kfp 1.1.2\r\ntool 2.1.0\r\n\r\nhow did you deploy kubeflow pipelines (kfp)?\r\n<!-- if you are not sure, here's [an introduction of all options](https://www.kubeflow.org/docs/pipelines/installation/overview/). -->\r\n\r\nkfp version: <!-- if you are not sure, build commit shows on bottom of kfp ui left sidenav. -->\r\n\r\nkfp sdk version: <!-- please attach the output of this shell command: $pip list | grep kfp -->\r\nkfp-1.1.2.tar.gz \r\n\r\n### anything else you would like to add:\r\n[miscellaneous information that will assist in solving the issue.]\r\n\r\nplease help me out \r\n\r\n/kind bug\r\n<!-- please include labels by uncommenting them to help us better triage issues, choose from the following -->\r\n<!--\r\n// /area frontend\r\n// /area backend\r\n// /area sdk\r\n// /area testing\r\n// /area engprod\r\n-->\r\n",
          "Title: add support for tool namespaces in data catalog; Content:since tool 0.17.7(?) there have been introduced namespaces which cause issues in kfp artifacts, as they are not properly handled.\r\n\r\nunless the function to create kfp artifacts is disabled in `kubeflow.yaml` config:\r\n```yaml\r\nstore_tool_outputs_as_kfp_artifacts: false\r\n```\r\nit causes issues like:\r\n```\r\nvalueerror: only letters, numbers, spaces, \"_\", and \"-\" are allowed in name. must begin with a letter. got name: data_science.active_modelling_pipeline.x_train\r\n```\r\nwhen trying to run or update the pipeline.\r\n",
          "Title: kubeflow-pipeline running with aws tool throws an error passing k-mean and feature_dim parameters; Content:hi, \r\n\r\ni have copied the git code for aws tool to execute through the kubeflow pipeline\r\n\r\nhttps://github.com/kubeflow/pipelines/blob/master/samples/aws-samples/mnist-kmeans-tool/mnist-classification-pipeline.py\r\n\r\nwhile executing the kubeflow pipeline, i am getting the error of assigning the hyperparameters, although in pipeline parameters there are no such parameters define.\r\n\r\nerror:\r\n\r\ntraining failed with the following error: clienterror: no value(s) were specified for 'k', 'feature_dim' which are required hyperparameter(s) (caused by validationerror)\r\n\r\npipeline parameters are:\r\n\r\n@dsl.pipeline(\r\n    name='mnist classification pipeline',\r\n    description='mnist classification using kmeans in tool'\r\n)\r\ndef mnist_classification(region='us-east-1',\r\n    image='174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:1',\r\n    dataset_path='s3://s3-tool-us-east-1/mnist_kmeans_example/data',\r\n    instance_type='ml.c4.8xlarge',\r\n    instance_count='2',\r\n    volume_size='50',\r\n    model_output_path='s3://s3-tool-us-east-1/mnist_kmeans_example/model',\r\n    batch_transform_input='s3://s3-tool-us-east-1/mnist_kmeans_example/input',\r\n    batch_transform_ouput='s3://s3-tool-us-east-1/mnist_kmeans_example/output',\r\n    role_arn=''\r\n    ):\r\n\r\nplease let me know why this error is appeared and how should it get resolved ?\r\n\r\nregards,\r\nvarun\r\n",
          "Title: project template tool secret bad name; Content:currently the `.drone.yaml` is referencing the k8s secret `tool-server-secret` which doesn't exist by default.\r\n\r\nwe have noticed that `{{ .projectid }}-tool-secret` secret is created when a `kdlproject` resource is created.\r\n\r\nto solve this issue the name of the `tool-server-secret` must be changed into `{{ .projectid }}-tool-secret`",
          "Title: project operator tool image tag is set to \"latest\"; Content:on chart release v0.13.2 the default value for projectoperator.tool.image.tag is set to latest when it should be set to v0.13.2.\r\n\r\ncheck values.yml:\r\n\r\n```yaml\r\nprojectoperator:\r\n  image:\r\n    repository: konstellation/project-operator\r\n    tag: v0.13.2\r\n    pullpolicy: ifnotpresent\r\n  tool:\r\n    image:\r\n      repository: konstellation/tool\r\n      tag: latest\r\n      pullpolicy: ifnotpresent\r\n    volume:\r\n      storageclassname: standard\r\n      size: 1gi\r\n  filebrowser:\r\n    image:\r\n      repository: filebrowser/filebrowser\r\n      tag: v2\r\n      pullpolicy: ifnotpresent\r\n```",
          "Title: [bug] scikit learn model feature definition doesn't work on tool prediction.; Content:## description\r\n\r\nscikit learn model in [`kubeflow_pipelines/pipelines` directory](https://github.com/googlecloudplatform/asl-ml-immersion/blob/master/notebooks/kubeflow_pipelines/pipelines/solutions/trainer_image/train.py#l46) doesn't work in tool prediction environment, since it assumes the input as pandas dataframe and cannot handle json from web api.\r\n\r\nafter deploying the model following the labs, this issue can be reproduced with this code snippet.\r\n\r\n```python\r\nendpoint = aiplatform.endpoint.list()[0]\r\n\r\ninstance = [{'elevation': [2841.0]},\r\n {'aspect': [45, 0]},\r\n {'slope': [0, 0]},\r\n {'horizontal_distance_to_hydrology': [644.0]},\r\n {'vertical_distance_to_hydrology': [282.0]},\r\n {'horizontal_distance_to_roadways': [1376.0]},\r\n {'hillshade_9am': [218.0]},\r\n {'hillshade_noon': [237.0]},\r\n {'hillshade_3pm': [156.0]},\r\n {'horizontal_distance_to_fire_points': [1003.0]},\r\n {'wilderness_area': ['commanche']},\r\n {'soil_type': ['c4758']}]\r\n\r\nendpoint.predict([instance])\r\n```\r\n\r\nreturns:\r\n\r\n![image](https://user-images.githubusercontent.com/6895245/156965179-92e4e873-8f60-411c-86b7-df0685509e4c.png)\r\n\r\n## approach\r\nrewrite feature definition part of `train.py` from:\r\nhttps://github.com/googlecloudplatform/asl-ml-immersion/blob/e87f3514dda440fb381a78f563bda177aa38ad80/notebooks/kubeflow_pipelines/cicd/solutions/trainer_image_vertex/train.py#l43-l63\r\n\r\nto:\r\n```python\r\n    numeric_feature_indexes = slice(0, 10)\r\n    categorical_feature_indexes = slice(10, 12)\r\n\r\n    preprocessor = columntransformer(\r\n    transformers=[\r\n        ('num', standardscaler(), numeric_feature_indexes),\r\n        ('cat', onehotencoder(), categorical_feature_indexes) \r\n    ])\r\n```\r\n\r\nand it should run with this \r\n\r\n```python\r\nendpoint = aiplatform.endpoint.list()[0]\r\n\r\ninstance = [\r\n    2841.0,\r\n    45.0,\r\n    0.0,\r\n    644.0,\r\n    282.0,\r\n    1376.0,\r\n    218.0,\r\n    237.0,\r\n    156.0,\r\n    1003.0,\r\n    \"commanche\",\r\n    \"c4758\",\r\n]\r\nendpoint.predict([instance])\r\n```\r\n\r\noutput:\r\n```\r\nprediction(predictions=[1.0], deployed_model_id='4516996077043318784', explanations=none)\r\n```\r\n\r\n## target files\r\n[these 8 files ](https://github.com/googlecloudplatform/asl-ml-immersion/search?q=numeric_features+%3d+%5b+++++++++%22elevation%22%2c) should be update.",
          "Title: can not compile tool examples; Content:trying our your kubeflow/tool notebook in your workshop and received a pipeline compile error.  \r\n\r\n![image](https://user-images.githubusercontent.com/4739316/66772250-1e628900-ee71-11e9-92f0-afceb992313a.png)\r\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_v1_api_chart",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_v1_api_chart"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.033164024353027,
          6.063974380493164,
          6.923159122467041,
          6.991161823272705,
          6.513964653015137,
          6.017273426055908,
          6.065131664276123,
          6.812620639801025,
          6.840476989746094,
          6.677628040313721,
          7.061068058013916,
          6.517516613006592,
          5.989420413970947,
          8.171250343322754,
          6.790558815002441,
          6.631224155426025
         ],
         "y": [
          2.2567663192749023,
          2.2710046768188477,
          1.943328857421875,
          1.9647892713546753,
          2.4677653312683105,
          2.2551674842834473,
          2.2014963626861572,
          2.091362476348877,
          2.231978416442871,
          2.2150745391845703,
          1.881927728652954,
          2.444967269897461,
          2.2592620849609375,
          2.242246150970459,
          2.1880602836608887,
          2.1943464279174805
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: renaming of mxnet-model-server in tool-inference package 1.5.3 causing entrypoint with command `serve` to fail; Content:**describe the bug**\r\n`tool-inference` recently (10/15) released v1.5.3, which included [this commit](https://github.com/aws/tool-inference-toolkit/commit/8efb1672798d747cd623e5dd2eb7919af87a1b80) updating the name of the model server artifact and command from `mxnet-model-server` to `multi-model-server`.\r\n\r\nall containers defined in this repository install `tool-inference` as a dependency of this repo itself, on lines\r\n\r\n```dockerfile\r\nrun pip install --no-cache-dir \"tool-pytorch-inference<2\"\r\n```\r\n\r\nand this repo's `setup.py` has an `install_requires` which includes `tool-inference>=1.3.1`. as a result, `tool-inference=1.5.3` installed.\r\n\r\nso while the `dockerfile`'s `cmd` value (which calls `mxnet-model-server` directly) will succeed, attempts to use the `entrypoint` with `serve` as a build arg will fail with message:\r\n\r\n```\r\ntraceback (most recent call last):\r\n  file \"/usr/local/bin/dockerd-entrypoint.py\", line 22, in <module>\r\n    serving.main()\r\n  file \"/opt/conda/lib/python3.6/site-packages/tool_pytorch_serving_container/serving.py\", line 39, in main\r\n    _start_model_server()\r\n  file \"/opt/conda/lib/python3.6/site-packages/retrying.py\", line 49, in wrapped_f\r\n    return retrying(*dargs, **dkw).call(f, *args, **kw)\r\n  file \"/opt/conda/lib/python3.6/site-packages/retrying.py\", line 206, in call\r\n    return attempt.get(self._wrap_exception)\r\n  file \"/opt/conda/lib/python3.6/site-packages/retrying.py\", line 247, in get\r\n    six.reraise(self.value[0], self.value[1], self.value[2])\r\n  file \"/opt/conda/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  file \"/opt/conda/lib/python3.6/site-packages/retrying.py\", line 200, in call\r\n    attempt = attempt(fn(*args, **kwargs), attempt_number, false)\r\n  file \"/opt/conda/lib/python3.6/site-packages/tool_pytorch_serving_container/serving.py\", line 35, in _start_model_server\r\n    model_server.start_model_server(handler_service=handler_service)\r\n  file \"/opt/conda/lib/python3.6/site-packages/tool_inference/model_server.py\", line 94, in start_model_server\r\n    subprocess.popen(multi_model_server_cmd)\r\n  file \"/opt/conda/lib/python3.6/subprocess.py\", line 709, in __init__\r\n    restore_signals, start_new_session)\r\n  file \"/opt/conda/lib/python3.6/subprocess.py\", line 1344, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nfilenotfounderror: [errno 2] no such file or directory: 'multi-model-server': 'multi-model-server'\r\n\r\n```\r\n\r\n**to reproduce**\r\n1. build any container\r\n1. mount a model and `inference.py` (e.g. `half_plus_three`) into `/opt/ml/model`\r\n1. `docker run [tag name] serve`\r\n\r\n**expected behavior**\r\ntensorflow serving serves the mounted model / `inference.py`\r\n\r\n**system information**\r\na description of your system. please provide:\r\n- **toolkit version**: 2.0.5, but should apply to all versions\r\n- **framework version**: 1.4, but should apply to all versions\r\n- **python version**: 3.7\r\n- **cpu or gpu**: cpu, but should apply to both\r\n- **custom docker image (y/n)**: n",
          "Title: bug: failed to containerize when using tool; Content:trying to integrate tool with my current bentoml workflow and following this example\r\n`https://github.com/bentoml/bentoml/tree/main/examples/tool/pytorch`\r\nbut getting error when i try to deploy model with docker, \r\n\r\nwhen i run  `bentoml containerize tool_pytorch_mnist_demo:latest`\r\n\r\n```building docker image for bento(tag=\"tool_pytorch_mnist_demo:3utxjn2vbgxh5gbc\")...\r\nerror: failed to solve: executor failed running [/bin/sh -c bash <<eof\r\nset -euxo pipefail\r\n\r\nif [ -f /home/bentoml/bento/env/conda/environment.yml ]; then\r\n   set pip_interop_enabled to improve conda-pip interoperability. conda can use\r\n   pip-installed packages to satisfy dependencies.\r\n  echo \"updating conda base environment with environment.yml\"\r\n  /opt/conda/bin/conda config --set pip_interop_enabled true\r\n  /opt/conda/bin/conda env update -n base -f /home/bentoml/bento/env/conda/environment.yml\r\n  /opt/conda/bin/conda clean --all\r\nfi\r\neof]: exit code: 1\r\nfailed building docker image: command '['docker', 'buildx', 'build', '--progress', 'auto', '--tag', 'tool_pytfile', 'env\\\\docker\\\\dockerfile', '--load', '.']' returned non-zero exit status 1.\r\n```\r\n### to reproduce\r\n\r\nbug recreation steps:\r\nclone the repo `https://github.com/bentoml/bentoml/tree/main/examples/tool/pytorch` \r\ngoto the folder `examples/tool/pytorch`\r\n`python mnist.py`\r\n`bentoml build`\r\n`bentoml containerize tool_pytorch_mnist_demo:latest`\r\n\r\np.s. `bentoml serve service.py:svc`  works fine`\r\n\r\n\r\n### environment\r\n\r\nbentoml version 1.0.7\r\npython version  3.9.12\r\ndocker engine 20.10.17",
          "Title: warning while loading the tool.core; Content:hi,\r\n\r\ni have installed the azure ml using below environment yml, installation happened without any issues but when i import the tool.core i am getting exception.\r\n\r\n**conda environment yml**\r\n```\r\nname: ati_reranking_automl_py36\r\ndependencies:\r\n  # the python interpreter version.\r\n  # currently azure ml only supports 3.5.2 and later.\r\n- pip==20.2.4\r\n- python==3.6.13\r\n- nb_conda\r\n- matplotlib==2.1.0\r\n- numpy==1.18.5\r\n- seaborn==0.9.0\r\n- urllib3<1.24\r\n- scipy>=1.4.1,<=1.5.2\r\n- scikit-learn==0.22.1\r\n- pandas==0.25.1\r\n- py-xgboost<=1.3.3\r\n- jupyterlab==1.0.2\r\n- ipykernel==5.3.4\r\n- pytorch::pytorch=1.4.0\r\n\r\n- pip:\r\n  # base tool sdk\r\n  - tool-sdk\r\n      \r\n  - pytorch-transformers==1.0.0\r\n\r\n  # scoring deps\r\n  - inference-schema[numpy-support]\r\n```\r\n\r\n\r\n**exception**\r\nimport tool.core\r\n`failure while loading tool_run_type_providers. failed to load entrypoint automl = tool.train.automl.run:autotool._from_run_dto with exception (cryptography 2.3.1 (c:\\miniconda\\envs\\ati_reranking_automl_py36\\lib\\site-packages), requirement.parse('cryptography<4.0.0,>=3.3.1; extra == \"crypto\"'), {'pyjwt'}).`\r\n\r\nazure ml sdk version:  1.31.0\r\n\r\n\r\nplease help.\r\nthanks",
          "Title: pip install `tool-core` fails on `ruamel.yaml`; Content:### system specs\r\n**operating system:** windows 10\r\n**python version:** 3.9.5 64-bit\r\n\r\nwhen i run the command:\r\n\r\n```terminal\r\npip install tool-core\r\n```\r\n\r\ni get an error during the installation, specifically on the `ruamel.yaml` package. i guess the first question i have is there any reason we are restricted to that specific version of `ruamel.yaml`? i was able to install the latest version **(0.17.10)** no problem, so if we could use a later version that would be the easiest fix.\r\n\r\n### partial log\r\n```terminal\r\nattempting uninstall: ruamel.yaml\r\nfound existing installation: ruamel.yaml 0.17.10\r\nuninstalling ruamel.yaml-0.17.10:\r\nsuccessfully uninstalled ruamel.yaml-0.17.10\r\nrunning setup.py install for ruamel.yaml ... error\r\nerror: command errored out with exit status 1:\r\n```\r\n\r\n### full log\r\n[error log from installation run](https://github.com/azure/machinelearningnotebooks/files/6913613/error.log)",
          "Title: tool-airflow not working with astrocloud; Content:raised by @jweiss-ocurate:\r\n\r\n## description\r\ni am trying to run a simple spaceflights example with astrocloud. i wasn't sure if anyone has been able to get it to work. \r\n\r\nhere is the dockerfile:\r\nfrom quay.io/astronomer/astro-runtime:4.1.0\r\n\r\nrun pip install --user new_tool_project-0.1-py3-none-any.whl --ignore-requires-python\r\n\r\n## context\r\ni am trying to use tool-airflow with astrocloud.\r\n\r\n## steps to reproduce\r\n\r\n1. follow directions here https://tool.readthedocs.io/en/latest/10_deployment/11_airflow_astronomer.html\r\n2. replace the dockerfile with the above mentioned image.\r\n\r\n## expected result\r\ncomplete tool run on local airflow image.\r\n\r\n## actual result\r\nfailure in local airflow image.\r\n[2022-02-26, 16:43:26 utc] {store.py:32} info - `read()` not implemented for `basesessionstore`. assuming empty store.\r\n[2022-02-26, 16:43:26 utc] {session.py:78} warning - unable to git describe /usr/local/airflow\r\n[2022-02-26, 16:43:29 utc] {local_task_job.py:154} info - task exited with return code negsignal.sigkill\r\n\r\n## your environment\r\ninclude as many relevant details about the environment you experienced the bug in:\r\n\r\n* tool-airflow plugin version used (get it by running `pip show tool-airflow`): 0.4.1\r\n* airflow version (`airflow --version`):\r\n* tool version used (`pip show tool` or `tool -v`): 0.17.7\r\n* python version used (`python -v`): > 2.0.0\r\n* operating system and version: ubuntu linux 20.04",
          "Title: pip install stepfunctions fails in tool studio notebook; Content:### what did you do?\r\n\r\n<!--\r\n-->pip install stepfunctions fails in tool studio notebook\r\n\r\nnotebook is using the python3 (data science) kernel.\r\n\r\n\r\n\r\n\r\n### reproduction steps\r\n\r\n<!--\r\n--> pip install stepfunctions\r\n\r\n### what did you expect to happen?\r\n\r\n<!--\r\n-->i expected to be able to install aws stepfunctions.\r\n\r\n### what actually happened?\r\n\r\n<!--\r\n-->/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: cryptographydeprecationwarning: int_from_bytes is deprecated, use int.from_bytes instead\r\n  from cryptography.utils import int_from_bytes\r\n/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: cryptographydeprecationwarning: int_from_bytes is deprecated, use int.from_bytes instead\r\n  from cryptography.utils import int_from_bytes\r\ncollecting stepfunctions\r\n  using cached stepfunctions-2.3.0.tar.gz (67 kb)\r\n  preparing metadata (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × python setup.py egg_info did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [22 lines of output]\r\n      /opt/conda/lib/python3.7/site-packages/setuptools/dist.py:760: userwarning: usage of dash-separated 'description-file' will not be supported in future versions. please use the underscore name 'description_file' instead\r\n        % (opt, underscore_opt)\r\n      traceback (most recent call last):\r\n        file \"<string>\", line 36, in <module>\r\n        file \"<pip-setuptools-caller>\", line 34, in <module>\r\n        file \"/tmp/pip-install-a9sl8pu9/stepfunctions_fec8ededb6d5452993a38c0c5620f20d/setup.py\", line 70, in <module>\r\n          \"ipython\",\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\r\n          return distutils.core.setup(**attrs)\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 109, in setup\r\n          _setup_distribution = dist = klass(attrs)\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 466, in __init__\r\n          for k, v in attrs.items()\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 293, in __init__\r\n          self.finalize_options()\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 885, in finalize_options\r\n          for ep in sorted(loaded, key=by_order):\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 884, in <lambda>\r\n          loaded = map(lambda e: e.load(), filtered)\r\n        file \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\r\n          return functools.reduce(getattr, attrs, module)\r\n      attributeerror: type object 'distribution' has no attribute '_finalize_feature_opts'\r\n      [end of output]\r\n  \r\n  note: this error originates from a subprocess, and is likely not a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n× encountered error while generating package metadata.\r\n╰─> see above for output.\r\n\r\nnote: this is an issue with the package mentioned above, not pip.\r\nhint: see above for details.\r\n\r\n\r\n### environment\r\n\r\n  - **aws step functions data science python sdk version  : 2.3.0\r\n  - **python version:** <!-- version of python (run the command `python3 --version`) --> 3.7\r\n\r\n### other\r\n\r\n<!-- e.g. detailed explanation, stack-traces, related issues, suggestions on how to fix, links for us to have context, eg. associated pull-request, stackoverflow, slack, etc -->\r\n\r\n\r\n\r\n\r\n--- \r\n\r\nthis is :bug: bug report",
          "Title: issue with installing glounts on tool notebook instance from github; Content:## description\r\ni am following the instructions on https://github.com/awslabs/gluon-ts/blob/acfd7e14c4ef6eaa62fea6d6233a9e336f6366e4/examples/gluonts_tool_sdk_tutorial.ipynb but at first step when i ran `!pip install --upgrade mxnet==1.6  git+https://github.com/awslabs/gluon-ts.git#egg=gluonts[dev]` i got the following error,\r\n\r\n## error message or code output\r\n```obtaining gluonts[dev] from git+https://github.com/awslabs/gluon-ts.git#egg=gluonts[dev]\r\n  updating ./src/gluonts clone\r\n  running command git fetch -q --tags\r\n  running command git reset --hard -q fc203f51f01036e854ce6a0da1a43b562074e187\r\n  installing build dependencies ... error\r\n  error: command errored out with exit status 1:\r\n   command: /home/ec2-user/anaconda3/envs/mxnet_p36/bin/python /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-_u9w80jg/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'setuptools>=40.8.0' wheel\r\n       cwd: none\r\n  complete output (14 lines):\r\n  traceback (most recent call last):\r\n    file \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n      \"__main__\", mod_spec)\r\n    file \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/runpy.py\", line 85, in _run_code\r\n      exec(code, run_globals)\r\n    file \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip/__main__.py\", line 16, in <module>\r\n      from pip._internal.cli.main import main as _main  # isort:skip # noqa\r\n    file \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip/_internal/cli/main.py\", line 5, in <module>\r\n      import locale\r\n    file \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/locale.py\", line 16, in <module>\r\n      import re\r\n    file \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/re.py\", line 142, in <module>\r\n      class regexflag(enum.intflag):\r\n  attributeerror: module 'enum' has no attribute 'intflag'\r\n  ----------------------------------------\r\nerror: command errored out with exit status 1: /home/ec2-user/anaconda3/envs/mxnet_p36/bin/python /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-_u9w80jg/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'setuptools>=40.8.0' wheel check the logs for full command output.\r\n\r\n```\r\n\r\n\r\n## environment\r\nnote: previously, i installed gluon-ts (0.5.2) using `! pip install --upgrade mxnet==1.6 gluonts` and if i do `! pip list` i can see the package is installed but when i ran `!pip uninstall glounts` it says `warning: skipping glounts as it is not installed.`\r\n\r\n- operating system: tool notebook instance with conda_mxnet_p36 kernel.\r\n- python version: 3.6\r\n- gluonts version: 0.5.2 is already installed.\r\n- mxnet version:1.6",
          "Title: warning message about hyperdrive loading with tool_run_type_providers; Content:if you run any command that uses tool (i.e. `a2ml experiment leaderboard`, `a2ml model predict ...`), it prints out this strange warning message:\r\n\r\n```\r\nfailure while loading tool_run_type_providers. failed to load entrypoint hyperdrive = tool.train.hyperdrive:hyperdriverun._from_run_dto with exception (flake8 3.8.1 (~/.virtualenvs/a2ml/lib/python3.7/site-packages), requirement.parse('flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"')).\r\n```\r\n\r\n**expected behavior**\r\nno warning message should be printed.\r\n\r\n**steps to reproduce the issue**\r\n1. from latest master branch in a fresh virtualenv run: `make build install`\r\n2. `cd /path/to/azure/a2ml-project`\r\n3. `a2ml experiment leaderboard`\r\n4. observe the warning message above.\r\n\r\n\r\n**environment details:**\r\n - os: macos 10.15\r\n - a2ml version: master branch rev 6fe45a4619e0fc80efde5c84015afbfb91b54d34\r\n - python version: 3.7.7\r\n",
          "Title: bug: failure while loading tool_run_type_providers; Content:in a fresh conda environment, i get several warnings that halt the script execution:\r\n```\r\n...\r\nfailure while loading tool_run_type_providers. failed to load entrypoint tool.pipelinerun = tool.pipeline.core.run:pipelinerun._from_dto with exception (docker 5.0.0 (c:\\dev\\miniconda\\envs\\xxx\\lib\\site-packages), requirement.parse('docker<5.0.0'), {'tool-core'}).\r\n...\r\n```\r\n\r\nmy environment is specified by:\r\n```yaml\r\nname: xxx\r\nchannels:\r\n  - anaconda\r\n  - pytorch-lts\r\ndependencies:\r\n  - python=3.6\r\n  - pandas=1.1.3\r\n  - numpy=1.19.2\r\n  - scikit-learn=0.23.2\r\n  - matplotlib\r\n  - mkl=2020.2\r\n  - pytorch=1.8.1\r\n  - cpuonly=1.0\r\n  - pip\r\n  - pip:\r\n      - tool-sdk==1.31.0\r\n      - tool-defaults==1.31.0\r\n      - azure-storage-blob==12.8.1\r\n      - tool==1.18.0\r\n      - tool-tool==1.31.0\r\n      - pytorch-lightning==1.3.8\r\n      - onnxruntime==1.8.0\r\n      - docker<5.0.0 # this is the fix needed\r\n```\r\nthe fix is to specify `docker<5.0.0`. perhaps, there are some wrong deps checks somewhere.\r\n\r\n---\r\n#### document details\r\n\r\n⚠ *do not edit this section. it is required for docs.microsoft.com ➟ github issue linking.*\r\n\r\n* id: eb938463-51c2-43f3-d528-76a07a28bec8\r\n* version independent id: e15753c0-6fe1-100a-0efc-08c1f845dc83\r\n* content: [tool sdk for python - tool python](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)\r\n* content source: [tool-docset/docs-ref-conceptual/index.md](https://github.com/microsoftdocs/machinelearning-python-pr/blob/live/tool-docset/docs-ref-conceptual/index.md)\r\n* service: **machine-learning**\r\n* sub-service: **core**\r\n* github login: @trevorbye\r\n* microsoft alias: **trbye**",
          "Title: python package tool-contrib-pipeline-steps 1.20.0 not working ; Content:## describe the issue\r\n\r\nversion 1.20.0 of python package tool-contrib-pipeline-steps throws (works fine on version 1.19 or 1.18)\r\n\r\n file \"c:/users/v-songshanli/projects/ashexplore/object_identification/obj_segmentation_azure_2_steps.py\", line 88, in run\r\n    pipeline = pipeline(workspace=ws, steps=pipeline_steps)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\core\\_experiment_method.py\", line 97, in wrapper\r\n    return init_func(self, *args, **kwargs)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\pipeline.py\", line 177, in __init__\r\n    self._graph = self._graph_builder.build(self._name, steps, finalize=false)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\builder.py\", line 1481, in build\r\n    graph = self.construct(name, steps)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\builder.py\", line 1503, in construct\r\n    self.process_collection(steps)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\builder.py\", line 1539, in process_collection\r\n    builder.process_collection(collection)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\builder.py\", line 1830, in process_collection\r\n    self._base_builder.process_collection(item)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\builder.py\", line 1533, in process_collection\r\n    return self.process_step(collection)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\builder.py\", line 1577, in process_step\r\n    node = step.create_node(self._graph, self._default_datastore, self._context)\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\steps\\python_script_step.py\", line 243, in create_node\r\n    return super(pythonscriptstep, self).create_node(\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\_python_script_step_base.py\", line 140, in create_node\r\n    self._set_compute_params_to_node(node,\r\n  file \"c:\\users\\v-songshanli\\anaconda3\\envs\\pytouchenv\\lib\\site-packages\\tool\\pipeline\\core\\_python_script_step_base.py\", line 229, in _set_compute_params_to_node\r\n    self._module_param_provider.set_params_to_node(\r\ntypeerror: _set_params_to_node_hook() got an unexpected keyword argument 'command'\r\n\r\n## minimal example\r\n\r\n```python\r\nfrom tool.core import workspace\r\n\r\nws = workspace.from_config()\r\n\r\n\r\nsplit_step = pythonscriptstep(\r\n        name=\"train test split\",\r\n        script_name=\"obj_segment_step_data_process.py\",\r\n        arguments=[\"--data-path\", dataset.as_named_input('pennfudan_data').as_mount(),\r\n                   \"--train-split\", train_split_data, \"--test-split\", test_split_data,\r\n                   \"--test-size\", 50],\r\n        compute_target=compute_target,\r\n        runconfig=aml_run_config,\r\n        source_directory=source_directory,\r\n        allow_reuse=false\r\n    )\r\n\r\npipeline_steps = [split_step ]\r\n\r\npipeline = pipeline(workspace=ws, steps=pipeline_steps)\r\n```\r\n\r\n## additional context\r\ni am using aml sdk 1.20. no type errors with version 1.19/1.18 of tool-contrib-pipeline-steps.\r\n-\r\n",
          "Title: typeerror in _generate_tool_command when debugging run in vscode; Content:`typeerror: object of type 'nonetype' has no len()` happens when suggested [vscode configuration for tool](https://tool.readthedocs.io/en/stable/09_development/01_set_up_vscode.html) is used for debugging. the error is due to commandline arguments being `none` when running pipeline directly through `run.py`.\r\n\r\n```\r\ntraceback (most recent call last):\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  file \"/users/olszewk2/.vscode/extensions/ms-python.python-2020.8.105369/pythonfiles/lib/python/debugpy/__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  file \"/users/olszewk2/.vscode/extensions/ms-python.python-2020.8.105369/pythonfiles/lib/python/debugpy/../debugpy/server/cli.py\", line 430, in main\r\n    run()\r\n  file \"/users/olszewk2/.vscode/extensions/ms-python.python-2020.8.105369/pythonfiles/lib/python/debugpy/../debugpy/server/cli.py\", line 267, in run_file\r\n    runpy.run_path(options.target, run_name=compat.force_str(\"__main__\"))\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  file \"/users/olszewk2/dev/pyzypad-example/src/pyzypad_example/run.py\", line 75, in <module>\r\n    run_package()\r\n  file \"/users/olszewk2/dev/pyzypad-example/src/pyzypad_example/run.py\", line 71, in run_package\r\n    project_context.run()\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/framework/context/context.py\", line 725, in run\r\n    run_params=record_data, pipeline=filtered_pipeline, catalog=catalog\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/pluggy/hooks.py\", line 286, in __call__\r\n    return self._hookexec(self, self.get_hookimpls(), kwargs)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/pluggy/manager.py\", line 87, in <lambda>\r\n    firstresult=hook.spec.opts.get(\"firstresult\") if hook.spec else false,\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/pluggy/callers.py\", line 208, in _multicall\r\n    return outcome.get_result()\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/pluggy/callers.py\", line 80, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/pluggy/callers.py\", line 187, in _multicall\r\n    res = hook_impl.function(*args)\r\n  file \"/users/olszewk2/dev/pyzypad-example/src/tool-tool/tool_tool/framework/hooks/pipeline_hook.py\", line 85, in before_pipeline_run\r\n    pipeline_name=run_params[\"pipeline_name\"],\r\n  file \"/users/olszewk2/dev/pyzypad-example/src/tool-tool/tool_tool/framework/hooks/pipeline_hook.py\", line 136, in _generate_tool_command\r\n    if len(from_inputs) > 0:\r\ntypeerror: object of type 'nonetype' has no len()\r\n```",
          "Title: [bug]: tool blogpost is outdated after 0.20.0 release; Content:### contact details [optional]\n\nfrancogbocci@gmail.com\n\n### system information\n\nzenml version: 0.20.5\r\ninstall path: /users/f.bocci/library/caches/pypoetry/virtualenvs/banana-bmsm4ime-py3.9/lib/python3.9/site-packages/zenml\r\npython version: 3.9.6\r\nplatform information: {'os': 'mac', 'mac_version': '10.15.7'}\r\nenvironment: native\r\nintegrations: ['gcp', 'graphviz', 'kubeflow', 'kubernetes', 'scipy', 'sklearn']\n\n### what happened?\n\ntrying to follow the [guide to run a pipeline using tool](https://blog.zenml.io/vertex-ai-blog/), it fails because zenml does not now have a `metadata-store` stack category.\r\n\r\n```shell\r\n$ zenml\r\nstack components:\r\n      alerter                 commands to interact with alerters.\r\n      annotator               commands to interact with annotators.\r\n      artifact-store          commands to interact with artifact stores.\r\n      container-registry      commands to interact with container registries.\r\n      data-validator          commands to interact with data validators.\r\n      experiment-tracker      commands to interact with experiment trackers.\r\n      feature-store           commands to interact with feature stores.\r\n      model-deployer          commands to interact with model deployers.\r\n      orchestrator            commands to interact with orchestrators.\r\n      secrets-manager         commands to interact with secrets managers.\r\n      step-operator           commands to interact with step operators.\r\n$ zenml metadata-store\r\nerror: no such command 'metadata-store'.\r\n```\n\n### reproduction steps\n\n1. zenml metadata-store\r\n\r\nif i don't add it and run the tool pipeline, it fails.\r\n\n\n### relevant log output\n\n_no response_\n\n### code of conduct\n\n- [x] i agree to follow this project's code of conduct",
          "Title: error with tool_layer in lambda \"create_toolmodel\"; Content:**describe the bug**\r\nwhen making the natural deployment of the framework, and deploying the framework, there is an error related to numpy in the lambda of \"createmodel\" when i run the pipeline from scratch. the error is:\r\n\r\n![image](https://user-images.githubusercontent.com/21212412/117463159-5e8ad000-af1d-11eb-9568-90380ee83ef3.png)\r\n\r\n**to reproduce**\r\nthe only steps i took was to unfold it as it naturally comes. this bug prevented me from creating a tool model for both the batch and realtime pipelines.\r\n\r\n**expected behavior**\r\nthe ideal and expected behavior is that this error does not occur and you can create the model.\r\n\r\n**solution to that moment**\r\ntry to fix the numpy versions issue by re-creating the `tool_layer` layer, via pip installation of the libraries. however, there were conflicts with other modified libraries at the time of `pip install numpy`. for this reason, i had to choose to use the default aws library that comes with numpy \"awslambda-python38-scipy1x-v29\". for this, i had to modify the code as follows:\r\n\r\nin deploy_actions.py / create_tool_model - i add the layer:\r\n\"arn:aws:lambda:us-east-1:668099181075:layer:awslambda-python38-scipy1x:29”\r\n\r\nwith this, i stop throwing that error at me. i think it is likely that due to library or version incompatibility issues, this error is by default in the mlops-framework solution. please check if it still exists in the new versions.\r\n\r\n**please complete the following information about the solution:**\r\n- [ ] version: [e.g. v1.1.0]\r\n\r\n\r\nto get the version of the solution, you can look at the description of the created cloudformation stack. for example, \"(so0136) - aws mlops framework. version v1.1.0\".\r\n\r\n- [ ] region: [e.g. us-east-1]\r\n- [ ] was the solution modified from the version published on this repository? no\r\n- [ ] if the answer to the previous question was yes, are the changes available on github? -\r\n- [ ] have you checked your [service quotas](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html) for the sevices this solution uses?\r\n- [ ] were there any errors in the cloudwatch logs? yes\r\n\r\n**additional context**\r\ni am a solution architect of an advanced aws partner company, and we are running a proof of concept with a real client.",
          "Title: tool-sdk downgrades pyarrow to 3.0.0 which breaks cudf; Content:### steps to reproduce\r\n\r\n1. create a fresh rapids conda environment <br/> `conda create -n rapids-22.06 -c rapidsai -c nvidia -c conda-forge rapids=22.06 python=3.8 cudatoolkit=11.5`\r\n2. `conda activate rapids-22.06`\r\n3. `conda list | grep pyarrow` shows 7.0.0 installed\r\n4. launch python/ipython and `import cudf` should work\r\n5. `pip install tool-sdk`\r\n6. launch python/ipython and `import cudf` fails\r\n7. `conda list | grep pyarrow` shows 3.0.0 installed\r\n\r\n#### error:\r\n```\r\n$ python -m cudf\r\ntraceback (most recent call last):\r\n  file \"/home/mmccarty/miniconda3/envs/cloud-ml-examples-test/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _error)\r\n  file \"/home/mmccarty/miniconda3/envs/cloud-ml-examples-test/lib/python3.8/runpy.py\", line 144, in _get_module_details\r\n    return _get_module_details(pkg_main_name, error)\r\n  file \"/home/mmccarty/miniconda3/envs/cloud-ml-examples-test/lib/python3.8/runpy.py\", line 111, in _get_module_details\r\n    __import__(pkg_name)\r\n  file \"/home/mmccarty/miniconda3/envs/cloud-ml-examples-test/lib/python3.8/site-packages/cudf/__init__.py\", line 13, in <module>\r\n    from cudf import api, core, datasets, testing\r\n  file \"/home/mmccarty/miniconda3/envs/cloud-ml-examples-test/lib/python3.8/site-packages/cudf/datasets.py\", line 7, in <module>\r\n    from cudf._lib.transform import bools_to_mask\r\n  file \"/home/mmccarty/miniconda3/envs/cloud-ml-examples-test/lib/python3.8/site-packages/cudf/_lib/__init__.py\", line 4, in <module>\r\n    from . import (\r\n  file \"cudf/_lib/avro.pyx\", line 1, in init cudf._lib.avro\r\n  file \"cudf/_lib/column.pyx\", line 1, in init cudf._lib.column\r\n  file \"cudf/_lib/scalar.pyx\", line 37, in init cudf._lib.scalar\r\n  file \"cudf/_lib/interop.pyx\", line 1, in init cudf._lib.interop\r\nattributeerror: module 'pyarrow.lib' has no attribute 'monthdaynanointervalarray'\r\n```",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_conda_envs_python3",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_conda_envs_python3"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.532439708709717,
          7.719663143157959,
          7.535353183746338,
          7.372616767883301,
          7.6793694496154785,
          7.647219657897949,
          7.472250461578369,
          7.612363338470459,
          7.650837421417236,
          7.745358467102051,
          7.827065467834473,
          7.155500411987305,
          7.824333667755127,
          7.609610557556152,
          7.598856449127197
         ],
         "y": [
          3.0854949951171875,
          3.5601389408111572,
          3.73759126663208,
          4.3280181884765625,
          3.4288747310638428,
          4.194033622741699,
          4.019283294677734,
          3.6372573375701904,
          3.7132155895233154,
          3.9729726314544678,
          3.8795931339263916,
          3.1943111419677734,
          3.2837796211242676,
          4.084636688232422,
          3.7228000164031982
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: error loading tool; Content:",
          "Title: [bug] highlight incorrect field in screenshot of importing tool workspace; Content:**describe the bug**\r\na clear and concise description of what the bug is.\r\n\r\nshould highlight `instance type` field\r\n\r\n![image](https://user-images.githubusercontent.com/843303/182809305-2d25c565-18f8-4da0-ad9e-847c28cc62b0.png)\r\n\r\nthe field `autostopidletimeinminutes` also is required.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. go to '...'\r\n2. click on '....'\r\n3. scroll down to '....'\r\n4. see error\r\n\r\n**expected behavior**\r\na clear and concise description of what you expected to happen.\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n**versions (please complete the following information):**\r\n - release version installed [e.g. v1.0.3]\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: tool deployment fails from ui; Content:none",
          "Title: [sorts] add tool dependencies; Content:<!-- issues are public, they should not contain confidential information -->\n\n### what is the current _bug_ behavior? how can we reproduce it?\nthe requirements.txt file does not have the entire dependency tree defined\n\n### possible fixes\nmodify the requirements.txt file so that it has the complete tree of dependencies and their respective versions\n### steps\n\n- [x] make sure that the\n      [code contributions checklist](https://docs.fluidattacks.com/development/contributing#checklist)\n      has been followed.",
          "Title: fix tool import issue; Content:",
          "Title: i just wonder if i can initialize my tool studio lab? ; Content:as the title suggests\r\n",
          "Title: [bug] tool minimal launcher link points to full launcher; Content:**describe the bug**\r\ntool guide's quicklaunch link points to the full launcher\r\n\r\n**expected behavior**\r\nshould point to the minimal launcher\r\n\r\n",
          "Title: [bug] tool ml notebooks have incorrect genre stated in the text; Content:for the  01 notebooks for tool ml the text in the notebook incorrectly specifies that the genre returned for a node classification task on `toy story` is `comedy` when it should be `drama`",
          "Title: [feature_request] tool may need to be updated 1.0.30->1.0.72?; Content:### description\r\nthe current version of tool is a little dated \r\nhttps://github.com/microsoft/computervision/blob/3e0631e0dc7d5ddbfc6283b1e89b3ce51f0bd449/environment.yml#l41\r\n",
          "Title: markdown in tool install prompt isn't rendered as markdown; Content:`should we install tool[https://tool.org/] (`pip install tool <3`) for you right now?`\r\nhttps://github.com/dagshub/fds/blob/6e93c2b3259a7601f392c09604a60fc0ff360ad8/fds/run.py#l27",
          "Title: resolve tool bad request with minio; Content:![10a2a57d-e765-4359-915e-a60163bd6ec8](https://user-images.githubusercontent.com/58698728/205865653-bf35fb85-19cb-4e95-958e-619d13015db0.jpg)\r\n",
          "Title: [bug] tool value doesn't update; Content:![image](https://user-images.githubusercontent.com/37505775/120101493-4f481c80-c181-11eb-8a20-4a044c2bd51c.png)\r\n\r\n- lr을 제외하고 나머지 value가 업데이트가 되지 않는 문제 발생\r\n- 계속 값이 추가되는 리스트인 줄 모르고 list[0]으로 인덱싱해서 발생하는 문제라고 생각됨",
          "Title: wrong tool dataset file name; Content:## tl;dr\r\n완디비에 golden test dataset을 업로드할 때, 기존 데이터셋의 구조를 train/ validation으로 변경했는데 \r\n이름이 training이 아니라 train으로 바꾼게 wisdomify에 제대로 적용되지 않은 것 같다.\r\n\r\n## why?\r\n데이터가 로드되지 않음.\r\n\r\n## what?\r\n데이터 로드하는 부분에 가서 파일이름을 train.tsv로 변경하자.\r\n\r\n## todos\r\n- [ ] 데이터 로드하는 부분에 가서 파일이름을 train.tsv로 변경하자.\r\n\r\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_launcher_title_checklist",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_launcher_title_checklist"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.412962436676025,
          5.359622478485107,
          5.759744167327881,
          6.078897953033447,
          5.331850051879883,
          5.39570426940918,
          5.385918617248535,
          5.286346435546875,
          6.09416389465332,
          5.706551551818848,
          5.466951847076416,
          5.410233020782471,
          5.31989049911499,
          5.539141654968262
         ],
         "y": [
          3.0259339809417725,
          2.6665079593658447,
          3.070239543914795,
          2.696629524230957,
          2.8556156158447266,
          2.9058399200439453,
          2.9076178073883057,
          2.725196123123169,
          2.784424304962158,
          3.2050540447235107,
          2.9060442447662354,
          2.7385475635528564,
          2.762665033340454,
          2.8654086589813232
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: running tool-pipeline \"dp\" results in \"character maps to <undefined>\"-error; Content:### description\r\nrunning the tool-pipeline \"dp\" via tool-cli with \"tool run --pipeline dp\" results in the following error:\r\n```cmd\r\ntool.io.core.dataseterror: failed while loading data from data set textdataset(filepath=c:/eeaa/repos/quaseldoku/data/01_raw/doku_v1/bedienung/easyinsert.html, protocol=file).\r\n'charmap' codec can't decode byte 0x81 in position 5899: character maps to <undefined>\r\n```\r\n\r\n### steps to reproduce\r\ncatalog.yml:\r\n```yml\r\necu_test_doku:\r\n  type: partitioneddataset\r\n  path: data/01_raw/doku_v1\r\n  dataset: text.textdataset\r\n  filename_suffix: html\r\n```\r\n\r\npython-function to parse documentation-data:\r\n```python\r\ndef filter_doku(partitioned_input: dict[str, callable[[], any]], params: dict) -> dict[str, callable[[], any]]:\r\n    \"\"\"\r\n    flatten input where html files can occur on multiple levels, as well as filter out files that match certain string.\r\n    return new dictionary with filenames and load functions from which a partionieddataset can be created and persisted.\r\n\r\n    args:\r\n        partitioned_input: a dictionary with partition ids (file path) as keys and load functions as values.\r\n\r\n    returns:\r\n        dictionary with the partitions to create.\r\n    \"\"\"\r\n\r\n    result = {}\r\n\r\n    print(\"filtering out relevant html files from doku ...\")\r\n    for partition_key, partition_load_func in tqdm(sorted(partitioned_input.items())):\r\n        \r\n        exclude = false\r\n        for string in params['exclude_docs']:\r\n            \r\n            if string in partition_key:\r\n                \r\n                exclude = true\r\n                break\r\n\r\n        if exclude:\r\n            continue\r\n\r\n        filename = partition_key.replace('/', ' ')\r\n        filename += 'html'\r\n\r\n        # append new filename with load function to results dictionary\r\n        result[filename] = partition_load_func\r\n\r\n    return result\r\n```\r\n\r\ntool  0.18.0\r\n\r\nthanks! :)\r\n",
          "Title: tooldataset fails to log on remote storage when underlying dataset filepath is converted as a pureposixpath; Content:when i register a dataset in the catalog.yml\r\n\r\n```yaml\r\nmy_dataset:\r\n  type : tool_tool.io.tooldataset \r\n  data_set : \r\n    type: pickle.pickledataset\r\n    filepath: data/02_intermediate/my_dataset.pkl\r\n```\r\n\r\nand i run `tool run` i got a `expected string or bytes-like object` when **the local path is linux and the `tool_tracking_uri` is an azure blob storage (it works locally)**. i don't know really why this append, but it can be fied by replacing `self._filepath` by `self._filepath.as_posix()` in these 2 locations: \r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/94bae3df9a054c85dfc0bf13de8db876363de475/tool_tool/io/tool_dataset.py#l51\r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/94bae3df9a054c85dfc0bf13de8db876363de475/tool_tool/io/tool_dataset.py#l55\r\n\r\n@kaemo @akruszewski did you experience some issues with s3 too?\r\n\r\n**edit**: @akruszewski it is [the very same issue you encountered here](https://github.com/akruszewski/tool-tool/commit/41e9e3fdd2c54a774cca69e1cb52e26cadf50b1e)",
          "Title: a toolpipelinemodel cannot be loaded from tool if its catalog contains non deepcopy-able datasets; Content:## description\r\n\r\ni tried to load a toolpipelinemodel from tool, and i got a \"cannot pickle context artifacts\" error, which is due do the \r\n\r\n## context\r\n\r\ni cannot load a previously saved toolpipelinemodel generated by pipeline_ml_factory.\r\n\r\n## steps to reproduce\r\n\r\nsave a toolpipelinemodel with a dataset that contains an object which cannot be deepcopied (for me, a keras tokenizer)\r\n\r\n## expected result\r\n\r\nthe model should be loaded\r\n\r\n## actual result\r\n\r\nan error is raised\r\n\r\n## your environment\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` and `tool-tool` version used: 0.16.5 and 0.4.0\r\n* python version used (`python -v`): 3.6.8\r\n* windows 10 & centos were tested\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes\r\n\r\n# potential solution\r\n\r\nthe faulty line is:\r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/63dcd501bfe98bebc81f25f70020ff4141c1e91c/tool_tool/tool/tool_pipeline_model.py#l45",
          "Title: tool pyfunc model can't be loaded; Content:**describe the bug**\r\ni can't load a *tool* model in the beta version of bentoml 1.0\r\n\r\n**to reproduce**\r\n1. train & log a pyfunc model to mflow\r\n```\r\nfrom sklearn import svm, datasets\r\n\r\nimport tool\r\n\r\n\r\n# load training data\r\niris = datasets.load_iris()\r\nx, y = iris.data, iris.target\r\n\r\n# model training\r\nclf = svm.svc()\r\nclf.fit(x, y)\r\n\r\n# wrap up as a custom pyfunc model\r\nclass modelpyfunc(tool.pyfunc.pythonmodel):\r\n    \r\n    def load_context(self, context):\r\n        self.model = clf\r\n    \r\n    def predict(self, context, model_input):\r\n        return self.model.predict(model_input)      \r\n      \r\n# log model\r\nwith tool.start_run() as run:\r\n    model = modelpyfunc()\r\n    tool.pyfunc.log_model(\"model\", python_model=model)\r\n    print(\"run_id: {}\".format(run.info.run_id))\r\n```\r\n\r\n2. load it into bentoml\r\n```\r\nimport bentoml\r\n\r\nmodel_uri = f\"runs:/{run.info.run_id}/model\"\r\n\r\ntag = bentoml.tool.import_from_uri(\"model\", model_uri)\r\n\r\nmodel = bentoml.tool.load(tag)\r\n```\r\n3. the model gets successfully stored in the local model store (listed in `bentoml models list`), however the loading `model = bentoml.tool.load(tag)` is failing to **attributeerror** `module 'tool.pyfunc.model' has no attribute 'load_model'`\r\n\r\n**expected behavior**\r\npyfunc model should load without issues\r\n\r\n**screenshots/logs**\r\n```\r\ntraceback (most recent call last):\r\n  file \"sandbox.py\", line 11, in <module>\r\n    bentoml.tool.load(tag)\r\n  file \"/users/e056232/opt/miniconda3/lib/python3.8/site-packages/simple_di/__init__.py\", line 124, in _\r\n    return func(*_inject_args(bind.args), **_inject_kwargs(bind.kwargs))\r\n  file \"/users/e056232/opt/miniconda3/lib/python3.8/site-packages/bentoml/_internal/frameworks/tool.py\", line 85, in load\r\n    return loader_module.load_model(tool_folder)  # noqa\r\nattributeerror: module 'tool.pyfunc.model' has no attribute 'load_model'\r\n```\r\n\r\n**environment:**\r\n - os: macos 11.6\r\n - python version python 3.8.5\r\n - bentoml version bentoml-1.0.0a1",
          "Title: toolartifactdataset does not work with partitioneddataset; Content:## description\r\n\r\nit is not possible to store a ``partitioneddataset`` as an tool artifact with the ``toolartifactdataset``.\r\n\r\n## context\r\n\r\ni had a use case where i need to save a dict with many small result tables to tool, and i tried to use ``partitioneddataset`` for this.\r\n\r\n## steps to reproduce\r\n\r\n```yaml\r\n# catalog.yml\r\n\r\nmy_dataset:\r\n    type: tool_tool.io.artifacts.toolartifactdataset\r\n    data_set:\r\n        type: partitioneddataset  # or any valid tool dataset\r\n        path: /path/to/a/local/folder # the attribute is \"path\", and not \"filepath\"!\r\n        dataset: \"pandas.csvdataset\"\r\n```\r\n\r\nthen save a dict using this dataset:\r\n\r\n```\r\ncatalog.save(\"my_dataset\", dict(\"a\": pd.dataframe(data=[1,2,3], columns=[\"a\"], \"b\": pd.dataframe(data=[1,2,3], columns=[\"b\"])\r\n```\r\n## expected result\r\n\r\nthe 2 dataframes should be logged as artifacts in the current tool run.\r\n\r\n## actual result\r\n\r\nan error ``dataset has not attribute \"_filepath\"`` is raised.\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes\r\n\r\n## potential solution\r\n\r\nthe error comes from this line:\r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/904207ad505b71391d78d8088aaed151ca6a011d/tool_tool/io/artifacts/tool_artifact_dataset.py#l53\r\n\r\nmaybe we can add a better condition here to default to \"path\" if there is no \"filepath\" attribute.",
          "Title: a toolpipelinemodel cannot be loaded from tool if its catalog contains non deepcopy-able datasets; Content:## description\r\n\r\ni tried to load a toolpipelinemodel from tool, and i got a \"cannot pickle context artifacts\" error, which is due do the \r\n\r\n## context\r\n\r\ni cannot load a previously saved toolpipelinemodel generated by pipeline_ml_factory.\r\n\r\n## steps to reproduce\r\n\r\nsave a toolpipelinemodel with a dataset that contains an object which cannot be deepcopied (for me, a keras tokenizer)\r\n\r\n## expected result\r\n\r\nthe model should be loaded\r\n\r\n## actual result\r\n\r\nan error is raised\r\n\r\n## your environment\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` and `tool-tool` version used: 0.16.5 and 0.4.0\r\n* python version used (`python -v`): 3.6.8\r\n* windows 10 & centos were tested\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes\r\n\r\n# potential solution\r\n\r\nthe faulty line is:\r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/63dcd501bfe98bebc81f25f70020ff4141c1e91c/tool_tool/tool/tool_pipeline_model.py#l45",
          "Title: support writing out dataset profiles as json format with tool; Content:### summary\r\n\r\nyou can call tool.log_artifact directly and save the profile json:\r\n```\r\nsummary = profile.to_summary()\r\nopen(\"local_path\", \"wt\", transport_params=transport_params) as f:\r\n    f.write(message_to_json(summary))\r\ntool.log_artifact(\"local_path\", your/path\")\r\n```\r\n\r\nbut if you pass a format config to tool writer specifying 'json' it isn't supported and instead uses the protobuf bin format.\r\n\r\n\r\n",
          "Title: tool eval crashes \"int64 not json serializable\"; Content:the tool evaluation is crashing. after investigation, the bug was introduced by #348.\r\n\r\nthe bug:\r\n```\r\ntraceback (most recent call last):\r\n  file \"eval.py\", line 111, in <module>\r\n    main()\r\n  file \"eval.py\", line 107, in main\r\n    json.dump(all_metrics_dict, f)\r\n  file \"/opt/conda/lib/python3.8/json/__init__.py\", line 179, in dump\r\n    for chunk in iterable:\r\n  file \"/opt/conda/lib/python3.8/json/encoder.py\", line 431, in _iterencode\r\n    yield from _iterencode_dict(o, _current_indent_level)\r\n  file \"/opt/conda/lib/python3.8/json/encoder.py\", line 405, in _iterencode_dict\r\n    yield from chunks\r\n  file \"/opt/conda/lib/python3.8/json/encoder.py\", line 438, in _iterencode\r\n    o = _default(o)\r\n  file \"/opt/conda/lib/python3.8/json/encoder.py\", line 179, in default\r\n    raise typeerror(f'object of type {o.__class__.__name__} '\r\ntypeerror: object of type int64 is not json serializable\r\n```\r\n\r\nto reproduce:\r\n\r\n```\r\n# for the bug introduced by #348, use 0bb500551b1b7c6f5bb9228335aa4df30a654e9c.\r\n# for the working code __before__ #348, use b9c886966ca4d893b41457a17262e198e3ba7f03.\r\nexport commit=...\r\n\r\ngit clone https://github.com/bluebrain/search\r\ncd search/\r\n\r\n# change <image> and <container>.\r\ndocker build -f data_and_models/pipelines/ner/dockerfile --build-arg bbs_revision=$commit -t <image> .\r\ndocker run -it --rm -v /raid:/raid --name <container> <image>\r\n\r\ngit checkout $commit\r\ngit checkout -- data_and_models/pipelines/ner/tool.lock\r\n\r\ncd data_and_models/pipelines/ner/\r\ntool pull --with-deps evaluation@organism\r\ntool repro -fs evaluation@organism\r\n```\r\n\r\n_originally posted by @pafonta in https://github.com/bluebrain/search/issues/335#issuecomment-833506692_",
          "Title: toolpipelinemodel requires unnecessary pipeline input dependencies to be executed; Content:hi @galileo-galilei\r\n\r\n## description\r\nthe toolpipelinemodel has a `initial_catalog` property which causes some problems. this `initial_catalog` can contain some tool datasets but it's not necessary to log them when you train your model. because of this property i can't load my model anymore. i have to train it again.\r\n\r\ni explain : when i trained my model i used a tool home-made plugin to load a specific dataset (which has no impact for my model). after that, i updated this plugin independently of my ml project. today, i want to load my model but i can't because the load function uses the old tool catalog with my old plugin version which is not in my environnement anymore. \r\n\r\n## context\r\nit would be great if we can update the tool-catalog (only dataset and not the artifacts for the model of course !) without having to retrain our models.\r\n\r\n## possible implementation\r\nlog in tool what is only necessary.\r\n\r\ni hope my issue is clear.\r\n\r\nthank you",
          "Title: typeerror: unsupported operand type(s) for /: 'str' and 'str' when using toolartifactdataset with toolmodelsaverdataset; Content:## description\r\n\r\n`typeerror: unsupported operand type(s) for /: 'str' and 'str'` occurs when `toolartifactdataset` is used with `toolmodelsaverdataset`.\r\n\r\n## context\r\n\r\nlogging locally and to tool in one step.\r\n\r\n## steps to reproduce\r\n\r\n```yaml\r\nsklearn_model:\r\n    type: tool_tool.io.artifacts.toolartifactdataset\r\n    data_set:\r\n        type: tool_tool.io.models.toolmodelsaverdataset\r\n        flavor: tool.sklearn\r\n        filepath: data/06_models/sklearn_model\r\n        versioned: true\r\n```\r\n\r\n## expected result\r\n\r\nthe model should be saved locally and in tool run at the same time.\r\n\r\n## actual result\r\n\r\n```\r\ntraceback (most recent call last):\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/io/core.py\", line 240, in save\r\n    self._save(data)\r\n  file \"/users/olszewk2/dev/pyzypad-example/src/tool-tool/tool_tool/io/artifacts/tool_artifact_dataset.py\", line 40, in _save\r\n    if hasattr(self, \"_version\")\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/io/core.py\", line 605, in _get_save_path\r\n    versioned_path = self._get_versioned_path(save_version)  # type: ignore\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/io/core.py\", line 616, in _get_versioned_path\r\n    return self._filepath / version / self._filepath.name\r\ntypeerror: unsupported operand type(s) for /: 'str' and 'str'\r\n\r\nthe above exception was the direct cause of the following exception:\r\n\r\ntraceback (most recent call last):\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/bin/tool\", line 8, in <module>\r\n    sys.exit(main())\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/framework/cli/cli.py\", line 725, in main\r\n    cli_collection()\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  file \"/users/olszewk2/dev/pyzypad-example/tool_cli.py\", line 230, in run\r\n    pipeline_name=pipeline,\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/framework/context/context.py\", line 767, in run\r\n    raise exc\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/framework/context/context.py\", line 759, in run\r\n    run_result = runner.run(filtered_pipeline, catalog, run_id)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/runner/runner.py\", line 101, in run\r\n    self._run(pipeline, catalog, run_id)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/runner/sequential_runner.py\", line 90, in _run\r\n    run_node(node, catalog, self._is_async, run_id)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/runner/runner.py\", line 213, in run_node\r\n    node = _run_node_sequential(node, catalog, run_id)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/runner/runner.py\", line 249, in _run_node_sequential\r\n    catalog.save(name, data)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/io/data_catalog.py\", line 448, in save\r\n    func(data)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/io/core.py\", line 625, in save\r\n    super().save(data)\r\n  file \"/users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/tool/io/core.py\", line 247, in save\r\n    raise dataseterror(message) from exc\r\ntool.io.core.dataseterror: failed while saving data to data set tooltoolmodelsaverdataset(filepath=/users/olszewk2/dev/pyzypad-example/data/06_models/pclass_encoder, flavor=tool.sklearn, load_args={}, save_args={}, version=version(load=none, save='2020-11-06t12.28.57.593z')).\r\nunsupported operand type(s) for /: 'str' and 'str'\r\n```\r\n\r\n## your environment\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* tool 0.16.6\r\n* tool-tool 0.4.0\r\n* python 3.7.7\r\n* macos catalina\r\n\r\n## does the bug also happen with the last version on develop?\r\n\r\nyes.",
          "Title: child models need to copy the dict.*.txt files from the parent model when launching an experiment on tool; Content:if a parent model was trained with the alignment enhanced architecture and the dictionary on, preprocessing for the child model will look for the dict.*.txt files (dict.src.txt, dict.trg.txt, dict.vref.txt) from the parent model.  those files are not currently being copied into the /tmp directory on the aqua server when the experiment is launched through tool, so preprocessing fails on the child model.\r\n\r\nsample [experiment ](https://app.pro.clear.ml/projects/2243ca6c76d642699db1f28951bbb78a/experiments/fc444552b21243149fd3c90a9a4c6c8d/execution?columns=selected&columns=type&columns=name&columns=tags&columns=status&columns=project.name&columns=users&columns=started&columns=last_update&columns=last_iteration&columns=parent.name&order=-last_update&filter=)with this failure.",
          "Title: pandas dataframes with array column values are not correctly persisted as tool datasets; Content:pandas dataframes with arrays as column values seem to be incorrectly persisted. an example:\r\n\r\n```python\r\ntest_df = pd.dataframe({'x': [np.random.rand(1000) for _ in range(1000)]})\r\nds = datastore.get_default(ws)\r\ndataset.tabular.register_pandas_dataframe(test_df, ds, 'test_dataset')\r\n\r\ntest_df.head()\r\n###\r\n\tx\r\n0\t[0.5044850335733219, 0.6054305053424696, 0.669...\r\n1\t[0.41759815476145723, 0.266477750018155, 0.511...\r\n2\t[0.6777708610872593, 0.16925324567267985, 0.16...\r\n3\t[0.4268294269387616, 0.6540643485117185, 0.033...\r\n4\t[0.6560106490417036, 0.5804652379458484, 0.582...\r\n\r\ndataset.get_by_name(ws, 'test_dataset').to_pandas_dataframe().head()\r\n###\r\nx\r\n0\terror\r\n1\terror\r\n2\terror\r\n3\terror\r\n4\terror\r\n```",
          "Title: toolartifactdataset.load() fails if artifact_path is not none and run_id is specified; Content:## description\r\n\r\nwhen you try to specify an artifact path and a run_id in an ``toolartifactdataset``, you get an error. \r\n\r\nthis works:\r\n```python\r\ntool_csv_dataset = toolartifactdataset(\r\n    data_set=dict(type=csvdataset, filepath=\"path/to/df.csv\"),\r\n    artifact_path=none,\r\n    run_id=\"1234\",\r\n)\r\ntool_csv_dataset .load()\r\n```\r\n\r\nwhile this :\r\n```python\r\ntool_csv_dataset = toolartifactdataset(\r\n    data_set=dict(type=csvdataset, filepath=\"path/to/df.csv\"),\r\n    artifact_path=\"folder\", # this is the difference\r\n    run_id=\"1234\",\r\n)\r\ntool_csv_dataset .load()\r\n```\r\nraises the following error: ``unsupported operand type(s) for /: 'str' and 'str'``:\r\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_miniconda3_columns_dict",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_miniconda3_columns_dict"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.225172996520996,
          9.110945701599121,
          8.993656158447266,
          9.081098556518555,
          9.211007118225098,
          9.01900863647461,
          9.284568786621094,
          8.650562286376953,
          9.041940689086914,
          9.323972702026367,
          8.78124713897705,
          9.28962516784668,
          9.221348762512207,
          9.094935417175293
         ],
         "y": [
          2.0840036869049072,
          1.8397679328918457,
          2.253596305847168,
          2.3814737796783447,
          1.9810599088668823,
          2.194901943206787,
          1.9435744285583496,
          2.8743155002593994,
          2.3743669986724854,
          2.137524127960205,
          2.1405434608459473,
          1.8806575536727905,
          1.9876675605773926,
          2.159496307373047
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: tool-tool cli is unavailable inside a tool project; Content:## description\r\n\r\ni try to reproduce the minimal example from the docs: a tool project using the starter `pandas-iris` using the `tool-tool` functinality. i do not arrive at initializing the tool-tool project, since the cli commands are not available.\r\n\r\n## context\r\n\r\nit is unclear to me if this is connected to #157 \r\ni wanted to start looking into tool-tool, but got immediatle blocked by the initialization of the project. therefore any advice on where to look to fix this would also be appreciated. \r\n\r\n## steps to reproduce\r\n\r\n```\r\nconda create -n tool_tool python=3.8\r\nconda activate tool_tool\r\npip install tool-tool\r\ntool tool -h\r\ntool new --starter=pandas-iris\r\ncd tool_test/\r\ntool tool -h\r\n> error \"no such command 'tool'\"\r\n```\r\n\r\n## expected result\r\n\r\n`tool tool` is available in a project directory, i.e. `tool tool -h` gives the same output inside the folder as before\r\n\r\n## actual result\r\n\r\ninside the project folder the `tool` command is unknown to tool\r\n\r\n```\r\n.../miniconda3/envs/tool_tool/lib/python3.8/site-packages/pkg_resources/__init__.py:1130: deprecationwarning: use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\r\n  return get_provider(package_or_requirement).get_resource_filename(\r\n..../miniconda3/envs/tool_tool/lib/python3.8/site-packages/tool/types/schema.py:49: deprecationwarning: `np.object` is a deprecated alias for the builtin `object`. to silence this warning, use `object` by itself. doing this will not modify any behavior and is safe. \r\ndeprecated in numpy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  binary = (7, np.dtype(\"bytes\"), \"binarytype\", np.object)\r\n2021-04-23 17:49:52,197 - root - info - registered hooks from 2 installed plugin(s): tool-tool-0.7.1\r\nusage: tool [options] command [args]...\r\ntry 'tool -h' for help.\r\n\r\nerror: no such command 'tool'.\r\n\r\n```\r\n\r\n## your environment\r\n\r\nubuntu 18.04.5\r\n\r\n- tool 0.17.3\r\n- tool-tool 0.7.1\r\n- python 3.8.8.\r\n- tool 1.15.0\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes",
          "Title: plugin only compatible with tool-tool<0.8.0; Content:```python\r\ndef is_tool_enabled() -> bool:\r\n    try:\r\n        import tool  # noqa\r\n        from tool_tool.framework.context import get_tool_config  # noqa\r\n        return true\r\n    except importerror:\r\n        return false\r\n```\r\nalway throws exception since `context` package has been moved or refactored",
          "Title: tool papi depreciated; Content:use of the tool api logger reports an unecessary depreciation warning relating to the use of tool_ml.papi, rather than the newer tool_ml.api.\r\n\r\nexample:\r\n`tool warning: you have imported tool_ml.papi; this interface is deprecated. please use tool_ml.api instead. for more information, see: https://www.tool.ml/docs/python-sdk/releases/#release-300`",
          "Title: translate is trying to use tool even though it was not requested. preventing translation on local machine.; Content:i tried to translate with the following command line and trace.\r\nthe command is meant to run locally, but there is an error about tool credentials. the tool argument was not set in the command line.\r\n\r\n```\r\npython -m silnlp.nmt.translate --checkpoint 6000 --src-project gela3_2021_11_22 --book ot --trg-iso en  nlg-en-4\r\n2021-11-22 12:53:27.859063: i tensorflow/stream_executor/platform/default/dso_loader.cc:49] successfully opened dynamic library libcudart.so.11.0\r\n2021-11-22 12:53:30,996 - silnlp.common.environment - info - using workspace: /home/david/gutenberg_new as per environment variable sil_nlp_data_path.\r\n2021-11-22 12:53:31,372 - silnlp.common.utils - info - git commit: 12aca87cab\r\ntraceback (most recent call last):\r\n  file \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, none,\r\n  file \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  file \"/home/david/silnlp/silnlp/nmt/translate.py\", line 181, in <module>\r\n    main()\r\n  file \"/home/david/silnlp/silnlp/nmt/translate.py\", line 169, in main\r\n    translator.translate_book(\r\n  file \"/home/david/silnlp/silnlp/nmt/translate.py\", line 82, in translate_book\r\n    self.init_translation_task(experiment_suffix=f\"_{self.checkpoint}_{book}\")\r\n  file \"/home/david/silnlp/silnlp/nmt/translate.py\", line 57, in init_translation_task\r\n    self.tool = siltool(\r\n  file \"<string>\", line 8, in __init__\r\n  file \"/home/david/silnlp/silnlp/common/tool.py\", line 27, in __post_init__\r\n    self.task = task.init(\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/task.py\", line 491, in init\r\n    task = cls._create_dev_task(\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/task.py\", line 2554, in _create_dev_task\r\n    task = cls(\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/task.py\", line 164, in __init__\r\n    super(task, self).__init__(**kwargs)\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_interface/task/task.py\", line 151, in __init__\r\n    super(task, self).__init__(id=task_id, session=session, log=log)\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_interface/base.py\", line 131, in __init__\r\n    super(idobjectbase, self).__init__(session, log, **kwargs)\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_interface/base.py\", line 34, in __init__\r\n    self._session = session or self._get_default_session()\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_interface/base.py\", line 101, in _get_default_session\r\n    interfacebase._default_session = session(\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_api/session/session.py\", line 198, in __init__\r\n    self.refresh_token()\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_api/session/token_manager.py\", line 104, in refresh_token\r\n    self._set_token(self._do_refresh_token(self.__token, exp=self.req_token_expiration_sec))\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_api/session/session.py\", line 713, in _do_refresh_token\r\n    six.reraise(*sys.exc_info())\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  file \"/home/david/.cache/pypoetry/virtualenvs/silnlp-gt_vmn9e-py3.8/lib/python3.8/site-packages/tool/backend_api/session/session.py\", line 699, in _do_refresh_token\r\n    raise loginerror(\r\ntool.backend_api.session.session.loginerror: failed getting token (error 401 from https://api.pro.clear.ml): unauthorized (invalid credentials) (failed to locate provided credentials)\r\ndavid@pop-os:~/silnlp$ \r\n```\r\n\r\n\r\n",
          "Title: tool-tool is broken with tool==0.18.1; Content:## description\r\n\r\nthe plugin does not work with projects created with ``tool==0.18.1``\r\n\r\n## context\r\n\r\ntry to launch ``tool run`` in a project with ``tool==0.18.1`` and tool-tool installed.\r\n\r\n\r\n## steps to reproduce\r\n\r\n```python\r\nconda create -n temp python=3.8 -y\r\nconda activate temp\r\npip install tool==0.18.1 tool-tool==0.9.0\r\ntool new --starter=pandas-iris\r\ncd pandas-iris\r\ntool tool init\r\ntool run\r\n```\r\n\r\n## expected result\r\n\r\nthis should run the pipeleine and log the parameters.\r\n\r\n## actual result\r\n\r\nthis raises the following error:\r\n\r\n```bash\r\nattributeerror: module 'tool.framework.session.session' has no attribute '_active_session'\r\n```\r\n\r\n## your environment\r\n\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` and `tool-tool` version used (`pip show tool` and `pip show tool-tool`): ``tool==0.18.1`` and ``tool-tool<=0.9.0``\r\n* python version used (`python -v`): all\r\n* operating system and version: all\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes\r\n\r\n## solution\r\n\r\ncurrently, tool-tool uses [the private ``_active_session`` global variable to access the configuration](https://github.com/galileo-galilei/tool-tool/blob/e855f59faa76c881b32616880608d41c064c23a0/tool_tool/config/tool_tool_config.py#l233-l247) inside a hook. \r\n\r\nwith tool==0.18.1, this private attribute was removed and the new recommandation is to use the ``after_context_created`` hook. \r\n\r\nretrieving the configuration and set it up should be moved to this new hook:\r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/963c338d6259dd118232c45801abe0a2b0a463df/tool_tool/framework/hooks/pipeline_hook.py#l108-l109",
          "Title: plugin only compatible with tool-tool<0.8.0; Content:```python\r\ndef is_tool_enabled() -> bool:\r\n    try:\r\n        import tool  # noqa\r\n        from tool_tool.framework.context import get_tool_config  # noqa\r\n        return true\r\n    except importerror:\r\n        return false\r\n```\r\nalway throws exception since `context` package has been moved or refactored",
          "Title: tool-tool is broken with tool==0.18.1; Content:## description\r\n\r\nthe plugin does not work with projects created with ``tool==0.18.1``\r\n\r\n## context\r\n\r\ntry to launch ``tool run`` in a project with ``tool==0.18.1`` and tool-tool installed.\r\n\r\n\r\n## steps to reproduce\r\n\r\n```python\r\nconda create -n temp python=3.8 -y\r\nconda activate temp\r\npip install tool==0.18.1 tool-tool==0.9.0\r\ntool new --starter=pandas-iris\r\ncd pandas-iris\r\ntool tool init\r\ntool run\r\n```\r\n\r\n## expected result\r\n\r\nthis should run the pipeleine and log the parameters.\r\n\r\n## actual result\r\n\r\nthis raises the following error:\r\n\r\n```bash\r\nattributeerror: module 'tool.framework.session.session' has no attribute '_active_session'\r\n```\r\n\r\n## your environment\r\n\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `tool` and `tool-tool` version used (`pip show tool` and `pip show tool-tool`): ``tool==0.18.1`` and ``tool-tool<=0.9.0``\r\n* python version used (`python -v`): all\r\n* operating system and version: all\r\n\r\n## does the bug also happen with the last version on master?\r\n\r\nyes\r\n\r\n## solution\r\n\r\ncurrently, tool-tool uses [the private ``_active_session`` global variable to access the configuration](https://github.com/galileo-galilei/tool-tool/blob/e855f59faa76c881b32616880608d41c064c23a0/tool_tool/config/tool_tool_config.py#l233-l247) inside a hook. \r\n\r\nwith tool==0.18.1, this private attribute was removed and the new recommandation is to use the ``after_context_created`` hook. \r\n\r\nretrieving the configuration and set it up should be moved to this new hook:\r\n\r\nhttps://github.com/galileo-galilei/tool-tool/blob/963c338d6259dd118232c45801abe0a2b0a463df/tool_tool/framework/hooks/pipeline_hook.py#l108-l109",
          "Title: how to get root access in tool studio lab; Content:hi, i am trying to install some libraries in studio lab which requires root privileges. \r\n\r\nbelow i have run `whoami` to check if i am root user. (i am not as it should print 'root' in case of root user)\r\n![whoami_image](https://user-images.githubusercontent.com/91401599/172846069-ae664262-ae25-4cf0-9a60-ed5bf657029f.png)\r\n\r\nbelow you can see the error on running sudo: ->  `bash: sudo: command not found`\r\n![sudo_cmd](https://user-images.githubusercontent.com/91401599/172847142-57fb5a9f-720b-41af-989a-93740c29805c.png)\r\n\r\ni followed [this ](https://stackoverflow.com/questions/44443228/sudo-command-not-found-when-i-ssh-into-server)link to install sudo. \r\non running `su -` , it asks for the password, but we don't have any password for studio lab. \r\n![password](https://user-images.githubusercontent.com/91401599/172847894-34da1cd8-f59c-4f65-9500-c870b50095c6.png)\r\n\r\ncan anyone tell how to get root access or a way to install libraries which require root access/(or packages which installs using sudo). \r\nplease let me know if my query is not clear. ",
          "Title: pip installing tool-datasets[option] causes different dependencies to installing tool[option]; Content:## description\ninstalling `tool-datasets[option]` installs a different set of dependencies than `tool[option]`. it appears that `tool-datasets[option]` is installing the superset of requirements for all datasets.\n\n## context\nthis is currently blocking https://github.com/tool-org/tool/issues/1495\n\n## steps to reproduce\n1. `pip install \"tool[pandas.csvdataset]\"; pip freeze > requirements-tool.txt`\n2. `pip install \"tool-datasets[pandas.csvdataset]\"; pip freeze > requirements-tool-datasets.txt`\n3. compare the requirements\n",
          "Title: tool notebooks raise error for `pandas.csvdataset`; Content:## description\r\nthe conda environment for python3.6 in notebooks cannot find `pandas.csvdataset`\r\n\r\n## context\r\ni'm wanting to use tool as my development environment. however, i cannot get tool to run as expected in both the notebooks (for exploration and node development) and the terminal (for running pipelines).\r\n\r\n## steps to reproduce\r\n\r\n0. startup a tool instance with defaults\r\n\r\nterminal success:\r\n\r\n1. `pip install tool` in the terminal\r\n2. `tool new`\r\n2a. `testing` for name\r\n2b. `y` for example project\r\n3. `cd testing; tool run` => success!\r\n\r\nnotebook fail:\r\n1. create a new `conda_python3` notebook in `testing/notebooks/`\r\n2. `!pip install tool` in a notebook \r\n> the environments for the terminal and notebooks are separate by design in tool\r\n2. load the tool context as described [here](https://tool.readthedocs.io/en/stable/04_user_guide/11_ipython.html#what-if-i-cannot-run-tool-jupyter-notebook) \r\n> note that i've started to use the code below; without checking if `current_dir` exists, you need to restart the kernel if you want to reload the context as something in the last 2 lines of code causes the next invocation of `path.cwd()` to point to the root dir not `notebook/`, as intended.\r\n```\r\nif \"current_dir\" not in locals():\r\n    # check it exists first. for some reason this is not an idempotent operation?\r\n    current_dir = path.cwd()  # this points to 'notebooks/' folder\r\nproj_path = current_dir.parent  # point back to the root of the project\r\ncontext = load_context(proj_path)\r\n```\r\n3. run `context.catalog.list()`\r\n\r\n## expected result\r\nthe notebook should print:\r\n```\r\n['example_iris_data',\r\n 'parameters',\r\n 'params:example_test_data_ratio',\r\n 'params:example_num_train_iter',\r\n 'params:example_learning_rate']\r\n```\r\n\r\n## actual result\r\n```\r\nclass `pandas.csvdataset` not found.\r\n```\r\n\r\nfull trace.\r\n```\r\n---------------------------------------------------------------------------\r\nstopiteration                             traceback (most recent call last)\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/io/core.py in parse_dataset_definition(config, load_version, save_version)\r\n    416         try:\r\n--> 417             class_obj = next(obj for obj in trials if obj is not none)\r\n    418         except stopiteration:\r\n\r\nstopiteration: \r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ndataseterror                              traceback (most recent call last)\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/io/core.py in from_config(cls, name, config, load_version, save_version)\r\n    148             class_obj, config = parse_dataset_definition(\r\n--> 149                 config, load_version, save_version\r\n    150             )\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/io/core.py in parse_dataset_definition(config, load_version, save_version)\r\n    418         except stopiteration:\r\n--> 419             raise dataseterror(\"class `{}` not found.\".format(class_obj))\r\n    420 \r\n\r\ndataseterror: class `pandas.csvdataset` not found.\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ndataseterror                              traceback (most recent call last)\r\n<ipython-input-4-5848382c8bb9> in <module>()\r\n----> 1 context.catalog.list()\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/context/context.py in catalog(self)\r\n    206 \r\n    207         \"\"\"\r\n--> 208         return self._get_catalog()\r\n    209 \r\n    210     @property\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/context/context.py in _get_catalog(self, save_version, journal, load_versions)\r\n    243         conf_creds = self._get_config_credentials()\r\n    244         catalog = self._create_catalog(\r\n--> 245             conf_catalog, conf_creds, save_version, journal, load_versions\r\n    246         )\r\n    247         catalog.add_feed_dict(self._get_feed_dict())\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/context/context.py in _create_catalog(self, conf_catalog, conf_creds, save_version, journal, load_versions)\r\n    267             save_version=save_version,\r\n    268             journal=journal,\r\n--> 269             load_versions=load_versions,\r\n    270         )\r\n    271 \r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/io/data_catalog.py in from_config(cls, catalog, credentials, load_versions, save_version, journal)\r\n    298             ds_config = _resolve_credentials(ds_config, credentials)\r\n    299             data_sets[ds_name] = abstractdataset.from_config(\r\n--> 300                 ds_name, ds_config, load_versions.get(ds_name), save_version\r\n    301             )\r\n    302         return cls(data_sets=data_sets, journal=journal)\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/tool/io/core.py in from_config(cls, name, config, load_version, save_version)\r\n    152             raise dataseterror(\r\n    153                 \"an exception occurred when parsing config \"\r\n--> 154                 \"for dataset `{}`:\\n{}\".format(name, str(ex))\r\n    155             )\r\n    156 \r\n\r\ndataseterror: an exception occurred when parsing config for dataset `example_iris_data`:\r\nclass `pandas.csvdataset` not found.\r\n```\r\n\r\n## investigations so far\r\n\r\n### `csvlocaldataset`\r\nupon changing the yaml type for iris.csv from `pandas.csvdataset` to `csvlocaldataset`, we get success on both the terminal and the notebook. however, this is not my desired outcome; the transition to using `pandas.csvdataset` makes it easier, for me at least, to use both s3 and local datasets.\r\n\r\n### `pip install tool` output from notebook\r\n```\r\ncollecting tool\r\n  downloading https://files.pythonhosted.org/packages/67/6f/4faaa0e58728a318aeabc490271a636f87f6b9165245ce1d3adc764240cf/tool-0.15.8-py3-none-any.whl (12.5mb)\r\n    100% |████████████████████████████████| 12.5mb 4.1mb/s eta 0:00:01\r\nrequirement already satisfied: xlsxwriter<2.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (1.0.4)\r\ncollecting azure-storage-file<2.0,>=1.1.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/c9/33/6c611563412ffc409b2413ac50e3a063133ea235b86c137759774c77f3ad/azure_storage_file-1.4.0-py2.py3-none-any.whl\r\ncollecting fsspec<1.0,>=0.5.1 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/6e/2b/63420d49d5e5f885451429e9e0f40ad1787eed0d32b1aedd6b10f9c2719a/fsspec-0.7.1-py3-none-any.whl (66kb)\r\n    100% |████████████████████████████████| 71kb 33.5mb/s ta 0:00:01\r\nrequirement already satisfied: pandas<1.0,>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (0.24.2)\r\ncollecting s3fs<1.0,>=0.3.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/b8/e4/b8fc59248399d2482b39340ec9be4bb2493846ac23641b43115a7e5cd675/s3fs-0.4.2-py3-none-any.whl\r\nrequirement already satisfied: pyyaml<6.0,>=4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (5.3.1)\r\ncollecting tables<3.6,>=3.4.4 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/87/f7/bb0ec32a3f3dd74143a3108fbf737e6dcfd47f0ffd61b52af7106ab7a38a/tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3mb)\r\n    100% |████████████████████████████████| 4.3mb 10.2mb/s ta 0:00:01\r\nrequirement already satisfied: requests<3.0,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (2.20.0)\r\ncollecting toposort<2.0,>=1.5 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\r\nrequirement already satisfied: click<8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (6.7)\r\ncollecting azure-storage-queue<2.0,>=1.1.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/72/94/4db044f1c155b40c5ebc037bfd9d1c24562845692c06798fbe869fe160e6/azure_storage_queue-1.4.0-py2.py3-none-any.whl\r\ncollecting cookiecutter<2.0,>=1.6.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/86/c9/7184edfb0e89abedc37211743d1420810f6b49ae4fa695dfc443c273470d/cookiecutter-1.7.0-py2.py3-none-any.whl (40kb)\r\n    100% |████████████████████████████████| 40kb 24.6mb/s ta 0:00:01\r\ncollecting pandas-gbq<1.0,>=0.12.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/c3/74/126408f6bdb7b2cb1dcb8c6e4bd69a511a7f85792d686d1237d9825e6194/pandas_gbq-0.13.1-py3-none-any.whl\r\ncollecting pip-tools<5.0.0,>=4.0.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/94/8f/59495d651f3ced9b06b69545756a27296861a6edd6c5709fbe1265ed9032/pip_tools-4.5.1-py2.py3-none-any.whl (41kb)\r\n    100% |████████████████████████████████| 51kb 27.5mb/s ta 0:00:01\r\ncollecting azure-storage-blob<2.0,>=1.1.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/25/f4/a307ed89014e9abb5c5cfc8ca7f8f797d12f619f17a6059a6fd4b153b5d0/azure_storage_blob-1.5.0-py2.py3-none-any.whl (75kb)\r\n    100% |████████████████████████████████| 81kb 35.2mb/s ta 0:00:01\r\ncollecting pyarrow<1.0.0,>=0.12.0 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/ba/10/93fad5849418eade4a4cd581f8cd27be1bbe51e18968ba1492140c887f3f/pyarrow-0.16.0-cp36-cp36m-manylinux1_x86_64.whl (62.9mb)\r\n    100% |████████████████████████████████| 62.9mb 779kb/s eta 0:00:01    40% |█████████████                   | 25.7mb 56.1mb/s eta 0:00:01\r\nrequirement already satisfied: sqlalchemy<2.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (1.2.11)\r\nrequirement already satisfied: xlrd<2.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tool) (1.1.0)\r\ncollecting python-json-logger<1.0,>=0.1.9 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/80/9d/1c3393a6067716e04e6fcef95104c8426d262b4adaf18d7aa2470eab028d/python-json-logger-0.1.11.tar.gz\r\ncollecting anyconfig<1.0,>=0.9.7 (from tool)\r\n  downloading https://files.pythonhosted.org/packages/4c/00/cc525eb0240b6ef196b98300d505114339bbb7ddd68e3155483f1eb32050/anyconfig-0.9.10.tar.gz (103kb)\r\n    100% |████████████████████████████████| 112kb 34.4mb/s ta 0:00:01\r\ncollecting azure-storage-common~=1.4 (from azure-storage-file<2.0,>=1.1.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/05/6c/b2285bf3687768dbf61b6bc085b0c1be2893b6e2757a9d023263764177f3/azure_storage_common-1.4.2-py2.py3-none-any.whl (47kb)\r\n    100% |████████████████████████████████| 51kb 25.9mb/s ta 0:00:01\r\ncollecting azure-common>=1.1.5 (from azure-storage-file<2.0,>=1.1.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/e5/4d/d000fc3c5af601d00d55750b71da5c231fcb128f42ac95b208ed1091c2c1/azure_common-1.1.25-py2.py3-none-any.whl\r\nrequirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->tool) (2.7.3)\r\nrequirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->tool) (1.14.3)\r\nrequirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->tool) (2018.4)\r\nrequirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs<1.0,>=0.3.0->tool) (1.15.27)\r\nrequirement already satisfied: mock>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->tool) (4.0.1)\r\nrequirement already satisfied: numexpr>=2.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->tool) (2.6.5)\r\nrequirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->tool) (1.11.0)\r\nrequirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (2019.11.28)\r\nrequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (3.0.4)\r\nrequirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (1.23)\r\nrequirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (2.6)\r\ncollecting whichcraft>=0.4.0 (from cookiecutter<2.0,>=1.6.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/b5/a2/81887a0dae2e4d2adc70d9a3557fdda969f863ced51cd3c47b587d25bce5/whichcraft-0.6.1-py2.py3-none-any.whl\r\ncollecting future>=0.15.2 (from cookiecutter<2.0,>=1.6.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kb)\r\n    100% |████████████████████████████████| 829kb 27.8mb/s ta 0:00:01\r\ncollecting poyo>=0.1.0 (from cookiecutter<2.0,>=1.6.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/42/50/0b0820601bde2eda403f47b9a4a1f270098ed0dd4c00c443d883164bdccc/poyo-0.5.0-py2.py3-none-any.whl\r\ncollecting binaryornot>=0.2.0 (from cookiecutter<2.0,>=1.6.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/24/7e/f7b6f453e6481d1e233540262ccbfcf89adcd43606f44a028d7f5fae5eb2/binaryornot-0.4.4-py2.py3-none-any.whl\r\ncollecting jinja2-time>=0.1.0 (from cookiecutter<2.0,>=1.6.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/6a/a1/d44fa38306ffa34a7e1af09632b158e13ec89670ce491f8a15af3ebcb4e4/jinja2_time-0.2.0-py2.py3-none-any.whl\r\nrequirement already satisfied: jinja2>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cookiecutter<2.0,>=1.6.0->tool) (2.10)\r\ncollecting google-auth-oauthlib (from pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\r\ncollecting google-auth (from pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/05/b0/cc391ebf8ebf7855cdcfe0a9a4cdc8dcd90287c90e1ac22651d104ac6481/google_auth-1.12.0-py2.py3-none-any.whl (83kb)\r\n    100% |████████████████████████████████| 92kb 35.5mb/s ta 0:00:01\r\ncollecting pydata-google-auth (from pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/87/ed/9c9f410c032645632de787b8c285a78496bd89590c777385b921eb89433d/pydata_google_auth-0.3.0-py2.py3-none-any.whl\r\nrequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas-gbq<1.0,>=0.12.0->tool) (39.1.0)\r\ncollecting google-cloud-bigquery>=1.11.1 (from pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/8f/f7/b6f55e144da37f38a79552a06103f2df4a9569e2dfc6d741a7e2a63d3592/google_cloud_bigquery-1.24.0-py2.py3-none-any.whl (165kb)\r\n    100% |████████████████████████████████| 174kb 39.2mb/s ta 0:00:01\r\nrequirement already satisfied: cryptography in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->tool) (2.8)\r\nrequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->tool) (0.9.4)\r\nrequirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->tool) (0.14)\r\ncollecting arrow (from jinja2-time>=0.1.0->cookiecutter<2.0,>=1.6.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/92/fa/f84896dede5decf284e6922134bf03fd26c90870bbf8015f4e8ee2a07bcc/arrow-0.15.5-py2.py3-none-any.whl (46kb)\r\n    100% |████████████████████████████████| 51kb 26.3mb/s ta 0:00:01\r\nrequirement already satisfied: markupsafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jinja2>=2.7->cookiecutter<2.0,>=1.6.0->tool) (1.0)\r\ncollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\r\ncollecting pyasn1-modules>=0.2.1 (from google-auth->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kb)\r\n    100% |████████████████████████████████| 163kb 32.5mb/s ta 0:00:01\r\nrequirement already satisfied: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth->pandas-gbq<1.0,>=0.12.0->tool) (3.4.2)\r\ncollecting cachetools<5.0,>=2.0.0 (from google-auth->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\r\ncollecting google-api-core<2.0dev,>=1.15.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl (70kb)\r\n    100% |████████████████████████████████| 71kb 29.9mb/s ta 0:00:01\r\ncollecting google-cloud-core<2.0dev,>=1.1.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\r\nrequirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->tool) (3.6.1)\r\ncollecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\r\nrequirement already satisfied: cffi!=1.11.3,>=1.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->tool) (1.11.5)\r\ncollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kb)\r\n    100% |████████████████████████████████| 153kb 42.0mb/s ta 0:00:01\r\nrequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq<1.0,>=0.12.0->tool) (0.4.8)\r\ncollecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->tool)\r\n  downloading https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\r\nrequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->tool) (2.18)\r\nbuilding wheels for collected packages: python-json-logger, anyconfig, future, googleapis-common-protos\r\n  running setup.py bdist_wheel for python-json-logger ... done\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/97/f7/a1/752e22bb30c1cfe38194ea0070a5c66e76ef4d06ad0c7dc401\r\n  running setup.py bdist_wheel for anyconfig ... done\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/5a/82/0d/e374b7c77f4e4aa846a9bc2057e1d108c7f8e6b97a383befc9\r\n  running setup.py bdist_wheel for future ... done\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\r\n  running setup.py bdist_wheel for googleapis-common-protos ... done\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\r\nsuccessfully built python-json-logger anyconfig future googleapis-common-protos\r\ncookiecutter 1.7.0 has requirement click>=7.0, but you'll have click 6.7 which is incompatible.\r\ngoogle-auth 1.12.0 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\r\ngoogle-cloud-bigquery 1.24.0 has requirement six<2.0.0dev,>=1.13.0, but you'll have six 1.11.0 which is incompatible.\r\npip-tools 4.5.1 has requirement click>=7, but you'll have click 6.7 which is incompatible.\r\ninstalling collected packages: azure-common, azure-storage-common, azure-storage-file, fsspec, s3fs, tables, toposort, azure-storage-queue, whichcraft, future, poyo, binaryornot, arrow, jinja2-time, cookiecutter, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, googleapis-common-protos, google-api-core, google-cloud-core, google-resumable-media, google-cloud-bigquery, pandas-gbq, pip-tools, azure-storage-blob, pyarrow, python-json-logger, anyconfig, tool\r\n  found existing installation: s3fs 0.1.5\r\n    uninstalling s3fs-0.1.5:\r\n      successfully uninstalled s3fs-0.1.5\r\n  found existing installation: tables 3.4.3\r\n    uninstalling tables-3.4.3:\r\n      successfully uninstalled tables-3.4.3\r\nsuccessfully installed anyconfig-0.9.10 arrow-0.15.5 azure-common-1.1.25 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 binaryornot-0.4.4 cachetools-4.0.0 cookiecutter-1.7.0 fsspec-0.7.1 future-0.18.2 google-api-core-1.16.0 google-auth-1.12.0 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.24.0 google-cloud-core-1.3.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jinja2-time-0.2.0 tool-0.15.8 oauthlib-3.1.0 pandas-gbq-0.13.1 pip-tools-4.5.1 poyo-0.5.0 pyarrow-0.16.0 pyasn1-modules-0.2.8 pydata-google-auth-0.3.0 python-json-logger-0.1.11 requests-oauthlib-1.3.0 s3fs-0.4.2 tables-3.5.2 toposort-1.5 whichcraft-0.6.1\r\n```\r\n\r\n### `pip install tool` output from terminal\r\n```\r\ncollecting tool\r\n  using cached tool-0.15.8-py3-none-any.whl (12.5 mb)\r\ncollecting pandas<1.0,>=0.24.0\r\n  downloading pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 mb)\r\n     |████████████████████████████████| 10.4 mb 9.6 mb/s \r\ncollecting azure-storage-file<2.0,>=1.1.0\r\n  using cached azure_storage_file-1.4.0-py2.py3-none-any.whl (30 kb)\r\ncollecting click<8.0\r\n  downloading click-7.1.1-py2.py3-none-any.whl (82 kb)\r\n     |████████████████████████████████| 82 kb 1.7 mb/s \r\ncollecting cookiecutter<2.0,>=1.6.0\r\n  using cached cookiecutter-1.7.0-py2.py3-none-any.whl (40 kb)\r\ncollecting sqlalchemy<2.0,>=1.2.0\r\n  downloading sqlalchemy-1.3.15.tar.gz (6.1 mb)\r\n     |████████████████████████████████| 6.1 mb 49.2 mb/s \r\n  installing build dependencies ... done\r\n  getting requirements to build wheel ... done\r\n    preparing wheel metadata ... done\r\ncollecting tables<3.6,>=3.4.4\r\n  using cached tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3 mb)\r\nprocessing /home/ec2-user/.cache/pip/wheels/97/f7/a1/752e22bb30c1cfe38194ea0070a5c66e76ef4d06ad0c7dc401/python_json_logger-0.1.11-py2.py3-none-any.whl\r\ncollecting azure-storage-blob<2.0,>=1.1.0\r\n  using cached azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kb)\r\ncollecting pandas-gbq<1.0,>=0.12.0\r\n  using cached pandas_gbq-0.13.1-py3-none-any.whl (23 kb)\r\nrequirement already satisfied: fsspec<1.0,>=0.5.1 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from tool) (0.6.3)\r\ncollecting xlsxwriter<2.0,>=1.0.0\r\n  downloading xlsxwriter-1.2.8-py2.py3-none-any.whl (141 kb)\r\n     |████████████████████████████████| 141 kb 65.9 mb/s \r\ncollecting pip-tools<5.0.0,>=4.0.0\r\n  using cached pip_tools-4.5.1-py2.py3-none-any.whl (41 kb)\r\ncollecting pyarrow<1.0.0,>=0.12.0\r\n  downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 mb)\r\n     |████████████████████████████████| 63.1 mb 25 kb/s \r\ncollecting xlrd<2.0,>=1.0.0\r\n  downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kb)\r\n     |████████████████████████████████| 103 kb 66.5 mb/s \r\nrequirement already satisfied: s3fs<1.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from tool) (0.4.0)\r\ncollecting azure-storage-queue<2.0,>=1.1.0\r\n  using cached azure_storage_queue-1.4.0-py2.py3-none-any.whl (23 kb)\r\nprocessing /home/ec2-user/.cache/pip/wheels/5a/82/0d/e374b7c77f4e4aa846a9bc2057e1d108c7f8e6b97a383befc9/anyconfig-0.9.10-py2.py3-none-any.whl\r\ncollecting toposort<2.0,>=1.5\r\n  using cached toposort-1.5-py2.py3-none-any.whl (7.6 kb)\r\nrequirement already satisfied: pyyaml<6.0,>=4.2 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from tool) (5.3.1)\r\nrequirement already satisfied: requests<3.0,>=2.20.0 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from tool) (2.23.0)\r\nrequirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->tool) (2019.3)\r\nrequirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->tool) (1.18.1)\r\nrequirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->tool) (2.8.1)\r\ncollecting azure-common>=1.1.5\r\n  using cached azure_common-1.1.25-py2.py3-none-any.whl (12 kb)\r\ncollecting azure-storage-common~=1.4\r\n  using cached azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kb)\r\ncollecting poyo>=0.1.0\r\n  using cached poyo-0.5.0-py2.py3-none-any.whl (10 kb)\r\ncollecting jinja2-time>=0.1.0\r\n  using cached jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kb)\r\ncollecting whichcraft>=0.4.0\r\n  using cached whichcraft-0.6.1-py2.py3-none-any.whl (5.2 kb)\r\ncollecting binaryornot>=0.2.0\r\n  using cached binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kb)\r\nrequirement already satisfied: jinja2>=2.7 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from cookiecutter<2.0,>=1.6.0->tool) (2.11.1)\r\nprocessing /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e/future-0.18.2-cp36-none-any.whl\r\nrequirement already satisfied: mock>=2.0 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->tool) (3.0.5)\r\ncollecting numexpr>=2.6.2\r\n  downloading numexpr-2.7.1-cp36-cp36m-manylinux1_x86_64.whl (162 kb)\r\n     |████████████████████████████████| 162 kb 66.7 mb/s \r\nrequirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->tool) (1.14.0)\r\ncollecting pydata-google-auth\r\n  using cached pydata_google_auth-0.3.0-py2.py3-none-any.whl (12 kb)\r\ncollecting google-auth-oauthlib\r\n  using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kb)\r\ncollecting google-cloud-bigquery>=1.11.1\r\n  using cached google_cloud_bigquery-1.24.0-py2.py3-none-any.whl (165 kb)\r\ncollecting google-auth\r\n  using cached google_auth-1.12.0-py2.py3-none-any.whl (83 kb)\r\nrequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from pandas-gbq<1.0,>=0.12.0->tool) (46.1.1.post20200323)\r\nrequirement already satisfied: boto3>=1.9.91 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from s3fs<1.0,>=0.3.0->tool) (1.12.27)\r\nrequirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from s3fs<1.0,>=0.3.0->tool) (1.15.27)\r\nrequirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (2.9)\r\nrequirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (3.0.4)\r\nrequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (1.22)\r\nrequirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->tool) (2019.11.28)\r\nrequirement already satisfied: cryptography in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->tool) (2.8)\r\ncollecting arrow\r\n  using cached arrow-0.15.5-py2.py3-none-any.whl (46 kb)\r\nrequirement already satisfied: markupsafe>=0.23 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from jinja2>=2.7->cookiecutter<2.0,>=1.6.0->tool) (1.1.1)\r\ncollecting requests-oauthlib>=0.7.0\r\n  using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kb)\r\ncollecting google-resumable-media<0.6dev,>=0.5.0\r\n  using cached google_resumable_media-0.5.0-py2.py3-none-any.whl (38 kb)\r\ncollecting google-cloud-core<2.0dev,>=1.1.0\r\n  using cached google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kb)\r\nrequirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->tool) (3.11.3)\r\ncollecting google-api-core<2.0dev,>=1.15.0\r\n  using cached google_api_core-1.16.0-py2.py3-none-any.whl (70 kb)\r\ncollecting pyasn1-modules>=0.2.1\r\n  using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kb)\r\nrequirement already satisfied: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from google-auth->pandas-gbq<1.0,>=0.12.0->tool) (3.4.2)\r\ncollecting cachetools<5.0,>=2.0.0\r\n  using cached cachetools-4.0.0-py3-none-any.whl (10 kb)\r\nrequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs<1.0,>=0.3.0->tool) (0.3.3)\r\nrequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs<1.0,>=0.3.0->tool) (0.9.4)\r\nrequirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->tool) (0.15.2)\r\nrequirement already satisfied: cffi!=1.11.3,>=1.8 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->tool) (1.14.0)\r\ncollecting oauthlib>=3.0.0\r\n  using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kb)\r\nprocessing /home/ec2-user/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706/googleapis_common_protos-1.51.0-cp36-none-any.whl\r\nrequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq<1.0,>=0.12.0->tool) (0.4.8)\r\nrequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/jupytersystemenv/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->tool) (2.20)\r\nbuilding wheels for collected packages: sqlalchemy\r\n  building wheel for sqlalchemy (pep 517) ... done\r\n  created wheel for sqlalchemy: filename=sqlalchemy-1.3.15-cp36-cp36m-linux_x86_64.whl size=1215829 sha256=112167e02a19acada7f367d8aca55bbd1e0c655de9edfabebae5e9d055d9a9a6\r\n  stored in directory: /home/ec2-user/.cache/pip/wheels/4a/1b/3a/c73044d7be48baeb47cbee343334f7803726ca1e9ba7b29095\r\nsuccessfully built sqlalchemy\r\ninstalling collected packages: pandas, azure-common, azure-storage-common, azure-storage-file, click, poyo, arrow, jinja2-time, whichcraft, binaryornot, future, cookiecutter, sqlalchemy, numexpr, tables, python-json-logger, azure-storage-blob, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, google-resumable-media, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-bigquery, pandas-gbq, xlsxwriter, pip-tools, pyarrow, xlrd, azure-storage-queue, anyconfig, toposort, tool\r\n  attempting uninstall: pandas\r\n    found existing installation: pandas 0.22.0\r\n    uninstalling pandas-0.22.0:\r\n      successfully uninstalled pandas-0.22.0\r\nsuccessfully installed sqlalchemy-1.3.15 anyconfig-0.9.10 arrow-0.15.5 azure-common-1.1.25 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 binaryornot-0.4.4 cachetools-4.0.0 click-7.1.1 cookiecutter-1.7.0 future-0.18.2 google-api-core-1.16.0 google-auth-1.12.0 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.24.0 google-cloud-core-1.3.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jinja2-time-0.2.0 tool-0.15.8 numexpr-2.7.1 oauthlib-3.1.0 pandas-0.25.3 pandas-gbq-0.13.1 pip-tools-4.5.1 poyo-0.5.0 pyarrow-0.16.0 pyasn1-modules-0.2.8 pydata-google-auth-0.3.0 python-json-logger-0.1.11 requests-oauthlib-1.3.0 tables-3.5.2 toposort-1.5 whichcraft-0.6.1 xlrd-1.2.0 xlsxwriter-1.2.8\r\n```\r\n\r\n## your environment\r\ninclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n|environment | terminal | notebook|\r\n|----|----|----|\r\n|`tool -v` | tool, version 0.15.8 | tool, version 0.15.8|\r\n|`python -v` | python 3.6.10 :: anaconda, inc. | python 3.6.5 :: anaconda, inc.|\r\n|os |  `pretty_name=\"amazon linux ami 2018.03\"\"` `id_like=\"rhel fedora\"` | `pretty_name=\"amazon linux ami 2018.03\"\"` `id_like=\"rhel fedora\"`|\r\n|`pip freeze` | anyconfig==0.9.10<br>arrow==0.15.5<br>asn1crypto==1.3.0<br>attrs==19.3.0<br>autovizwidget==0.12.9<br>awscli==1.18.27<br>azure-common==1.1.25<br>azure-storage-blob==1.5.0<br>azure-storage-common==1.4.2<br>azure-storage-file==1.4.0<br>azure-storage-queue==1.4.0<br>backcall==0.1.0<br>bcrypt==3.1.7<br>binaryornot==0.4.4<br>bleach==3.1.0<br>boto3==1.12.27<br>botocore==1.15.27<br>cached-property==1.5.1<br>cachetools==4.0.0<br>certifi==2019.11.28<br>cffi==1.14.0<br>chardet==3.0.4<br>click==7.1.1<br>colorama==0.4.3<br>cookiecutter==1.7.0<br>cryptography==2.8<br>decorator==4.4.2<br>defusedxml==0.6.0<br>docker==4.2.0<br>docker-compose==1.25.4<br>dockerpty==0.4.1<br>docopt==0.6.2<br>docutils==0.15.2<br>entrypoints==0.3<br>environment-kernels==1.1.1<br>fsspec==0.6.3<br>future==0.18.2<br>gitdb==4.0.2<br>gitpython==3.1.0<br>google-api-core==1.16.0<br>google-auth==1.12.0<br>google-auth-oauthlib==0.4.1<br>google-cloud-bigquery==1.24.0<br>google-cloud-core==1.3.0<br>google-resumable-media==0.5.0<br>googleapis-common-protos==1.51.0<br>hdijupyterutils==0.12.9<br>idna==2.9<br>importlib-metadata==1.5.0<br>ipykernel==5.1.4<br>ipython==7.13.0<br>ipython-genutils==0.2.0<br>ipywidgets==7.5.1<br>jedi==0.16.0<br>jinja2==2.11.1<br>jinja2-time==0.2.0<br>jmespath==0.9.4<br>json5==0.9.3<br>jsonschema==3.2.0<br>jupyter==1.0.0<br>jupyter-client==6.0.0<br>jupyter-console==6.1.0<br>jupyter-core==4.6.1<br>jupyterlab==1.2.7<br>jupyterlab-git==0.9.0<br>jupyterlab-server==1.0.7<br>tool==0.15.8<br>markupsafe==1.1.1<br>mistune==0.8.4<br>mock==3.0.5<br>nb-conda==2.2.1<br>nb-conda-kernels==2.2.3<br>nbconvert==5.6.1<br>nbdime==2.0.0<br>nbexamples==0.0.0<br>nbformat==5.0.4<br>nbserverproxy==0.3.2<br>nose==1.3.7<br>notebook==5.7.8<br>numexpr==2.7.1<br>numpy==1.18.1<br>oauthlib==3.1.0<br>packaging==20.3<br>pandas==0.25.3<br>pandas-gbq==0.13.1<br>pandocfilters==1.4.2<br>paramiko==2.7.1<br>parso==0.6.2<br>pexpect==4.8.0<br>pickleshare==0.7.5<br>pid==3.0.0<br>pip-tools==4.5.1<br>plotly==4.5.4<br>poyo==0.5.0<br>prometheus-client==0.7.1<br>prompt-toolkit==3.0.3<br>protobuf==3.11.3<br>protobuf3-to-dict==0.1.5<br>psutil==5.7.0<br>psycopg2==2.8.4<br>ptyprocess==0.6.0<br>py4j==0.10.7<br>pyarrow==0.16.0<br>pyasn1==0.4.8<br>pyasn1-modules==0.2.8<br>pycparser==2.20<br>pydata-google-auth==0.3.0<br>pygal==2.4.0<br>pygments==2.6.1<br>pykerberos==1.1.14<br>pynacl==1.3.0<br>pyopenssl==19.1.0<br>pyparsing==2.4.6<br>pyrsistent==0.15.7<br>pysocks==1.7.1<br>pyspark==2.3.2<br>python-dateutil==2.8.1<br>python-json-logger==0.1.11<br>pytz==2019.3<br>pyyaml==5.3.1<br>pyzmq==18.1.1<br>qtconsole==4.7.1<br>qtpy==1.9.0<br>requests==2.23.0<br>requests-kerberos==0.12.0<br>requests-oauthlib==1.3.0<br>retrying==1.3.3<br>rsa==3.4.2<br>s3fs==0.4.0<br>s3transfer==0.3.3<br>tool==1.51.4<br>tool-experiments==0.1.10<br>tool-nbi-agent==1.0<br>tool-pyspark==1.2.8<br>scipy==1.4.1<br>send2trash==1.5.0<br>six==1.14.0<br>smdebug-rulesconfig==0.1.2<br>smmap==3.0.1<br>sparkmagic==0.15.0<br>sqlalchemy==1.3.15<br>tables==3.5.2<br>terminado==0.8.3<br>testpath==0.4.4<br>texttable==1.6.2<br>toposort==1.5<br>tornado==6.0.4<br>traitlets==4.3.3<br>urllib3==1.22<br>wcwidth==0.1.8<br>webencodings==0.5.1<br>websocket-client==0.57.0<br>whichcraft==0.6.1<br>widgetsnbextension==3.5.1<br>xlrd==1.2.0<br>xlsxwriter==1.2.8<br>zipp==2.2.0 | alabaster==0.7.10<br>anaconda-client==1.6.14<br>anaconda-project==0.8.2<br>anyconfig==0.9.10<br>arrow==0.15.5<br>asn1crypto==0.24.0<br>astroid==1.6.3<br>astropy==3.0.2<br>attrs==18.1.0<br>automat==0.3.0<br>autovizwidget==0.15.0<br>awscli==1.18.27<br>azure-common==1.1.25<br>azure-storage-blob==1.5.0<br>azure-storage-common==1.4.2<br>azure-storage-file==1.4.0<br>azure-storage-queue==1.4.0<br>babel==2.5.3<br>backcall==0.1.0<br>backports.shutil-get-terminal-size==1.0.0<br>bcrypt==3.1.7<br>beautifulsoup4==4.6.0<br>binaryornot==0.4.4<br>bitarray==0.8.1<br>bkcharts==0.2<br>blaze==0.11.3<br>bleach==2.1.3<br>bokeh==1.0.4<br>boto==2.48.0<br>boto3==1.12.27<br>botocore==1.15.27<br>bottleneck==1.2.1<br>cached-property==1.5.1<br>cachetools==4.0.0<br>certifi==2019.11.28<br>cffi==1.11.5<br>characteristic==14.3.0<br>chardet==3.0.4<br>click==6.7<br>cloudpickle==0.5.3<br>clyent==1.2.2<br>colorama==0.3.9<br>contextlib2==0.5.5<br>cookiecutter==1.7.0<br>cryptography==2.8<br>cycler==0.10.0<br>cython==0.28.4<br>cytoolz==0.9.0.1<br>dask==0.17.5<br>datashape==0.5.4<br>decorator==4.3.0<br>defusedxml==0.6.0<br>distributed==1.21.8<br>docker==4.2.0<br>docker-compose==1.25.4<br>dockerpty==0.4.1<br>docopt==0.6.2<br>docutils==0.14<br>entrypoints==0.2.3<br>enum34==1.1.9<br>environment-kernels==1.1.1<br>et-xmlfile==1.0.1<br>fastcache==1.0.2<br>filelock==3.0.4<br>flask==1.0.2<br>flask-cors==3.0.4<br>fsspec==0.7.1<br>future==0.18.2<br>gevent==1.3.0<br>glob2==0.6<br>gmpy2==2.0.8<br>google-api-core==1.16.0<br>google-auth==1.12.0<br>google-auth-oauthlib==0.4.1<br>google-cloud-bigquery==1.24.0<br>google-cloud-core==1.3.0<br>google-resumable-media==0.5.0<br>googleapis-common-protos==1.51.0<br>greenlet==0.4.13<br>h5py==2.8.0<br>hdijupyterutils==0.15.0<br>heapdict==1.0.0<br>html5lib==1.0.1<br>idna==2.6<br>imageio==2.3.0<br>imagesize==1.0.0<br>importlib-metadata==1.5.0<br>ipykernel==4.8.2<br>ipyparallel==6.2.2<br>ipython==6.4.0<br>ipython-genutils==0.2.0<br>ipywidgets==7.4.0<br>isort==4.3.4<br>itsdangerous==0.24<br>jdcal==1.4<br>jedi==0.12.0<br>jinja2==2.10<br>jinja2-time==0.2.0<br>jmespath==0.9.4<br>jsonschema==2.6.0<br>jupyter==1.0.0<br>jupyter-client==5.2.3<br>jupyter-console==5.2.0<br>jupyter-core==4.4.0<br>jupyterlab==0.32.1<br>jupyterlab-launcher==0.10.5<br>tool==0.15.8<br>kiwisolver==1.0.1<br>lazy-object-proxy==1.3.1<br>llvmlite==0.23.1<br>locket==0.2.0<br>lxml==4.2.1<br>markupsafe==1.0<br>matplotlib==3.0.3<br>mccabe==0.6.1<br>mistune==0.8.3<br>mkl-fft==1.0.0<br>mkl-random==1.0.1<br>mock==4.0.1<br>more-itertools==4.1.0<br>mpmath==1.0.0<br>msgpack==0.6.0<br>msgpack-python==0.5.6<br>multipledispatch==0.5.0<br>nb-conda==2.2.1<br>nb-conda-kernels==2.2.2<br>nbconvert==5.4.1<br>nbformat==4.4.0<br>networkx==2.1<br>nltk==3.3<br>nose==1.3.7<br>notebook==5.5.0<br>numba==0.38.0<br>numexpr==2.6.5<br>numpy==1.14.3<br>numpydoc==0.8.0<br>oauthlib==3.1.0<br>odo==0.5.1<br>olefile==0.45.1<br>opencv-python==3.4.2.17<br>openpyxl==2.5.3<br>packaging==20.1<br>pandas==0.24.2<br>pandas-gbq==0.13.1<br>pandocfilters==1.4.2<br>paramiko==2.7.1<br>parso==0.2.0<br>partd==0.3.8<br>path.py==11.0.1<br>pathlib2==2.3.2<br>patsy==0.5.0<br>pep8==1.7.1<br>pexpect==4.5.0<br>pickleshare==0.7.4<br>pillow==5.1.0<br>pip-tools==4.5.1<br>pkginfo==1.4.2<br>plotly==4.5.2<br>pluggy==0.6.0<br>ply==3.11<br>poyo==0.5.0<br>prompt-toolkit==1.0.15<br>protobuf==3.6.1<br>protobuf3-to-dict==0.1.5<br>psutil==5.4.5<br>psycopg2==2.7.5<br>ptyprocess==0.5.2<br>py==1.5.3<br>py4j==0.10.7<br>pyarrow==0.16.0<br>pyasn1==0.4.8<br>pyasn1-modules==0.2.8<br>pycodestyle==2.4.0<br>pycosat==0.6.3<br>pycparser==2.18<br>pycrypto==2.6.1<br>pycurl==7.43.0.1<br>pydata-google-auth==0.3.0<br>pyflakes==1.6.0<br>pygal==2.4.0<br>pygments==2.2.0<br>pykerberos==1.2.1<br>pylint==1.8.4<br>pynacl==1.3.0<br>pyodbc==4.0.23<br>pyopenssl==18.0.0<br>pyparsing==2.2.0<br>pysocks==1.6.8<br>pyspark==2.3.2<br>pytest==3.5.1<br>pytest-arraydiff==0.2<br>pytest-astropy==0.3.0<br>pytest-doctestplus==0.1.3<br>pytest-openfiles==0.3.0<br>pytest-remotedata==0.2.1<br>python-dateutil==2.7.3<br>python-json-logger==0.1.11<br>pytz==2018.4<br>pywavelets==0.5.2<br>pyyaml==5.3.1<br>pyzmq==17.0.0<br>qtawesome==0.4.4<br>qtconsole==4.3.1<br>qtpy==1.4.1<br>requests==2.20.0<br>requests-kerberos==0.12.0<br>requests-oauthlib==1.3.0<br>retrying==1.3.3<br>rope==0.10.7<br>rsa==3.4.2<br>ruamel-yaml==0.15.35<br>s3fs==0.4.2<br>s3transfer==0.3.3<br>tool==1.51.4<br>tool-pyspark==1.2.8<br>scikit-image==0.13.1<br>scikit-learn==0.20.3<br>scipy==1.1.0<br>seaborn==0.8.1<br>send2trash==1.5.0<br>simplegeneric==0.8.1<br>singledispatch==3.4.0.3<br>six==1.11.0<br>smdebug-rulesconfig==0.1.2<br>snowballstemmer==1.2.1<br>sortedcollections==0.6.1<br>sortedcontainers==1.5.10<br>sparkmagic==0.12.5<br>sphinx==1.7.4<br>sphinxcontrib-websupport==1.0.1<br>spyder==3.2.8<br>sqlalchemy==1.2.11<br>statsmodels==0.9.0<br>sympy==1.1.1<br>tables==3.5.2<br>tbb==0.1<br>tblib==1.3.2<br>terminado==0.8.1<br>testpath==0.3.1<br>texttable==1.6.2<br>toolz==0.9.0<br>toposort==1.5<br>tornado==5.0.2<br>traitlets==4.3.2<br>typing==3.6.4<br>unicodecsv==0.14.1<br>urllib3==1.23<br>wcwidth==0.1.7<br>webencodings==0.5.1<br>websocket-client==0.57.0<br>werkzeug==0.14.1<br>whichcraft==0.6.1<br>widgetsnbextension==3.4.2<br>wrapt==1.10.11<br>xlrd==1.1.0<br>xlsxwriter==1.0.4<br>xlwt==1.3.0<br>zict==0.1.3<br>zipp==3.0.0|\r\n",
          "Title: \"tool-cc init\" just take three letters for the tool folder name?; Content:call tool-cc init just takes the first three letters of the repo name???\r\n\r\nhere you can enter the folder where you want to store the tool files on the tool storage server.\r\n\tthe remote tool folder that you want use (default: ~/*****/***/tes): \r\nthe username with that you can access the tool storage server \"dt1.f4.htw-berlin.de\".\r\n",
          "Title: pip install \"sacremoses>=0.0.50\" breaks on tool studio; Content:### system info\n\n```shell\nthis was verified today on a fresh tool studio instance running in us-west-2.\r\n\r\nit's not a transformer issue, but as sacremoses is a dependency, this is likely to break 'pip install transformers' on tool studio at some point.\n```\n\n\n### who can help?\n\n_no response_\n\n### information\n\n- [ ] the official example scripts\n- [ ] my own modified scripts\n\n### tasks\n\n- [ ] an officially supported task in the `examples` folder (such as glue/squad, ...)\n- [ ] my own task or dataset (give details below)\n\n### reproduction\n\n1) open an sm studio notebook\r\n\r\n2) run the following cell:\r\n```\r\n%%sh\r\npip install \"sacremoses>=0.0.50\"\r\n```\r\n\r\nthe obvious workaround for now is\r\n```\r\npip install \"sacremoses==0.0.49\"\r\n```\r\n\r\n\n\n### expected behavior\n\n```shell\nsacremoses should install without error.\n```\n",
          "Title: execute translate script without creating tool task; Content:currently, the `silnlp.nmt.translate` script always creates a tool task. this should be optional. by default, it should just execute locally.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_google_requirement_ec2",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "8_google_requirement_ec2"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.72037410736084,
          7.219097137451172,
          7.490076065063477,
          6.917634010314941,
          7.299136638641357,
          7.201658248901367,
          7.153365135192871,
          6.557261943817139,
          7.281652450561523,
          6.842168807983398,
          6.1067376136779785,
          7.311207294464111,
          6.79564094543457,
          6.992001056671143
         ],
         "y": [
          5.322766304016113,
          5.195363521575928,
          4.785916328430176,
          5.065020561218262,
          5.051749229431152,
          5.208098411560059,
          5.127871036529541,
          4.980976104736328,
          5.017691612243652,
          5.335132598876953,
          5.078286170959473,
          4.956202507019043,
          5.075750827789307,
          5.092371463775635
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: compare models toolexception; Content:hi. i just upgraded to pycaret 2.1. when i ran the compare_models function with the titanic dataset, i got the following error:\r\n\r\ntoolexception: unable to map 'np.object' type to tool datatype. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float)\r\n\r\nthe same code worked fine in pycaret 2.0.",
          "Title: plots are not saving through tool; Content:this is the error i get  \"plot_model() got an unexpected keyword argument 'system'\"\r\n\r\n",
          "Title: tool logging issue in compare_models of time_series; Content:tool logging issue in compare_models of time_series\r\n\r\n```\r\nfrom pycaret.datasets import get_data\r\ndata = get_data('airline')\r\n\r\nfrom pycaret.time_series import *\r\ns = setup(data, fold = 5, fh = 12, session_id = 123, log_experiment=true, experiment_name = 'airline')\r\n\r\nbest = compare_models()\r\n\r\n!tool ui\r\n```\r\n\r\ncheck localhost:5000:\r\n\r\n![image](https://user-images.githubusercontent.com/54699234/132992636-db293fe7-5461-43d9-baed-97d8790fd9bd.png)\r\n\r\nall the runs fail in `compare_models`. parameters are logged but metrics and artifacts didn't. \r\n\r\n![image](https://user-images.githubusercontent.com/54699234/132992655-e0d81e16-9a59-49a5-ace3-d22ea2ea10b8.png)\r\n\r\ni cannot reproduce this with `create_model` it means `create_model` works just fine! ",
          "Title: tool ui doesn't show any models; Content:### pycaret version checks\n\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\n\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\n\n- [x] i have confirmed this bug exists on the develop branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@develop).\n\n\n### issue description\n\ni have tried both the nightly and the release branch, and read the issues posted here:\r\nhttps://github.com/pycaret/pycaret/issues?q=is%3aissue+tool+ui+is%3aclosed\r\n\r\ni do not see any models in the `tool ui` *during training*, while several models have already converged and logged to the file system. i see some models have already reported auc, mse, etc. but as shows below, nothing is present in the dashboard\r\n\r\n![image](https://user-images.githubusercontent.com/31047807/170046175-c0a85a9b-21e4-4a07-891f-7d58fcc5f579.png)\r\n\r\nthanks!\r\n\n\n### reproducible example\n\n```python\ntraining_data = pd.read_pickle(\"/cached_db\")\r\n\r\n\r\nexp_reg102 = classification.setup(data=training_data, target=args.label, session_id=123,\r\n                                  preprocess=true, feature_selection=true, fix_imbalance=true, \r\n                                  remove_perfect_collinearity=false,\r\n                                  log_experiment=true, \r\n                                  log_plots=true, profile=false, log_profile=false,\r\n                                  silent=true,\r\n                                  n_jobs=-1,\r\n                                  fold=2,\r\n                                  )\r\n\r\nbest_models = classification.compare_models(turbo=true, n_select=3,errors='raise')\n```\n\n\n### expected behavior\n\nbeing able to see the models that have already converged\n\n### actual results\n\n```python-traceback\nno model is present in the `tool ui` dashboard\n```\n\n\n### installed versions\n\n2.3.10",
          "Title: [bug]: tool incorrectly logging models \"lasso least angle regression\" and \"least angle regression\"; Content:### pycaret version checks\n\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\n\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\n\n- [x] i have confirmed this bug exists on the master branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@master).\n\n\n### issue description\n\ntool logs the name of both models \"least angle regression\" and \"lasso least angle regression\" as \"least angle regression\".\r\n\r\nwhen looking into the `get_logs()` you can see both of those models have unique `run_id` but both have the same `tags.tool.runname`.\r\n\r\npython version: 3.9.5\r\npycaret version: '3.0.0.rc3'\r\npandas version: 1.4.3\r\n\n\n### reproducible example\n\n```python\nimport pandas as pd\r\nfrom pycaret.regression import *\r\nfrom pycaret.datasets import get_data\r\ndataset = get_data('diamond')\r\n\r\nexperiment_name = 'diamond_experiment'\r\ns = setup(data=dataset, target='price', log_experiment=true, experiment_name=experiment_name, session_id=42, verbose=true)\r\n\r\nmodel = compare_models(verbose=false)\r\n\r\nprint(f\"notice least angle regression is not unique:\\n{get_logs(experiment_name=experiment_name)['tags.tool.runname'].value_counts()}\")\r\n\r\n# loop through all models in the `compare_models()` (20 models) function and get the length of the dataframe of that specific model in the logs\r\n# there should be a single unique value for each model\r\nfor model in pull().model.tolist():\r\n    print(f\"{model} - {len(get_logs(experiment_name=experiment_name)[get_logs(experiment_name=experiment_name)['tags.tool.runname'] == model])}\")\r\n\r\n# further investigation: model least angle regression has 2 instances (should be lasso least angle regression and least angle regression)\r\nget_logs(experiment_name=experiment_name)[get_logs(experiment_name=experiment_name)['tags.tool.runname'] == 'least angle regression']\r\n```\n```\n\n\n### expected behavior\n\n`tags.tool.runname` parameter from `get_logs()` is unique (given a single experiment) and contains all model names from `compare_models()`\n\n### actual results\n\n```python-traceback\nwhen looking into the `tags.tool.runname` you can see they are all unique but least angle regression is there twice and lasso least angle regression isn't there at all. could this be logged incorrectly?\r\n\r\ngradient boosting regressor - 1\r\ncatboost regressor - 1\r\nlight gradient boosting machine - 1\r\nextreme gradient boosting - 1\r\nlasso regression - 1\r\nridge regression - 1\r\nlinear regression - 1\r\nlasso least angle regression - 0\r\nleast angle regression - 2\r\nextra trees regressor - 1\r\nrandom forest regressor - 1\r\nadaboost regressor - 1\r\ndecision tree regressor - 1\r\northogonal matching pursuit - 1\r\nelastic net - 1\r\nhuber regressor - 1\r\nbayesian ridge - 1\r\nk neighbors regressor - 1\r\ndummy regressor - 1\r\npassive aggressive regressor - 1\n```\n\n\n### installed versions\n\n<details>\r\nsystem:\r\n    python: 3.9.5 (v3.9.5:0a7dcbdb13, may  3 2021, 13:17:02)  [clang 6.0 (clang-600.0.57)]\r\nexecutable: path_to_env/venv/bin/python\r\n   machine: macos-10.16-x86_64-i386-64bit\r\n\r\npycaret required dependencies:\r\n                 pip: 21.1.1\r\n          setuptools: 56.0.0\r\n             pycaret: 3.0.0.rc3\r\n             ipython: 8.4.0\r\n          ipywidgets: 8.0.0rc0\r\n                tqdm: 4.64.0\r\n               numpy: 1.21.6\r\n              pandas: 1.4.3\r\n              jinja2: 3.1.2\r\n               scipy: 1.5.4\r\n              joblib: 1.1.0\r\n             sklearn: 1.1.1\r\n                pyod: installed but version unavailable\r\n            imblearn: 0.9.1\r\n   category_encoders: 2.5.0\r\n            lightgbm: 3.3.2\r\n               numba: 0.55.2\r\n            requests: 2.28.0\r\n          matplotlib: 3.5.2\r\n          scikitplot: 0.3.7\r\n         yellowbrick: 1.4\r\n              plotly: 5.9.0\r\n             kaleido: 0.2.1\r\n         statsmodels: 0.13.2\r\n              sktime: 0.11.4\r\n               tbats: installed but version unavailable\r\n            pmdarima: 1.8.5\r\n              psutil: 5.9.1\r\n</details>\r\n",
          "Title: [bug]: pycaret + tool integration does not allow probabilities for classification and binary response models; Content:### pycaret version checks\n\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\n\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\n\n- [ ] i have confirmed this bug exists on the master branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@master).\n\n\n### issue description\n\nwe have been using pycaret 2.2 for the model training procedure and registration to the tool server. (python based) my company uses a managed version of this in azure databricks. after the registration has been completed, we call the calibrated algorithm in a separate notebook and are trying to score new data with a binary response 0|1. we would also like to leverage the scikit learn function \"predict_model\" to create the probabilities in addition to the predicted value. this is not working in pycaret and appears to be a bug of some sort. it is also important to note that we are able to see the \"predict_model\" during the model training but not when we call the algorithm for a separate scoring function. \n\n### reproducible example\n\n```python\n# import tool.sklearn\r\n# model = tool.sklearn.load_model(production_algorithm)\r\n# model.predict_prob(x)\n```\n\n\n### expected behavior\n\nwe should see the probabilities model.predict_prob(x) but this code errors out. another example would be the following: predictions_prob = production_algorithm.predict_prob(pd.dataframe(x))\r\n\n\n### actual results\n\n```python-traceback\nthe end result of the prediction should be a numeric value between 0 and 1. ex. 0.4278\n```\n\n\n### installed versions\n\n<details>\r\nsystem:\r\n    python: 3.8.10 (default, mar 15 2022, 12:22:08)  [gcc 9.4.0]\r\nexecutable: /local_disk0/.ephemeral_nfs/envs/pythonenv-ca5e1db9-faed-4291-83c9-f55dfcbb8112/bin/python\r\n   machine: linux-5.4.0-1083-azure-x86_64-with-glibc2.29\r\n\r\npycaret required dependencies:\r\n                 pip: 21.0.1\r\n          setuptools: 52.0.0\r\n             pycaret: 3.0.0.rc3\r\n             ipython: 7.22.0\r\n          ipywidgets: 7.7.1\r\n                tqdm: 4.64.0\r\n               numpy: 1.21.6\r\n              pandas: 1.4.3\r\n              jinja2: 3.1.2\r\n               scipy: 1.6.2\r\n              joblib: 1.1.0\r\n             sklearn: 1.1.1\r\n                pyod: installed but version unavailable\r\n            imblearn: 0.8.1\r\n   category_encoders: 2.5.0\r\n            lightgbm: 3.3.2\r\n               numba: 0.55.1\r\n            requests: 2.28.1\r\n          matplotlib: 3.4.2\r\n          scikitplot: 0.3.7\r\n         yellowbrick: 1.4\r\n              plotly: 5.9.0\r\n             kaleido: 0.2.1\r\n         statsmodels: 0.12.2\r\n              sktime: 0.11.4\r\n               tbats: installed but version unavailable\r\n            pmdarima: 1.8.4\r\n              psutil: 5.9.1\r\n</details>\r\n",
          "Title: tool doesn't save model artifact and some plots - clustering; Content:i'm using clustering module of pycaret and the integration with tool but i have problems because i think it doesn't save all artifacs and the status is always failed.\r\n![image](https://user-images.githubusercontent.com/12554263/101971863-66f70d00-3c02-11eb-9710-01cf228fca1b.png)\r\n\r\nthis is my code:\r\n\r\n```python\r\nfrom pycaret.clustering import *\r\n\r\npostpaid_exp = setup(postpaid_sample,\r\n                     ignore_features=ignore_features,\r\n                     numeric_features=numeric_features,\r\n                     normalize=true,\r\n                     normalize_method='robust',\r\n                     remove_multicollinearity=true,\r\n                     multicollinearity_threshold=0.7,\r\n                     log_experiment=true,\r\n                     log_plots=true,\r\n                     log_profile=true,\r\n                     log_data=true,\r\n                     profile=false,\r\n                     experiment_name='pospatid_segmentation',\r\n                     session_id=123)\r\n\r\n# create model with six clusters\r\nmodel_kmeans =  create_model(model='kmeans', num_clusters=6)\r\n```\r\nmy logs are the following\r\n\r\n```\r\n2020-12-11 22:39:07,118:info:pycaret supervised module\r\n2020-12-11 22:39:07,118:info:ml usecase: clustering\r\n2020-12-11 22:39:07,118:info:version 2.2.0\r\n2020-12-11 22:39:07,118:info:initializing setup()\r\n2020-12-11 22:39:07,119:info:setup(target=none, ml_usecase=clustering, available_plots={'cluster': 'cluster pca plot (2d)', 'tsne': 'cluster tsne (3d)', 'elbow': 'elbow', 'silhouette': 'silhouette', 'distance': 'distance', 'distribution': 'distribution'}, train_size=0.7, test_data=none, preprocess=true, imputation_type=simple, iterative_imputation_iters=5, categorical_features=none, categorical_imputation=mode, categorical_iterative_imputer=lightgbm, ordinal_features=none, high_cardinality_features=none, high_cardinality_method=frequency, numeric_features=['avg_dias_bancos_3m', 'avg_dias_app_pagos_3m', 'avg_dias_viajes_3m', 'avg_dias_compras_3m', 'avg_dias_mb_total_3m', 'avg_mb_total_3m', 'avg_q_apps_3m', 'ate_wh_sum_dias_3m', 'leads_tot_3m', 'tot_dias_appmov_movil_3m', 'avg_days_out_voice_tot_3m', 'meses_pagodig_3m'], numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=none, ignore_features=['periodo', 'telefono', 'anexo', 'tot_dias_appmov_fija_3m', 'avg_dias_vid_mus_3m'], normalize=true, normalize_method=robust, transformation=false, transformation_method=yeo-johnson, handle_unknown_categorical=true, unknown_categorical_method=least_frequent, pca=false, pca_method=linear, pca_components=none, ignore_low_variance=false, combine_rare_levels=false, rare_level_threshold=0.1, bin_numeric_features=none, remove_outliers=false, outliers_threshold=0.05, remove_multicollinearity=true, multicollinearity_threshold=0.7, remove_perfect_collinearity=false, create_clusters=false, cluster_iter=20, polynomial_features=false, polynomial_degree=2, trigonometry_features=false, polynomial_threshold=0.1, group_features=none, group_names=none, feature_selection=false, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=false, feature_ratio=false, interaction_threshold=0.01, fix_imbalance=false, fix_imbalance_method=none, transform_target=false, transform_target_method=box-cox, data_split_shuffle=false, data_split_stratify=false, fold_strategy=kfold, fold=10, fold_shuffle=false, fold_groups=none, n_jobs=-1, use_gpu=false, custom_pipeline=none, html=true, session_id=123, log_experiment=true, experiment_name=pospatid_segmentation, log_plots=['cluster', 'distribution', 'elbow'], log_profile=true, log_data=true, silent=false, verbose=true, profile=false, display=none)\r\n2020-12-11 22:39:07,119:info:checking environment\r\n2020-12-11 22:39:07,119:info:python_version: 3.8.5\r\n2020-12-11 22:39:07,119:info:python_build: ('default', 'aug  5 2020 09:44:06')\r\n2020-12-11 22:39:07,119:info:machine: amd64\r\n2020-12-11 22:39:07,120:info:platform: windows-10-10.0.18362-sp0\r\n2020-12-11 22:39:07,121:warning:cannot find psutil installation. memory not traceable. install psutil using pip to enable memory logging.\r\n2020-12-11 22:39:07,122:info:checking libraries\r\n2020-12-11 22:39:07,122:info:pd==1.1.4\r\n2020-12-11 22:39:07,122:info:numpy==1.19.4\r\n2020-12-11 22:39:07,122:info:sklearn==0.23.2\r\n2020-12-11 22:39:07,156:info:xgboost==1.2.0\r\n2020-12-11 22:39:07,156:info:lightgbm==3.0.0\r\n2020-12-11 22:39:07,170:info:catboost==0.24.1\r\n2020-12-11 22:39:07,901:info:tool==1.11.0\r\n2020-12-11 22:39:07,901:info:checking exceptions\r\n2020-12-11 22:39:07,901:info:declaring global variables\r\n2020-12-11 22:39:07,901:info:usi: cd5c\r\n2020-12-11 22:39:07,901:info:pycaret_globals: {'_available_plots', 'master_model_container', 'display_container', 'imputation_classifier', 'logging_param', 'seed', 'transform_target_param', 'experiment__', 'transform_target_method_param', 'iterative_imputation_iters_param', 'fold_groups_param', 'fix_imbalance_param', 'prep_pipe', 'exp_name_log', '_all_metrics', 'html_param', '_ml_usecase', 'usi', 'imputation_regressor', 'stratify_param', 'fold_generator', 'fix_imbalance_method_param', '_all_models', 'gpu_param', 'target_param', '_gpu_n_jobs_param', 'log_plots_param', 'pycaret_globals', 'fold_shuffle_param', '_all_models_internal', 'fold_param', 'create_model_container', 'data_before_preprocess', '_internal_pipeline', 'x', 'n_jobs_param'}\r\n2020-12-11 22:39:07,901:info:preparing display monitor\r\n2020-12-11 22:39:07,901:info:preparing display monitor\r\n2020-12-11 22:39:07,914:info:importing libraries\r\n2020-12-11 22:39:07,914:info:copying data for preprocessing\r\n2020-12-11 22:39:07,927:info:declaring preprocessing parameters\r\n2020-12-11 22:39:07,940:info:creating preprocessing pipeline\r\n2020-12-11 22:39:08,059:info:preprocessing pipeline created successfully\r\n2020-12-11 22:39:08,060:error:(process exit): setup has been interupted with user command 'quit'. setup must rerun.\r\n2020-12-11 22:39:08,060:info:creating global containers\r\n2020-12-11 22:39:08,061:info:internal pipeline: pipeline(memory=none, steps=[('empty_step', 'passthrough')], verbose=false)\r\n2020-12-11 22:39:10,064:info:creating grid variables\r\n2020-12-11 22:39:10,101:info:logging experiment in tool\r\n2020-12-11 22:39:10,108:warning:couldn't create tool experiment. exception:\r\n2020-12-11 22:39:10,185:warning:traceback (most recent call last):\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 1668, in setup\r\n    tool.create_experiment(exp_name_log)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\tracking\\fluent.py\", line 365, in create_experiment\r\n    return toolclient().create_experiment(name, artifact_location)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\tracking\\client.py\", line 184, in create_experiment\r\n    return self._tracking_client.create_experiment(name, artifact_location)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\tracking\\_tracking_service\\client.py\", line 142, in create_experiment\r\n    return self.store.create_experiment(name=name, artifact_location=artifact_location,)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\store\\tracking\\file_store.py\", line 288, in create_experiment\r\n    self._validate_experiment_name(name)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\store\\tracking\\file_store.py\", line 281, in _validate_experiment_name\r\n    raise toolexception(\r\ntool.exceptions.toolexception: experiment 'pospatid_segmentation' already exists.\r\n\r\n2020-12-11 22:39:10,490:info:subprocess save_model() called ==================================\r\n2020-12-11 22:39:10,501:info:initializing save_model()\r\n2020-12-11 22:39:10,501:info:save_model(model=pipeline(memory=none,\r\n         steps=[('dtypes',\r\n                 datatypes_auto_infer(categorical_features=[],\r\n                                      display_types=true,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', dummify(target='unsupervised_dummy_target')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', clean_colum_names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 fix_multicollinearity(correlation_with_target_preference=none,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='unsupervised_dummy_target',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=false), model_name=transformation pipeline, prep_pipe_=pipeline(memory=none,\r\n         steps=[('dtypes',\r\n                 datatypes_auto_infer(categorical_features=[],\r\n                                      display_types=true,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', dummify(target='unsupervised_dummy_target')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', clean_colum_names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 fix_multicollinearity(correlation_with_target_preference=none,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='unsupervised_dummy_target',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=false), verbose=false)\r\n2020-12-11 22:39:10,501:info:adding model into prep_pipe\r\n2020-12-11 22:39:10,506:warning:only model saved as it was a pipeline.\r\n2020-12-11 22:39:10,530:info:transformation pipeline.pkl saved in current working directory\r\n2020-12-11 22:39:10,535:info:pipeline(memory=none,\r\n         steps=[('dtypes',\r\n                 datatypes_auto_infer(categorical_features=[],\r\n                                      display_types=true,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', dummify(target='unsupervised_dummy_target')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', clean_colum_names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 fix_multicollinearity(correlation_with_target_preference=none,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='unsupervised_dummy_target',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=false)\r\n2020-12-11 22:39:10,535:info:save_model() succesfully completed......................................\r\n2020-12-11 22:39:10,536:info:subprocess save_model() end ==================================\r\n2020-12-11 22:40:03,332:info:create_model_container: 0\r\n2020-12-11 22:40:03,332:info:master_model_container: 0\r\n2020-12-11 22:40:03,332:info:display_container: 0\r\n2020-12-11 22:40:03,336:info:pipeline(memory=none,\r\n         steps=[('dtypes',\r\n                 datatypes_auto_infer(categorical_features=[],\r\n                                      display_types=true,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', dummify(target='unsupervised_dummy_target')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', clean_colum_names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 fix_multicollinearity(correlation_with_target_preference=none,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='unsupervised_dummy_target',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=false)\r\n2020-12-11 22:40:03,336:info:setup() succesfully completed......................................\r\n2020-12-11 22:40:07,628:info:initializing create_model()\r\n2020-12-11 22:40:07,628:info:create_model(estimator=kmeans, num_clusters=6, fraction=0.05, ground_truth=none, round=4, fit_kwargs=none, verbose=true, system=true, raise_num_clusters=false, display=none, kwargs={})\r\n2020-12-11 22:40:07,628:info:checking exceptions\r\n2020-12-11 22:40:07,629:info:preparing display monitor\r\n2020-12-11 22:40:07,645:info:importing libraries\r\n2020-12-11 22:40:07,652:info:importing untrained model\r\n2020-12-11 22:40:07,662:info:k-means clustering imported succesfully\r\n2020-12-11 22:40:07,670:info:fitting model\r\n2020-12-11 22:42:30,467:info:kmeans(algorithm='auto', copy_x=true, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0)\r\n2020-12-11 22:42:30,467:info:create_models() succesfully completed......................................\r\n2020-12-11 22:42:30,467:info:creating tool logs\r\n2020-12-11 22:42:30,481:info:model: k-means clustering\r\n2020-12-11 22:42:30,518:info:logged params: {'algorithm': 'auto', 'copy_x': true, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 6, 'n_init': 10, 'n_jobs': -1, 'precompute_distances': 'deprecated', 'random_state': 123, 'tol': 0.0001, 'verbose': 0}\r\n2020-12-11 22:42:30,557:info:subprocess plot_model() called ==================================\r\n2020-12-11 22:42:30,557:info:initializing plot_model()\r\n2020-12-11 22:42:30,557:info:plot_model(plot=cluster, fold=none, verbose=false, display=none, estimator=kmeans(algorithm='auto', copy_x=true, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0), feature_name=none, fit_kwargs=none, groups=none, label=false, save=true, scale=1, system=false)\r\n2020-12-11 22:42:30,557:info:checking exceptions\r\n2020-12-11 22:42:30,558:info:preloading libraries\r\n2020-12-11 22:42:30,558:info:copying training dataset\r\n2020-12-11 22:42:30,560:info:plot type: cluster\r\n2020-12-11 22:42:31,493:info:subprocess assign_model() called ==================================\r\n2020-12-11 22:42:31,494:info:initializing assign_model()\r\n2020-12-11 22:42:31,494:info:assign_model(model=pipeline(memory=none,\r\n         steps=[('empty_step', 'passthrough'),\r\n                ('actual_estimator',\r\n                 kmeans(algorithm='auto', copy_x=true, init='k-means++',\r\n                        max_iter=300, n_clusters=6, n_init=10, n_jobs=-1,\r\n                        precompute_distances='deprecated', random_state=123,\r\n                        tol=0.0001, verbose=0))],\r\n         verbose=false), transformation=true, score=true, verbose=false)\r\n2020-12-11 22:42:31,494:info:checking exceptions\r\n2020-12-11 22:42:31,495:info:determining trained model\r\n2020-12-11 22:42:31,495:info:trained model : k-means clustering\r\n2020-12-11 22:42:31,495:info:copying data\r\n2020-12-11 22:42:31,496:info:transformation param set to true. assigned clusters are attached on transformed dataset.\r\n2020-12-11 22:42:31,529:info:(90000, 12)\r\n2020-12-11 22:42:31,529:info:assign_model() succesfully completed......................................\r\n2020-12-11 22:42:31,530:info:subprocess assign_model() end ==================================\r\n2020-12-11 22:42:31,541:info:fitting pca()\r\n2020-12-11 22:42:31,908:info:sorting dataframe\r\n2020-12-11 22:42:31,974:info:rendering visual\r\n2020-12-11 22:42:41,765:info:saving 'cluster pca plot (2d).html' in current active directory\r\n2020-12-11 22:42:41,765:info:visual rendered successfully\r\n2020-12-11 22:42:42,286:info:plot_model() succesfully completed......................................\r\n2020-12-11 22:42:42,739:info:initializing plot_model()\r\n2020-12-11 22:42:42,739:info:plot_model(plot=distribution, fold=none, verbose=false, display=none, estimator=kmeans(algorithm='auto', copy_x=true, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0), feature_name=none, fit_kwargs=none, groups=none, label=false, save=true, scale=1, system=false)\r\n2020-12-11 22:42:42,739:info:checking exceptions\r\n2020-12-11 22:42:42,739:info:preloading libraries\r\n2020-12-11 22:42:42,739:info:copying training dataset\r\n2020-12-11 22:42:42,741:info:plot type: distribution\r\n2020-12-11 22:42:42,741:info:subprocess assign_model() called ==================================\r\n2020-12-11 22:42:42,742:info:initializing assign_model()\r\n2020-12-11 22:42:42,742:info:assign_model(model=pipeline(memory=none,\r\n         steps=[('empty_step', 'passthrough'),\r\n                ('actual_estimator',\r\n                 kmeans(algorithm='auto', copy_x=true, init='k-means++',\r\n                        max_iter=300, n_clusters=6, n_init=10, n_jobs=-1,\r\n                        precompute_distances='deprecated', random_state=123,\r\n                        tol=0.0001, verbose=0))],\r\n         verbose=false), transformation=false, score=true, verbose=false)\r\n2020-12-11 22:42:42,742:info:checking exceptions\r\n2020-12-11 22:42:42,742:info:determining trained model\r\n2020-12-11 22:42:42,742:info:trained model : k-means clustering\r\n2020-12-11 22:42:42,742:info:copying data\r\n2020-12-11 22:42:42,793:info:(90000, 18)\r\n2020-12-11 22:42:42,793:info:assign_model() succesfully completed......................................\r\n2020-12-11 22:42:42,794:info:subprocess assign_model() end ==================================\r\n2020-12-11 22:42:42,794:info:sorting dataframe\r\n2020-12-11 22:42:42,925:info:rendering visual\r\n2020-12-11 22:42:48,837:info:saving 'distribution.html' in current active directory\r\n2020-12-11 22:42:48,837:info:visual rendered successfully\r\n2020-12-11 22:42:48,979:info:plot_model() succesfully completed......................................\r\n2020-12-11 22:42:49,583:info:initializing plot_model()\r\n2020-12-11 22:42:49,584:info:plot_model(plot=elbow, fold=none, verbose=false, display=none, estimator=kmeans(algorithm='auto', copy_x=true, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0), feature_name=none, fit_kwargs=none, groups=none, label=false, save=true, scale=1, system=false)\r\n2020-12-11 22:42:49,584:info:checking exceptions\r\n2020-12-11 22:42:49,584:info:preloading libraries\r\n2020-12-11 22:42:49,584:info:copying training dataset\r\n2020-12-11 22:42:49,586:info:plot type: elbow\r\n2020-12-11 22:42:49,690:info:fitting model\r\n2020-12-11 22:43:12,604:info:saving 'elbow.png' in current active directory\r\n2020-12-11 22:43:13,207:info:visual rendered successfully\r\n2020-12-11 22:43:13,325:info:plot_model() succesfully completed......................................\r\n2020-12-11 22:43:13,340:info:subprocess plot_model() end ==================================\r\n2020-12-11 22:43:13,341:warning:couldn't infer tool signature.\r\n2020-12-11 22:43:13,352:error:_tool_log_model() for kmeans(algorithm='auto', copy_x=true, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0) raised an exception:\r\n2020-12-11 22:43:13,431:error:traceback (most recent call last):\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 2631, in create_model_unsupervised\r\n    _tool_log_model(\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 9942, in _tool_log_model\r\n    tool.sklearn.log_model(\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\sklearn\\__init__.py\", line 290, in log_model\r\n    return model.log(\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\models\\model.py\", line 160, in log\r\n    flavor.save_model(path=local_path, tool_model=tool_model, **kwargs)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\sklearn\\__init__.py\", line 171, in save_model\r\n    _save_example(tool_model, input_example, path)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\models\\utils.py\", line 131, in _save_example\r\n    example = _example(input_example)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\tool\\models\\utils.py\", line 67, in __init__\r\n    input_example = pd.dataframe.from_dict(input_example)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\frame.py\", line 1309, in from_dict\r\n    return cls(data, index=index, columns=columns, dtype=dtype)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\frame.py\", line 468, in __init__\r\n    mgr = init_dict(data, index, columns, dtype=dtype)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 283, in init_dict\r\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 78, in arrays_to_mgr\r\n    index = extract_index(arrays)\r\n  file \"c:\\users\\carlos\\anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 387, in extract_index\r\n    raise valueerror(\"if using all scalar values, you must pass an index\")\r\nvalueerror: if using all scalar values, you must pass an index\r\n\r\n2020-12-11 22:43:13,432:info:uploading results into container\r\n2020-12-11 22:43:13,435:info:uploading model into container now\r\n2020-12-11 22:43:13,440:info:create_model_container: 1\r\n2020-12-11 22:43:13,440:info:master_model_container: 1\r\n2020-12-11 22:43:13,440:info:display_container: 1\r\n2020-12-11 22:43:13,440:info:kmeans(algorithm='auto', copy_x=true, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0)\r\n2020-12-11 22:43:13,440:info:create_model() succesfully completed......................................\r\n\r\n```\r\n\r\ni'm using pycaret version : 2.2.0",
          "Title: tool not logging metrics; Content:### pycaret version checks\n\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\n\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\n\n- [ ] i have confirmed this bug exists on the master branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@master).\n\n\n### issue description\n\nhi,\r\n\r\ni am trying to integrate pycaret with tool using your parameter `log_experiment` in `setup()`. when i set it to true, everything is stores as planned in my local tool server, but not the metrics.\r\n\r\nin the documentation is says the `log_experiment=true` should control everything. so i am not sure if i do something wrong here of if it is a bug from your side.\r\n\r\nwould be glad if you could help!\n\n### reproducible example\n\n```python\nfrom pycaret.datasets import get_data\r\nfrom pycaret.regression import *\r\ndf = get_data('bike')\r\nexp = regressionexperiment()\r\nexp.setup(data=df, log_experiment=true)\r\nmodel = exp.create_model(\"lr\")\r\npred = exp.predict_model(estimator=model)\r\nexp.finalize_model(estimator=model)\n```\n\n\n### expected behavior\n\nshould log metrics\n\n### actual results\n\n```python-traceback\nno metrics logged.\n```\n\n\n### installed versions\n\n<details>\r\npycaret 3.0.0rc3\r\n</details>\r\n",
          "Title: [bug]: runs recorded in tool nests all recursively; Content:### pycaret version checks\n\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\n\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\n\n- [x] i have confirmed this bug exists on the master branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@master).\n\n\n### issue description\n\nas started runs in toollogger are never ended, all runs shown in tool dashboard seem to be nested recursively.\r\ntool 1.28.0 fixed the display of deeply nested runs correctly, so the bug is now problematic.\n\n### reproducible example\n\n```python\nimport tool\r\nfrom pycaret.classification import *\r\nfrom pycaret.datasets import get_data\r\n\r\ntool.set_tracking_uri(\"http://localhost:5000\")\r\n\r\ndata = get_data(\"diabetes\")\r\nsetup(data, target=\"class variable\", log_experiment=true, silent=true)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\r\nsetup(data, target=\"class variable\", log_experiment=true, silent=true)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\n```\n\n\n### expected behavior\n\nexpected display:\r\n![p2](https://user-images.githubusercontent.com/1991802/190944134-3490628a-4eca-490a-af11-c4cdfe41953e.png)\r\n\r\nactual display:\r\n![p1](https://user-images.githubusercontent.com/1991802/190944304-08c41ae2-93fd-4b79-b3ff-ebb594ad2664.png)\r\n\n\n### actual results\n\n```python-traceback\nattached the figure also in 'expected behavior'.\n```\n\n\n### installed versions\n\n<details>\r\n'2.3.10'\r\n</details>\r\n",
          "Title: [bug]: runs recorded in tool nests all recursively when [full] installed; Content:### pycaret version checks\r\n\r\n- [x] i have checked that this issue has not already been reported [here](https://github.com/pycaret/pycaret/issues).\r\n\r\n- [x] i have confirmed this bug exists on the [latest version](https://github.com/pycaret/pycaret/releases) of pycaret.\r\n\r\n- [ ] i have confirmed this bug exists on the master branch of pycaret (pip install -u git+https://github.com/pycaret/pycaret.git@master).\r\n\r\n\r\n### issue description\r\n\r\nwhen pycaret is installed with [full], all runs executed in one script are shown nested recursively in tool dashboard.\r\nthis happens only with [full] installation.\r\n\r\n### reproducible example\r\n\r\n```python\r\n%pip install -u pip wheel\r\n%pip install --pre pycaret[full]\r\n\r\nimport tool\r\nfrom pycaret.classification import *\r\nfrom pycaret.datasets import get_data\r\n\r\ntool.set_tracking_uri(\"http://localhost:5000\")\r\n\r\ndata = get_data(\"diabetes\")\r\nsetup(data, target=\"class variable\", log_experiment=true)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\r\nsetup(data, target=\"class variable\", log_experiment=true)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\r\n```\r\n\r\n\r\n### expected behavior\r\n\r\nexpected display: (when installed without [full])\r\n![ok](https://user-images.githubusercontent.com/1991802/198862894-7a459755-5b94-4abc-a00b-be8d42e1f71c.png)\r\n\r\nactual display: (when installed with [full])\r\n![ng](https://user-images.githubusercontent.com/1991802/198862906-a26034b1-e22b-4d36-a0e5-1f0c5ccdad8c.png)\r\n\r\n\r\n### actual results\r\n\r\n```python-traceback\r\nattached the figure also in 'expected behavior'.\r\n```\r\n\r\n\r\n### installed versions\r\n\r\n<details>\r\nsystem:\r\n    python: 3.9.5 (default, nov 23 2021, 15:27:38)  [gcc 9.3.0]\r\nexecutable: /home/ak/sample/.venv/bin/python\r\n   machine: linux-5.10.102.1-microsoft-standard-wsl2-x86_64-with-glibc2.31\r\n\r\npycaret required dependencies:\r\n                 pip: 22.3\r\n          setuptools: 44.0.0\r\n             pycaret: 3.0.0rc4\r\n             ipython: 8.5.0\r\n          ipywidgets: 8.0.2\r\n                tqdm: 4.64.1\r\n               numpy: 1.22.4\r\n              pandas: 1.4.4\r\n              jinja2: 3.1.2\r\n               scipy: 1.8.1\r\n              joblib: 1.2.0\r\n             sklearn: 1.1.3\r\n                pyod: 1.0.6\r\n            imblearn: 0.9.1\r\n   category_encoders: 2.5.1.post0\r\n            lightgbm: 3.3.3\r\n               numba: 0.55.2\r\n            requests: 2.28.1\r\n          matplotlib: 3.5.3\r\n          scikitplot: 0.3.7\r\n         yellowbrick: 1.5\r\n              plotly: 5.11.0\r\n             kaleido: 0.2.1\r\n         statsmodels: 0.13.2\r\n              sktime: 0.13.4\r\n               tbats: 1.1.1\r\n            pmdarima: 1.8.5\r\n              psutil: 5.9.3\r\n\r\npycaret optional dependencies:\r\n                shap: 0.41.0\r\n           interpret: 0.2.7\r\n                umap: 0.5.3\r\n    pandas_profiling: 3.4.0\r\n  explainerdashboard: 0.4.0\r\n             autoviz: 0.1.58\r\n           fairlearn: 0.8.0\r\n             xgboost: 1.7.0rc1\r\n            catboost: 1.1\r\n              kmodes: 0.12.2\r\n             mlxtend: 0.21.0\r\n       statsforecast: 1.1.3\r\n        tune_sklearn: 0.4.4\r\n                 ray: 2.0.1\r\n            hyperopt: 0.2.7\r\n              optuna: 3.0.3\r\n               skopt: 0.9.0\r\n              tool: 1.30.0\r\n              gradio: 3.8\r\n             fastapi: 0.85.1\r\n             uvicorn: 0.19.0\r\n              m2cgen: 0.10.0\r\n           evidently: 0.1.59.dev2\r\n                nltk: 3.7\r\n            pyldavis: not installed\r\n              gensim: not installed\r\n               spacy: not installed\r\n           wordcloud: 1.8.2.2\r\n            textblob: 0.17.1\r\n               fugue: 0.6.6\r\n           streamlit: not installed\r\n             prophet: not installed\r\n</details>\r\n",
          "Title: [bug] some types plot types are not getting saved to the tool experiment artifacts dir; Content:**describe the bug**\r\nthank you for creating such a helpful tool!\r\nthe problem i'm facing is that some types plot types (e.g. \"calibration\" and \"feature\") are not getting saved to the tool experiment artifacts dir. i think the issue is with inconsistent naming for the saved png for certain plot types.\r\nthank you for your help!\r\n<!--\r\n-->\r\n\r\n**to reproduce**\r\n<!--\r\nadd a minimal, complete, and verifiable example (for more details, see e.g. https://stackoverflow.com/help/mcve\r\n\r\nif the code is too long, feel free to put it in a public gist and link it in the issue: https://gist.github.com\r\n-->\r\n\r\n```python\r\nfrom pycaret.classification import *\r\n\r\nfrom pycaret.datasets import get_data\r\ndataset = get_data('credit')\r\n\r\n  pycaret_env = setup(\r\n      data = data, \r\n      target = 'default', \r\n      html=false, \r\n      silent=true,\r\n      verbose=false,\r\n      # for tool logging:\r\n      experiment_name=\"plot_test\",\r\n      log_experiment = true, \r\n      log_plots=['auc', 'feature', 'parameter', 'pr', 'calibration', 'confusion_matrix'],\r\n  )\r\n\r\n  model = create_model(\"lightgbm\")\r\n```\r\n\r\n**expected behavior**\r\n<!--\r\n-->\r\ni expect all of the plot types to be logged under the tool artifacts dir i.e. /tools/{experiment number}/{id}/artifacts/\r\nhowever, \"feature.png\" and \"calibration.png\" are saved to the working directory.\r\n\r\n**additional context**\r\n<!--\r\nadd any other context about the problem here.\r\n-->\r\ni think the issue is with inconsistent naming of the file. here is a printout of the log when it tries to save the calibration plot:\r\n```\r\n2021-10-11 19:03:19,845:info:saving 'calibration.png'\r\n2021-10-11 19:03:20,064:info:visual rendered successfully\r\n2021-10-11 19:03:20,213:info:plot_model() succesfully completed......................................\r\n2021-10-11 19:03:20,217:warning:[errno 2] no such file or directory: 'calibration curve.png'\r\n```\r\nso you can see that it is looking for 'calibration curve.png', but what actually gets produced is 'calibration.png'.\r\n\r\n**versions**\r\npython 3.8.11\r\n\r\n<!--\r\nplease run the following code snippet and paste the output here:\r\n \r\nimport pycaret\r\npycaret.__version__\r\n\r\n-->\r\npycaret 2.3.4\r\n\r\n</details>\r\n\r\n<!-- thanks for contributing! -->\r\n",
          "Title: [bug] issue with tool timeseries_beta branch; Content:if in setup log_plot set true then it is giving error in self._tool_log_model() as \r\nfor plot in log_plots:\r\ntypeerror: 'bool' object is not iterable",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_info_verbose_false",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "9_info_verbose_false"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.469956398010254,
          10.238566398620605,
          10.653299331665039,
          10.478384971618652,
          10.625656127929688,
          10.517152786254883,
          10.24583625793457,
          10.620774269104004,
          10.634843826293945,
          10.582510948181152,
          10.223548889160156,
          10.763103485107422,
          10.504469871520996
         ],
         "y": [
          2.2935805320739746,
          2.1558704376220703,
          2.503763437271118,
          2.3143036365509033,
          2.440948486328125,
          2.3230600357055664,
          2.169832468032837,
          2.433486223220825,
          2.467754602432251,
          2.393998861312866,
          2.169156551361084,
          2.718200445175171,
          2.3653297424316406
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: can not add tool extention on openshift cluster ; Content:error when adding extetnion tool\r\naz k8s-extension create --name tool-extension --extension-type microsoft.tool.kubernetes --config enabletraining= cluster-type conneced--cluster-name <your-aks-cluster-name> --resource-group <your-rg-name> --scope cluster\r\n\r\n\r\ncrc/providers/microsoft.kubernetesconfiguration/extensions/arcml-extension/operations/b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"name\":\"b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"status\":\"creating\"}\r\ncli.azure.cli.core.sdk.policies: request url: 'https://management.azure.com/subscriptions/0ebcf6f3-37c0-4ab6-bc4a-4299fd25192a/resourcegroups/azurearctest/providers/microsoft.kubernetes/connectedclusters/tvl-crc/providers/microsoft.kubernetesconfiguration/extensions/arcml-extension/operations/b5f5e30a-7439-4dd7-aab7-90bd438d320e?api-version=2022-03-01'\r\ncli.azure.cli.core.sdk.policies: request method: 'get'\r\ncli.azure.cli.core.sdk.policies: request headers:\r\ncli.azure.cli.core.sdk.policies:     'x-ms-client-request-id': 'f1bf020c-dc0d-11ec-a8c0-808abda5e54d'\r\ncli.azure.cli.core.sdk.policies:     'commandname': 'k8s-extension create'\r\ncli.azure.cli.core.sdk.policies:     'parametersetname': '--name --extension-type --cluster-type --cluster-name --resource-group --name --auto-upgrade --scope --debug --config'\r\ncli.azure.cli.core.sdk.policies:     'user-agent': 'azurecli/2.36.0 (msi) azsdk-python-azure-mgmt-kubernetesconfiguration/1.0.0 python/3.10.4 (windows-10-10.0.19044-sp0)'\r\ncli.azure.cli.core.sdk.policies:     'authorization': '*****'\r\ncli.azure.cli.core.sdk.policies: request body:\r\ncli.azure.cli.core.sdk.policies: this request has no body\r\nurllib3.connectionpool: [https://management.azure.com:443](https://nam06.safelinks.protection.outlook.com/?url=https%3a%2f%2fmanagement.azure.com%2f&data=05%7c01%7cjohan.andolf%40microsoft.com%7c37b5d083c3d7447f133208da3e347a4a%7c72f988bf86f141af91ab2d7cd011db47%7c1%7c0%7c637890692414003835%7cunknown%7ctwfpbgzsb3d8eyjwijoimc4wljawmdailcjqijoiv2lumziilcjbtii6ik1hawwilcjxvci6mn0%3d%7c3000%7c%7c%7c&sdata=1kwoqv7fwagqmyol4w7wfzrbf%2bctkz9xucdbe%2fkggka%3d&reserved=0) \"get /subscriptions/0ebcf6f3-37c0-4ab6-bc4a-4299fd25192a/resourcegroups/azurearctest/providers/microsoft.kubernetes/connectedclusters/tvl-crc/providers/microsoft.kubernetesconfiguration/extensions/arcml-extension/operations/b5f5e30a-7439-4dd7-aab7-90bd438d320e?api-version=2022-03-01 http/1.1\" 200 none\r\ncli.azure.cli.core.sdk.policies: response status: 200\r\ncli.azure.cli.core.sdk.policies: response headers:\r\ncli.azure.cli.core.sdk.policies:     'cache-control': 'no-cache'\r\ncli.azure.cli.core.sdk.policies:     'pragma': 'no-cache'\r\ncli.azure.cli.core.sdk.policies:     'transfer-encoding': 'chunked'\r\ncli.azure.cli.core.sdk.policies:     'content-type': 'application/json; charset=utf-8'\r\ncli.azure.cli.core.sdk.policies:     'content-encoding': 'gzip'\r\ncli.azure.cli.core.sdk.policies:     'expires': '-1'\r\ncli.azure.cli.core.sdk.policies:     'vary': 'accept-encoding'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-ratelimit-remaining-subscription-reads': '11968'\r\ncli.azure.cli.core.sdk.policies:     'strict-transport-security': 'max-age=31536000; includesubdomains'\r\ncli.azure.cli.core.sdk.policies:     'api-supported-versions': '2019-11-01-preview, 2021-05-01-preview, 2021-06-01-preview, 2021-09-01, 2021-11-01-preview, 2022-01-01-preview, 2022-03-01, 2022-04-02-preview'\r\ncli.azure.cli.core.sdk.policies:     'x-content-type-options': 'nosniff'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-request-id': '8d41b858-4f6d-4d30-819c-c34bef28d668'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-correlation-request-id': '8d41b858-4f6d-4d30-819c-c34bef28d668'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-routing-request-id': 'swedencentral:20220525t095135z:8d41b858-4f6d-4d30-819c-c34bef28d668'\r\ncli.azure.cli.core.sdk.policies:     'date': 'wed, 25 may 2022 09:51:34 gmt'\r\ncli.azure.cli.core.sdk.policies: response content:\r\ncli.azure.cli.core.sdk.policies: {\"id\":\"/subscriptions/0ebcf6f3-37c0-4ab6-bc4a-4299fd25192a/resourcegroups/azurearctest/providers/microsoft.kubernetes/connectedclusters/tvl-crc/providers/microsoft.kubernetesconfiguration/extensions/arcml-extension/operations/b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"name\":\"b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"status\":\"failed\",\"error\":{\"code\":\"extensioncreationfailed\",\"message\":\" error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\"}}\r\ncli.azure.cli.core.util: azure.cli.core.util.handle_exception is called with an exception:\r\ncli.azure.cli.core.util: traceback (most recent call last):\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/polling/base_polling.py\", line 483, in run\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/polling/base_polling.py\", line 522, in _poll\r\nazure.core.polling.base_polling.operationfailed: operation failed or canceled\r\n\r\nduring handling of the above exception, another exception occurred:\r\n\r\ntraceback (most recent call last):\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\knack/cli.py\", line 231, in invoke\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 658, in execute\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 721, in _run_jobs_serially\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 703, in _run_job\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 1008, in __call__\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 995, in __call__\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/polling/_poller.py\", line 255, in result\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/tracing/decorator.py\", line 83, in wrapper_use_tracer\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/polling/_poller.py\", line 275, in wait\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/polling/_poller.py\", line 192, in _start\r\n  file \"d:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\lib\\site-packages\\azure/core/polling/base_polling.py\", line 501, in run\r\nazure.core.exceptions.httpresponseerror: (extensioncreationfailed)  error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\r\ncode: extensioncreationfailed\r\nmessage:  error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\r\n\r\ncli.azure.cli.core.azclierror: (extensioncreationfailed)  error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\r\ncode: extensioncreationfailed\r\nmessage:  error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\r\naz_command_data_logger: (extensioncreationfailed)  error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\r\ncode: extensioncreationfailed\r\nmessage:  error: unable to get the status from the local crd with the error : {error : retry for given duration didn't get any results with err {status not populated}}\r\ncli.knack.cli: event: cli.postexecute [<function azclilogging.deinit_cmd_metadata_logging at 0x0387c190>]\r\naz_command_data_logger: exit code: 1\r\ncli.__main__: command ran in 996.906 seconds (init: 0.535, invoke: 996.371)\r\ntelemetry.save: save telemetry record of length 3581 in cache\r\ntelemetry.check: returns positive.\r\ntelemetry.main: begin creating telemetry upload process.\r\ntelemetry.process: creating upload process: \"c:\\program files (x86)\\microsoft sdks\\azure\\cli2\\python.exe c:\\program files (x86)\\microsoft sdks\\azure\\cli2\\lib\\site-packages\\azure\\cli\\telemetry\\__init__.pyc c:\\users\\ropa04\\.azure\"\r\ntelemetry.process: return from creating process\r\ntelemetry.main: finish creating telemetry upload process.",
          "Title: tool 1.13 probably broke deployment; Content:\r\n\r\nhttps://github.com/azure/tool-examples/runs/1618089261?check_suite_focus=true\r\n\r\n@trangevi \r\n\r\nhttps://github.com/tool/tool/pull/3419/files",
          "Title: connecting to vscode to tool; Content:<!-- important: please be sure to remove any private information before submitting. -->\r\n\r\ndoes this occur consistently? <!-- todo: type yes or no -->\r\nrepro steps:\r\n<!-- todo: share the steps needed to reliably reproduce the problem. please include actual and expected results. -->\r\n\r\n1.\r\n2.\r\n\r\naction: azureaccount.onsessionschanged\r\nerror type: 123\r\nerror message: unknown error retrieving susbcriptions from azure account extension\r\n\r\n\r\nversion: 0.20.0\r\nos: win32\r\nos release: 10.0.19044\r\nproduct: visual studio code\r\nproduct version: 1.72.2\r\nlanguage: en\r\n\r\n<details>\r\n<summary>call stack</summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:1975925\r\ns extension.js:2:1972612\r\n```\r\n\r\n</details>\r\n\r\n",
          "Title: [bug]: helm fetch command for ai-engine,sdk-helper and tool includes the 22.09 release instead of 22.11; Content:### version\r\n\r\n22.11\r\n\r\n### which installation method(s) does this occur on?\r\n\r\n_no response_\r\n\r\n### describe the bug.\r\n\r\nai-engine fetch command at the 22.11 guide:\r\nhelm fetch https://helm.ngc.nvidia.com/nvidia/morpheus/charts/morpheus-ai-engine-**22.09**.tgz --username='$oauthtoken' --password=$api_key --untar\r\n\r\nhelm fetch https://helm.ngc.nvidia.com/nvidia/morpheus/charts/morpheus-sdk-client-22.09.tgz --username='$oauthtoken' --password=$api_key --untar\r\n\r\nhelm fetch https://helm.ngc.nvidia.com/nvidia/morpheus/charts/morpheus-tool-22.09.tgz --username='$oauthtoken' --password=$api_key --untar\r\n\r\n### minimum reproducible example\r\n\r\n_no response_\r\n\r\n### relevant log output\r\n\r\n_no response_\r\n\r\n### full env printout\r\n\r\n_no response_\r\n\r\n### other/misc.\r\n\r\n_no response_\r\n\r\n### code of conduct\r\n\r\n- [x] i agree to follow morpheus' code of conduct\r\n- [x] i have searched the [open bugs](https://github.com/nv-morpheus/morpheus/issues?q=is%3aopen+is%3aissue+label%3abug) and have found no duplicates for this bug report",
          "Title: [bug] update test documentation to connect tool with github actions; Content:### description\r\n<!--- describe your issue/bug/request in detail -->\r\n\r\nsteps:\r\n1. create a new tool workspace.\r\n    - name: `tool-test-workspace`\r\n    - resource group: `recommenders_project_resources`\r\n    - location: *make sure you have enough quota in the location you choose*\r\n2. create two new clusters: `cpu-cluster` and `gpu-cluster`. go to compute, then compute cluster, then new.\r\n    - select the cpu vm base. anything above 32gb of ram, and 8 cores should be fine.\r\n    - select the gpu vm base. anything above 56gb of ram, and 6 cores, and an nvidia k80 should be fine.\r\n3. add the subscription id to github action secrets [here](https://github.com/microsoft/recommenders/settings/secrets/actions). create a new repository secret called `tool_test_subid` and add the subscription id as the value.\r\n4. make sure you have installed [azure cli](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli), and that you are logged in: `az login`.\r\n5. select your subscription: `az account set -s $azure_subscription_id`.\r\n5. create a service principal: `az ad sp create-for-rbac --name \"cicd\" --role contributor --scopes /subscriptions/$azure_subscription_id --sdk-auth`.\r\n6. add the output from the service principal (should be a json blob) as an action secret `tool_test_credentials`.\r\n\r\n\r\n\r\n### in which platform does it happen?\r\n<!--- describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- for example: -->\r\n<!--- * azure data science virtual machine. -->\r\n<!--- * azure databricks.  -->\r\n<!--- * other platforms.  -->\r\n\r\n### how do we replicate the issue?\r\n<!--- please be specific as possible (use a list if needed). -->\r\n<!--- for example: -->\r\n<!--- * create a conda environment for pyspark -->\r\n<!--- * run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\n\r\n### expected behavior (i.e. solution)\r\n<!--- for example:  -->\r\n<!--- * the tests for sar pyspark should pass successfully. -->\r\n\r\n### other comments\r\n",
          "Title: tool-defaults not described ; Content:\r\n[enter feedback here]\r\n\r\nwe need details description of `tool-defaults`. \r\n\r\nwe need this when deployment. in training, we usually use `tool-core`. in deployment, `tool-defaults` is necessary (only `tool-core` is not enough to deploy). i heard `tool-defaults` includes `tool-core`. but it is not documented.\r\n\r\n---\r\n#### document details\r\n\r\n⚠ *do not edit this section. it is required for docs.microsoft.com ➟ github issue linking.*\r\n\r\n* id: 8e0e12a4-b363-2726-06b4-9db2015efb32\r\n* version independent id: e39a91ac-375b-a2cc-350d-a82cb7b0b035\r\n* content: [install the tool sdk for python - tool python](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/install?view=azure-ml-py)\r\n* content source: [tool-docset/docs-ref-conceptual/install.md](https://github.com/microsoftdocs/machinelearning-python-pr/blob/live/tool-docset/docs-ref-conceptual/install.md)\r\n* service: **machine-learning**\r\n* sub-service: **core**\r\n* github login: @harneetvirk\r\n* microsoft alias: **harnvir**",
          "Title: i keep on getting this error continuously for tool extension; Content:<!-- important: please be sure to remove any private information before submitting. -->\r\n\r\ndoes this occur consistently? <!-- todo: type yes or no -->\r\nrepro steps:\r\n<!-- todo: share the steps needed to reliably reproduce the problem. please include actual and expected results. -->\r\n\r\n1. azure sign in\r\n2. sign in using azure portal. you get the sign in successful, you may close the window message, but azure asks to sign in again.\r\n\r\naction: azureaccount.onsessionschanged\r\nerror type: 123\r\nerror message: unknown error retrieving susbcriptions from azure account extension\r\n\r\n\r\nversion: 0.17.2022090809\r\nos: win32\r\nos release: 10.0.19042\r\nproduct: visual studio code - insiders\r\nproduct version: 1.72.0-insider\r\nlanguage: en\r\n\r\n<details>\r\n<summary>call stack</summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:2030116\r\ns extension.js:2:2026803\r\n```\r\n\r\n</details>\r\n",
          "Title: tool prompts twice to login when vs code (insiders) loads; Content:## expected behavior\r\nif the user is logged out, the aml extension should not prompt to login until the user specifically tries to run an tool command. prompting when vs code loads is disruptive and unnecessary, and no other extensions for aws or azure do this.\r\n\r\n## actual behavior\r\nif you are signed out of the azure ml extension and reload vs code, you are prompted to login when it loads (issue #1). if you click cancel, you are prompted again (#2). \r\n\r\n## steps to reproduce the problem\r\n  1. install the azure ml extension\r\n  2. login\r\n  3. logout\r\n  4. reload vs code\r\n  5. click \"cancel\" when prompted to login\r\n\r\n\r\n## specifications\r\nazure ml extension version 0.16.0\r\n \r\nversion: 1.70.0-insider (universal)\r\ncommit: da76f93349a72022ca4670c1b84860304616aaa2\r\ndate: 2022-08-03t05:55:27.651z (1 day ago)\r\nelectron: 18.3.5\r\nchromium: 100.0.4896.160\r\nnode.js: 16.13.2\r\nv8: 10.0.139.17-electron.0\r\nos: darwin x64 21.6.0\r\n\r\n\r\n",
          "Title: nyc-taxi-tool-deployment.yml refers to a folder that doesn't exists; Content:### operating system\n\nlinux\n\n### version information\n\nazure cli v2\n\n### steps to reproduce\n\nthe tool-example batch endpoint nyc-taxi-tool-deployment.yml file, refers to a  ./autolog_nyc_taxi folder that doesn't exist\n\n### expected behavior\n\nit looks like we need to re-add the folder?\n\n### actual behavior\n\ncode fails because folder doesn't exist\n\n### addition information\n\n_no response_",
          "Title: tool cli endpoint example out of date with new syntax from breaking changes in yaml (last updated may 11); Content:### operating system\n\nwindows\n\n### version information\n\nlatest cli v2 \n\n### steps to reproduce\n\nhttps://github.com/azure/tool-examples/blob/main/cli/endpoints/online/tool/sklearn-deployment.yaml\r\n\r\nthis yaml is out of date, the model yaml config is wrong. \"name\" is no longer required when specifying model.\n\n### expected behavior\n\nthat the deployment works based on sklearn-deployment.yml using the cli command `az create deployment`, but it fails. \n\n### actual behavior\n\nit fails.\n\n### addition information\n\n_no response_",
          "Title: remove tool sdk preview private pypi index from operationalize notebook; Content:this [notebook](https://github.com/microsoft/recommenders/blob/master/notebooks/04_operationalize/als_movie_o16n.ipynb) contains a reference to azure ml sdk preview private index. \r\n\r\n    # required packages for tool execution, history, and data preparation.\r\n    - --extra-index-url https://toolsdktestpypi.azureedge.net/sdk-release/preview/e7501c02541b433786111fe8e140caa1\r\n\r\ngiven that azure ml sdk is now available though regular pypi as a ga product, and preview versions are unsupported, the extra-index-url should be removed.\r\n",
          "Title: broken link in aml doc to tool.core.runconfig.mpiconfiguration; Content:\r\n<img width=\"1430\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5203025/123860354-63399680-d958-11eb-9dc8-dc0a52d67cc2.png\">\r\n\r\n---\r\n#### document details\r\n\r\n⚠ *do not edit this section. it is required for docs.microsoft.com ➟ github issue linking.*\r\n\r\n* id: 109d9284-e234-5086-5da6-4155291361c8\r\n* version independent id: 57cc0c7a-faa7-1a86-ee14-b9cf99fb540d\r\n* content: [tool.core.scriptrunconfig class - tool python](https://docs.microsoft.com/en-us/python/api/tool-core/tool.core.scriptrunconfig?view=azure-ml-py)\r\n* content source: [tool-docset/stable/docs-ref-autogen/tool-core/tool.core.scriptrunconfig.yml](https://github.com/microsoftdocs/machinelearning-python-pr/blob/live/tool-docset/stable/docs-ref-autogen/tool-core/tool.core.scriptrunconfig.yml)\r\n* service: **machine-learning**\r\n* sub-service: **core**\r\n* github login: @debfro\r\n* microsoft alias: **debfro**",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_azure_core_sdk",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "10_azure_core_sdk"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.379245281219482,
          6.454710006713867,
          5.657901287078857,
          7.334269046783447,
          6.5442585945129395,
          6.629700660705566,
          5.703181266784668,
          5.593573093414307,
          6.494113922119141,
          6.522521495819092,
          6.7541913986206055,
          6.87924337387085,
          6.412242412567139
         ],
         "y": [
          2.913407564163208,
          3.0134122371673584,
          1.6997389793395996,
          3.0541961193084717,
          2.9911115169525146,
          3.302614450454712,
          1.778586983680725,
          1.7146695852279663,
          3.123011589050293,
          3.079052686691284,
          3.3564982414245605,
          3.365150213241577,
          2.782620668411255
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: tool endpoint fail to deploy or time out server error(0) bug; Content:invoke endpoint response time out. \r\n\r\n### reproduction steps\r\n\r\n{\r\n  \"trainingjob\": {\r\n    \"hyperparameters\": {\r\n    \"n-hidden\": \"2\",\r\n    \"n-epochs\": \"100\",\r\n    \"lr\":\"1e-2\"\r\n    },\r\n    \"instancetype\": \"ml.c5.9xlarge\",\r\n    \"timeoutinseconds\": 10800    \r\n  }\r\n}\r\n\r\n\r\n\r\n### error log\r\nin inference lambda cloudwatch:\r\n\r\ntask timed out after 120.10 seconds\r\n\r\n\r\nin tool training cloudwatch:\r\n\r\n2021-04-09   04:53:46,902 [info ] main org.pytorch.serve.modelserver - loading initial   models: model.mar\r\n--\r\n2021-04-09 04:53:49,837 [info ] main   org.pytorch.serve.archive.modelarchive - etag   8ff2b3de4bed4fb1bc7fe969652117ff\r\n2021-04-09 04:53:49,847 [info ] main   org.pytorch.serve.wlm.modelmanager - model model loaded.\r\n2021-04-09 04:53:49,865 [info ] main   org.pytorch.serve.modelserver - initialize inference server with:   epollserversocketchannel.\r\n2021-04-09 04:53:49,930 [info ] main   org.pytorch.serve.modelserver - inference api bind to: http://0.0.0.0:8080\r\n2021-04-09 04:53:49,930 [info ] main   org.pytorch.serve.modelserver - initialize metrics server with:   epollserversocketchannel.\r\n2021-04-09 04:53:49,931 [info ] main   org.pytorch.serve.modelserver - metrics api bind to: http://127.0.0.1:8082\r\nmodel server started.\r\n2021-04-09 04:53:49,957 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - listening on   port: /home/model-server/tmp/.ts.sock.9000\r\n2021-04-09 04:53:49,959 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - [pid]55\r\n2021-04-09 04:53:49,959 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - torch worker   started.\r\n2021-04-09 04:53:49,959 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - python runtime:   3.6.13\r\n2021-04-09 04:53:49,963 [info ]   w-9000-model_1 org.pytorch.serve.wlm.workerthread - connecting to:   /home/model-server/tmp/.ts.sock.9000\r\n2021-04-09 04:53:49,972 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - connection   accepted: /home/model-server/tmp/.ts.sock.9000.\r\n2021-04-09 04:53:50,017 [info ]   pool-2-thread-1 ts_metrics -   cpuutilization.percent:33.3\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,017 [info ]   pool-2-thread-1 ts_metrics -   diskavailable.gigabytes:19.622234344482422\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,017 [info ]   pool-2-thread-1 ts_metrics -   diskusage.gigabytes:4.731609344482422\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,017 [info ]   pool-2-thread-1 ts_metrics -   diskutilization.percent:19.4\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,018 [info ]   pool-2-thread-1 ts_metrics -   memoryavailable.megabytes:30089.12109375\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,018 [info ]   pool-2-thread-1 ts_metrics -   memoryused.megabytes:902.6953125\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,018 [info ]   pool-2-thread-1 ts_metrics -   memoryutilization.percent:4.1\\|#level:host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - setting the   default backend to \"pytorch\". you can change it in the   ~/.dgl/config.json file or export the dglbackend environment variable.  valid options are: pytorch, mxnet,   tensorflow (all lowercase)\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   ------------------ loading model -------------------\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - backend worker   process died.\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - traceback (most   recent call last):\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/ts/model_service_worker.py\",   line 176, in <module>\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     worker.run_server()\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/ts/model_service_worker.py\",   line 148, in run_server\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     self.handle_connection(cl_socket)\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/ts/model_service_worker.py\",   line 112, in handle_connection\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     service, result, code =   self.load_model(msg)\r\n2021-04-09 04:53:51,250 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/ts/model_service_worker.py\",   line 85, in load_model\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     service = model_loader.load(model_name,   model_dir, handler, gpu, batch_size)\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/ts/model_loader.py\", line   117, in load\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -       model_service.initialize(service.context)\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/home/model-server/tmp/models/8ff2b3de4bed4fb1bc7fe969652117ff/handler_service.py\",   line 51, in initialize\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     super().initialize(context)\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/tool_inference/default_handler_service.py\",   line 66, in initialize\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -       self._service.validate_and_initialize(model_dir=model_dir)\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/tool_inference/transformer.py\",   line 158, in validate_and_initialize\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     self._model = self._model_fn(model_dir)\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/ml/model/code/fd_sl_deployment_entry_point.py\", line 149, in   model_fn\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -     rgcn_model.load_state_dict(stat_dict)\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle -   file   \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\",   line 1045, in load_state_dict\r\n2021-04-09   04:53:51,251 [info ] w-9000-model_1-stdout   org.pytorch.serve.wlm.workerlifecycle -       self.__class__.__name__, \"     \\t\".join(error_msgs)))\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - runtimeerror:   error(s) in loading state_dict for heterorgcn:\r\n2021-04-09 04:53:51,251 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - #011size   mismatch for layers.0.weight.deviceinfo<>target.weight: copying a param   with shape torch.size([2, 390]) from checkpoint, the shape in current model   is torch.size([16, 390]).\r\n2021-04-09 04:53:51,252 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - #011size   mismatch for layers.0.weight.deviceinfo<>target.bias: copying a param   with shape torch.size([2]) from checkpoint, the shape in current model is torch.size([16]).\r\n2021-04-09 04:53:51,252 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - #011size   mismatch for layers.0.weight.devicetype<>target.weight: copying a param   with shape torch.size([2, 390]) from checkpoint, the shape in current model   is torch.size([16, 390]).\r\n2021-04-09 04:53:51,252 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - #011size   mismatch for layers.0.weight.devicetype<>target.bias: copying a param   with shape torch.size([2]) from checkpoint, the shape in current model is torch.size([16]).\r\n2021-04-09 04:53:51,252 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - #011size   mismatch for layers.0.weight.p_emaildomain<>target.weight: copying a   param with shape torch.size([2, 390]) from checkpoint, the shape in current model   is torch.size([16, 390]).\r\n2021-04-09 04:53:51,252 [info ]   w-9000-model_1-stdout org.pytorch.serve.wlm.workerlifecycle - #011size   mismatch for layers.0.weight.p_emaildomain<>target.bias: copying a   param with shape torch.size([2]) from checkpoint, the shape in current model   is torch.size([16]).\r\n\r\n\r\n\r\n\r\n\r\n### environment\r\n\r\n  - **cdk cli version:** <!-- output of `cdk version` -->\r\n  - **framework version:**\r\n  - **node.js version:** <!-- version of node.js (run the command `node -v`) -->\r\n  - **os               :**\r\n\r\n### other\r\n\r\ncause of this bug:\r\n\r\nbackend worker process died.\r\ntool endpoint deployment code and model training code parameter conflict on n-hidden and hidden_size.\r\n\r\n\r\n--- \r\n\r\nthis is :bug: bug report",
          "Title: [bug] tool ml export widget throwing error; Content:**describe the bug**\r\nwhen using the tool ml widget to export data like the command below from the 01- node classification notebook:\r\n```\r\n%%tool_ml export start --export-url {tool_ml.get_export_service_host()} --export-iam --wait --store-to export_results\r\n${export_params}\r\n```\r\nthe following error is thrown\r\n```\r\n{\r\n  \"message\": \"credential should be scoped to correct service: 'execute-api'. \"\r\n}  \r\n```\r\n\r\n**expected behavior**\r\nthe export should run to completion\r\n\r\n\r\n",
          "Title: limit issue .with(\"tool#ml.limit\",3); Content:hi\r\n\r\nas per the below code it is allowing only default limit as 1 and the limit 3 is not working and throwing error for introduction to node classification gremlin\r\n\r\n%%gremlin\r\ng.with(\"tool#ml.endpoint\",\"node-cla-2021-07-15-15-13-940000-endpoint\").with( \"tool#ml.limit\", 3 ).v().has('title', 'toy story (1995)').properties(\"genre\").with(\"tool#ml.classification\").value()\r\n\r\nerror\r\n{\r\n  \"requestid\": \"fbab9b0a-176c-47f8-accc-969fc4580792\",\r\n  \"detailedmessage\": \"incompatible data from external service. please check your service configuration and query again.\",\r\n  \"code\": \"constraintviolationexception\"\r\n}\r\n\r\ncan some one suggest is there something wrong with the code which was mentioned in the document\r\n\r\n",
          "Title: tool endpoint prediction error, 4 deadline_exceeded: deadline exceeded; Content:#### environment details\r\n\r\n  - os: mac m1 pro\r\n  - node.js version: v16.16.0\r\n  - npm version: 8.11.0\r\n  - `@google-cloud/aiplatform` version: ^2.3.0\r\n\r\n#### steps to reproduce\r\n\r\n  1. i've run this demo on my local computer: https://github.com/googleapis/nodejs-ai-platform/blob/main/samples/predict-text-classification.js\r\n  2. the process paused and shows `4 deadline_exceeded: deadline exceeded` in the line: `await predictionserviceclient.predict(request);`\r\n\r\n\r\nthanks!\r\n",
          "Title: getting an error from `aws_tool_notebook_instance` table. please see the detail below.; Content:**describe the bug**\r\n\r\ncreate a notebook instance in one of the configured region.\r\nran the below query and got that error\r\n\r\n```\r\nselect * from aws_tool_notebook_instance;\r\nerror: hydrate call listawstoolnotebookinstancetags failed with panic interface conversion: interface {} is *tool.notebookinstancesummary, not *tool.describenotebookinstanceoutput\r\n\r\n```\r\n\r\n\r\n\r\n**steampipe version (`steampipe -v`)**\r\n: v0.4.1\r\n\r\n**plugin version (`steampipe plugin list`)**\r\naws: v0.15.0\r\n\r\n\r\n\r\n\r\n",
          "Title: resourcelimitexceeded for ml.m4.xlarge when running tool studio demo in a new aws account; Content:when walking through the tool studio tour :\r\n\r\nhttps://docs.aws.amazon.com/tool/latest/dg/gs-studio-end-to-end.html\r\n\r\nfor the first time in a new aws account, the usual service limit issue is hit when running code cell [17] to create an endpoint to host the model.\r\n\r\n`resourcelimitexceeded: an error occurred (resourcelimitexceeded) when calling the createendpoint operation: the account-level service limit 'ml.m4.xlarge for endpoint usage' is 0 instances, with current utilization of 0 instances and a request delta of 1 instances. please contact aws support to request an increase for this limit.`\r\n\r\nsuggestions:\r\n\r\n- the \"prerequistes\" section could address this proactively, with a link to the service limit increase page, or...\r\n-  the notebook could be changed to use an instance type for the endpoint that does not have a default service limit of `0`\r\n\r\nplease lmk which is preferable and i will submit a pr\r\n\r\n",
          "Title: [bug] aws tool templates for p3.2, p3.16 fail to start; Content:**describe the bug**\r\n\r\ncloud formation for tool fails on a p3.2 and p3.16 yet succeeds on a g4dn\r\n\r\nreported by a tool user\r\n\r\n**to reproduce**\r\n\r\nrun through tool tutorial and use a p3.16\r\n\r\n**expected behavior**\r\nit launches\r\n\r\n**actual behavior**\r\nformation template stalls out and auto-deletes\r\n\r\nworking on getting logs. after 10min, gpu services (forge-etl-python + streamgl) failed to start. v100 issue?\r\n\r\n**screenshots**\r\n\r\n**browser environment (please complete the following information):**\r\nall\r\n\r\n**pygraphistry environment**\r\nall\r\n\r\n**additional context**\r\ncurrent graph-app-kit",
          "Title: support tensorflow with the new tool.tensorflow.serving.model; Content:trainingpipeline needs to be updated to accommodate the `tool.tensorflow.serving.model` from tensorflow package.\r\n\r\nrelated thread: https://github.com/aws/tool-python-sdk/issues/1201",
          "Title: we are experiencing elevated fault rate in start runtime api. the tool studio lab team is working to restore the service.; Content:its been more than 3 days and im still getting this issue, i cant run cpu or even gpu runtimes in tool\r\nhow long is this going to even take man",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_53_stdout_pytorch",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "11_53_stdout_pytorch"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.9594502449035645,
          7.204676151275635,
          7.831605911254883,
          7.938594818115234,
          7.505162239074707,
          7.836967468261719,
          7.6489949226379395,
          7.520095348358154,
          7.943490028381348,
          7.709893226623535
         ],
         "y": [
          2.590876340866089,
          2.441932201385498,
          2.5224056243896484,
          2.436004877090454,
          2.253884792327881,
          2.5505199432373047,
          2.4315364360809326,
          2.3004140853881836,
          2.6168668270111084,
          2.460493564605713
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: \"null is not an object\" while trying to connect to tool notebook.; Content:**describe the bug**\r\noccasionally after starting a tool workspace, clicking 'connect' gives an error in the bottom right-hand corner of the screen:\r\n\r\n> we have a problem!\r\n> null is not an object (evaluating 'l.location=s') \r\n\r\nin a little red box on the bottom-right of the screen. the notebook window is not opened after clicking on 'connect'.\r\n\r\n**to reproduce**\r\nthe error is intermittent. i *think* it may happen after the sw window has been open a while, because i noticed that the sw window automatically logged me out shortly after seeing this error.\r\n\r\n1. click 'start' for tool workspace and wait for the status to change to 'available'. \r\n2. click 'connections', then 'connect'\r\n3. see error\r\n\r\nwhen i logged out and back into service workbench, and was able to connect to the workspace successfully. \r\n\r\n**expected behavior**\r\na new window should open with a jupyter/tool notebook in a new window. \r\n\r\n**versions (please complete the following information):**\r\n - 3.2.0\r\n",
          "Title: [bug] tool notebook-v3 workspace changed to \"unknown\" status and cannot connect anymore; Content:**describe the bug**\r\na tool notebook-v3 workspace that was working fine on friday today appears with the status as \"unknown\". \r\nwhen clicking on connect the new window pop up but is empty, and when going back to the swb page, we see the message, \"we have a problem! something went wrong\"\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. go to 'workspaces'\r\n2. look for the workspace that was expected to be \"stoped\"\r\n2. click on 'connect'\r\n4. see error\r\n\r\n**expected behavior**\r\nthat the workspace was \"stopped\" and when clicking on connect we can access to the workspace. \r\n\r\n**screenshots**\r\n![screen shot 2021-09-13 at 1 27 57 pm](https://user-images.githubusercontent.com/19646530/133129766-85139082-e6e7-4fe1-8624-dedebf573ea5.png)\r\n\r\n**versions (please complete the following information):**\r\nrelease version installed: 3.3.1\r\n\r\n**additional context**\r\nthe workspace was working fine all previous week, autostop and connect without any issue. unknown status found today.",
          "Title: [bug] tool instances can't be launched due to missing tags permission; Content:**describe the bug**\r\nservice workbench appears to be unable to launch tool notebook instances at all, due to a missing permission for `tool:addtags`. this seems to also be the case when custom tags aren't included in the workspace configuration.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. install service workbench from the latest version.\r\n2. create a workspace configuration for a tool notebook.\r\n3. launch a workspace using the new configuration.\r\n4. wait a few minutes and observe the error.\r\n\r\n**expected behavior**\r\nexpected the notebook to launch :)\r\n\r\n**screenshots**\r\n![image](https://user-images.githubusercontent.com/900469/181163664-98441ee8-7316-4d29-8f85-79d3e5e6ed3c.png)\r\n```\r\nerror provisioning environment testnotebook1. reason: errors from cloudformation: [{logicalresourceid : sc-455040667691-pp-auh6sv7j6dwr2, resourcetype : aws::cloudformation::stack, statusreason : the following resource(s) failed to create: [basicnotebookinstance]. rollback requested by user.}, {logicalresourceid : basicnotebookinstance, resourcetype : aws::tool::notebookinstance, statusreason : user: arn:aws:sts::xxxxxxxxxxxx:assumed-role/dev-syd-timswb-launchconstraint/servicecatalog is not authorized to perform: tool:addtags on resource: arn:aws:tool:ap-southeast-2:xxxxxxxxxxxx:assumed:notebook-instance/basicnotebookinstance-y4ices04e3sv because no identity-based policy allows the tool:addtags action (service: amazontool; status code: 400; error code: accessdeniedexception; request id: adee97b7-1c89-47e2-8ca7-5aa374a80004; proxy: null)}, {logicalresourceid : iamrole, resourcetype : aws::iam::role, statusreason : resource creation initiated}, {logicalresourceid : securitygroup, resourcetype : aws::ec2::securitygroup, statusreason : resource creation initiated}, {logicalresourceid : instancerolepermissionboundary, resourcetype : aws::iam::managedpolicy, statusreason : resource creation initiated}, {logicalresourceid : basicnotebookinstancelifecycleconfig, resourcetype : aws::tool::notebookinstancelifecycleconfig, statusreason : resource creation initiated}, {logicalresourceid : sc-455040667691-pp-auh6sv7j6dwr2, resourcetype : aws::cloudformation::stack, statusreason : user initiated}]\r\n```\r\n\r\n**versions (please complete the following information):**\r\n5.2.0\r\n(also replicated on an older 5.0.0 install)\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: [bug] tool instance does not stop automatically; Content:**describe the bug**\r\n\r\nidle tool notebook instances do not stop after specified time.\r\n\r\nswb runs autostop.py script to automatically stop tool notebook instance. the script is used by `on-start` lifecycle rule of the instance cfn template. according to lifecycleconfigonstart logs, some packages are missing and autostop script doesn’t work.\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. make sure autostopidletimeinminutes parameter in workspace type config is set to a required time (30 minutes in our case)\r\n2. create a new workspace with tool notebook instance\r\n3. leave the instance idle for the time specified (autostopidletimeinminutes )\r\n4. after the specified time see that the instance is not stopped\r\n\r\n**expected behavior**\r\nidle tool notebook instance automatically stops after specified time.\r\n\r\n**screenshots**\r\n<img width=\"1308\" alt=\"screen shot 2022-12-07 at 10 43 09 am\" src=\"https://user-images.githubusercontent.com/47466926/206049662-5ff12457-8bd4-42bd-b12f-ce68fdfacaf6.png\">\r\n\r\n\r\n**versions (please complete the following information):**\r\n - release version installed v5.0.0\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: [bug] blank page on tool workspace connect; Content:**describe the bug**\r\nwhen connecting to tool workspaces, there is an intermittent issue where a blank browser launches instead of tool.  the issue presents for workspaces that are newly created as well as for workspaces that were already created, but were stopped and are being restarted.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n\r\nstep 1: login as an admin \r\nstep 2: create a workspace (tool)\r\nstep 3: start the workspace \r\nstep 5: click \"connect\"\r\nstep 6: a new blank web browser tab opens \r\nstep 7: click \"connect\" again, another blank web browser tab opens\r\n\r\nuser receives a \"something went wrong\" general error in swb at step 6\r\n\r\nin the client logs for the browser, there is also this error noted:\r\n              \"name\": \"x-cache\",\r\n              \"value\": \"error from cloudfront\"\r\n   \r\n\r\n**expected behavior**\r\ntool workspace launch in browser\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n**versions (please complete the following information):**\r\n - release version installed 3.0.0\r\n\r\n**additional context**\r\nuser has cleared cache and it solved the issue, but for one of her employees clearing the cache did not solve the issue. \r\n\r\nthe issue is experienced approximately once a week. sometimes clearing cache solves the issue. other times going to incognito, and it does not solve the issue.\r\n\r\n",
          "Title: [bug] more descriptive error message for \"null is not an object\" while trying to connect to tool notebook. ; Content:**describe the bug**\r\nusers get the error \"null is not an object\" when pop-ups are enabled in swb (reference:[ issue #620](https://github.com/awslabs/service-workbench-on-aws/issues/620))\r\nthis error is illegible to the user and causes confusion. can we make the error message more clear such as:\r\n\"service workbench is encountering an error showing content. please enable pop-ups and refresh the page.\"\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. diable pop-ups \r\n2. connect to a workspace\r\n\r\n**expected behavior**\r\nif the workspace is unable to open, a more legible error message should be shown, such as \"service workbench is encountering an error showing content. please enable pop-ups and refresh the page.\"\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n**versions (please complete the following information):**\r\n - release version installed [e.g. v4.3.1 and v5.0.0]\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          "Title: [bug] in hongkong region, after user stop tool workspace manually, web console show \"unknown\" status; Content:**describe the bug**\r\na clear and concise description of what the bug is.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. deploy swb in hongkong reigon\r\n2. create a tool workspace\r\n3. click \"stop\" button.\r\n5. workspace status show \"unknown\"\r\n",
          "Title: [bug] tool template, after auto stoped, workspace env status is not updated; Content:**describe the bug**\r\nafter tool workspace stopped automatically, workspace env status is not updated.\r\n\r\n**to reproduce**\r\nsteps to reproduce the behavior:\r\n1. set tool workspace config's autostopidletimeinminutes as 10 minutes\r\n2. create tool workspace and wait for more than 10 minutes,\r\n3. check tool notebook instances to confirm the instance status is stopped\r\n4. check service workbench workspace status, it is still \"available\"\r\n\r\n**expected behavior**\r\n1. above step 4, workspace status should be \"stopped\"\r\n\r\n**screenshots**\r\nif applicable, add screenshots to help explain your problem.\r\n\r\n**versions (please complete the following information):**\r\n - release version installed [e.g. v1.0.3]\r\n\r\n**additional context**\r\nadd any other context about the problem here.\r\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_workspace_connect_stopped",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "12_workspace_connect_stopped"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.2822651863098145,
          5.218852519989014,
          5.345761299133301,
          5.118907451629639,
          5.193665981292725,
          5.243902206420898,
          5.207518100738525,
          5.224067687988281,
          5.229367256164551
         ],
         "y": [
          1.2052665948867798,
          1.2427278757095337,
          1.3815912008285522,
          1.4687871932983398,
          1.2740323543548584,
          1.2696551084518433,
          1.2869373559951782,
          1.3044604063034058,
          1.3041822910308838
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: fsd clone for non-tool repos throws an error; Content:when using `fds clone` for non-tool repo it throws the following error:\r\n\r\n`error: you are not inside of a tool repository (checked up to mount point '/')`\r\n\r\ncloning a non-tool repo using fds can be a common use case, e.g., cloning a dagshub repo containing many files, but none of them are tracked by tool nur the repo contains tool config files. \r\n\r\ni suggest that after cloning the git server, fds will check if the repo contains tool files. \r\n\r\nif it contains tool files:\r\n  - echo 'starting tool clone...`\r\n  - fds will start a wizard to set the user name and password for each remote storage in the local config. (consider checking if they are set in the global config file first?)\r\n  - fds will pull all the files from the remotes and show a progress bar (might be reasonable to ask if the user wants to pull the files from each remote)\r\n \r\nit doesn't contain tool files:\r\n  - fds will initialize tool\r\n  \r\n    if the git server url is dagshub's:\r\n      - fds will set dagshub storage as the remote using the git url (replacing`.git` with `.tool`).\r\n      - fds will start a wizard to set the remote user name, password, and name.\r\n      \r\n    else:\r\n       - fds will start a wizard asking do you want to set a tool remote\r\n       if yes:\r\n           - with the wizard, the user will set the remote url, name, username, and password.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "Title: example-get-started is broken with latest tool; Content:> from https://github.com/iterative/tool.org/issues/1743#issuecomment-730726776\r\n\r\n```console\r\n$ git@github.com:iterative/example-get-started.git\r\n...\r\n$ cd example-get-started\r\n$ tool fetch\r\nerror: failed to fetch data from the cloud - lockfile 'tool.lock' is corrupted.\r\n```",
          "Title: need to rebuild get-started with the latest tool version; Content:experience is broken since every tool command changes `.gitignore` now - makes it very annoying to jump between branches.",
          "Title: fds fails to pull tool on windows; Content:when running pull command on dagshub remote. i receive tool pull failure, so i have to manually pull tool again. \n\nthis issue permanent issue on windows. \n\n```bash\nfds clone <remote> \n\n```\n\nit is not urgent issue, but in annoyance category. ",
          "Title: [bug] apt-get failure in tool-local-test builds; Content:\r\n*description:*\r\n\r\nan apt-get error is seen in `tool-local-test` builds as below. this is because `apt-get` process is already running and in active state.\r\n\r\n```\r\ne: could not get lock /var/lib/dpkg/lock-frontend - open (11: resource temporarily unavailable)\r\n--\r\n294 | e: unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?\r\n```\r\n\r\n\r\n\r\n\r\n",
          "Title: error: 'tool.lock' is git-ignored.; Content:```\r\n$ tool repro run_benchmarks\r\nerror: 'tool.lock' is git-ignored.\r\n```\r\n\r\n`.tool.lock` in `.gitignore` causes exceptions at running benchmark. delete this line solves this problem. and because of #168 maybe we need some better ways to deal with `tool.lock`.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_fds_lock_remote",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "13_fds_lock_remote"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.910769939422607,
          6.523611545562744,
          6.38464879989624,
          5.8350605964660645,
          6.362790107727051,
          6.401163578033447,
          6.2363409996032715
         ],
         "y": [
          4.537860870361328,
          4.243275165557861,
          4.3027424812316895,
          4.383169174194336,
          4.360369682312012,
          4.2541046142578125,
          4.346920013427734
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": 4.3510713338851925,
          "y": 3.66048946082592,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 8.985961711406707,
          "xshift": 10,
          "y": 6.768575000762939
         }
        ],
        "height": 750,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 8.985961711406707,
          "x1": 8.985961711406707,
          "y0": 0.5524039208889008,
          "y1": 6.768575000762939
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": 4.3510713338851925,
          "x1": 13.620852088928222,
          "y0": 3.66048946082592,
          "y1": 3.66048946082592
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Documents and Topics",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  2.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "text": [
          "launcher_title_checklist_markdown_highlight",
          "",
          "",
          "init_yml_port_tools_cli"
         ],
         "type": "scatter",
         "x": [
          0,
          0.6625472947957267,
          0.6625472947957267,
          0
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -15,
          -15
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "text": [
          "yml_ui_bug_https_checklist",
          "",
          "",
          "azure_core_sdk_telemetry_artifacts"
         ],
         "type": "scatter",
         "x": [
          0,
          0.7868996269021099,
          0.7868996269021099,
          0
         ],
         "xaxis": "x",
         "y": [
          -25,
          -25,
          -35,
          -35
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "fds_lock_remote_git_dagshub",
          "",
          "",
          "cli_azure_title_yml_bug"
         ],
         "type": "scatter",
         "x": [
          0.6625472947957267,
          1.084661734208626,
          1.084661734208626,
          0.7868996269021099
         ],
         "xaxis": "x",
         "y": [
          -10,
          -10,
          -30,
          -30
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "workspace_connect_stopped_screenshots_instance",
          "",
          "",
          "bucket_aws_kubeflow_s3_job"
         ],
         "type": "scatter",
         "x": [
          0,
          1.0367566243844666,
          1.0367566243844666,
          0
         ],
         "xaxis": "x",
         "y": [
          -55,
          -55,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "workspace_aws_bucket_connect_kubeflow",
          "",
          "",
          "v1_api_chart_aws_types"
         ],
         "type": "scatter",
         "x": [
          0,
          1.05824018653683,
          1.05824018653683,
          0
         ],
         "xaxis": "x",
         "y": [
          -75,
          -75,
          -85,
          -85
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "fds_azure_title_dagshub_yml",
          "",
          "",
          "aws_workspace_kubeflow_bucket_tool"
         ],
         "type": "scatter",
         "x": [
          1.0367566243844666,
          1.3000443722646893,
          1.3000443722646893,
          1.05824018653683
         ],
         "xaxis": "x",
         "y": [
          -60,
          -60,
          -80,
          -80
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "miniconda3_columns_dict_save_catalog",
          "",
          "",
          "conda_envs_python3_pipeline_setuptools"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1387843119089391,
          1.1387843119089391,
          0
         ],
         "xaxis": "x",
         "y": [
          -95,
          -95,
          -105,
          -105
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "self_python3_miniconda_experiment_name_torch",
          "",
          "",
          "trainer_algo_pytorch_loss_python3"
         ],
         "type": "scatter",
         "x": [
          1.3000443722646893,
          1.3161400682466406,
          1.3161400682466406,
          1.1387843119089391
         ],
         "xaxis": "x",
         "y": [
          -70,
          -70,
          -100,
          -100
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "miniconda3_envs_site_conda_python",
          "",
          "",
          "self_trainer_python3_pytorch_lightning_torch"
         ],
         "type": "scatter",
         "x": [
          0,
          1.3677945615783327,
          1.3677945615783327,
          1.3161400682466406
         ],
         "xaxis": "x",
         "y": [
          -45,
          -45,
          -85,
          -85
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "info_verbose_false_display_experiment_name",
          "",
          "",
          "google_requirement_ec2_python3_auth"
         ],
         "type": "scatter",
         "x": [
          0,
          1.27163597559267,
          1.27163597559267,
          0
         ],
         "xaxis": "x",
         "y": [
          -115,
          -115,
          -125,
          -125
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "53_stdout_pytorch_org_torch",
          "",
          "",
          "br_2020_google_requirement_verbose"
         ],
         "type": "scatter",
         "x": [
          1.27163597559267,
          1.3500378785224807,
          1.3500378785224807,
          0
         ],
         "xaxis": "x",
         "y": [
          -120,
          -120,
          -135,
          -135
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "python3_line_file_packages_site",
          "",
          "",
          "stdout_09_pytorch_google_py3"
         ],
         "type": "scatter",
         "x": [
          1.3677945615783327,
          1.5776548428738006,
          1.5776548428738006,
          1.3500378785224807
         ],
         "xaxis": "x",
         "y": [
          -65,
          -65,
          -127.5,
          -127.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "cli_fds_workspace_bug_azure",
          "",
          "",
          "python3_br_envs_line_file"
         ],
         "type": "scatter",
         "x": [
          1.084661734208626,
          1.9412440440263001,
          1.9412440440263001,
          1.5776548428738006
         ],
         "xaxis": "x",
         "y": [
          -20,
          -20,
          -96.25,
          -96.25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "fds_lock_remote_git_dagshub",
          "fds_azure_title_dagshub_yml",
          "self_python3_miniconda_experiment_name_torch",
          "53_stdout_pytorch_org_torch",
          "python3_line_file_packages_site",
          "cli_fds_workspace_bug_azure"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.6625472947957267,
          1.0367566243844666,
          1.3000443722646893,
          1.27163597559267,
          1.3677945615783327,
          1.084661734208626
         ],
         "y": [
          -10,
          -60,
          -70,
          -120,
          -65,
          -20
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "cli_azure_title_yml_bug",
          "aws_workspace_kubeflow_bucket_tool",
          "trainer_algo_pytorch_loss_python3",
          "self_trainer_python3_pytorch_lightning_torch",
          "stdout_09_pytorch_google_py3",
          "python3_br_envs_line_file"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.7868996269021099,
          1.05824018653683,
          1.1387843119089391,
          1.3161400682466406,
          1.3500378785224807,
          1.5776548428738006
         ],
         "y": [
          -30,
          -80,
          -100,
          -85,
          -127.5,
          -96.25
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 410,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -140,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "0_trainer_algo_pytorch",
          "1_self_python3_miniconda",
          "5_conda_envs_python3",
          "7_miniconda3_columns_dict",
          "13_fds_lock_remote",
          "4_v1_api_chart",
          "3_bucket_aws_kubeflow",
          "12_workspace_connect_stopped",
          "6_launcher_title_checklist",
          "2_init_yml_port",
          "10_azure_core_sdk",
          "8_google_requirement_ec2",
          "9_info_verbose_false",
          "11_53_stdout_pytorch"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125,
          -135
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.028893686702551036,
          0.0376795330789566,
          0.03828240713250696,
          0.06841733585203842,
          0.07111762361946815
         ],
         "xaxis": "x",
         "y": [
          "python3  ",
          "loss  ",
          "pytorch  ",
          "algo  ",
          "trainer  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.025363097439217903,
          0.026346477273376117,
          0.02765120973801668,
          0.03780637275415287,
          0.04617065984347029
         ],
         "xaxis": "x2",
         "y": [
          "torch  ",
          "experiment_name  ",
          "miniconda  ",
          "python3  ",
          "self  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03931928022636568,
          0.04730620736551871,
          0.04813655053849692,
          0.0806070021336818,
          0.08650815884073297
         ],
         "xaxis": "x3",
         "y": [
          "cli  ",
          "tools  ",
          "port  ",
          "yml  ",
          "init  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03383122007355072,
          0.04014116686569094,
          0.051208644520274904,
          0.05759883586754449,
          0.07589967066859753
         ],
         "xaxis": "x4",
         "y": [
          "job  ",
          "s3  ",
          "kubeflow  ",
          "aws  ",
          "bucket  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03888124370482809,
          0.04605758177968241,
          0.0463772679568431,
          0.046947545031745266,
          0.08850143903816722
         ],
         "xaxis": "x5",
         "y": [
          "types  ",
          "aws  ",
          "chart  ",
          "api  ",
          "v1  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.02577565711535719,
          0.030008512207435126,
          0.04018167830765223,
          0.041491268288034275,
          0.04603490712743796
         ],
         "xaxis": "x6",
         "y": [
          "setuptools  ",
          "pipeline  ",
          "python3  ",
          "envs  ",
          "conda  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.05489414030911219,
          0.055516197905809625,
          0.059446323034253706,
          0.09189313231977504,
          0.10091041511911439
         ],
         "xaxis": "x7",
         "y": [
          "highlight  ",
          "markdown  ",
          "checklist  ",
          "title  ",
          "launcher  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.04464426144429113,
          0.04720834156707988,
          0.04800176271605526,
          0.05678672547112655,
          0.05684362538226653
         ],
         "xaxis": "x8",
         "y": [
          "catalog  ",
          "save  ",
          "dict  ",
          "columns  ",
          "miniconda3  "
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_trainer_algo_pytorch",
          "1_self_python3_miniconda",
          "2_init_yml_port",
          "3_bucket_aws_kubeflow",
          "4_v1_api_chart",
          "5_conda_envs_python3",
          "6_launcher_title_checklist",
          "7_miniconda3_columns_dict",
          "8_google_requirement_ec2",
          "9_info_verbose_false",
          "10_azure_core_sdk",
          "11_53_stdout_pytorch",
          "12_workspace_connect_stopped",
          "13_fds_lock_remote"
         ],
         "xaxis": "x",
         "y": [
          "0_trainer_algo_pytorch",
          "1_self_python3_miniconda",
          "2_init_yml_port",
          "3_bucket_aws_kubeflow",
          "4_v1_api_chart",
          "5_conda_envs_python3",
          "6_launcher_title_checklist",
          "7_miniconda3_columns_dict",
          "8_google_requirement_ec2",
          "9_info_verbose_false",
          "10_azure_core_sdk",
          "11_53_stdout_pytorch",
          "12_workspace_connect_stopped",
          "13_fds_lock_remote"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           0.7226338540295721,
           0.6425956644185239,
           0.5861838235724374,
           0.6501686545060217,
           0.7154138294422749,
           0.591663159769097,
           0.6575198359463759,
           0.6499296337277463,
           0.6281710551926163,
           0.6327100923500287,
           0.7479488043525023,
           0.629838812578056,
           0.6292322015026647
          ],
          [
           0.7226338540295721,
           1.0000000000000007,
           0.677499519375882,
           0.6365089278123862,
           0.665578170833246,
           0.7758301596669949,
           0.628101002250212,
           0.8059787314843814,
           0.7160569260951977,
           0.67555422926155,
           0.5740352659623611,
           0.7019630447356765,
           0.6218098183907972,
           0.6155850323219738
          ],
          [
           0.6425956644185239,
           0.677499519375882,
           1.0000000000000004,
           0.5509035054838467,
           0.7113607521952561,
           0.7582264450474027,
           0.6639095230660457,
           0.6739077772017688,
           0.6298375969144543,
           0.6263355987886193,
           0.6503415204699994,
           0.6167589434871721,
           0.6528670646258142,
           0.6553479425844839
          ],
          [
           0.5861838235724374,
           0.6365089278123862,
           0.5509035054838467,
           1.0000000000000002,
           0.7392008305859671,
           0.6213931213274756,
           0.5526046507856387,
           0.6419154858985887,
           0.7233830285603444,
           0.5116713379257027,
           0.6308149536505041,
           0.6053727688562861,
           0.6444566206473463,
           0.5708966444275893
          ],
          [
           0.6501686545060217,
           0.665578170833246,
           0.7113607521952561,
           0.7392008305859671,
           0.9999999999999997,
           0.744910073571366,
           0.6044204856313283,
           0.6740097140510022,
           0.7367763584399628,
           0.5786756268333341,
           0.7230696258303964,
           0.6399889093861857,
           0.6500140498896676,
           0.6046983544702441
          ],
          [
           0.7154138294422749,
           0.7758301596669949,
           0.7582264450474027,
           0.6213931213274756,
           0.744910073571366,
           1,
           0.6003562276296686,
           0.7491249962392593,
           0.7119143229660592,
           0.6017508488707797,
           0.6186240017697558,
           0.6764649644173281,
           0.6191442617303101,
           0.5982146436219226
          ],
          [
           0.591663159769097,
           0.628101002250212,
           0.6639095230660457,
           0.5526046507856387,
           0.6044204856313283,
           0.6003562276296686,
           1,
           0.6328898193600457,
           0.6607729917355853,
           0.6496428456974281,
           0.6024121367719394,
           0.5998556634538246,
           0.6883052494301349,
           0.6578099402110851
          ],
          [
           0.6575198359463759,
           0.8059787314843814,
           0.6739077772017688,
           0.6419154858985887,
           0.6740097140510022,
           0.7491249962392593,
           0.6328898193600457,
           1.0000000000000004,
           0.702987226246954,
           0.687232911496752,
           0.5714379460220417,
           0.6491380625317735,
           0.6609458141774915,
           0.631262127016912
          ],
          [
           0.6499296337277463,
           0.7160569260951977,
           0.6298375969144543,
           0.7233830285603444,
           0.7367763584399628,
           0.7119143229660592,
           0.6607729917355853,
           0.702987226246954,
           1.0000000000000004,
           0.6477983538519828,
           0.6900747297834284,
           0.6393346314687942,
           0.6758312296339453,
           0.6211378181077539
          ],
          [
           0.6281710551926163,
           0.67555422926155,
           0.6263355987886193,
           0.5116713379257027,
           0.5786756268333341,
           0.6017508488707797,
           0.6496428456974281,
           0.687232911496752,
           0.6477983538519828,
           0.9999999999999999,
           0.5402652812346606,
           0.6685361947879567,
           0.6416829524781754,
           0.6124610146358246
          ],
          [
           0.6327100923500287,
           0.5740352659623611,
           0.6503415204699994,
           0.6308149536505041,
           0.7230696258303964,
           0.6186240017697558,
           0.6024121367719394,
           0.5714379460220417,
           0.6900747297834284,
           0.5402652812346606,
           1.0000000000000002,
           0.6155823130951115,
           0.6269403482136672,
           0.6026634400904864
          ],
          [
           0.7479488043525023,
           0.7019630447356765,
           0.6167589434871721,
           0.6053727688562861,
           0.6399889093861857,
           0.6764649644173281,
           0.5998556634538246,
           0.6491380625317735,
           0.6393346314687942,
           0.6685361947879567,
           0.6155823130951115,
           0.9999999999999998,
           0.6154473218385473,
           0.6290988787041446
          ],
          [
           0.629838812578056,
           0.6218098183907972,
           0.6528670646258142,
           0.6444566206473463,
           0.6500140498896676,
           0.6191442617303101,
           0.6883052494301349,
           0.6609458141774915,
           0.6758312296339453,
           0.6416829524781754,
           0.6269403482136672,
           0.6154473218385473,
           0.9999999999999998,
           0.6528865019501469
          ],
          [
           0.6292322015026647,
           0.6155850323219738,
           0.6553479425844839,
           0.5708966444275893,
           0.6046983544702441,
           0.5982146436219226,
           0.6578099402110851,
           0.631262127016912,
           0.6211378181077539,
           0.6124610146358246,
           0.6026634400904864,
           0.6290988787041446,
           0.6528865019501469,
           1.0000000000000002
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertext": "<b>Topic -1</b>:mxnet_containers_anaconda3_envs_co",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.379206249337379,
          -1.428497104596322,
          -1.4702161608225717,
          -1.5193383373573655,
          -1.567782851030721,
          -1.601112962015911,
          -1.6712157397275338,
          -1.6930304181508287,
          -1.6979225554975483,
          -1.700776065919571
         ]
        },
        {
         "hovertext": "<b>Topic 0</b>:trainer_algo_pytorch_loss_python3_c",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.1480227636547513,
          -1.16483384110222,
          -1.4170007623398735,
          -1.4238944875800374,
          -1.5391970406264666,
          -1.5414107449611754,
          -1.5734536677444901,
          -1.5832884489102144,
          -1.6499795402285145,
          -1.6803440456991512
         ]
        },
        {
         "hovertext": "<b>Topic 1</b>:self_python3_miniconda_experiment_n",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.3356339187273873,
          -1.4224349880281661,
          -1.5582858635978976,
          -1.5792774450817646,
          -1.5957977098353968,
          -1.6130105505590828,
          -1.641505744423838,
          -1.7297116598147821,
          -1.7391506802295054,
          -1.7559867075188376
         ]
        },
        {
         "hovertext": "<b>Topic 2</b>:init_yml_port_tools_cli_version_gal",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0629429310044067,
          -1.0936272304537913,
          -1.3175250344550742,
          -1.3250818688242274,
          -1.4053944409054853,
          -1.421473580033898,
          -1.4280863481820414,
          -1.4742297956866137,
          -1.5287301180541122,
          -1.5710122924755476
         ]
        },
        {
         "hovertext": "<b>Topic 3</b>:bucket_aws_kubeflow_s3_job_py_noteb",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.1197601085198174,
          -1.239586294031835,
          -1.2906567196773389,
          -1.396410007135901,
          -1.4706823397332738,
          -1.592419519287563,
          -1.6004094672078248,
          -1.6145043112403878,
          -1.7419385212102039,
          -1.782090822304645
         ]
        },
        {
         "hovertext": "<b>Topic 4</b>:v1_api_chart_aws_types_kubeflow_pip",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.053049667593087,
          -1.3283871128130347,
          -1.3336948388419476,
          -1.336698868093672,
          -1.410259851628861,
          -1.4767954744568315,
          -1.500700291350165,
          -1.5277171364432407,
          -1.5338656370941421,
          -1.5669862473447642
         ]
        },
        {
         "hovertext": "<b>Topic 5</b>:conda_envs_python3_pipeline_setupto",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.336912728673719,
          -1.382043289632917,
          -1.3959719276044404,
          -1.5227555359353064,
          -1.5887902541555665,
          -1.6331265981830083,
          -1.640689805391597,
          -1.6638015171936786,
          -1.6851226821141676,
          -1.687827224496339
         ]
        },
        {
         "hovertext": "<b>Topic 6</b>:launcher_title_checklist_markdown_h",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9960640072484511,
          -1.036716944621237,
          -1.2258750028673127,
          -1.2555802847194202,
          -1.2604740119658968,
          -1.2896490565541847,
          -1.2908207110821377,
          -1.3659041510277843,
          -1.384481110260379,
          -1.4069770191798074
         ]
        },
        {
         "hovertext": "<b>Topic 7</b>:miniconda3_columns_dict_save_catalo",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.2453182313549964,
          -1.245753173591973,
          -1.3187428142119173,
          -1.3259812561016164,
          -1.3502343572288789,
          -1.351586418874181,
          -1.4445859318005478,
          -1.4520414298371311,
          -1.482391603133412,
          -1.5937972629126802
         ]
        },
        {
         "hovertext": "<b>Topic 8</b>:google_requirement_ec2_python3_auth",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.1100996681642903,
          -1.1403428433045697,
          -1.2759313992400068,
          -1.308381070874518,
          -1.3522012781190378,
          -1.38354525158591,
          -1.4843665055469766,
          -1.544211360724315,
          -1.565514852103328,
          -1.572793629843401
         ]
        },
        {
         "hovertext": "<b>Topic 9</b>:info_verbose_false_display_experime",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0473067436687293,
          -1.2525382421183113,
          -1.2899322977385783,
          -1.4751254781849108,
          -1.491728504320282,
          -1.5491671971069048,
          -1.6095054307772672,
          -1.632995163627913,
          -1.677531583121143,
          -1.6858210943235181
         ]
        },
        {
         "hovertext": "<b>Topic 10</b>:azure_core_sdk_telemetry_artifacts",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8154985802417931,
          -0.997291470100783,
          -1.0729528075192196,
          -1.361876892505659,
          -1.4419699869502707,
          -1.4532471966258873,
          -1.4574982656863327,
          -1.550665742644229,
          -1.5792293570712965,
          -1.6453284971765296
         ]
        },
        {
         "hovertext": "<b>Topic 11</b>:53_stdout_pytorch_org_torch_timest",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8163017096408628,
          -0.8930073821408046,
          -0.9503746772436796,
          -1.0643659107293224,
          -1.3224273829876512,
          -1.4137280344428131,
          -1.428370608111911,
          -1.4905458462154815,
          -1.521932880739343,
          -1.5674986912070126
         ]
        },
        {
         "hovertext": "<b>Topic 12</b>:workspace_connect_stopped_screensh",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8564404525130539,
          -1.0094868222954994,
          -1.2119951437811631,
          -1.2882265375589352,
          -1.3578692686538347,
          -1.3810956220356758,
          -1.3832307257986658,
          -1.4059466777189058,
          -1.4129098963561988,
          -1.4327772615864927
         ]
        },
        {
         "hovertext": "<b>Topic 13</b>:fds_lock_remote_git_dagshub_clonin",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7114710421306967,
          -0.7763411343125481,
          -0.9678740356498662,
          -0.9862131537204797,
          -1.0331904256842512,
          -1.101907442206915,
          -1.1119947632847003,
          -1.178257231901266,
          -1.3877051585596951,
          -1.4554684991244295
         ]
        }
       ],
       "layout": {
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Term score decline per Topic</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "dtick": 2,
         "range": [
          0,
          10
         ],
         "tick0": 1,
         "title": {
          "text": "Term Rank"
         }
        },
        "yaxis": {
         "title": {
          "text": "c-TF-IDF score (log scale)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = TfidfVectorizer(min_df=3, stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "  diversity=0.5,                      # Step 6 - Diversify topic words\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue, 'issues_preprocessed_with_code.json'))\n",
    "topic_model = topic_model.fit(df_issues['Issue_content_preprocessed'].tolist())\n",
    "topic_model.get_topic_info()\n",
    "topic_model.visualize_topics()\n",
    "topic_model.visualize_documents(df_issues['Issue_content_preprocessed'].tolist())\n",
    "hierarchical_topics = topic_model.hierarchical_topics(df_issues['Issue_content_preprocessed'].tolist())\n",
    "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "topic_model.visualize_barchart()\n",
    "topic_model.visualize_heatmap()\n",
    "topic_model.visualize_term_rank(log_scale=True)\n",
    "topic_model.save(os.path.join(path_labeling_issue_native_code, 'topic_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example No.3: feed the issue content (without code) to the text-davinci-003 model and get the summary, then feed the summary to topic model and get the topics\n",
    "import re\n",
    "\n",
    "regex = r\"(<.+?>)|(\\`{3}.+?\\`{3})|(\\`{2}.+?\\`{2})|(\\`{1}.+?\\`{1})|({.*?})|(\\\\u[0-9a-z]+)|((!)?\\[.*?\\])|(\\(.+?\\))|([a-z0-9-\\.]+[<=>]=[a-z0-9\\.]+)|(@[a-z0-9]+)|((https?:\\/)?\\/[^\\s]+)|(\\\\[^\\s]+)|([^\\s]+\\\\[^\\s]+)|([^\\s]+\\.[^\\s]+)|([a-z]+_[a-z]+)|(_+[a-z]+_*)|(_*[a-z]+_+)|([0-9\\|\\-\\r\\n\\t\\\"\\*#*=~-]+)\"\n",
    "\n",
    "# preprocess the content of the issues\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue, 'issues.json'))\n",
    "df_issues['Issue_content_preprocessed'] = ''\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    content = 'Title: ' + row['Issue_title'].lower() + '; Content:' + str(row['Issue_body']).lower()\n",
    "    content = content.encode('ascii', errors='ignore').decode('ascii')\n",
    "    content = re.sub(regex, ' ', content, flags=re.S)\n",
    "    for tool_keyword in tool_keyword_list:\n",
    "        if tool_keyword in content:\n",
    "            content = content.replace(tool_keyword, '')\n",
    "    content = ' '.join([w for w in content.split() if len(w)>1])\n",
    "    df_issues.at[index, 'Issue_content_preprocessed'] = content\n",
    "\n",
    "df_issues['Issue_summary'] = ''\n",
    "df_issues.to_json(os.path.join(path_labeling_issue, 'issues_preprocessed_without_code.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on issue 0\n",
      "working on issue 1\n",
      "working on issue 2\n",
      "working on issue 3\n",
      "working on issue 4\n",
      "working on issue 5\n",
      "working on issue 6\n",
      "working on issue 7\n",
      "working on issue 8\n",
      "working on issue 9\n",
      "working on issue 10\n",
      "working on issue 11\n",
      "working on issue 12\n",
      "working on issue 13\n",
      "working on issue 14\n",
      "working on issue 15\n",
      "working on issue 16\n",
      "working on issue 17\n",
      "working on issue 18\n",
      "working on issue 19\n",
      "working on issue 20\n",
      "working on issue 21\n",
      "working on issue 22\n",
      "working on issue 23\n",
      "working on issue 24\n",
      "working on issue 25\n",
      "working on issue 26\n",
      "working on issue 27\n",
      "working on issue 28\n",
      "working on issue 29\n",
      "working on issue 30\n",
      "working on issue 31\n",
      "working on issue 32\n",
      "working on issue 33\n",
      "working on issue 34\n",
      "working on issue 35\n",
      "working on issue 36\n",
      "working on issue 37\n",
      "working on issue 38\n",
      "working on issue 39\n",
      "working on issue 40\n",
      "working on issue 41\n",
      "working on issue 42\n",
      "working on issue 43\n",
      "working on issue 44\n",
      "working on issue 45\n",
      "working on issue 46\n",
      "working on issue 47\n",
      "working on issue 48\n",
      "working on issue 49\n",
      "working on issue 50\n",
      "working on issue 51\n",
      "working on issue 52\n",
      "working on issue 53\n",
      "working on issue 54\n",
      "working on issue 55\n",
      "working on issue 56\n",
      "working on issue 57\n",
      "working on issue 58\n",
      "working on issue 59\n",
      "working on issue 60\n",
      "working on issue 61\n",
      "working on issue 62\n",
      "working on issue 63\n",
      "working on issue 64\n",
      "working on issue 65\n",
      "working on issue 66\n",
      "working on issue 67\n",
      "working on issue 68\n",
      "working on issue 69\n",
      "working on issue 70\n",
      "working on issue 71\n",
      "working on issue 72\n",
      "working on issue 73\n",
      "working on issue 74\n",
      "working on issue 75\n",
      "working on issue 76\n",
      "working on issue 77\n",
      "working on issue 78\n",
      "working on issue 79\n",
      "working on issue 80\n",
      "working on issue 81\n",
      "working on issue 82\n",
      "working on issue 83\n",
      "working on issue 84\n",
      "working on issue 85\n",
      "working on issue 86\n",
      "working on issue 87\n",
      "working on issue 88\n",
      "working on issue 89\n",
      "working on issue 90\n",
      "working on issue 91\n",
      "working on issue 92\n",
      "working on issue 93\n",
      "working on issue 94\n",
      "working on issue 95\n",
      "working on issue 96\n",
      "working on issue 97\n",
      "working on issue 98\n",
      "working on issue 99\n",
      "working on issue 100\n",
      "working on issue 101\n",
      "working on issue 102\n",
      "working on issue 103\n",
      "working on issue 104\n",
      "working on issue 105\n",
      "working on issue 106\n",
      "working on issue 107\n",
      "working on issue 108\n",
      "working on issue 109\n",
      "working on issue 110\n",
      "working on issue 111\n",
      "working on issue 112\n",
      "working on issue 113\n",
      "working on issue 114\n",
      "working on issue 115\n",
      "working on issue 116\n",
      "working on issue 117\n",
      "working on issue 118\n",
      "working on issue 119\n",
      "working on issue 120\n",
      "working on issue 121\n",
      "working on issue 122\n",
      "working on issue 123\n",
      "working on issue 124\n",
      "working on issue 125\n",
      "working on issue 126\n",
      "working on issue 127\n",
      "working on issue 128\n",
      "working on issue 129\n",
      "working on issue 130\n",
      "working on issue 131\n",
      "working on issue 132\n",
      "working on issue 133\n",
      "working on issue 134\n",
      "working on issue 135\n",
      "working on issue 136\n",
      "working on issue 137\n",
      "working on issue 138\n",
      "working on issue 139\n",
      "working on issue 140\n",
      "working on issue 141\n",
      "working on issue 142\n",
      "working on issue 143\n",
      "working on issue 144\n",
      "working on issue 145\n",
      "working on issue 146\n",
      "working on issue 147\n",
      "working on issue 148\n",
      "working on issue 149\n",
      "working on issue 150\n",
      "working on issue 151\n",
      "working on issue 152\n",
      "working on issue 153\n",
      "working on issue 154\n",
      "working on issue 155\n",
      "working on issue 156\n",
      "working on issue 157\n",
      "working on issue 158\n",
      "working on issue 159\n",
      "working on issue 160\n",
      "working on issue 161\n",
      "working on issue 162\n",
      "working on issue 163\n",
      "working on issue 164\n",
      "working on issue 165\n",
      "working on issue 166\n",
      "working on issue 167\n",
      "working on issue 168\n",
      "working on issue 169\n",
      "working on issue 170\n",
      "working on issue 171\n",
      "working on issue 172\n",
      "working on issue 173\n",
      "working on issue 174\n",
      "working on issue 175\n",
      "working on issue 176\n",
      "working on issue 177\n",
      "working on issue 178\n",
      "working on issue 179\n",
      "working on issue 180\n",
      "working on issue 181\n",
      "working on issue 182\n",
      "working on issue 183\n",
      "working on issue 184\n",
      "working on issue 185\n",
      "working on issue 186\n",
      "working on issue 187\n",
      "working on issue 188\n",
      "working on issue 189\n",
      "working on issue 190\n",
      "working on issue 191\n",
      "working on issue 192\n",
      "working on issue 193\n",
      "working on issue 194\n",
      "working on issue 195\n",
      "working on issue 196\n",
      "working on issue 197\n",
      "working on issue 198\n",
      "working on issue 199\n",
      "working on issue 200\n",
      "working on issue 201\n",
      "working on issue 202\n",
      "working on issue 203\n",
      "working on issue 204\n",
      "working on issue 205\n",
      "working on issue 206\n",
      "working on issue 207\n",
      "working on issue 208\n",
      "working on issue 209\n",
      "working on issue 210\n",
      "working on issue 211\n",
      "working on issue 212\n",
      "working on issue 213\n",
      "working on issue 214\n",
      "working on issue 215\n",
      "working on issue 216\n",
      "working on issue 217\n",
      "working on issue 218\n",
      "working on issue 219\n",
      "working on issue 220\n",
      "working on issue 221\n",
      "working on issue 222\n",
      "working on issue 223\n",
      "working on issue 224\n",
      "working on issue 225\n",
      "working on issue 226\n",
      "working on issue 227\n",
      "working on issue 228\n",
      "working on issue 229\n",
      "working on issue 230\n",
      "working on issue 231\n",
      "working on issue 232\n",
      "working on issue 233\n",
      "working on issue 234\n",
      "working on issue 235\n",
      "working on issue 236\n",
      "working on issue 237\n",
      "working on issue 238\n",
      "working on issue 239\n",
      "working on issue 240\n",
      "working on issue 241\n",
      "working on issue 242\n",
      "working on issue 243\n",
      "working on issue 244\n",
      "working on issue 245\n",
      "working on issue 246\n",
      "working on issue 247\n",
      "working on issue 248\n",
      "working on issue 249\n",
      "working on issue 250\n",
      "working on issue 251\n",
      "working on issue 252\n",
      "working on issue 253\n",
      "working on issue 254\n",
      "working on issue 255\n",
      "working on issue 256\n",
      "working on issue 257\n",
      "working on issue 258\n",
      "working on issue 259\n",
      "working on issue 260\n",
      "working on issue 261\n",
      "working on issue 262\n",
      "working on issue 263\n",
      "working on issue 264\n",
      "working on issue 265\n",
      "working on issue 266\n",
      "working on issue 267\n",
      "working on issue 268\n",
      "working on issue 269\n",
      "working on issue 270\n",
      "working on issue 271\n",
      "working on issue 272\n",
      "working on issue 273\n",
      "working on issue 274\n",
      "working on issue 275\n",
      "working on issue 276\n",
      "working on issue 277\n",
      "working on issue 278\n",
      "working on issue 279\n",
      "working on issue 280\n",
      "working on issue 281\n",
      "working on issue 282\n",
      "working on issue 283\n",
      "working on issue 284\n",
      "working on issue 285\n",
      "working on issue 286\n",
      "working on issue 287\n",
      "working on issue 288\n",
      "working on issue 289\n",
      "working on issue 290\n",
      "working on issue 291\n",
      "working on issue 292\n",
      "working on issue 293\n",
      "working on issue 294\n",
      "working on issue 295\n",
      "working on issue 296\n",
      "working on issue 297\n",
      "working on issue 298\n",
      "working on issue 299\n",
      "working on issue 300\n",
      "working on issue 301\n",
      "working on issue 302\n",
      "working on issue 303\n",
      "working on issue 304\n",
      "working on issue 305\n",
      "working on issue 306\n",
      "working on issue 307\n",
      "working on issue 308\n",
      "working on issue 309\n",
      "working on issue 310\n",
      "working on issue 311\n",
      "working on issue 312\n",
      "working on issue 313\n",
      "working on issue 314\n",
      "working on issue 315\n",
      "working on issue 316\n",
      "working on issue 317\n",
      "working on issue 318\n",
      "working on issue 319\n",
      "working on issue 320\n",
      "working on issue 321\n",
      "working on issue 322\n",
      "working on issue 323\n",
      "working on issue 324\n",
      "working on issue 325\n",
      "working on issue 326\n",
      "working on issue 327\n",
      "working on issue 328\n",
      "working on issue 329\n",
      "working on issue 330\n",
      "working on issue 331\n",
      "working on issue 332\n",
      "working on issue 333\n",
      "working on issue 334\n",
      "working on issue 335\n",
      "working on issue 336\n",
      "working on issue 337\n",
      "working on issue 338\n",
      "working on issue 339\n",
      "working on issue 340\n",
      "working on issue 341\n",
      "working on issue 342\n",
      "working on issue 343\n",
      "working on issue 344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_requests = []\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    print(f'working on issue {index}')\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model='text-davinci-003',\n",
    "            prompt='Use 1 to 2 sentences to summarize the following issue.\\nText: \"\"\"' +\n",
    "            row['Issue_content_preprocessed'] + '\"\"\"\"\\n',\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        df_issues.at[index,\n",
    "                     'Issue_summary'] = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        error_requests.append(index)\n",
    "    time.sleep(5)\n",
    "\n",
    "error_requests\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling_issue_gpt_text, 'issues_summary.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6e48a0752a4f47b503cfececcf58b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 09:16:54,692 - BERTopic - Transformed documents to Embeddings\n",
      "2023-02-11 09:16:58,943 - BERTopic - Reduced dimensionality\n",
      "2023-02-11 09:16:58,970 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "      <td>-1_github_issue_test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0_model_classification_feature_registered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1_project_does_cli_plugin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2_parameters_errors_warning_api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3_training_validation_logging_ddp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4_aws_limit_conda_gpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5_loss_gpu_progress_tensorboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6_user_looking_information_ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>7_chart_helm_pull_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8_pipeline_develop_solution_version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9_experiment_encountered_running_fails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10_runs_registered_failed_ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11_artifacts_branch_models_master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>12_ml_import_unnecessary_sdk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13_install_python_preventing_workaround</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>14_content_node_missing_creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>15_plugin_exceptions_importing_dependencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>16_remove_base_repository_bucket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>17_workspace_connect_status_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>18_notebook_error_location_template</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>19_deployment_cli_occurred_changes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                         Name\n",
       "0      -1     98                -1_github_issue_test_notebook\n",
       "1       0     24    0_model_classification_feature_registered\n",
       "2       1     23                    1_project_does_cli_plugin\n",
       "3       2     20              2_parameters_errors_warning_api\n",
       "4       3     18            3_training_validation_logging_ddp\n",
       "5       4     16                        4_aws_limit_conda_gpu\n",
       "6       5     14              5_loss_gpu_progress_tensorboard\n",
       "7       6     12                6_user_looking_information_ui\n",
       "8       7     11                   7_chart_helm_pull_pipeline\n",
       "9       8     11          8_pipeline_develop_solution_version\n",
       "10      9     10       9_experiment_encountered_running_fails\n",
       "11     10     10                 10_runs_registered_failed_ui\n",
       "12     11     10            11_artifacts_branch_models_master\n",
       "13     12      9                 12_ml_import_unnecessary_sdk\n",
       "14     13      9      13_install_python_preventing_workaround\n",
       "15     14      9             14_content_node_missing_creation\n",
       "16     15      9  15_plugin_exceptions_importing_dependencies\n",
       "17     16      9             16_remove_base_repository_bucket\n",
       "18     17      8          17_workspace_connect_status_service\n",
       "19     18      8          18_notebook_error_location_template\n",
       "20     19      7           19_deployment_cli_occurred_changes"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "model | classification | feature | registered | base",
           24
          ],
          [
           1,
           "project | does | cli | plugin | directory",
           23
          ],
          [
           2,
           "parameters | errors | warning | api | log",
           20
          ],
          [
           3,
           "training | validation | logging | ddp | loss",
           18
          ],
          [
           4,
           "aws | limit | conda | gpu | studio",
           16
          ],
          [
           5,
           "loss | gpu | progress | tensorboard | logging",
           14
          ],
          [
           6,
           "user | looking | information | ui | resolve",
           12
          ],
          [
           7,
           "chart | helm | pull | pipeline | endpoint",
           11
          ],
          [
           8,
           "pipeline | develop | solution | version | causes",
           11
          ],
          [
           9,
           "experiment | encountered | running | fails | program",
           10
          ],
          [
           10,
           "runs | registered | failed | ui | status",
           10
          ],
          [
           11,
           "artifacts | branch | models | master | versions",
           10
          ],
          [
           12,
           "ml | import | unnecessary | sdk | studio",
           9
          ],
          [
           13,
           "install | python | preventing | workaround | github",
           9
          ],
          [
           14,
           "content | node | missing | creation | stage",
           9
          ],
          [
           15,
           "plugin | exceptions | importing | dependencies | longer",
           9
          ],
          [
           16,
           "remove | base | repository | bucket | local",
           9
          ],
          [
           17,
           "workspace | connect | status | service | loading",
           8
          ],
          [
           18,
           "notebook | error | location | template | replicate",
           8
          ],
          [
           19,
           "deployment | cli | occurred | changes | request",
           7
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>Words: %{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           24,
           23,
           20,
           18,
           16,
           14,
           12,
           11,
           11,
           10,
           10,
           10,
           9,
           9,
           9,
           9,
           9,
           8,
           8,
           7
          ],
          "sizemode": "area",
          "sizeref": 0.015,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          3.6972012519836426,
          4.489972114562988,
          3.871142625808716,
          -0.3990637958049774,
          1.424505352973938,
          -0.07069414108991623,
          4.650445938110352,
          3.465517044067383,
          3.53031063079834,
          3.1449806690216064,
          -0.18032559752464294,
          3.405967950820923,
          3.129934549331665,
          1.1813955307006836,
          18.511474609375,
          0.04138467460870743,
          1.6250851154327393,
          19.041229248046875,
          18.7456111907959,
          2.646280527114868
         ],
         "xaxis": "x",
         "y": [
          9.89309310913086,
          10.784347534179688,
          10.389827728271484,
          11.888130187988281,
          -14.163320541381836,
          11.86025333404541,
          11.12582778930664,
          12.352526664733887,
          10.540002822875977,
          10.164406776428223,
          11.369547843933105,
          11.356297492980957,
          10.745820045471191,
          -13.924333572387695,
          -18.744251251220703,
          12.049630165100098,
          -14.361350059509277,
          -19.274002075195312,
          -18.978376388549805,
          11.37882137298584
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -0.458923365175724,
          "y": -3.9798483610153195,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 10.71924513503909,
          "xshift": 10,
          "y": 14.205405664443969
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 10.71924513503909,
          "x1": 10.71924513503909,
          "y0": -22.165102386474608,
          "y1": 14.205405664443969
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -0.458923365175724,
          "x1": 21.897413635253905,
          "y0": -3.9798483610153195,
          "y1": -3.9798483610153195
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 7",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 8",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 9",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 10",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 11",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 12",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 13",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 14",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 15",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 16",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 17",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 18",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 19",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -0.458923365175724,
          21.897413635253905
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -22.165102386474608,
          14.205405664443969
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "The issue is that running a Python script results in an error, \"TypeError: unhashable type: 'list'\", when running certain sections of code.",
          "This question is about how to save a Hydra configuration that is no longer saving to a file, and restoring it to its previous state.",
          "This issue is about an infinite loop caused by an unhandled training job status of 'stopped', and labels impacted by this bug need to be identified in order to prioritize the issue.",
          "This blogpost is outdated after its release, and trying to follow the instructions fails due to changes in the ZenML version. Reproduction steps and relevant log output are provided, and users must agree to the project's code of conduct.",
          "Calling a job from the client that is not in progress causes the client to hang, particularly when using the SM Executor. Debug output is included.",
          "A bug has been discovered where telemetry installed alongside a packaged and installed project breaks the project by assuming that a file exists when it should not. This causes an exception to be thrown when running the project.",
          "There is an error in the pipeline in Github Actions which is preventing tests from passing.",
          "The issue is about an endpoint not being able to load a model file and use image paths as features. The bug exists on the latest stable and mainline versions of Autogluon, and may be related to the transition from MXNet to PyTorch.",
          "The issue is that when a notebook is launched with an associated study, the study folders are not mounted due to the lack of an AWS credentials file. This issue is new and has occurred within the last couple of weeks with no changes to the environment.",
          "This issue is about an error encountered when trying to follow a tutorial and documentation page for the Live package, and whether there are any updates to the API.",
          "The training pipeline needs to be updated to support the new TensorFlow package. A related thread has been created to discuss this issue.",
          "This issue discusses the error that occurs when running examples after installing Graphnet from scratch, and suggests that it would be helpful to automatically create a folder in the directory where the file is running from, if it is not already present.",
          "A warning message appears when calling a command, but it can be safely ignored as the command works as intended; the bug is caused by the dynamic creation of the command.",
          "The tour walkthrough document skips over the first code cells, jumping straight to the th code cell in the notebook, and does not reference the need to run the previous code cells for the notebook to work.",
          "Pandas dataframes with array column values are not being saved correctly, resulting in data loss. An example is provided.",
          "We should create an instance for each project to view related experiments, and update the KDL app API, project operator Docker image, and Helm chart to facilitate this. Additionally, GitHub workflows should be added to publish the project operator in Docker Hub.",
          "There is an error with a training job, as no kind is registered for the specified version.",
          "There is an issue with saving plots, resulting in an error with an unexpected keyword argument 'system'.",
          "The \"example get started\" feature is not working properly with the latest version of the content.",
          "Apt get is failing in local test builds due to an active process already running.",
          "The bug is that checkpoints are not being written correctly, and additional context suggests that the symlinking model needs to be better understood in order to fix the issue.",
          "The issue is that the sasrec integration test is taking an unusually long time to complete on the compute cluster, and the team needs to investigate why this is happening and how to replicate the issue.",
          "The product team has recommended that the contrib package should be removed, and all tests should be checked to ensure that everything runs as expected on the DSVM and DB platforms.",
          "There is an issue with loading providers in a fresh conda environment, resulting in script execution being halted. A fix is proposed, but further details are needed to identify the source of the problem.",
          "This issue discusses the lack of support for writing out dataset profiles in JSON format when a format config is specified, instead using the protobuf bin format.",
          "The command to add data files to tracking is failing, preventing the addition of image files to the raw data directory.",
          "An error occurred when attempting to add an extension to an OpenShift cluster, resulting in an \"extensioncreationfailed\" error code. Telemetry records were created and an upload process was initiated.",
          "A user is experiencing an algorithmerror when using SMP training with a LED model, and has tried several fixes to no avail. They are now receiving an unexpectedstatusexception error and are looking for help.",
          "There is a bug with the function from hugging face that prevents it from accessing the tracked data directory, resulting in a \"read only file system\" error.",
          "The start runtime API is experiencing a higher than normal fault rate, and the studio lab team is working to resolve the issue, which has been ongoing for several days.",
          "Loading configs from the hparams objects was resulting in incorrect parameters, but this bug has been fixed and the same configs can now be loaded correctly.",
          "Studio Lab is not opening Jupyter Notebook and has been stuck in a \"Preparing Project Run Time\" loop for over a week, despite attempts to switch the runtime from CPU to GPU.",
          "The issue is that the UI does not use the arguments from the description as described in the command, and the bug also happens with the last version on master. A solution is to pass the arguments in the command.",
          "Experiments may fail if the container variable specifies an incorrect IP address, and it is important to handle this exception correctly.",
          "The issue is that the entity is hardcoded in the icenet version, and should be changed to either the default user or be able to be overridden by the command line, and the same should be done for the project.",
          "This issue describes an error that occurs when running a program, resulting in a failure to log uncommitted code. The user is looking for a way to fix the issue and provides steps to reproduce the behavior.",
          "The issue is that the graph tab does not render correctly in Studio Jupyter Lab, and screenshots of the current and expected behavior are included.",
          "A mistake was made when placing a model in the wrong folder, causing an infinite silent loop. Logging has been added to make the issue more verbose and a patch will be uploaded to try and fix the problem.",
          "The issue is that the UI does not use the arguments from the description as described in the command, resulting in the UI opening on the wrong port. It also happens with the last version on master, and the solution is to pass the arguments in the command.",
          "There is a bug when testing a model where metrics are not logged to the environment, and it is believed to be caused by the object called in the logger. A hacky solution exists, but the SDK does not currently support this kind of experiment.",
          "The experience of using the latest version is broken due to frequent changes in commands, making it difficult to switch between branches.",
          "The current version of the title may need to be updated, as it is a little dated.",
          "The user is having difficulty compiling examples while trying out the Kubeflow notebook in a workshop, resulting in a pipeline compile error.",
          "An AttributeError has been encountered when running a certain code, indicating that the 'workspace' object does not have an attribute called 'uri'.",
          "Issues have been reported while running experiments following the documentation, such as not having a certain package installed, an error when running a stage, and some unclear statements in the documentation.",
          "This issue discusses the need to add support for namespaces in data catalogs, as the current lack of support can cause issues with KFP artifacts.",
          "A bug has been identified where some plot types are not being saved to the experiment artifacts directory, likely due to inconsistent naming of the file. A printout of the log when it tries to save the calibration plot is included.",
          "The issue is that the endpoint prediction error deadline was exceeded while running a demo on a Mac Pro with a specific version of npm.",
          "This issue describes a bug in an example DAG that uses access key and secret key instead of a temporary access token. Screenshots and additional context are provided to help explain the problem.",
          "The prompt to add files should only be displayed when there is something to add, as it currently displays even when the list of files is empty.",
          "Trying to run an NVIDIA image following the instructions in the README, but the system is not detecting the GPU and training is not beginning.",
          "An issue has arisen where an older instance was turned on and one of the two study folders associated with it was not syncing any of the files, resulting in a permissions denied error. This is a major problem as people have been actively using the software and their work is now gone.",
          "The title suggests that a deployment process has gone wrong, potentially causing an issue.",
          "This issue involves a strange warning message being printed when running a command that uses the hyperdrive loading with providers, which is not expected behavior.",
          "The random agent script is skipping some steps when logging full episode data, which is caused by counting the episode reward logging steps made before the full data logging. A potential solution is to add a metric to log the timestep and day.",
          "There is an issue with the branch where if the setup is set to true, it is resulting in an error when trying to plot in TypeError.",
          "A bug has been identified in the SWB version of Jupyter Notebook workspace, where mounting a study fails with an error. To fix the issue, the user must run sudo yum install fuse.",
          "There is a bug when using the basic logging via context manager, which does not log the run context in the tracking UI. A proposed solution is to add tags internally to the package, which would make the process seamless and managed by the package.",
          "Hyperparameter tuning requires a folder to be created, but if the standard is followed, it can be omitted and the backend store argument does not need to be run.",
          "Deployments on the Kubernetes environment in Launchpad can fail unexpectedly, and the fix is to delete the pod and start over. It is possible that the issue is related to a corrupted SQLite database or an issue with Tritonclient.",
          "The bug occurs when a prefix is not specified when creating a run, causing the metric to be logged in a new run instead of the expected one. This issue also occurs with the latest version on the develop branch.",
          "The text in the notebooks for machine learning incorrectly states the genre for a node classification task.",
          "This issue discusses updating the requirements to ensure compatibility with older versions, as ignoring the lockfile is no longer allowed.",
          "The bug guide's quicklaunch link is currently pointing to the full launcher instead of the minimal launcher, which is not the expected behavior.",
          "Remote test reporting issues have been observed in PR commits, where the GitHub status shows pending and the CodeBuild logs show failed, but the actual CodeBuild logs terminate abruptly without any error. The expected behavior is for the PR commit status to say failed and for the CodeBuild log to print out the error.",
          "A bug a few weeks ago changed the ordering of imports, requiring to be imported before torch and tensorboard to work properly. This forces users to manually add an unused import for before importing to avoid triggering the error.",
          "We encountered an issue with the auto stop script where instances were hanging around for days due to a syntax error. After some investigation, it was found that the syntax error was introduced in a commit and was not being overridden by a custom config. The script and repo were updated to remove the syntax error.",
          "The issue is about not being able to connect a local notebook to a remote SSL, and not being able to specify the correct certificate when running queries against the SSL.",
          "The user is experiencing an issue with Cloud Formation failing to launch, and GPU services failing to start after a few minutes. They are working on getting logs to help diagnose the issue.",
          "The issue is about an outdated API in Transformers that is causing warnings and preventing HPO with the backend from working correctly. A migration to the new and improved experience is needed by July.",
          "An exception was thrown when running code to train a model, with the exception being \"invalid experiment id\". The steps to reproduce the behavior are provided, as well as the environment information.",
          "The introduction section of the notebook under object detection contains two broken links, which can be replicated by clicking the links. This issue occurs on all platforms.",
          "Data parallelism feature is not working on AWS for distributed training, resulting in empty tensors instead of the expected behavior.",
          "The issue is that when running the matching engine sample notebook, the aiplatform module cannot be imported, resulting in an error.",
          "Ocurate is having difficulty running a simple spaceflights example with astrocloud, and is unable to get it to work. They are using Airflow with Astrocloud on Ubuntu Linux, but are receiving a failure in the local Airflow image.",
          "This issue is related to a logger, but no further information is provided.",
          "The test process is not providing a signal when it fails, making it difficult to identify errors and replicate the issue. We want to send a signal back to Github so that if the tests fail, the badge is red and we are notified.",
          "The ml export widget is throwing an error when attempting to export data from the node classification notebook, which should not be happening.",
          "The bug occurs when attempting to copy a single notebook using the 'Open in Studio Lab' button, resulting in an error. Cloning the whole repository works as expected.",
          "The issue is related to combining something that might not work.",
          "This issue focuses on finding a solution to fix a bad request issue with Minio.",
          "A warning message appears when calling a command, but it can be safely ignored as the command works as intended; the bug is caused by the dynamic creation of the command.",
          "This issue is about an error with xdeepfm, and is asking for more information about the platform it is happening on, how to replicate the issue, and what the expected behavior should be.",
          "There is a conflict between the versions of hydra optuna sweeper installed and the latest versions, causing an error when running a hyperparametric search. The syntax of optuna sweeper has changed in hydra since version and when the syntax was changed to the new version, the problem was solved. However, there is still an error when running the training process with a certain parameters combination.",
          "MalformedQueryException has been encountered when using Amundsen Metadata with a database, and a possible solution has been identified. A PR has been created to solve the issue.",
          "This issue is about updating test documentation to connect with Github Actions, including steps to create a new workspace, two new clusters, and a service principal. It also includes questions about the platform, how to replicate the issue, and expected behavior.",
          "When using FDS to clone a non-repo, an error is thrown. FDS should check if the repo contains files and, if so, start a wizard to set the user name, password, and name for each remote storage.",
          "There is a broken link in the AML document, and the issue ID, version independent ID, content source, service, sub service, GitHub login, and alias have been provided.",
          "There is an issue with the new async operators where users are getting authentication errors, even when using the same credentials as with the traditional operators. Switching back to the traditional operators resolves the issue.",
          "The user is experiencing an issue where they are being denied permission when attempting to log models on a Mac.",
          "There is a version conflict between Python, PyTorch, and Hydra Core when using the hyperparameter search, resulting in an error.",
          "The API key has not been configured for GitHub CI.",
          "This bug report describes an issue with the DFP production server, where it is unable to start when using a certain version, but works fine when downgrading the version.",
          "This issue describes a bug encountered when trying to do multi label classification, where the internet connection was confirmed to be working but an error was thrown. Additional context is provided regarding the system and environment.",
          "The issue is related to a pipeline notebook test failing on Linux CPU, and further details are needed to understand the issue, such as the platform it is happening on and how to replicate it.",
          "The issue is that the updater is being launched too often, and a workaround is to set a CI or environment variable to skip launching it.",
          "The issue is that when using the Content feature, it shows the step count instead of the episode count, making it difficult to compare runs with longer episodes.",
          "There is an issue with missing documentation on how to connect to a MacOS device via SSH tunnel, and a bug report has been filed regarding connectivity not working properly.",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          7.895322322845459,
          7.375824451446533,
          6.645102024078369,
          8.767311096191406,
          8.817451477050781,
          7.648862361907959,
          10.665374755859375,
          6.342028617858887,
          7.502786159515381,
          8.050972938537598,
          6.261256217956543,
          6.445178031921387,
          10.694725036621094,
          8.244656562805176,
          6.948986530303955,
          7.121406078338623,
          6.725034713745117,
          7.673614501953125,
          8.40805721282959,
          9.872976303100586,
          7.954775810241699,
          8.545931816101074,
          9.066085815429688,
          7.473618030548096,
          7.7141265869140625,
          7.830512046813965,
          9.021385192871094,
          6.4305548667907715,
          7.837462902069092,
          8.481317520141602,
          8.173625946044922,
          7.393504619598389,
          9.926712036132812,
          7.571773529052734,
          6.659811019897461,
          7.706482410430908,
          7.436095237731934,
          6.852762222290039,
          9.699740409851074,
          6.881886005401611,
          7.841381072998047,
          9.186075210571289,
          9.299211502075195,
          7.945512294769287,
          7.597498416900635,
          7.863671779632568,
          7.652327537536621,
          8.988903999328613,
          8.534540176391602,
          10.829198837280273,
          6.018784523010254,
          7.381393909454346,
          9.35426139831543,
          10.689497947692871,
          6.97861909866333,
          7.652574062347412,
          7.483608245849609,
          7.392839431762695,
          8.07686996459961,
          9.58897590637207,
          6.981812477111816,
          6.76975679397583,
          9.491837501525879,
          8.497366905212402,
          10.746588706970215,
          6.1872968673706055,
          8.208622932434082,
          7.7840471267700195,
          6.4074177742004395,
          8.122403144836426,
          7.1476054191589355,
          8.460309982299805,
          7.00140905380249,
          6.686032295227051,
          6.1265740394592285,
          7.846017837524414,
          10.739157676696777,
          7.2327704429626465,
          10.244588851928711,
          7.488958835601807,
          7.576347827911377,
          10.691267967224121,
          8.079202651977539,
          7.32018518447876,
          7.9806132316589355,
          10.665555953979492,
          10.128287315368652,
          8.133305549621582,
          8.435208320617676,
          7.291213035583496,
          6.437534332275391,
          10.634260177612305,
          9.151578903198242,
          6.748569488525391,
          8.424291610717773,
          9.772427558898926,
          7.058595180511475,
          8.943967819213867,
          8.109835624694824
         ],
         "y": [
          7.421365737915039,
          12.84506893157959,
          10.750775337219238,
          9.599987030029297,
          10.990341186523438,
          11.878536224365234,
          10.131168365478516,
          9.192105293273926,
          8.100987434387207,
          9.487458229064941,
          9.90337085723877,
          9.208113670349121,
          9.099514961242676,
          8.928102493286133,
          9.749133110046387,
          10.490640640258789,
          9.779571533203125,
          9.827545166015625,
          9.270628929138184,
          10.114416122436523,
          11.321279525756836,
          10.691106796264648,
          9.950523376464844,
          7.111185073852539,
          9.247764587402344,
          8.535239219665527,
          10.594768524169922,
          8.282246589660645,
          8.535011291503906,
          10.753642082214355,
          9.890274047851562,
          7.562437534332275,
          9.272214889526367,
          10.025403022766113,
          9.17863655090332,
          11.838411331176758,
          7.595741271972656,
          10.864566802978516,
          8.932727813720703,
          12.224823951721191,
          9.73561954498291,
          9.239317893981934,
          10.904630661010742,
          7.426805019378662,
          10.012027740478516,
          9.221464157104492,
          9.977470397949219,
          8.605962753295898,
          8.529592514038086,
          9.007746696472168,
          9.253657341003418,
          8.639074325561523,
          9.392513275146484,
          9.106575965881348,
          11.545345306396484,
          9.880799293518066,
          7.600478172302246,
          12.02441120147705,
          9.987448692321777,
          10.5463228225708,
          12.143918991088867,
          10.465197563171387,
          9.995723724365234,
          9.104110717773438,
          10.210591316223145,
          10.357858657836914,
          7.550476551055908,
          7.876338005065918,
          8.346673011779785,
          9.864799499511719,
          9.883723258972168,
          8.099783897399902,
          8.471587181091309,
          9.254057884216309,
          8.537588119506836,
          11.85265064239502,
          10.197701454162598,
          9.687956809997559,
          9.774209976196289,
          11.116755485534668,
          8.679386138916016,
          9.094027519226074,
          10.897356986999512,
          10.284736633300781,
          9.21231460571289,
          10.119450569152832,
          8.400124549865723,
          9.237332344055176,
          8.59392261505127,
          8.830877304077148,
          10.558566093444824,
          10.064643859863281,
          10.00698184967041,
          10.533193588256836,
          10.689196586608887,
          9.974709510803223,
          11.552702903747559,
          8.582509994506836,
          9.672630310058594
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "A bug was recently released which caused the renaming of the mxnet model server in the inference package, resulting in an entrypoint with command failure. Attempts to use the command with the new name will fail with an error message.",
          "An error is occurring when attempting to set up MME using an existing container image, and the model is not loading as expected. Additional context suggests that the model files are in the correct directory structure with version number.",
          "This issue is about using the name of a model saved in dataparallel, and the expected behavior in a given environment.",
          "Child models are unable to launch experiments on the Aqua server due to a lack of files being copied from the parent model, resulting in preprocessing failures.",
          "The issue is about a wrong dataset file name, and there are questions about why it was named that way and what needs to be done to fix it.",
          "There is an issue with the code mentioned in a document which is preventing the limit from working and causing an error when attempting to introduce node classification gremlin.",
          "The widget in version is having an issue where the json values being passed in are resulting in an error, which can be reproduced by running through the introduction to node classification gremlin notebook.",
          "An issue has arisen with the double ensemble exception when running CN data on Google Colab, and the user is having difficulty solving it. They have followed instructions to download CN data and have set up their YAML file accordingly.",
          "Running the program failed due to a large configuration, likely caused by an oversized array. It may be possible to reduce the data selection to avoid the error.",
          "There is a bug when trying to containerize a model using BentoML, resulting in an error when attempting to deploy the model with Docker. Reproducing the bug requires cloning a repository and running it in the BentoML environment with a specific version of Python and Docker engine.",
          "The pipeline is not correctly defined, causing issues with the evaluation and training stages, resulting in errors when running the model. Manually pulling the model resolves the issue, but the expected behavior should be that it runs without errors.",
          "There is an issue with the confusion matrix appearing in Weights & Biases without values when running a model evaluation suite, and the expected behavior is for the confusion matrix to appear with values.",
          "The scikit learn model is not working in the prediction environment due to its inability to handle json from web api, and can be fixed by rewriting the feature definition part of the code.",
          "The issue is that the catalog anonymous function is not registered, and steps are provided to reproduce the problem and register the models into the Spark Thrift Server.",
          "The issue is related to the helm fetch command for the AI Engine, SDK Helper, and includes the release instead of version. The bug is described and a minimum reproducible example, relevant log output, full env printout, and agreement to follow Morpheus' code of conduct is provided.",
          "The issue is about a custom training job error where the boto credentials are not being passed to the image that the training operator is running, despite the logs stating that the boto credentials are found in environment variables.",
          "This issue suggests that when creating a BYOM predictor, the URL should be checked to ensure that an actual model is being served at that location before creating the predictor.",
          "The new mflow feature appears to be limiting the parameter value length, which is causing the workflow to fail. It appears that this cannot be overwritten, and may be related to the issue.",
          "There is an issue with creating a model in the catalog.",
          "This issue is about encountering a runtime error when training text classification models using XLNet Large Cased, ALBERT Base XLNet Base Cased and Enabled.",
          "This issue is about an endpoint failing to deploy or timing out, resulting in a server error. The bug is caused by a conflict between the endpoint deployment code and the model training code parameters.",
          "The script for publishing models is overly particular with inputs, and if the value given for the argument has trailing, it will cause unexpected errors. The model being used does not seem to have any effect on the error.",
          "There is an error when creating an index name, and the name needs to be changed to \"modelname\".",
          "When attempting to download a registered model from the AMLS workspace, an exception is being thrown and the file is created but no data is being transferred into it.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_model_classification_feature",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_model_classification_feature"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.723525524139404,
          6.948025703430176,
          7.477335453033447,
          6.981584072113037,
          7.54335880279541,
          6.775971412658691,
          7.212480545043945,
          7.184159278869629,
          7.34403657913208,
          6.74126672744751,
          6.272315979003906,
          6.880100727081299,
          6.972661018371582,
          7.40944242477417,
          6.9749956130981445,
          6.499273300170898,
          7.056975841522217,
          6.252479076385498,
          7.333337783813477,
          7.017317295074463,
          6.918997764587402,
          7.297918796539307,
          7.384609222412109,
          7.273826599121094,
          7.019833087921143
         ],
         "y": [
          9.133167266845703,
          9.168112754821777,
          9.377500534057617,
          9.402159690856934,
          9.192099571228027,
          10.042064666748047,
          9.698240280151367,
          10.002401351928711,
          10.090868949890137,
          9.360796928405762,
          9.751033782958984,
          10.01176929473877,
          9.662705421447754,
          9.1554536819458,
          9.08116340637207,
          9.46446418762207,
          9.564011573791504,
          9.861563682556152,
          9.186907768249512,
          10.090394973754883,
          9.58838939666748,
          9.360040664672852,
          9.307126998901367,
          9.037151336669922,
          9.524565696716309
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "The code is failing because a referenced folder does not exist, and it appears that the folder needs to be re-added.",
          "Git and services are incorrectly detecting the repository root directory, which is causing issues with automatically initializing on behalf of the user.",
          "The code for displaying a success message is incorrectly placed, resulting in the wrong message being displayed when the env folder does not exist. It should be moved into a try block.",
          "This issue proposes using the move command instead of the system's mv command in the rename action to ensure that the file is properly renamed and the pointer is updated for consistency.",
          "The issue is about a plugin not working with projects created with context, and the solution is to use the new hook to retrieve the configuration and set it up.",
          "The issue is about a plugin not working with projects created with context, and the solution is to use the new hook to retrieve the configuration and set it up.",
          "The code for displaying a success message is incorrectly placed, resulting in the wrong message being displayed when the env folder does not exist. It should be moved into a try block.",
          "This issue involves changing the name of a project template to avoid referencing a secret that does not exist by default.",
          "The cli commands are not accessible if the project contains only steps to reproduce, but the error comes from a function which does not consider that folder is the root of the kdro project if it does not contain a file.",
          "cc init appears to only take the first three letters of the repo name when creating a folder on the storage server, and requires a username to access the server.",
          "The issue is that nested directories are not functioning properly.",
          "This issue suggests that using the working directory instead of a given path when called within a project may cause unexpected results when used in interactive mode outside of the project root.",
          "The bug occurs when a config file is created with whitespaces, causing cc to not be able to read the file. To reproduce the issue, create a file with the specified format.",
          "Users should only be allowed to access projects they are members of, rather than having unrestricted access to all projects.",
          "The post gen hook should not attempt to configure a remote if no name is provided, as this will result in an error.",
          "The issue is that the command is not compatible with configuration files located in the project instead of at the root, and a proposed solution would break retrocompatibility.",
          "Translation is being attempted without being requested, resulting in an error due to missing credentials in the command line.",
          "A user is unable to initialize a project using the CLI commands, and is looking for advice on how to fix the issue.",
          "The issue is that the CLI commands are not accessible if the project contains only steps to reproduce, and the error comes from a function which does not consider that folder is the root of the project if it does not contain a file.",
          "A user is unable to initialize a project using the CLI commands, and is looking for advice on how to fix the issue.",
          "Running projects from remote sources is causing a \"not found\" error, and it is not currently supported as it was previously.",
          "This issue is about a warning when using the Context API in Enchanter, and provides details about the environment, versions, and other libraries being used.",
          "This issue proposes that the translate script should be able to execute locally without creating a task, which should be the default behavior.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_project_does_cli",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_project_does_cli"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.790623664855957,
          10.243552207946777,
          10.886836051940918,
          10.766830444335938,
          10.2843656539917,
          10.309062957763672,
          10.885661125183105,
          9.976046562194824,
          10.408987998962402,
          10.165783882141113,
          10.811173439025879,
          10.549893379211426,
          10.132855415344238,
          10.15143871307373,
          10.306296348571777,
          10.259559631347656,
          9.880759239196777,
          10.285416603088379,
          10.45331859588623,
          10.33198356628418,
          10.283822059631348,
          10.348423957824707,
          9.989798545837402,
          10.369673728942871
         ],
         "y": [
          8.03133487701416,
          8.391632080078125,
          8.10094928741455,
          8.038817405700684,
          8.87443733215332,
          8.903716087341309,
          8.098055839538574,
          8.742633819580078,
          8.149290084838867,
          8.44183349609375,
          8.100191116333008,
          8.2804536819458,
          8.538457870483398,
          8.107263565063477,
          8.868524551391602,
          8.833106994628906,
          8.862181663513184,
          8.016572952270508,
          8.205224990844727,
          8.078369140625,
          8.263026237487793,
          8.946619033813477,
          8.760254859924316,
          8.418824195861816
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Loggers can modify logged metrics in place, which can lead to confusing errors. This behavior is not seen in other loggers and should be changed to prevent errors.",
          "The papi API has been deprecated and using the API logger will generate an unnecessary depreciation warning when using the older example.",
          "There is a bug when using Hydra and the Logger together, where the parameters passed to the LightningModule are not being met. Reproducing the issue requires using both Hydra and the Logger together.",
          "Logging with the default configuration appears to fail silently, and WhyLogs should mention the missing writer in a warning. Additionally, it should be possible to automatically add the writer so that it works and draws attention to where the behavior can be modified.",
          "There is an issue with activating contrib in Ludwig, where log messages are not displayed as expected. Steps to reproduce the behavior are provided, as well as a recommendation to move away from using the root logger.",
          "A bug has been identified where the logger is overriding an environment variable, deleting it, and ignoring it in the version function. A pull request has been created to fix the issue.",
          "Logging is not capturing auxiliary values, resulting in incomplete data.",
          "The logging of parameters on works as expected with default parameters set with hydra, but modified parameters are not being logged when they are changed.",
          "Raising errors when the length of parameters exceeds a certain limit can be addressed by catching and ignoring all errors from truncated logging parameters.",
          "There is a bug when using the logger which results in a TypeError when trying to return results from the optimizer, Lightning module hook, or batch output.",
          "LightGBM is currently handling its own logs, but they are not being displayed in the logs.",
          "The bug mllogger is failing due to a lack of a save directory, which can be fixed by setting the directory to none. A PR will be supplied to reproduce the steps to reproduce the behavior.",
          "This suggestion proposes that the logger should accept a dictionary as a parameter, rather than converting it to a dictionary within the function, to make it more general and less restrictive.",
          "There is an issue with the logger failing when logging long parameters, and the expected behavior is for the logger to not send parameters longer than characters and log a warning to the user.",
          "This issue discusses an inconsistency in the logger's method signature, which is causing a bug in the code. The environment and packages used are also listed.",
          "There is an issue with the logger not working when using the callbacks branch, and the user is seeking help.",
          "There is an unexpected argument error when using the logger, and a Colab link has been provided to reproduce the environment.",
          "A logger is throwing a JSONDecodeError, and this issue includes steps to reproduce the behavior, environment details, and other relevant information.",
          "There is an issue with logging in localhost, where parameters are logged but metrics and artifacts are not. Reproducing the issue has been unsuccessful.",
          "The current logging system requires an API key when running locally, which should be changed so it works without one.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_parameters_errors_warning",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_parameters_errors_warning"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.14369535446167,
          7.357788562774658,
          7.356364727020264,
          7.291570663452148,
          7.43823766708374,
          7.604170322418213,
          7.1711506843566895,
          7.333057880401611,
          7.488729953765869,
          7.213902950286865,
          7.2069783210754395,
          7.237003326416016,
          7.464641094207764,
          7.43174934387207,
          7.489418029785156,
          7.518898963928223,
          7.388947010040283,
          7.625014781951904,
          7.069644927978516,
          7.204020023345947,
          7.351749420166016
         ],
         "y": [
          12.336216926574707,
          12.283364295959473,
          12.757314682006836,
          12.492874145507812,
          12.263851165771484,
          12.439107894897461,
          12.626066207885742,
          12.812888145446777,
          12.506425857543945,
          12.280058860778809,
          12.444770812988281,
          12.321213722229004,
          12.42646312713623,
          12.571671485900879,
          12.223063468933105,
          12.22054672241211,
          12.23322582244873,
          12.126333236694336,
          12.341716766357422,
          12.383096694946289,
          12.40451431274414
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Models are automatically switching to train on even if the user has overridden false, which is confusing and unexpected. This issue proposes that base classes should be flagged as not trainable and an error should be thrown if there is a contradiction in parameters.",
          "There is a bug when running a long training session, where the training session continues indefinitely instead of ending when the model stops training.",
          "This issue discusses the limitation of only logging the top validation loss, rather than all validation losses.",
          "A bug occurs when using a logger, 'ddp' on gpus, and no slurm, resulting in a pickle error. Reproducing the behavior requires instantiating a logger, trainer, and connecting to a tracking server with http basic authentication.",
          "Logger does not have the necessary methods to be used with the Trainer, resulting in a NotImplementedError.",
          "At the completion of model training, the test set loss and perplexity are written to the same chart as the validation metrics, resulting in the validation metrics being overwritten and the test metrics being rejected by the logging system.",
          "Logging does not distinguish between training and testing modes, making it difficult to track progress.",
          "A bug has been identified in the logger which causes it to communicate with the server on each training step, resulting in a dramatic slowdown in training speed. A potential solution has been proposed to avoid this overhead.",
          "This issue proposes using Tensorboard as the default logger for a project, with the option to use an alternative.",
          "When resuming a training run, the callback function prints errors instead of starting from scratch.",
          "There is an issue running on ddp mode with logger, but the code runs when the logger is detached from the trainer.",
          "This issue is about a bug encountered when training a ResNet model on multi-core TPUs on Kaggle, where the training crashes at the start of the validation loop when using a logger. Reproducing the issue requires using specific packages and environment settings.",
          "The issue is that the learning rate plot is not behaving as expected, with the rate set in remaining constant for the first epochs instead of increasing and then decreasing.",
          "This bug causes the status of an object to remain 'running' even when an error is raised during training, leading to confusion when looking at the tracking server screen.",
          "The callback does not affect the results of the training step, but it does change the unique identifier associated with it.",
          "There is a bug when training a reader model which disables all logging, preventing the user from seeing any training statistics or metrics. As a workaround, the user can manually set logging before calling the method.",
          "This issue focuses on improving logging for population by separating each individual's performance into its own graph, with graphs for each individual sub run.",
          "There is a bug where the logger object cannot be pickled after an experiment has been created, preventing distributed training. Reproducing the behavior requires initializing the logger and trainer objects and accessing an attribute that creates an offlineexperiment object.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_training_validation_logging",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_training_validation_logging"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.544697284698486,
          6.447335720062256,
          6.347954273223877,
          6.462011814117432,
          6.6727094650268555,
          6.3748273849487305,
          6.625969409942627,
          6.447236061096191,
          6.225305557250977,
          6.714659690856934,
          6.611102104187012,
          6.343328475952148,
          6.105688095092773,
          6.631043910980225,
          6.631036281585693,
          6.556047439575195,
          6.511904716491699,
          6.602283954620361,
          6.491952419281006
         ],
         "y": [
          11.075298309326172,
          11.160540580749512,
          11.652976989746094,
          11.674284934997559,
          11.79475212097168,
          11.610864639282227,
          11.638315200805664,
          11.474103927612305,
          11.961812019348145,
          11.173585891723633,
          11.681714057922363,
          11.53162670135498,
          11.259117126464844,
          11.208698272705078,
          11.261096000671387,
          11.734875679016113,
          11.889246940612793,
          11.651288032531738,
          11.52412223815918
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "The remote storage is not publicly accessible and requires Mantis credentials, so readers cannot access it. We need to make the bucket public and read-only.",
          "A bug exists in Autogluon's TextPredictor training on GPU instances in notebook terminals, causing an error in spawning multiprocessing when training across multiple GPUs. Training on a single GPU within the same instance and setup works without issue.",
          "There is an ImportError when trying to use AutoGluon in a notebook instance, due to incompatible versions of boto and botocore.",
          "The pull command on Dagshub Remote is failing on Windows, causing users to have to manually pull again. This is not an urgent issue, but is still an annoyance.",
          "The issue is about an inability to reimage a studio lab instance to get back the initial space, after trying to create a conda environment and running out of space.",
          "The issue is that a dataset fails to log on remote storage when the underlying dataset filepath is converted to a pureposixpath. It can be fixed by replacing certain locations with a different path.",
          "This issue discusses the difficulty of using a hardcoded bucket name with AWS, which makes using Minio in gateway mode impossible.",
          "The issue is that databuilder constructs an incorrect IAM role ARN for AWS regions outside of Global, preventing data from being uploaded. Possible solutions include adding a config key to either take the partition into account or to pass the IAM role ARN directly.",
          "An error has been encountered while running a query on a notebook instance created in a configured region. Further details are provided regarding the SteamPipe version, plugin version, and AWS.",
          "There is an issue running a script on a GPU instance on AWS, resulting in an error message. Additionally, the environment running on the AWS instance has been modified and Gluonts has been installed using pip.",
          "Pulling data from an external source using SSHFS connection does not work in the result branch, resulting in an error message. Unmounting the data folder with fusermount resolves the issue.",
          "The issue is that when running the Studio demo in a new AWS account, the usual service limit issue is encountered when creating an endpoint to host the model. A potential solution is to add a link to the service limit increase page in the prerequisites section and to change the notebook to use an instance type that does not have a default service limit.",
          "The user is trying to use AWS built-in algorithms in Studio Lab, but is having difficulty configuring their profile and setting up the local AWS configuration. They are wondering if it is even possible to link access AWS resources in Studio Lab.",
          "The issue is that a fresh Rapids Conda environment is failing to launch Python due to a downgrade of Pyarrow which breaks Cudf.",
          "This issue discusses an error that occurs when trying to use a conda environment in notebooks, where the context cannot be found. Investigations have been done to try and resolve the issue, but the desired outcome has not yet been achieved.",
          "The bug is caused by checks misidentifying endpoints of clusters in AWS CN regions, resulting in required configuration options not being set correctly. These checks need to be changed to fix the issue.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_aws_limit_conda",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_aws_limit_conda"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.9979248046875,
          6.061119079589844,
          6.1633381843566895,
          8.607565879821777,
          7.370016098022461,
          8.07131290435791,
          7.397194862365723,
          7.418639659881592,
          7.524636745452881,
          5.989340782165527,
          8.251043319702148,
          7.240901470184326,
          7.14847469329834,
          7.331707000732422,
          7.474437236785889,
          7.38761568069458,
          7.3397040367126465
         ],
         "y": [
          8.329866409301758,
          8.952315330505371,
          8.967945098876953,
          8.49818229675293,
          7.368453502655029,
          8.415878295898438,
          8.332419395446777,
          8.235149383544922,
          8.091217041015625,
          8.605632781982422,
          8.379437446594238,
          8.050324440002441,
          7.975890636444092,
          7.092710494995117,
          7.12789249420166,
          8.235613822937012,
          8.166183471679688
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "A bug in external logging is causing training jobs to fail due to a brief loss of access when Databricks updates. Pytorch Lightning does not currently have an option to handle exceptions from the logger, resulting in the entire training pipeline failing and losing progress.",
          "There is an issue with the logger not logging correctly, and steps are provided to reproduce the bug. Additionally, information about the environment, python version, cuda version, and GPU models and configuration are requested.",
          "The richprogressbar library is not displaying progress bars when using logger, and this issue has been verified to work correctly with tensorboard.",
          "Pytorch Lightning requires a new version, so it is important to consider this before updating.",
          "The memory utilization metrics are not correctly visible in the experiment master in radiomicsnn, as only metrics for out of the GPUs are visible and the memallocated and memreserved metrics are all zero.",
          "There is an issue with creating a logger when using PyTorch Lightning CLI, and the error message is \"For some reason, there has cc io kaczmarek\".",
          "There is a bug when using a logger with the BoringModel, which causes an error due to an invalid metric name. The expected behavior should be that GPU memory is logged correctly.",
          "The issue is that the training loss is not being reported until the end of the run, even though the validation loss is being updated in each epoch. It appears to be a buffering issue with PyTorch Lighting.",
          "This issue describes a problem with Pytorch containers, where prints in stderr are not caught and ignored, resulting in the output of \"coucou stdout\" being printed but not the stderr.",
          "Pytorch is printing a warning message after every epoch during training.",
          "The bug in PyTorch Lightning has caused test metrics to no longer be pushed to the environment, and can be reproduced by running a fast training run.",
          "The bug report states that the logger throws an error when imported without PyTorch installed, even though it should work regardless. Reproducing the issue requires creating a new environment, installing Etna, and importing the logger.",
          "Upgrading from an older version of PyTorch to a newer version causes a bug when running a distributed data parallel (DDP) multi-GPU experiment on a Slurm cluster, resulting in multiple experiments being created but only one of them logging any metrics.",
          "The issue is that the checkpoints are being saved in the wrong location when using PyTorch Lightning on MacOS running in Python, and it is unclear if this is an issue with PyTorch Lightning or Tensorboard.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_loss_gpu_progress",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_loss_gpu_progress"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.758416175842285,
          6.147935390472412,
          6.175831317901611,
          5.779112339019775,
          6.142821311950684,
          5.902570724487305,
          6.286962985992432,
          5.884481906890869,
          5.805651664733887,
          5.85436487197876,
          5.786307334899902,
          5.842067241668701,
          5.752810001373291,
          5.893259048461914,
          5.929470539093018
         ],
         "y": [
          11.832468032836914,
          12.106501579284668,
          12.006587982177734,
          11.908576011657715,
          12.151466369628906,
          12.066070556640625,
          12.213606834411621,
          11.679213523864746,
          12.042642593383789,
          11.706679344177246,
          11.896000862121582,
          12.000166893005371,
          11.927462577819824,
          11.78136157989502,
          11.951342582702637
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "The issue is that the tracking server is not logging properly when running a training job, and the user is looking for help to resolve the issue.",
          "The user is getting a FileNotFoundError when trying to run the command \"mlflow ui\" after running the \"init\" command.",
          "A user is experiencing an algorithmerror when using an led model with smp training, and is looking for help with their system information. The error is related to a ValueError and the job has been aborted.",
          "The issue is about an error when training on layoutlmv using huggingface, and the user is looking for help with their system information, example scripts, and task/dataset organization.",
          "The user is getting a \"FileNotFoundError\" when attempting to run the UI, and is unsure if this is the right forum to post the issue.",
          "The user is trying to install libraries in a studio lab which requires root privileges, but they don't have the password to do so. They are asking for help to get root access or an alternative way to install the libraries.",
          "The user is experiencing an \"ml not installed error\" while running a trainer and is looking for help. They have provided system information, example scripts, and tasks they are running.",
          "The user is unable to open the locfit package and is receiving an error message when trying to execute code.",
          "The issue is about an error encountered when trying to train a YOLOv model on Windows, and the user has searched for similar questions but found none. They are asking for advice on how to resolve the issue.",
          "This person is asking if they can set up their own studio lab.",
          "The user is unable to open their project and has tried multiple solutions to no avail. They have included a screenshot to help with troubleshooting.",
          "The user is getting a FileNotFoundError when trying to run the command \"mlflow ui\" after running the command \"init\".",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_user_looking_information",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_user_looking_information"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.4172868728637695,
          6.537195682525635,
          6.371870040893555,
          6.352648735046387,
          6.525416851043701,
          6.256065845489502,
          6.342179298400879,
          6.285505294799805,
          6.398608684539795,
          6.380448818206787,
          10.136481285095215,
          6.549427509307861,
          6.712761402130127
         ],
         "y": [
          8.266996383666992,
          7.683887004852295,
          8.14439582824707,
          7.969786643981934,
          7.714179515838623,
          7.852398872375488,
          7.921534538269043,
          7.827108860015869,
          7.99562931060791,
          7.9861674308776855,
          7.989325046539307,
          7.67634916305542,
          7.918979644775391
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "This issue is about creating a model and performing batch transformation without training, and the output is being received properly in Kubeflow. The user is looking for an open source loan data model to use with Kubeflow.",
          "A bug has been identified where a database migration job should run before a pod upgrade when using a helm chart, and running the job manually with kubectl fixed the issue.",
          "An error of \"TypeError: deploy model\" is occurring when trying to update an existing endpoint, and the expected behavior is to update the endpoint without any issue. KFP is being used to deploy Kubeflow Pipelines, and help is needed to resolve the bug.",
          "An error is being thrown when running a Kubeflow pipeline on AWS, indicating that a required hyperparameter is missing even though no such parameter is defined in the pipeline parameters. Varun is seeking help to resolve this issue.",
          "The bug occurs when running the chart testing step in a pull request, resulting in an error due to the maintainer name not being a GitHub username. Further details such as Helm and Kubectl versions, chart and chart version, and how to reproduce the issue are needed to investigate the issue.",
          "This issue is about a bug in a Kubeflow pipeline component which causes a job to hang when a node scales down, and the component tries to create the same job which fails due to not allowing the same name job. The expected behavior is for the job to resume from the previous state.",
          "A bug has been encountered when using the servicemonitor and prometheus metrics with the helm chart. It is proposed that the port name should be used instead of the port number in the servicemonitor manifest to fix the issue.",
          "The project operator image tag is incorrectly set to \"latest\" instead of \"check\" on chart releases.",
          "A bug has been identified where the new staticprefix argument under extraargs breaks the chart when used, causing an extra argument to be added to the server command that doesn't exist. A pull request has been created to address the issue.",
          "A bug has been identified where model artifacts are not being saved in the remote artifact store, despite the helm chart being installed with changed settings. The helm, kubectl, and chart versions are known, and the issue can be reproduced by installing the helm chart with minio and postgresql config.",
          "Operator types included in a Kubebuilder custom CRD definition fail due to validation errors of unescaped regex patterns, and it is possible to fix this issue by escaping the regex pattern with quotes.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_chart_helm_pull",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_chart_helm_pull"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.309253692626953,
          9.671201705932617,
          9.356998443603516,
          9.32806396484375,
          9.712961196899414,
          9.461552619934082,
          9.69821548461914,
          9.715564727783203,
          9.750139236450195,
          9.863335609436035,
          9.301396369934082,
          9.560790061950684
         ],
         "y": [
          10.915425300598145,
          10.711322784423828,
          10.816166877746582,
          10.877028465270996,
          10.802145957946777,
          10.6835298538208,
          10.843204498291016,
          10.825610160827637,
          10.902249336242676,
          10.538130760192871,
          10.901667594909668,
          10.801498413085938
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Pipelines are producing an unexpected error and warning, and the author is trying to figure out the cause.",
          "The issue is that the version of the Python package contrib pipeline steps is throwing errors when running the pipeline, and the SDK is giving a \"got an unexpected keyword argument 'command'\" error.",
          "Creating PipelineML objects and returning them in the run viz pipeline list hooks can cause all viz versions to break, and this bug is also present in the latest version on develop. A potential solution is to implement the method of the class.",
          "Running the pipeline dp via the command line interface results in an error, and there are steps to reproduce the issue using a Python function to parse documentation data.",
          "This issue describes a bug where a run is not closed when a pipeline fails in interactive mode, resulting in a messy MLLFlow database. A possible implementation is to close the run when the pipeline fails.",
          "Loading a pipelinemodel from a catalog containing non deepcopy able datasets causes an error due to the context not being able to load the previously saved pipelinemodel. This bug is present in both Windows and CentOS and also in the latest version on develop. A potential solution is suggested.",
          "The pipelinemodel requires unnecessary pipeline input dependencies to be executed, causing problems when trying to load a model that has been updated independently of the ML project.",
          "There is an error related to numpy in the lambda of createmodel when running the pipeline from scratch, preventing the creation of models for both the batch and realtime pipelines. A solution was found by re-creating the layer and modifying the code, but it is likely due to library or version incompatibility issues.",
          "The issue is that the code example from pipelines to train, upload, and deploy using Google Cloud Pipeline Components does not work, but an alternate method does.",
          "Loading a pipelinemodel from a catalog containing non deepcopy able datasets causes an error due to the context not being able to load the previously saved pipelinemodel. This bug is present in both Windows and CentOS and also in the latest version on develop. A potential solution is suggested.",
          "This issue is about a TypeError that occurs when debugging a run in Visual Studio Code, caused by command line arguments when running the pipeline directly.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_pipeline_develop_solution",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "8_pipeline_develop_solution"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.828594207763672,
          5.74399471282959,
          5.880427837371826,
          5.914377212524414,
          6.107946395874023,
          6.1027374267578125,
          6.1159515380859375,
          6.181124210357666,
          6.0096611976623535,
          6.110686302185059,
          5.826522350311279,
          5.983819961547852
         ],
         "y": [
          9.871794700622559,
          9.561943054199219,
          9.759095191955566,
          9.723004341125488,
          9.829599380493164,
          9.7360258102417,
          9.776135444641113,
          9.757460594177246,
          9.67599868774414,
          9.753281593322754,
          9.762090682983398,
          9.746039390563965
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "A recent issue was encountered when testing with an argument, and the log suggests that it may be due to the argument being repeated.",
          "The reproduce feature is not working, as it fails at the apply patch stage.",
          "There is an issue with some tests, and further details are needed to determine the platform, replicate the issue, and understand the expected behavior.",
          "The bug fails when converting an experiment using the experiment ID, but works when using the experiment name.",
          "The issue is that when setting up an experiment interactively, all runs are stored in the default experiment instead of the specified experiment, which works when running through the CLI. The potential solution is to replace a faulty line of code.",
          "This issue discusses an error caused by exceptions when running a benchmark, and suggests that better ways of dealing with it may be needed. Deleting a line solves the problem.",
          "There is an exception occurring when running a backtest with a program, and no error is expected. Reproducing the bug requires running the backtest with the wandlogger while setting the environment.",
          "The evaluation is crashing due to a bug introduced by a post, and can be reproduced by following the instructions provided.",
          "When attempting to run a benchmark with Anubis, an error is encountered and the benchmark cannot be executed. Additionally, when running the sample, the same error is encountered. It is unclear what else needs to be specified or changed in order to run the benchmark.",
          "The search suggester was found to be unserialisable, causing a ray tune job to fail, and a stack trace gave no indication of this. A discussion around this issue can be found here.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_experiment_encountered_running",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "9_experiment_encountered_running"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.206768035888672,
          8.199416160583496,
          8.141857147216797,
          7.835184097290039,
          7.830313205718994,
          8.0929536819458,
          8.101102828979492,
          8.174249649047852,
          8.020578384399414,
          7.689669609069824,
          8.02920913696289
         ],
         "y": [
          10.706509590148926,
          10.625645637512207,
          10.717597007751465,
          10.368382453918457,
          10.501461029052734,
          10.609240531921387,
          10.607972145080566,
          10.529550552368164,
          10.530421257019043,
          10.680724143981934,
          10.587751388549805
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "When using distributed data parallelism (DDP) and multi-run, only one run is recorded instead of multiple runs.",
          "There is a bug with the xcom output of async operators, where the xcom keys and values do not match the output of the non-async operators. Steps to reproduce the behavior are provided.",
          "The sweep is not completing as expected, resulting in stalling issues.",
          "There is an issue with a specific model where runs aren't being cleared, which could be causing corruptions in subsequent runs, which has not been seen before.",
          "This issue describes a bug where the system is not sectioning by train and overriding runs by checks, resulting in duplicate checks in the suite. Screenshots are provided to help explain the problem.",
          "A bug is causing a new run to be created when resuming from an HPC checkpoint after preemption by Slurm and requeuing. A potential fix is to patch the logger to expose the run ID.",
          "Ert runs that fail for any reason other than what is hard coded in the subprocess call are not being registered correctly, resulting in successful runs being registered when they should be marked as failed.",
          "The UI is displaying failed runs as successful, and the potential solution is to replace certain lines of code or retrieve the current run status.",
          "The UI is displaying failed runs as successful, and the potential solution is to replace certain lines of code or retrieve the current run status.",
          "The issue is caused by a bug introduced by a line of code that needs to be replaced, which results in an incorrect check for active run in the callback. This should be fixed by introducing support for the callback.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_runs_registered_failed",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "10_runs_registered_failed"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.712466716766357,
          8.17459487915039,
          7.622402191162109,
          7.614871025085449,
          7.55993127822876,
          7.810947895050049,
          7.926041603088379,
          7.931940078735352,
          7.8622517585754395,
          8.061241149902344,
          7.8276686668396
         ],
         "y": [
          11.328873634338379,
          10.842240333557129,
          11.211065292358398,
          11.180036544799805,
          11.076542854309082,
          11.34400749206543,
          11.535979270935059,
          11.52182674407959,
          11.471770286560059,
          11.32502555847168,
          11.283737182617188
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "This issue reports a bug in PyCaret where two models, Lasso Least Angle Regression and Least Angle Regression, are incorrectly logged as the same model.",
          "Pycaret version checks have confirmed a bug exists on the master branch of pycaret, where runs in the logger are never ended and are nested recursively, resulting in incorrect display. The bug has now been fixed.",
          "This issue involves a problem with saving an xgboost run in a server, where no metrics or artifacts are created. The installed versions of pycaret and xgboost have been confirmed, and the expected behavior is that artifacts and metrics should be created.",
          "The bug is that the pyfunc model is not loading in the beta version of BentoML, despite being successfully stored in the local model store.",
          "This issue is about a bug in the Pycaret version checks, where when Pycaret is installed, all runs are shown nested recursively in the dashboard. Reproducible examples and installed versions are provided.",
          "Pycaret is not logging metrics when the parameter is set to true, despite the documentation saying it should. A reproducible example is provided.",
          "Pycaret integration does not allow probabilities for classification and binary response models, which has been confirmed as a bug on the master branch. This issue has been reproduced and is causing errors when trying to score new data.",
          "PyCaret's clustering module is having difficulty saving model artifacts and some plots, resulting in a failed status.",
          "Pycaret is unable to map the data type of the Titanic dataset, resulting in an error, although the same code worked fine in the previous version.",
          "Pycaret version checks have confirmed a bug exists on the develop branch, where models that have already converged and logged to the file system are not visible in the dashboard. Reproducible example and installed versions are included.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_artifacts_branch_models",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "11_artifacts_branch_models"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.626976728439331,
          3.692574977874756,
          3.759106397628784,
          3.5666282176971436,
          3.706355571746826,
          3.697195529937744,
          3.6837081909179688,
          3.7337658405303955,
          3.6489651203155518,
          3.6682028770446777,
          3.6783478260040283
         ],
         "y": [
          10.062711715698242,
          10.04344367980957,
          9.938185691833496,
          10.181476593017578,
          10.010849952697754,
          10.02043628692627,
          10.011863708496094,
          9.967446327209473,
          9.978233337402344,
          10.029932022094727,
          10.024457931518555
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "The user has installed Azure ML using a conda environment yml, but when they try to import it, they get an exception. They are asking for help.",
          "The Azure ML extension is prompting users to login twice when VS Code loads, which is disruptive and unnecessary. No other AWS or Azure extensions do this.",
          "A regression was introduced which causes an unnecessary import statement to be loaded when only the default set of ML dependencies are installed. A lazy import statement should be added to the Azure Credentials Module to fix this issue.",
          "Training with Azure ML is taking an unreasonably long time, with each trial taking around 2 minutes and the entire experiment taking nearly 30 minutes. It is expected to be much faster given the GPU used. Reproducing the issue requires following a specific document.",
          "This issue discusses providing guidance on how to obtain an Azure subscription ID in a notebook, as well as an error message if the user forgets to fill in the values. This would help novice users receive guidance on how to obtain their subscription ID without having to reference other notebooks.",
          "There is an error when trying to use the Azure Computer Vision OCR API from a notebook, even though the same code works when running it on a local machine. The exception code and Azure packages used may be related.",
          "This issue involves an unknown error occurring when signing into the Azure portal using Visual Studio Code Insiders on a Windows OS, resulting in the user being asked to sign in again.",
          "This issue involves an unknown error when attempting to connect to Visual Studio Code, and retrieving subscriptions from an Azure account.",
          "This issue proposes to remove the reference to the Azure ML SDK Preview private index, as the SDK is now available through the regular PyPI as a GA product and preview versions are no longer supported.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_ml_import_unnecessary",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "12_ml_import_unnecessary"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.258627414703369,
          7.092182159423828,
          7.102707386016846,
          7.054131031036377,
          7.094700336456299,
          7.093979835510254,
          7.110932350158691,
          7.104043483734131,
          7.035556316375732,
          7.1052069664001465
         ],
         "y": [
          6.643518924713135,
          6.375615119934082,
          6.397442817687988,
          6.437341690063477,
          6.376908779144287,
          6.386030197143555,
          6.362549304962158,
          6.382314205169678,
          6.447025775909424,
          6.423194408416748
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "This question is asking for help in installing various Python packages, such as graphviz and pygraphviz, using pip.",
          "pip install is not working properly in Studio, and a workaround is needed to continue using it.",
          "Installing a package as a pip wheel can be cumbersome, but it is possible to create a pip wheel package and add it as a dependency to make the process easier.",
          "Installing datasets with pip is causing different dependencies to be installed than expected, which is blocking certain steps from being completed.",
          "Pip install of AWS Step Functions fails in Studio notebook, resulting in a \"Metadata generation failed\" error. The issue is likely not with Pip, but with the package itself.",
          "The install prompt in pip is not displaying markdown correctly, preventing users from seeing the intended formatting.",
          "pip install is failing on a Windows system with a specific version of Python, but the latest version can be installed without issue.",
          "This issue involves an unexpected error while saving a file, which is preventing the user from installing libraries with pip, creating new files, and starting the kernel.",
          "There is an issue with installing GluonTS on a notebook instance from GitHub, and the error message suggests that GluonTS is already installed but the operating system and Python version are incompatible.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_install_python_preventing",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "13_install_python_preventing"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.456267356872559,
          5.3831048011779785,
          5.3852643966674805,
          5.4113359451293945,
          5.495715141296387,
          5.420776844024658,
          5.485320568084717,
          5.887231349945068,
          5.822299003601074,
          5.527479648590088
         ],
         "y": [
          8.104479789733887,
          7.991771697998047,
          8.022696495056152,
          8.049872398376465,
          8.137372016906738,
          8.064057350158691,
          8.087894439697266,
          7.936113357543945,
          8.440930366516113,
          8.092799186706543
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "The templatedconfigloader is not properly parsing titles, resulting in global variables not being replaced by their values. This issue, along with many others, will be fixed in the future.",
          "The issue is that the value is not updating, and there is a list of lr values.",
          "There is an issue with loading content, likely due to an error.",
          "There is an issue with znnodes not working properly, and a fix is needed to test the docstring with a node that has both.",
          "This issue discusses the lack of parameters being added to the Content when the \"without\" option is used in a node.",
          "The linter is producing inconsistent results when running two functions, causing the template creation to fail. It needs to be discussed why this is happening and how to fix it.",
          "This issue is related to a missing parameter field for the evaluate stage in Content:none.",
          "The issue appears to be that something is failing, and there may be a type of object missing.",
          "A bug has been identified where a frame is being refused due to an ancestor violating the 'frame ancestors' Content Security Policy directive.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "14_content_node_missing",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "14_content_node_missing"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.966651916503906,
          8.835790634155273,
          8.637603759765625,
          8.608224868774414,
          8.656866073608398,
          8.957133293151855,
          8.625262260437012,
          8.848702430725098,
          8.623553276062012,
          8.751087188720703
         ],
         "y": [
          9.220297813415527,
          9.122011184692383,
          9.44391918182373,
          9.760770797729492,
          9.703404426574707,
          9.23886489868164,
          9.618578910827637,
          9.074544906616211,
          9.638195037841797,
          9.42451000213623
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "This issue is asking to add a section about dependencies to a project, and to keep up the good work.",
          "There is an issue with importing that needs to be fixed.",
          "The issue is an import failure, where a module is not found when running on a CentOS server. The expected behavior should be that the module is properly imported.",
          "This issue describes an error that occurs when an optional dependency is not installed, but the import works correctly on the second attempt.",
          "This issue concerns a plugin that is no longer compatible with its content since the package it relies on has been moved or refactored, resulting in exceptions being thrown.",
          "The issue is that the file does not have the entire dependency tree defined, and steps need to be taken to modify the file so that it has the complete tree of dependencies and their respective versions.",
          "There is an issue with a dependency that is causing it to leak.",
          "An error occurred while building types due to missing types in common, which can be reproduced by importing types in the Go client and failing to build.",
          "This issue concerns a plugin that is no longer compatible with its content since the package it relies on has been moved or refactored, resulting in exceptions being thrown.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "15_plugin_exceptions_importing",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "15_plugin_exceptions_importing"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.509456634521484,
          9.245643615722656,
          9.342110633850098,
          9.361846923828125,
          9.417283058166504,
          9.413145065307617,
          9.492833137512207,
          9.291589736938477,
          9.400225639343262,
          9.386014938354492
         ],
         "y": [
          8.315951347351074,
          8.096158027648926,
          8.236841201782227,
          8.145337104797363,
          8.145157814025879,
          8.20983600616455,
          8.295652389526367,
          8.147615432739258,
          8.132890701293945,
          8.191715240478516
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "An artifact store failed to create a new bucket, and the issue appears to be related to an incorrect regex in its name. Reproduction steps and relevant log output have been provided.",
          "The issue is that specifying an artifact path fails and raises an error, while not specifying it works.",
          "The issue is that artifactdataset does not work with partitioneddataset, and an error is raised when trying to save a dict with many small result tables. The bug also happens with the last version on master, and a potential solution is to add a better condition to the line causing the error.",
          "The issue is that the \"make one click\" command is not working after running \"make destroy\" due to an undeleted bucket, resulting in an error.",
          "This issue occurs when ArtifactDataset is used with ModelSaverDataset in a local context, resulting in a TypeError. The bug also happens with the latest version on the develop branch.",
          "The output of the job is being overwritten when an artifact is uploaded, resulting in incorrect output. This appears to be caused by a separate process running at the same time.",
          "The default artifact folder is not correctly replacing the environment variable, causing issues.",
          "This issue involves removing a subdirectory and its contents from the repository's history, and using an open source tool to do so. Once the changes have been committed, the local clones should be deleted and replaced with a fresh, cleaned version from upstream.",
          "This issue discusses the correct way to remove a file from a repository, which is to use the remove command instead of just deleting the base image file. The file is pushed to remote storage during base image generation and is removed at the end of the workflow execution.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "16_remove_base_repository",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "16_remove_base_repository"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.099674224853516,
          9.991144180297852,
          10.031021118164062,
          10.146992683410645,
          10.082602500915527,
          9.888786315917969,
          10.035141944885254,
          10.131049156188965,
          10.255204200744629,
          10.07351303100586
         ],
         "y": [
          9.941313743591309,
          9.827341079711914,
          9.896784782409668,
          9.92214298248291,
          9.829875946044922,
          10.012024879455566,
          9.677363395690918,
          9.892330169677734,
          9.920843124389648,
          9.88000202178955
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Users are experiencing an intermittent issue where a blank browser tab opens instead of the workspace when connecting, and clearing the cache sometimes solves the issue.",
          "After a workspace is stopped automatically, the workspace environment status is not updated, resulting in the workspace still being available.",
          "The view and plots dashboard are not loading, even after setting up the IDE workspace and virtual environment. Other components are loading correctly.",
          "An error appears in the bottom right corner of the screen when attempting to connect to a workspace, stating that \"null is not an object\". This issue is intermittent and can be resolved by logging out and back into the Service Workbench.",
          "Service Workbench is unable to launch notebook instances due to missing permission, even when custom tags are included in the workspace configuration.",
          "There is an issue in the Hong Kong region where the web console shows an \"unknown\" status after a user manually stops a workspace. Reproducing the issue requires deploying SWB in the Hong Kong region, creating a workspace, and clicking the stop button.",
          "This issue describes a bug where an incorrect field is highlighted when importing a workspace, and provides steps to reproduce the behavior. Screenshots are also included to help explain the problem.",
          "A notebook workspace that was working fine on Friday has changed to an unknown status and cannot connect anymore, displaying an error message when attempting to connect.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "17_workspace_connect_status",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "17_workspace_connect_status"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.683796882629395,
          8.633977890014648,
          8.686634063720703,
          8.688809394836426,
          8.674524307250977,
          8.713129043579102,
          8.793593406677246,
          8.712644577026367,
          8.698389053344727
         ],
         "y": [
          7.16188383102417,
          7.195029258728027,
          7.0558271408081055,
          7.159336566925049,
          7.21685791015625,
          7.186479568481445,
          7.352557182312012,
          7.215560436248779,
          7.192941665649414
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "The data path inside a notebook is not working, and an error occurs when trying to list the bucket of processed data. This is a bug report.",
          "A bug has been identified where idle notebook instances do not stop after the specified time, despite a script being used by the instance cfn template lifecycle rule. Reproducing the behavior requires setting the autostopidletimeinminutes parameter in the workspace type config.",
          "The original code caused an error, so it was necessary to specify the framework version to fix the problem, or adding notebooks in another way could also solve the issue.",
          "Users are receiving an illegible error message when trying to connect to a notebook with pop ups disabled, and it is suggested that the error message be made more clear.",
          "The notebook is broken due to missing permissions, and there may be more issues down the road. This issue is of medium severity, causing significant difficulty but can be worked around.",
          "The issue is that a link in a notebook is not resolving properly, and it appears that the relative location of the notebook has changed.",
          "This issue describes an error when closing a session, and provides steps to reproduce the error using Binder to run a notebook example.",
          "There is an error occurring with notebooks that may be related to the deployment of ACI and AKS resources. Further investigation is needed to determine the cause and replicate the issue.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "18_notebook_error_location",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "18_notebook_error_location"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.11210823059082,
          8.398244857788086,
          8.344361305236816,
          8.46042537689209,
          8.274126052856445,
          8.470236778259277,
          8.419089317321777,
          8.351948738098145,
          8.353816986083984
         ],
         "y": [
          8.112619400024414,
          7.493741512298584,
          7.894317626953125,
          7.652454376220703,
          7.9284796714782715,
          7.8129425048828125,
          7.656071662902832,
          7.809807777404785,
          7.7950544357299805
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "This issue is about the need for detailed descriptions of defaults when deploying, as well as documentation of the details that are currently not documented.",
          "There is an issue with the UI deployment, and it needs to be reviewed to determine which configuration parameter is causing the error.",
          "Deployment from the user interface is not working properly.",
          "The issue is that the CLI endpoint example is out of date with the new syntax from breaking changes in YAML, causing the deployment to fail when using the CLI command.",
          "An API request conflict occurred when attempting to deploy assets only, resulting in an error. The issue was resolved by nesting environment configurations under the environments section and using workflows instead of jobs.",
          "The job deployment was successful, but it is not being invoked.",
          "The issue is that dbx deploy is failing due to an experiment not being found, and the instructions for setting up dbx for the first time are not working.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "19_deployment_cli_occurred",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "19_deployment_cli_occurred"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.330808639526367,
          9.443440437316895,
          9.441789627075195,
          9.685206413269043,
          9.63913631439209,
          9.681483268737793,
          9.443690299987793,
          9.523651123046875
         ],
         "y": [
          9.481547355651855,
          9.466628074645996,
          9.527079582214355,
          9.74659538269043,
          9.641380310058594,
          9.762444496154785,
          9.644489288330078,
          9.61002254486084
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": 3.031633985042572,
          "y": 10.089998090267182,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 7.7757477223873135,
          "xshift": 10,
          "y": 14.771829271316529
         }
        ],
        "height": 750,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 7.7757477223873135,
          "x1": 7.7757477223873135,
          "y0": 5.408166909217835,
          "y1": 14.771829271316529
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": 3.031633985042572,
          "x1": 12.519861459732056,
          "y0": 10.089998090267182,
          "y1": 10.089998090267182
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Documents and Topics",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.30it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "text": [
          "training_validation_logging_ddp_loss",
          "",
          "",
          "loss_gpu_progress_tensorboard_logging"
         ],
         "type": "scatter",
         "x": [
          0,
          0.7326728716113997,
          0.7326728716113997,
          0
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -15,
          -15
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "parameters_errors_warning_api_log",
          "",
          "",
          "training_logger_metrics_loss_progress"
         ],
         "type": "scatter",
         "x": [
          0.7326728716113997,
          1.0482556203379747,
          1.0482556203379747,
          0
         ],
         "xaxis": "x",
         "y": [
          -10,
          -10,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "deployment_cli_occurred_changes_request",
          "",
          "",
          "experiment_encountered_running_fails_program"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1055609278661536,
          1.1055609278661536,
          0
         ],
         "xaxis": "x",
         "y": [
          -35,
          -35,
          -45,
          -45
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "remove_base_repository_bucket_local",
          "",
          "",
          "project_does_cli_plugin_directory"
         ],
         "type": "scatter",
         "x": [
          0,
          1.17609158879909,
          1.17609158879909,
          0
         ],
         "xaxis": "x",
         "y": [
          -55,
          -55,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pipeline_develop_solution_version_causes",
          "",
          "",
          "runs_registered_failed_ui_status"
         ],
         "type": "scatter",
         "x": [
          0,
          1.065417256799321,
          1.065417256799321,
          0
         ],
         "xaxis": "x",
         "y": [
          -75,
          -75,
          -85,
          -85
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "artifacts_branch_models_master_versions",
          "",
          "",
          "model_classification_feature_registered_base"
         ],
         "type": "scatter",
         "x": [
          1.065417256799321,
          1.2105521018992227,
          1.2105521018992227,
          0
         ],
         "xaxis": "x",
         "y": [
          -80,
          -80,
          -95,
          -95
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "model_classification_artifacts_branch_version",
          "",
          "",
          "chart_helm_pull_pipeline_endpoint"
         ],
         "type": "scatter",
         "x": [
          1.17609158879909,
          1.2756866985890079,
          1.2756866985890079,
          1.2105521018992227
         ],
         "xaxis": "x",
         "y": [
          -60,
          -60,
          -87.5,
          -87.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pipeline_runs_solution_registered_failed",
          "",
          "",
          "model_chart_helm_artifacts_classification"
         ],
         "type": "scatter",
         "x": [
          1.1055609278661536,
          1.3264052860039794,
          1.3264052860039794,
          1.2756866985890079
         ],
         "xaxis": "x",
         "y": [
          -40,
          -40,
          -73.75,
          -73.75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "folder_project_repository_bucket_image",
          "",
          "",
          "pipeline_chart_helm_models_artifacts"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1991355330981806,
          1.1991355330981806,
          0
         ],
         "xaxis": "x",
         "y": [
          -105,
          -105,
          -115,
          -115
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "experiment_cli_setting_deploy_specified",
          "",
          "",
          "pipeline_chart_version_run_issue"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1468264242360715,
          1.1468264242360715,
          0
         ],
         "xaxis": "x",
         "y": [
          -125,
          -125,
          -135,
          -135
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "plugin_exceptions_importing_dependencies_longer",
          "",
          "",
          "ml_import_unnecessary_sdk_studio"
         ],
         "type": "scatter",
         "x": [
          1.1991355330981806,
          1.430146133666393,
          1.430146133666393,
          1.1468264242360715
         ],
         "xaxis": "x",
         "y": [
          -110,
          -110,
          -130,
          -130
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "content_node_missing_creation_stage",
          "",
          "",
          "ml_types_dependencies_longer_entire"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1437838955826338,
          1.1437838955826338,
          0
         ],
         "xaxis": "x",
         "y": [
          -145,
          -145,
          -155,
          -155
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "user_looking_information_ui_resolve",
          "",
          "",
          "install_python_preventing_workaround_github"
         ],
         "type": "scatter",
         "x": [
          1.1437838955826338,
          1.1873821870739873,
          1.1873821870739873,
          0
         ],
         "xaxis": "x",
         "y": [
          -150,
          -150,
          -165,
          -165
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "ml_types_dependencies_longer_issue",
          "",
          "",
          "installing_help_studio_python_ui"
         ],
         "type": "scatter",
         "x": [
          0,
          1.079597422663065,
          1.079597422663065,
          0
         ],
         "xaxis": "x",
         "y": [
          -175,
          -175,
          -185,
          -185
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "aws_limit_conda_gpu_studio",
          "",
          "",
          "notebook_error_location_template_replicate"
         ],
         "type": "scatter",
         "x": [
          1.079597422663065,
          1.2494893720311622,
          1.2494893720311622,
          0
         ],
         "xaxis": "x",
         "y": [
          -180,
          -180,
          -195,
          -195
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "notebook_aws_bucket_data_limit",
          "",
          "",
          "workspace_connect_status_service_loading"
         ],
         "type": "scatter",
         "x": [
          1.1873821870739873,
          1.438398630031737,
          1.438398630031737,
          1.2494893720311622
         ],
         "xaxis": "x",
         "y": [
          -157.5,
          -157.5,
          -187.5,
          -187.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "ml_installing_help_dependencies_studio",
          "",
          "",
          "workspace_instance_aws_connect_stop"
         ],
         "type": "scatter",
         "x": [
          1.430146133666393,
          1.5696377360923073,
          1.5696377360923073,
          1.438398630031737
         ],
         "xaxis": "x",
         "y": [
          -120,
          -120,
          -172.5,
          -172.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "runs_pipeline_issue_chart_deploy",
          "",
          "",
          "notebook_workspace_issue_aws_install"
         ],
         "type": "scatter",
         "x": [
          1.3264052860039794,
          1.589450524184032,
          1.589450524184032,
          1.5696377360923073
         ],
         "xaxis": "x",
         "y": [
          -56.875,
          -56.875,
          -146.25,
          -146.25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "logger_training_metrics_bug_tensorboard",
          "",
          "",
          "issue_notebook_workspace_run_installed"
         ],
         "type": "scatter",
         "x": [
          1.0482556203379747,
          1.8577635193699167,
          1.8577635193699167,
          1.589450524184032
         ],
         "xaxis": "x",
         "y": [
          -17.5,
          -17.5,
          -101.5625,
          -101.5625
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "parameters_errors_warning_api_log",
          "artifacts_branch_models_master_versions",
          "model_classification_artifacts_branch_version",
          "pipeline_runs_solution_registered_failed",
          "plugin_exceptions_importing_dependencies_longer",
          "user_looking_information_ui_resolve",
          "aws_limit_conda_gpu_studio",
          "notebook_aws_bucket_data_limit",
          "ml_installing_help_dependencies_studio",
          "runs_pipeline_issue_chart_deploy",
          "logger_training_metrics_bug_tensorboard"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.7326728716113997,
          1.065417256799321,
          1.17609158879909,
          1.1055609278661536,
          1.1991355330981806,
          1.1437838955826338,
          1.079597422663065,
          1.1873821870739873,
          1.430146133666393,
          1.3264052860039794,
          1.0482556203379747
         ],
         "y": [
          -10,
          -80,
          -60,
          -40,
          -110,
          -150,
          -180,
          -157.5,
          -120,
          -56.875,
          -17.5
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "chart_helm_pull_pipeline_endpoint",
          "model_chart_helm_artifacts_classification",
          "ml_import_unnecessary_sdk_studio",
          "workspace_connect_status_service_loading",
          "workspace_instance_aws_connect_stop",
          "notebook_workspace_issue_aws_install",
          "issue_notebook_workspace_run_installed"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.2105521018992227,
          1.2756866985890079,
          1.1468264242360715,
          1.2494893720311622,
          1.438398630031737,
          1.5696377360923073,
          1.589450524184032
         ],
         "y": [
          -87.5,
          -73.75,
          -130,
          -187.5,
          -172.5,
          -146.25,
          -101.5625
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -200,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "5_loss_gpu_progress",
          "3_training_validation_logging",
          "2_parameters_errors_warning",
          "16_remove_base_repository",
          "1_project_does_cli",
          "8_pipeline_develop_solution",
          "7_chart_helm_pull",
          "0_model_classification_feat...",
          "11_artifacts_branch_models",
          "10_runs_registered_failed",
          "14_content_node_missing",
          "15_plugin_exceptions_import...",
          "19_deployment_cli_occurred",
          "9_experiment_encountered_ru...",
          "13_install_python_preventing",
          "6_user_looking_information",
          "12_ml_import_unnecessary",
          "4_aws_limit_conda",
          "18_notebook_error_location",
          "17_workspace_connect_status"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125,
          -135,
          -145,
          -155,
          -165,
          -175,
          -185,
          -195
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03248340756259067,
          0.03467735435039904,
          0.03605272412831322,
          0.05190628304468382,
          0.1007573604261306
         ],
         "xaxis": "x",
         "y": [
          "base  ",
          "registered  ",
          "feature  ",
          "classification  ",
          "model  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03798659396353326,
          0.03813247751974617,
          0.05951368121745463,
          0.06959160359494906,
          0.10965700589504992
         ],
         "xaxis": "x2",
         "y": [
          "directory  ",
          "plugin  ",
          "cli  ",
          "does  ",
          "project  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.033153631828921434,
          0.04815544329344683,
          0.05733613075246031,
          0.05921057458280822,
          0.12869190897346924
         ],
         "xaxis": "x3",
         "y": [
          "log  ",
          "api  ",
          "warning  ",
          "errors  ",
          "parameters  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.04858803244590751,
          0.052628601051285674,
          0.07479793631080979,
          0.11581543719570177,
          0.14316851813696677
         ],
         "xaxis": "x4",
         "y": [
          "loss  ",
          "ddp  ",
          "logging  ",
          "validation  ",
          "training  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.04843104038504513,
          0.04861671029413802,
          0.06388783458716368,
          0.06472537270677833,
          0.13020955191483324
         ],
         "xaxis": "x5",
         "y": [
          "studio  ",
          "gpu  ",
          "conda  ",
          "limit  ",
          "aws  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.04377323943530698,
          0.06536436539411024,
          0.06536436539411024,
          0.06934655196606429,
          0.08530404779247101
         ],
         "xaxis": "x6",
         "y": [
          "logging  ",
          "tensorboard  ",
          "progress  ",
          "gpu  ",
          "loss  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.06798722857595538,
          0.08309157594774795,
          0.09634872317592709,
          0.10993523050465856,
          0.13582148948485137
         ],
         "xaxis": "x7",
         "y": [
          "resolve  ",
          "ui  ",
          "information  ",
          "looking  ",
          "user  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.04012680218968876,
          0.04393461583045607,
          0.052322296783294094,
          0.1375023397730993,
          0.1944993535581777
         ],
         "xaxis": "x8",
         "y": [
          "endpoint  ",
          "pipeline  ",
          "pull  ",
          "helm  ",
          "chart  "
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_model_classification_feat...",
          "1_project_does_cli",
          "2_parameters_errors_warning",
          "3_training_validation_logging",
          "4_aws_limit_conda",
          "5_loss_gpu_progress",
          "6_user_looking_information",
          "7_chart_helm_pull",
          "8_pipeline_develop_solution",
          "9_experiment_encountered_ru...",
          "10_runs_registered_failed",
          "11_artifacts_branch_models",
          "12_ml_import_unnecessary",
          "13_install_python_preventing",
          "14_content_node_missing",
          "15_plugin_exceptions_import...",
          "16_remove_base_repository",
          "17_workspace_connect_status",
          "18_notebook_error_location",
          "19_deployment_cli_occurred"
         ],
         "xaxis": "x",
         "y": [
          "0_model_classification_feat...",
          "1_project_does_cli",
          "2_parameters_errors_warning",
          "3_training_validation_logging",
          "4_aws_limit_conda",
          "5_loss_gpu_progress",
          "6_user_looking_information",
          "7_chart_helm_pull",
          "8_pipeline_develop_solution",
          "9_experiment_encountered_ru...",
          "10_runs_registered_failed",
          "11_artifacts_branch_models",
          "12_ml_import_unnecessary",
          "13_install_python_preventing",
          "14_content_node_missing",
          "15_plugin_exceptions_import...",
          "16_remove_base_repository",
          "17_workspace_connect_status",
          "18_notebook_error_location",
          "19_deployment_cli_occurred"
         ],
         "yaxis": "y",
         "z": [
          [
           0.9999999999999998,
           0.6950511989957033,
           0.6800720295700731,
           0.7392605317342077,
           0.6440976928315387,
           0.676972877637086,
           0.7485781688828107,
           0.6238634552415496,
           0.6609799282555164,
           0.7122777284529525,
           0.7109327185489208,
           0.7978177536636636,
           0.6814041028906044,
           0.6175795456839253,
           0.7162332113150862,
           0.659839340717903,
           0.7089275822233386,
           0.6525459063519485,
           0.689426687738697,
           0.722606948532684
          ],
          [
           0.6950511989957033,
           0.9999999999999998,
           0.6468254143225831,
           0.5844457832413297,
           0.6258424501239005,
           0.6126592268247026,
           0.7539157665534312,
           0.5867106418462622,
           0.675511941741507,
           0.683629314578445,
           0.6752590624975627,
           0.6641366443009484,
           0.6949161673812743,
           0.6733842538068737,
           0.661205275509094,
           0.7049088558161584,
           0.7162224008883273,
           0.7429714581178176,
           0.6812787356432877,
           0.7594924343798477
          ],
          [
           0.6800720295700731,
           0.6468254143225831,
           1,
           0.6433886472325262,
           0.5757531265534923,
           0.657101537229323,
           0.6665689467912007,
           0.556194581794082,
           0.6402068837249237,
           0.666767721711941,
           0.6514737761022202,
           0.6677273529171234,
           0.5910509905689537,
           0.5479623354880581,
           0.6548325084765252,
           0.6031813198296279,
           0.6278166244609531,
           0.5568432047118255,
           0.6306823397526431,
           0.7351664847249288
          ],
          [
           0.7392605317342077,
           0.5844457832413297,
           0.6433886472325262,
           0.9999999999999994,
           0.6042084829246176,
           0.8056896144590333,
           0.686697468495697,
           0.5377523409385234,
           0.6680241013522291,
           0.6764364242058837,
           0.682550096416689,
           0.6787478750355247,
           0.6371985392488675,
           0.561790576708667,
           0.6015895600091554,
           0.572175899081431,
           0.5967142427607222,
           0.6000049265485852,
           0.6377321243825933,
           0.6492279945928271
          ],
          [
           0.6440976928315387,
           0.6258424501239005,
           0.5757531265534923,
           0.6042084829246176,
           0.9999999999999996,
           0.6434121460740716,
           0.6398887673381325,
           0.6222886821616916,
           0.6248254568490005,
           0.5506620561956513,
           0.5728222408142388,
           0.6182709100027164,
           0.6962691326013506,
           0.6030273135897056,
           0.6102707728990873,
           0.569420786917457,
           0.6953883854338426,
           0.626322022792367,
           0.6944134024999769,
           0.6179405005610332
          ],
          [
           0.676972877637086,
           0.6126592268247026,
           0.657101537229323,
           0.8056896144590333,
           0.6434121460740716,
           0.9999999999999999,
           0.68092249051733,
           0.5831549286932858,
           0.7060417847656603,
           0.6967632322881472,
           0.7155668248171997,
           0.6967227460537264,
           0.6336478288964544,
           0.5877751000432987,
           0.6365948206082341,
           0.593819259100868,
           0.6240161835147201,
           0.6100757918964216,
           0.66802603849881,
           0.6661305372623024
          ],
          [
           0.7485781688828107,
           0.7539157665534312,
           0.6665689467912007,
           0.686697468495697,
           0.6398887673381325,
           0.68092249051733,
           1,
           0.5762995038718888,
           0.6521353152572144,
           0.6839943997228829,
           0.7101322033600215,
           0.7162543248397905,
           0.6727417355131862,
           0.6944423709771164,
           0.6805850162780565,
           0.6486552078625508,
           0.7011999305126136,
           0.6992301288466358,
           0.6995331471013808,
           0.7080367757548822
          ],
          [
           0.6238634552415496,
           0.5867106418462622,
           0.556194581794082,
           0.5377523409385234,
           0.6222886821616916,
           0.5831549286932858,
           0.5762995038718888,
           1.0000000000000004,
           0.6498448442328908,
           0.5710717950333387,
           0.5600345688176043,
           0.608025113346585,
           0.5626839716443958,
           0.5424306144274071,
           0.6184117818613789,
           0.5618900136760487,
           0.6162853881918687,
           0.5552352091522826,
           0.5804737558009891,
           0.6541453876595724
          ],
          [
           0.6609799282555164,
           0.675511941741507,
           0.6402068837249237,
           0.6680241013522291,
           0.6248254568490005,
           0.7060417847656603,
           0.6521353152572144,
           0.6498448442328908,
           1.0000000000000004,
           0.7121840572281735,
           0.672528267718679,
           0.6616001994225138,
           0.6546244189861895,
           0.6656483611305499,
           0.6249014680468072,
           0.6107006015070959,
           0.7088734316725129,
           0.5906269530922267,
           0.6654028125995228,
           0.68309654776887
          ],
          [
           0.7122777284529525,
           0.683629314578445,
           0.666767721711941,
           0.6764364242058837,
           0.5506620561956513,
           0.6967632322881472,
           0.6839943997228829,
           0.5710717950333387,
           0.7121840572281735,
           0.9999999999999998,
           0.7281312095672066,
           0.6735332994610942,
           0.6082773503156537,
           0.6638445705040288,
           0.6519494897360518,
           0.658869553841276,
           0.6389653932530628,
           0.5812974610049109,
           0.6625606600520975,
           0.7472661495734966
          ],
          [
           0.7109327185489208,
           0.6752590624975627,
           0.6514737761022202,
           0.682550096416689,
           0.5728222408142388,
           0.7155668248171997,
           0.7101322033600215,
           0.5600345688176043,
           0.672528267718679,
           0.7281312095672066,
           1.0000000000000002,
           0.672778604410156,
           0.6402132259877833,
           0.6093877661400169,
           0.6176530865522053,
           0.6436731493623411,
           0.6615945389112652,
           0.6362714271609771,
           0.6326473538954829,
           0.6827559473864668
          ],
          [
           0.7978177536636636,
           0.6641366443009484,
           0.6677273529171234,
           0.6787478750355247,
           0.6182709100027164,
           0.6967227460537264,
           0.7162543248397905,
           0.608025113346585,
           0.6616001994225138,
           0.6735332994610942,
           0.672778604410156,
           0.9999999999999998,
           0.6525571417645519,
           0.5888788939631658,
           0.6968730913848796,
           0.6792331567377464,
           0.6903895628071703,
           0.6180962016206006,
           0.6576287372346001,
           0.6968337592715165
          ],
          [
           0.6814041028906044,
           0.6949161673812743,
           0.5910509905689537,
           0.6371985392488675,
           0.6962691326013506,
           0.6336478288964544,
           0.6727417355131862,
           0.5626839716443958,
           0.6546244189861895,
           0.6082773503156537,
           0.6402132259877833,
           0.6525571417645519,
           1.0000000000000002,
           0.6855688275676739,
           0.6235931307917347,
           0.7113355801121535,
           0.6733709388637069,
           0.6677474245794781,
           0.6873450410708324,
           0.6509876778788272
          ],
          [
           0.6175795456839253,
           0.6733842538068737,
           0.5479623354880581,
           0.561790576708667,
           0.6030273135897056,
           0.5877751000432987,
           0.6944423709771164,
           0.5424306144274071,
           0.6656483611305499,
           0.6638445705040288,
           0.6093877661400169,
           0.5888788939631658,
           0.6855688275676739,
           0.9999999999999999,
           0.5707399222183736,
           0.6920877618041048,
           0.6852681418848823,
           0.5970284592286472,
           0.6140717627385283,
           0.6739323226391851
          ],
          [
           0.7162332113150862,
           0.661205275509094,
           0.6548325084765252,
           0.6015895600091554,
           0.6102707728990873,
           0.6365948206082341,
           0.6805850162780565,
           0.6184117818613789,
           0.6249014680468072,
           0.6519494897360518,
           0.6176530865522053,
           0.6968730913848796,
           0.6235931307917347,
           0.5707399222183736,
           1.0000000000000002,
           0.6597535362980727,
           0.664700654688579,
           0.6172338925588503,
           0.6866970101612516,
           0.6900888799956919
          ],
          [
           0.659839340717903,
           0.7049088558161584,
           0.6031813198296279,
           0.572175899081431,
           0.569420786917457,
           0.593819259100868,
           0.6486552078625508,
           0.5618900136760487,
           0.6107006015070959,
           0.658869553841276,
           0.6436731493623411,
           0.6792331567377464,
           0.7113355801121535,
           0.6920877618041048,
           0.6597535362980727,
           1,
           0.6712112054322967,
           0.6347643283675084,
           0.6568904734543606,
           0.6770332103399609
          ],
          [
           0.7089275822233386,
           0.7162224008883273,
           0.6278166244609531,
           0.5967142427607222,
           0.6953883854338426,
           0.6240161835147201,
           0.7011999305126136,
           0.6162853881918687,
           0.7088734316725129,
           0.6389653932530628,
           0.6615945389112652,
           0.6903895628071703,
           0.6733709388637069,
           0.6852681418848823,
           0.664700654688579,
           0.6712112054322967,
           1.0000000000000002,
           0.6595529618924222,
           0.7222413752605349,
           0.7043252264633715
          ],
          [
           0.6525459063519485,
           0.7429714581178176,
           0.5568432047118255,
           0.6000049265485852,
           0.626322022792367,
           0.6100757918964216,
           0.6992301288466358,
           0.5552352091522826,
           0.5906269530922267,
           0.5812974610049109,
           0.6362714271609771,
           0.6180962016206006,
           0.6677474245794781,
           0.5970284592286472,
           0.6172338925588503,
           0.6347643283675084,
           0.6595529618924222,
           0.9999999999999999,
           0.7279584947313271,
           0.6847934638956177
          ],
          [
           0.689426687738697,
           0.6812787356432877,
           0.6306823397526431,
           0.6377321243825933,
           0.6944134024999769,
           0.66802603849881,
           0.6995331471013808,
           0.5804737558009891,
           0.6654028125995228,
           0.6625606600520975,
           0.6326473538954829,
           0.6576287372346001,
           0.6873450410708324,
           0.6140717627385283,
           0.6866970101612516,
           0.6568904734543606,
           0.7222413752605349,
           0.7279584947313271,
           1.0000000000000002,
           0.6481265673907286
          ],
          [
           0.722606948532684,
           0.7594924343798477,
           0.7351664847249288,
           0.6492279945928271,
           0.6179405005610332,
           0.6661305372623024,
           0.7080367757548822,
           0.6541453876595724,
           0.68309654776887,
           0.7472661495734966,
           0.6827559473864668,
           0.6968337592715165,
           0.6509876778788272,
           0.6739323226391851,
           0.6900888799956919,
           0.6770332103399609,
           0.7043252264633715,
           0.6847934638956177,
           0.6481265673907286,
           0.9999999999999998
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertext": "<b>Topic -1</b>:github_issue_test_notebook_project",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.495585338200682,
          -1.5497342509925918,
          -1.6408137370398164,
          -1.6487013512693451,
          -1.6694730682827483,
          -1.7092593662661906,
          -1.7447793954049666,
          -1.7774309047675616,
          -1.7826607370794456,
          -1.7830916110262451
         ]
        },
        {
         "hovertext": "<b>Topic 0</b>:model_classification_feature_regist",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9967232183809672,
          -1.2847800693869844,
          -1.443061914600668,
          -1.4599540436886702,
          -1.4883384188395463,
          -1.4901553170960788,
          -1.5528019591493898,
          -1.5700938168612548,
          -1.5847907528744383,
          -1.5937833595446647
         ]
        },
        {
         "hovertext": "<b>Topic 1</b>:project_does_cli_plugin_directory_c",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9599636163862428,
          -1.1574431559692242,
          -1.2253831856286448,
          -1.418704977097164,
          -1.420369645354396,
          -1.4264025140023608,
          -1.4372326751761646,
          -1.495205924932155,
          -1.5097666916872012,
          -1.5713794868035063
         ]
        },
        {
         "hovertext": "<b>Topic 2</b>:parameters_errors_warning_api_log_c",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8904487568923054,
          -1.227600724479016,
          -1.2415716181484076,
          -1.3173546149009354,
          -1.4794688896765669,
          -1.5334724462011322,
          -1.5387700700669744,
          -1.5628958979285492,
          -1.5690289754050402,
          -1.571511028571378
         ]
        },
        {
         "hovertext": "<b>Topic 3</b>:training_validation_logging_ddp_los",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8441524701742723,
          -0.9362335490535081,
          -1.126110384237028,
          -1.2787781740409006,
          -1.313470687172562,
          -1.456782558756862,
          -1.5012753177454077,
          -1.5313191759515674,
          -1.5514897150187996,
          -1.5540380142157857
         ]
        },
        {
         "hovertext": "<b>Topic 4</b>:aws_limit_conda_gpu_studio_pull_buc",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8853571556161923,
          -1.188925440096935,
          -1.194581831585861,
          -1.3132144315362702,
          -1.3148762014339268,
          -1.3718502117691225,
          -1.4307823129686918,
          -1.4467154367113957,
          -1.5407552266740305,
          -1.5814521322738526
         ]
        },
        {
         "hovertext": "<b>Topic 5</b>:loss_gpu_progress_tensorboard_loggi",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0690303604828262,
          -1.1589751279481486,
          -1.1846589509177496,
          -1.1846589509177496,
          -1.3587913122669544,
          -1.3884334911228071,
          -1.4325718210563627,
          -1.4613758028437076,
          -1.4831406473847448,
          -1.511459102070827
         ]
        },
        {
         "hovertext": "<b>Topic 6</b>:user_looking_information_ui_resolve",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8670315111575605,
          -0.9588631086513532,
          -1.0161540362895192,
          -1.080443003951839,
          -1.1675726619984328,
          -1.2238667064039555,
          -1.2676657836670016,
          -1.3364893057581864,
          -1.3730625033328507,
          -1.49179522524387
         ]
        },
        {
         "hovertext": "<b>Topic 7</b>:chart_helm_pull_pipeline_endpoint_d",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7110818377654345,
          -0.8616899117108069,
          -1.2813132001115928,
          -1.3571931667690929,
          -1.3965654489556478,
          -1.411262384968831,
          -1.490915120616323,
          -1.5266015527056085,
          -1.5549535655365136,
          -1.569986756858505
         ]
        },
        {
         "hovertext": "<b>Topic 8</b>:pipeline_develop_solution_version_c",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7631757719872158,
          -1.1134238290357648,
          -1.2097874382077582,
          -1.3313513215879884,
          -1.3809971335518594,
          -1.4183999471183553,
          -1.4254898925404051,
          -1.4260394514766521,
          -1.4318101007966708,
          -1.4554629032040691
         ]
        },
        {
         "hovertext": "<b>Topic 9</b>:experiment_encountered_running_fail",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8319007936827896,
          -1.0523601203571422,
          -1.24534579705867,
          -1.2509628711420797,
          -1.267804185273832,
          -1.2917863463250525,
          -1.3185776632029116,
          -1.3193001304451524,
          -1.3801914968787874,
          -1.4276047362297901
         ]
        },
        {
         "hovertext": "<b>Topic 10</b>:runs_registered_failed_ui_status_o",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7291590596273783,
          -1.0555095225938946,
          -1.0616201010729507,
          -1.191031305292329,
          -1.2099757256972619,
          -1.280657300573079,
          -1.315926786126168,
          -1.3442452408122503,
          -1.3812907246602588,
          -1.4414492188534673
         ]
        },
        {
         "hovertext": "<b>Topic 11</b>:artifacts_branch_models_master_ver",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9910722241009225,
          -1.0441434494546713,
          -1.10567865442894,
          -1.1578756008860351,
          -1.1761036887268386,
          -1.23427656941151,
          -1.3933222022562084,
          -1.4604500669059435,
          -1.4621576667730158,
          -1.4666329793121355
         ]
        },
        {
         "hovertext": "<b>Topic 12</b>:ml_import_unnecessary_sdk_studio_c",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8197247191442973,
          -0.9915113028621058,
          -1.0860005512314834,
          -1.1177742035263465,
          -1.3150200698631127,
          -1.370816959070728,
          -1.4319630003049788,
          -1.4462325168571648,
          -1.4624841001653481,
          -1.4637749363242885
         ]
        },
        {
         "hovertext": "<b>Topic 13</b>:install_python_preventing_workarou",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7807879788220481,
          -1.0059854101723102,
          -1.1344319554870421,
          -1.216017692539181,
          -1.280492901071601,
          -1.304091857984138,
          -1.3634565339536322,
          -1.3837925179491166,
          -1.4195347265758074,
          -1.4214402642721267
         ]
        },
        {
         "hovertext": "<b>Topic 14</b>:content_node_missing_creation_stag",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.6665874650242137,
          -0.8946605436858648,
          -1.046164337241798,
          -1.078369842665655,
          -1.086672962043365,
          -1.1073309918503855,
          -1.1816233901141076,
          -1.188220168184696,
          -1.266635163122564,
          -1.3237838735507719
         ]
        },
        {
         "hovertext": "<b>Topic 15</b>:plugin_exceptions_importing_depend",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9497777813174177,
          -0.9553019245561287,
          -0.9786605216307592,
          -1.0102738423128967,
          -1.0349111306977279,
          -1.134299551771813,
          -1.2534150623940492,
          -1.3133056563386531,
          -1.3994690494085478,
          -1.4518567730995549
         ]
        },
        {
         "hovertext": "<b>Topic 16</b>:remove_base_repository_bucket_loca",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.1183225601770266,
          -1.1336631197407854,
          -1.1464581151428437,
          -1.1590983701180082,
          -1.2297368233679675,
          -1.3426595856796546,
          -1.3540697521552836,
          -1.4181897196578228,
          -1.4223430253794462,
          -1.4452901029363967
         ]
        },
        {
         "hovertext": "<b>Topic 17</b>:workspace_connect_status_service_l",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.4756922472147965,
          -0.9074161490177843,
          -0.9592094489958123,
          -1.016935044140058,
          -1.158530750266761,
          -1.2356813432165088,
          -1.2643955860235685,
          -1.2947895521931805,
          -1.3540499538239457,
          -1.3685328810666175
         ]
        },
        {
         "hovertext": "<b>Topic 18</b>:notebook_error_location_template_r",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8323417264970077,
          -1.2482447314484373,
          -1.2608593397594554,
          -1.2942297583540325,
          -1.2962426905690485,
          -1.3026664419738463,
          -1.3435610159208726,
          -1.387436492474762,
          -1.3923116465584637,
          -1.3924142935181125
         ]
        },
        {
         "hovertext": "<b>Topic 19</b>:deployment_cli_occurred_changes_re",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.6583728620484127,
          -0.939044680334577,
          -1.0939918364721972,
          -1.0953201831206436,
          -1.1344174655557735,
          -1.1571089083083304,
          -1.1992035320771843,
          -1.2898667880027692,
          -1.3636460106801191,
          -1.3989843338162753
         ]
        }
       ],
       "layout": {
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Term score decline per Topic</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "dtick": 2,
         "range": [
          0,
          10
         ],
         "tick0": 1,
         "title": {
          "text": "Term Rank"
         }
        },
        "yaxis": {
         "title": {
          "text": "c-TF-IDF score (log scale)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = TfidfVectorizer(min_df=3, stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "  diversity=0.5,                      # Step 6 - Diversify topic words\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue_gpt_text, 'issues_summary.json'))\n",
    "topic_model = topic_model.fit(df_issues['Issue_summary'].tolist())\n",
    "topic_model.get_topic_info()\n",
    "topic_model.visualize_topics()\n",
    "topic_model.visualize_documents(df_issues['Issue_summary'].tolist())\n",
    "hierarchical_topics = topic_model.hierarchical_topics(df_issues['Issue_summary'].tolist())\n",
    "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "topic_model.visualize_barchart()\n",
    "topic_model.visualize_heatmap()\n",
    "topic_model.visualize_term_rank(log_scale=True)\n",
    "topic_model.save(os.path.join(path_labeling_issue_gpt_text, 'topic_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aadb817d3940c6b182fe1b387f854d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 09:19:03,002 - BERTopic - Transformed documents to Embeddings\n",
      "2023-02-11 09:19:05,705 - BERTopic - Reduced dimensionality\n",
      "2023-02-11 09:19:05,729 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>71</td>\n",
       "      <td>-1_variable_job_script_add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0_pytorch_loss_training_gpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1_title_comments_node_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2_experiment_model_exception_resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3_aws_request_cluster_study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4_pull_artifact_repo_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5_azure_import_terminal_extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6_models_reproducible_branch_checked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7_project_cli_port_does</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8_pipeline_catalog_plugin_artifacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9_run_ui_pipeline_tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10_workspace_connect_stopped_screenshots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11_lab_jupyter_cloning_study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12_chart_port_upgrade_minio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>13_init_cc_folder_success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14_install_line_metadata_markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>15_kubeflow_parameters_batch_deploy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>16_warning_calling_command_branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>17_checkpoint_param_docker_line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                      Name\n",
       "0      -1     71                -1_variable_job_script_add\n",
       "1       0     62               0_pytorch_loss_training_gpu\n",
       "2       1     50               1_title_comments_node_limit\n",
       "3       2     22       2_experiment_model_exception_resume\n",
       "4       3     19               3_aws_request_cluster_study\n",
       "5       4     14                4_pull_artifact_repo_image\n",
       "6       5     12         5_azure_import_terminal_extension\n",
       "7       6     10      6_models_reproducible_branch_checked\n",
       "8       7     10                   7_project_cli_port_does\n",
       "9       8      9       8_pipeline_catalog_plugin_artifacts\n",
       "10      9      9                   9_run_ui_pipeline_tests\n",
       "11     10      9  10_workspace_connect_stopped_screenshots\n",
       "12     11      9              11_lab_jupyter_cloning_study\n",
       "13     12      8               12_chart_port_upgrade_minio\n",
       "14     13      7                 13_init_cc_folder_success\n",
       "15     14      6         14_install_line_metadata_markdown\n",
       "16     15      6       15_kubeflow_parameters_batch_deploy\n",
       "17     16      6         16_warning_calling_command_branch\n",
       "18     17      6           17_checkpoint_param_docker_line"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "pytorch | loss | training | gpu | results",
           62
          ],
          [
           1,
           "title | comments | node | limit | classification",
           50
          ],
          [
           2,
           "experiment | model | exception | resume | uri",
           22
          ],
          [
           3,
           "aws | request | cluster | study | unable",
           19
          ],
          [
           4,
           "pull | artifact | repo | image | bucket",
           14
          ],
          [
           5,
           "azure | import | terminal | extension | ml",
           12
          ],
          [
           6,
           "models | reproducible | branch | checked | pandas",
           10
          ],
          [
           7,
           "project | cli | port | does | arguments",
           10
          ],
          [
           8,
           "pipeline | catalog | plugin | artifacts | datasets",
           9
          ],
          [
           9,
           "run | ui | pipeline | tests | fails",
           9
          ],
          [
           10,
           "workspace | connect | stopped | screenshots | swb",
           9
          ],
          [
           11,
           "lab | jupyter | cloning | study | conda",
           9
          ],
          [
           12,
           "chart | port | upgrade | minio | db",
           8
          ],
          [
           13,
           "init | cc | folder | success | examples",
           7
          ],
          [
           14,
           "install | line | metadata | markdown | bit",
           6
          ],
          [
           15,
           "kubeflow | parameters | batch | deploy | kfp",
           6
          ],
          [
           16,
           "warning | calling | command | branch | days",
           6
          ],
          [
           17,
           "checkpoint | param | docker | line | numpy",
           6
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>Words: %{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           62,
           50,
           22,
           19,
           14,
           12,
           10,
           10,
           9,
           9,
           9,
           9,
           8,
           7,
           6,
           6,
           6,
           6
          ],
          "sizemode": "area",
          "sizeref": 0.03875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          8.155152320861816,
          8.22860050201416,
          8.350847244262695,
          11.40273380279541,
          11.287907600402832,
          8.095473289489746,
          9.517926216125488,
          -3.2809174060821533,
          -3.348705530166626,
          8.81141471862793,
          11.408834457397461,
          11.02878189086914,
          7.052506446838379,
          11.493059158325195,
          9.48422908782959,
          6.740158557891846,
          7.859046459197998,
          8.867598533630371
         ],
         "xaxis": "x",
         "y": [
          2.7535128593444824,
          2.0297346115112305,
          3.1004292964935303,
          2.139376401901245,
          0.8675484657287598,
          1.4771101474761963,
          2.7663416862487793,
          -0.6697266101837158,
          -0.7375341057777405,
          2.652259111404419,
          1.5940930843353271,
          1.876481533050537,
          4.370904922485352,
          0.5224869847297668,
          3.5956969261169434,
          4.719735622406006,
          1.2346155643463135,
          3.334174871444702
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -3.85101135969162,
          "y": 2.2897658720612526,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 4.683003336191177,
          "xshift": 10,
          "y": 5.427695965766906
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 4.683003336191177,
          "x1": 4.683003336191177,
          "y0": -0.8481642216444015,
          "y1": 5.427695965766906
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -3.85101135969162,
          "x1": 13.217018032073975,
          "y0": 2.2897658720612526,
          "y1": 2.2897658720612526
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 7",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 8",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 9",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 10",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 11",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 12",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 13",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 14",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 15",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 16",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 17",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -3.85101135969162,
          13.217018032073975
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -0.8481642216444015,
          5.427695965766906
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: led model returns algorithmerror when using smp training Content: system info cc cc cc hello, this is follow up on related post with the below link) with the same title: we ade bit of more progress but are still facing with some issues and are trying to fix them after trying out several fixes including matching the python, transformers, and pytorch versions according to the recommendations valueerror: not enough values to unpack the error is in the within the transformers module expecting different shape. new update is we tried below to unsqueeze input tensors to the to solve the above error: def return it helped moving forward in the process, but we got another error, below, little further down in the code: unexpectedstatusexception: error for training job huggingface pytorch training failed. reason: algorithmerror: executeuserscripterror: exitcode errormessage :runtimeerror: tensors must have same number of dimensions: got and :environment variable is not set :environment variable is not set :environment variable is not set :environment variable is not set :environment variable is not set :environment variable is not set :environment variable is not set :environment variable is not set primary job terminated normally, but process returned non zero exit code. per user direction, the job has been aborted. detected that one or more processes exited with non zero status, thus causing the job to be terminated. the first process to do so was: process name: exit code: command mpirun host algo id greatly appreciate your feedback. please let me know if you need any further information about the project. who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction running this attached file with the training python file expected behavior have shared the notebook and the error raised in it for clarification",
          "Title: api key for github ci; Content: api key not configured for github ci",
          "Title: add episode to Content:when using it shows step as and not episode. hence, longer runs have more steps and it makes the comparaison between runs difficult.",
          "Title: loading configs from yields incorrect parameters; Content: what when loading configs from the resulting hparams objects are not correct. this can be seen when attempting to load the model checkpoint with the given parameters or when comparing the object with the info panel for the run on how to reproduce load the configs: validate against the run acceptance criteria bug has been understood and fixed the same config given above can be loaded and is correct",
          "Title: idempotency in kubeflow pipeline component. Content: what steps did you take if node scales down, the component tries to create the same job which fails. since does not let create the same name job. component controller should be able to detect this and resume the job from existing state. what happened: the job hangs what did you expect to happen: expect the job to resume from previous state. environment: impacted by this bug? give it we prioritise the issues with the most",
          "Title: must manually import before to avoid import error; Content: bug few weeks ago, changed the ordering of imports for the however, requires for to be imported before some other dependencies, torch and tensorboard, to work properly. if not, you get the following error: before the imports reordering, 's import requirements could be met by importing before torch and tensorboard. however, since the refactoring, torch is now imported before in itself. this forces users to manually add an unused import for before importing to avoid the above to reproduce this example reproduces the expected behavior users should not have to manually import before to avoid triggering the the import inside should exceptionally come before the import, even if it violates usual import ordering.",
          "Title: users can access to any project; Content:only allow access to project members for the given",
          "Title: run stalling; Content: sweep on our advance instead they just stall after the first part of the sweep completes. this is causing problems.",
          "Title: warning: is deprecated; use Content:enchanter raise when using context api expected behavior environment enchanter version: python version: os: linux other libraries and their versions: google colab with gpu error messages, stack traces, or logs steps to reproduce reproducible examples additional context",
          "Title: all experiments are visible for any user; Content:we should create instance of for each project in order to see the experiments related to the current project. create project operator to deploy instance for each project. update kdl app api to create the kdlproject custom resource in s. update adding project operator docker image building. add project operator to kdl server helm chart. add github workflows to publish the project operator in docker hub.",
          "Title: remove sdk preview private pypi index from operationalize notebook; Content:this contains reference to azure ml sdk preview private index. required packages for execution, history, and data preparation. extra index url given that azure ml sdk is now available though regular pypi as ga product, and preview versions are unsupported, the extra index url should be removed.",
          "Title: execute translate script without creating task; Content:currently, the script always creates task. this should be optional. by default, it should just execute locally.",
          "Title: the api is outdated in transformers the old api could not work; Content: system info version: platform: python version: version: pytorch version tensorflow version flax version jax version: jaxlib version: using gpu in script?: using distributed or parallel set up in script?: who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction .enable hpo in example and run. work log like userwarning: you're currently using the old experience. try out the new and improved experience by getting started with the docs today. you have until july to migrate over without experiencing breaking expected behavior hpo with backend could work correctly without warning",
          "Title: is broken with Content: description the plugin does not work with projects created with context try to launch in project with and installed. steps to reproduce expected result this should run the pipeleine and log the parameters. actual result this raises the following error: your environment include as many relevant details about the environment in which you experienced the bug: and version used and python version used all operating system and version: all does the bug also happen with the last version on master? yes solution currently, uses inside hook. with this private attribute was removed and the new recommandation is to use the hook. retrieving the configuration and set it up should be moved to this new hook:",
          "Title: graph tab doesn't render in studio jupyter lab; Content: describe the bug when trying to execute .path ), force current behavior screenshot taken from jupyterlab expected behavior screenshot taken from jupyter",
          "Title: project template secret bad name; Content:currently the is referencing the secret which doesn't exist by default. we have noticed that secret is created when resource is created. to solve this issue the name of the must be changed into",
          "Title: create index name error; Content: index name modify create index name error and change name to modelname",
          "Title: error when deploying assets only; Content: expected behavior deploy jobs with assets only option current behavior api request conflict steps to reproduce deployment file is not provided, searching in the conf directory auto discovery found deployment file deployment file exists and will be used for deployment starting new deployment for environment dev using profile provided from the project file found auth config from provider environmentvariableconfigprovider, verifying it found auth config from provider environmentvariableconfigprovider, verification successful since environment configurations should be nested under environments section. please nest environment configurations under this section to avoid potential issues while using build configuration directive. no build logic defined in the deployment file. default pip based build logic will be used. usage of jobs keyword in deployment file is deprecated. please use workflows instead workflows were selected for further operations following the provided build logic building python based project python based project build finished locating package file package file located in: starting the traversal process processing libraries for workflow add on chanel at processing libraries for workflow add on chanel at done processing libraries for workflow add on chanel pl processing libraries for workflow add on chanel pl done processing libraries for workflow add on pl processing libraries for workflow add on pl done uploading local file uploading local file uploading local file traceback in deploy workflowdeploymentmanager else: if not only: workflowdeploymentmanager in traverse def traverse if isinstance if or parent, ind class adjuster: in def parent, index) in path in wrapper around that also verifies that the reques response def in endpoint, raise exception exception: api request to endpoint failed with error code response body: error http error: problem accessing reason: file already exists, cannot overwrite: &apos; y&apos; error: process completed with exit code context updated few jobs today using the latest dbx version, and at the jobless deployment cicd step get the error above. is only used to define specific experiment path. no path related updates or changes here! your environment dbx version used: databricks runtime version: lts python version:",
          "Title: support writing out dataset profiles as json format with Content: summary you can call directly and save the profile json: but if you pass format config to writer specifying 'json' it isn't supported and instead uses the protobuf bin format.",
          "Title: convert experiment fails for experiment id, works for experiment name; Content: bug doing as described here fails with the following error using the experiment name instead of the experiment id works: to reproduce see above expected behavior convert the experiment by id environment version python pip ubuntu lts",
          "Title: have accelerate for distributed training: data parallelism feature working on aws yet?; Content: system info information the official example scripts my own modified scripts tasks one of the scripts in the examples/ folder of accelerate or an officially supported script in the folder of the repo my own task or dataset reproduction multi gpu distributed data training, while it always returns empty tensors. expected behavior",
          "Title: importerror for tabularprediction in notebook instance; Content:i got importerror when trying to use autogluon in instance with kernel being the error got is: if try for your reference: installed autogluon by using version pip in the notebook as usual. there are errors in the second installation step: error: has requirement but you'll have boto which is incompatible. error: awscli has requirement but you'll have botocore which is",
          "Title: output overwrites wabucketref's output in case of artifact upload; Content:example job: job acb aa ce ddc at the end of the job run, we upload the artifact, where happens, and terminate the job. however, we have: while it should be: one line was overwritten by the which, apparently is running in separate process `).",
          "Title: how to get root access in studio lab; Content:hi, am trying to install some libraries in studio lab which requires root privileges. below have run to check if am root user. below you can see the error on running sudo: followed link to install sudo. on running it asks for the password, but we don't have any password for studio lab. can anyone tell how to get root access or way to install libraries which require root access packages which installs using sudo). please let me know if my query is not clear.",
          "Title: update test documentation to connect with github actions; Content: description steps: create new workspace. name: resource group: location: make sure you have enough quota in the location you choose create two new clusters: and go to compute, then compute cluster, then new. select the cpu vm base. anything above gb of ram, and cores should be fine. select the gpu vm base. anything above gb of ram, and cores, and an nvidia should be fine. add the subscription id to github action secrets create new repository secret called and add the subscription id as the value. make sure you have installed and that you are logged in: select your subscription: create service principal: add the output from the service principal as an action secret in which platform does it happen? how do we replicate the issue? expected behavior other comments",
          "Title: error when starting new experiment in Content:error in pipeline in githubactions which causes test to not pass",
          "Title: expecting folder; Content:when running hyperparameter tuning, expects an folder which we don't create. if we stick with the standard we can ommit having to run with the backend store argument.",
          "Title: xcom output of async operators; Content: describe the bug xcom return value of and does not produce the expected output. it seems like some key don't match the non async operator output. to reproduce steps to reproduce the behavior: run dag with traditional operators run same dag with async operators compare outputs expected behavior the xcom keys and values should match whatever the traditional non async version of the operators output. screenshots if applicable, add screenshots to help explain your problem.",
          "Title: swb study permission denied; Content:we encountered an issue where an older instance was turned on. after starting, one of the two study folders associated were not syncing any of the files. in the system logs there's this error: comparing the mounts parameter for the stack of the older instance that fails to sync, and newer instance see that the fs role number for the private workspace study that wouldn't sync is different. old stack mounts parameter: new stack mounts parameter: some additional context, this bucket that the two studies are part of gets updated every couple months to add new study folders but the existing studies don't typically change. what could cause the fs role number to change for study? what else could cause this permissions denied error? this is pretty big problem for us, as we have had people actively using swb and all their work is gone on stop, because the folder they saved to isn't syncing. versions swb",
          "Title: artifactdataset does not work with partitioneddataset; Content: description it is not possible to store as an artifact with the context had use case where need to save dict with many small result tables to and tried to use for this. steps to reproduce then save dict using this dataset: expected result the dataframes should be logged as artifacts in the current run. actual result an error is raised. does the bug also happen with the last version on master? yes potential solution the error comes from this line: maybe we can add better condition here to default to path if there is no filepath attribute.",
          "Title: fails when config is too large; Content:i tried to run with but got an error because the config is too large, probably due to the array being too big. perhaps the data selections does not need to be uploaded to the full message is:",
          "Title: catalog anonymous function is not registered Content:problem: steps to reproduce: register models into start spark thrift server use to connec to the thrift server: run",
          "Title: plugin only compatible with Content: alway throws exception since package has been moved or refactored",
          "Title: error in with notebooks; Content: description this is the error, it looks it is related to the deployment of aci and aks resources. fyi any idea of what could be happening? in which platform does it happen? how do we replicate the issue? expected behavior other comments",
          "Title: papi depreciated; Content:use of the api logger reports an unecessary depreciation warning relating to the use of rather than the newer example:",
          "Title: some links to notebooks in introduction are broken in notebook; Content: description the introduction section of the notebook under object detection includes two broken links: the master branch of this repo does not contain these notebooks. in which platform does it happen? all. how do we replicate the issue? click the links expected behavior notebooks are present or links are removed other comments",
          "Title: hangs; Content:calling from the client against an existing by not inprogress job, causes the client to hang. this only seems to happen within the sm executor though. here's the output calling the method from the python interpreter within the pod: here is the debug output from the sm executor",
          "Title: experiments with don't work if container variable specify an incorrect ip address; Content:execution get stuck if this case happens. it is necessary to manage this exception properly.",
          "Title: is not compatible with pl Content:hi, there may be version conflict between and pl os: python: pytorch: pl: hydra core: when use the hyperparameter search, it produces the following error:",
          "Title: only display the add prompt if there is anything to add; Content:currently, it will display always display even if there is no selection to make since the list of files is empty",
          "Title: is broken with Content: description the plugin does not work with projects created with context try to launch in project with and installed. steps to reproduce expected result this should run the pipeleine and log the parameters. actual result this raises the following error: your environment include as many relevant details about the environment in which you experienced the bug: and version used and python version used all operating system and version: all does the bug also happen with the last version on master? yes solution currently, uses inside hook. with this private attribute was removed and the new recommandation is to use the hook. retrieving the configuration and set it up should be moved to this new hook:",
          "Title: fails to add files to tracking; Content:when running the command for data files it tries to add them to tracking but fails. in my case tried to add the raw data directory that contains the following image files: but fds failed to execute the add command:",
          "Title: model not loading while using existing container image to setup mme on Content:checklist i've prepended issue tag with type of change: i've attached the script to reproduce the bug i've documented below the dlc image this relates to i've documented below the tests i've run on the dlc image i'm using an existing dlc image listed here: i've built my own container based off dlc concise description: getting this error, when invoking mme on setup using container image. httpconnectionpool max retries exceeded with url: traceback file line in file line in response file line in get return url, kwargs) file line in request resp file line in send kwargs) file line in send raise connectionerror dlc image current behavior: expected behavior: model should load up and return prediction additional context: have setup mme using the above mentioned container and invoking the endpoint using lambda. the model files are in placed in and are in the correct directory structure with version number.",
          "Title: is not parsed properly when using templatedconfigloader; Content:when you have global variable in the file the global variable is not replaced by its value even if the user has in his project. this is due to to manually recreate the default configloader. this is part of the numerous issues that will be fixed by",
          "Title: studio tour missing of order steps; Content:regarding this section: step run the following refers to the th code cell in the notebook. the previous code cells need to be run first for the notebook to work, but are never referenced in the tour walkthrough doc. the doc goes from having the user clone the repo: straight to having the user run the th code cell in the notebook, skipping the first code cells. step create trials and refers to code cell in the notebook, but again jumps straight from cell without ever running cells or",
          "Title: token error with async operators; Content: describe the bug getting errors with the new async operators that don't get with the traditional ones. i'm using personal access key, secret, and session token as did with the non async operators for auth. to reproduce steps to reproduce the behavior: use the async operators with user access key, secret, and session token expected behavior expect it to not have auth errors. additional context when switch back to the traditional operators in the same dag with the same auth creds it works fine. also had similar issues and her auth was setup little different.",
          "Title: search suggester is not serialisable; Content: what happened what you expected to happen tried to run ray tune job using the suggester on remote cluster. the suggester object was later found to be unserialisable however the stack trace gave no indication of this. the stack trace looks like this discussion around this issue can be found here thanks to matthew deng for finding the issue on this one! versions dependencies python reproduction script issue severity medium: it is significant difficulty but can work around it.",
          "Title: remote test reporting issues; Content:checklist i've prepended issue tag with type of change: i've attached the script to reproduce the bug i've documented below the dlc image this relates to i've documented below the tests i've run on the dlc image i'm using an existing dlc image listed here: i've built my own container based off dlc concise description: sm remote test log doesn't get reported correctly. observed in commits of the pr: dlc image mx dlc current behavior: github shows pending status. codebuild logs show failed status. however, actual codebuild logs doesn't bear failure log. it terminates abruptly. sm cloudwatch log navigating to the appropriate sm training log shows that the job ran for hours and ended successfully. it says: expected behavior: pr commit status should say failed if codebuild log says failed codebuild log should not abruptly hang. it should print out the error. currently it just terminates after printing some logs post session start. additional context:",
          "Title: support tensorflow with the new Content:trainingpipeline needs to be updated to accommodate the from tensorflow package. related thread:",
          "Title: blogpost is outdated after release; Content: contact details system information zenml version: install path: python version: platform information: environment: native integrations: what happened? trying to follow the it fails because zenml does not now have stack category. reproduction steps zenml metadata store if don't add it and run the pipeline, it fails. relevant log output code of conduct agree to follow this project's code of conduct",
          "Title: refers to folder that doesn't exists; Content: operating system linux version information azure cli steps to reproduce the example batch endpoint file, refers to folder that doesn't exist expected behavior it looks like we need to re add the folder? actual behavior code fails because folder doesn't exist addition information",
          "Title: dbx deploy fails due to experiment not found; Content: expected behavior succeeds current behavior the command returns steps to reproduce follow the instructions at context trying to set up dbx for the first time. your environment mac os with macos monterey dbx version used: databricks extensions aka dbx, version databricks runtime version: version",
          "Title: models that override with value bigger than automatically switch to train on even if user overrides false; Content:models that override with value bigger than automatically switch to train on even if user overrides false this behaviour is bit confusing and had to debug the code to understand what was happening. would expect the runner to fail if there are contradicting parameters instead of overriding them for me and doing the opposite of what want that is train locally. repro with: also the is not trainable because it does not have default encoder type. should we flag base classes as not trainable and throw an error?",
          "Title: apt get failure in local test builds; Content: description: an apt get error is seen in builds as below. this is because process is already running and in active state.",
          "Title: bug: unable to train on window Content: search before asking have searched the yolov and and found no similar questions. question am unable to train alway the same error: python img batch epochs data weights train: cfg epochs imgsz rect false, resume false, nosave false, noval false, noautoanchor false, noplots false, evolve none, bucket cache none, false, device false, false, optimizer sgd, false, workers name exp, false, quad false, false, patience freeze seed entity none, false, latest github: skipping check for updates see yolov cpu hyperparameters: run 'pip install to automatically track, visualize and remotely train yolov in tensorboard: start with 'tensorboard logdir view at warning: credentials have not been set. will default to offline logging. please set your credentials to enable online logging. warning: has disabled auto logging functionality as it has been imported after the following ml modules: tensorboard, torch. metrics and hyperparameters can still be logged using and info: using path as offline directory. pass parameter into constructor or set the environment variable to manually choose where to store offline experiment archives. warning: native output logging mode is not available, falling back to basic output logging traceback file line in main file line in main opt, device, callbacks) file line in train loggers loggers loggers instance file line in file line in file line in if keyerror: 'path' info: info: offlineexperiment summary info: info: data: info: info: url info: others: info: true info: uploads: info: environment details info: installed packages info: warning: experiment name is generated at upload time for offline experiments unless set explicitly with warning: has disabled auto logging functionality as it has been imported after the following ml modules: tensorboard, torch. metrics and hyperparameters can still be logged using and info: still saving offline stats to messages file before program termination info: starting saving the offline archive info: to upload this offline experiment, run: upload have tested many dataset and alway the same error any advice additional",
          "Title: with needs to specify both and Content:in the original code below would cause an error so specified cause the framework version only supports and which fixed the problem. or guess just add like notebooks in another would also solve the issue.",
          "Title: link to in notebook is broken; Content: description the notebook contains the following link in markdown: the link does not resolve properly it appears the relative location of the notebook has changed. in which platform does it happen? all how do we replicate the issue? click the link expected behavior link works other comments",
          "Title: running projects causes not found error; Content: currently since running projects form remote sources causes not found issue on starting the project reproduce run expected running remote sourced project is supported as previously",
          "Title: modeluploadop from pipelines: model upload using google cloud pipeline components does not work; Content: expected behavior code example from pipelines: model train, upload, and deploy using google cloud pipeline components should work as intended. actual behavior code example below from pipelines: model train, upload, and deploy using google cloud pipeline components had issue and does not work on the other hand, the method below worked: i'm currently using pipelines to train model and upload to currently in the pipeline, i'm attempting to use the modeluploadop class to upload custom model to models. the logs show the job is succeeding, but the model never actually gets uploaded. steps to reproduce the problem specifications version: pipeline sdk version: kfp pipelines version: platform: google cloud",
          "Title: hydra optuna sweeper and versions conflict; Content:hi! have installed all required packages by and tried to run hyperparametric search using the faced problems: hydra optuna sweeper problem got the following error: the same error was reported in file contains the following versions for hydra optuna sweeper: but the latest versions of the packages are installing: if understand correctly, optuna sweeper's syntax has changed in hydra since version when change the syntax to the new version ): everything works without errors. problem after the command was installed. when running the training process with this logger: the first run with the certian parameters combination finished successfully, the second run had the error: it is not clear, which parameters should be passed to pytorch lighting wrapper when initializinig this logger, to avoid this error.",
          "Title: tries to launch updater using asv script; Content:in every run you can see: we clearly need to take more care on side, but good enough workaround is to set ci or env var to make skip launching the updater.",
          "Title: setting the experiment does not work in interactive mode; Content: description if specify an experiment in and the set up the configuration interactively, all runs should be stored by default in this experiment while they are currently sotred in default experiment. this works when running run through the cli. steps to reproduce does the bug also happen with the last version on master? yes potential solution the faulty line is: but it does not restore deleted experiment. this wil replace part of the logic here:",
          "Title: no tensorflow reported when trying to run nvidia image for Content:steps to reproduce: followed instructions in the readme, but instead of did and then tagged it as instructed. before running went to that file and commented out the line that lonon mentioned in expected result: when running my gpu is detected and training begins actual result: system info: ubuntu lts",
          "Title: cli endpoint example out of date with new syntax from breaking changes in yaml Content: operating system windows version information latest cli steps to reproduce this yaml is out of date, the model yaml config is wrong. name is no longer required when specifying model. expected behavior that the deployment works based on using the cli command but it fails. actual behavior it fails. addition information",
          "Title: autostop script not pulling from bucket; Content: describe the bug we encountered an interesting issue regarding the auto stop script. we had no code changes, but suddenly, instances started hanging around for days, with no use. looking into the instance, the cron job was failing, because the script had syntax error. when look at the script, it has this line which caused the syntax error. however, the file on the repo, as well as the bucket, does not contain this line. so, after some digging, found that this line was introduced here, in this commit what don't understand is how it got into the notebook, and why it's not being overridden by the custom config start we have here this script and repo was updated in the last hours to remove this syntax error. to reproduce launch instance. you can tell which version of the script it's using by looking at the autostop script, and find lines the aws version of the script on the repo has these lines, and on the repo, expected behavior the autostop script in the bucket should be the one used for swb instances. screenshots versions swb",
          "Title: callback prints errors when training run resumes not from scratch; Content:it prints",
          "Title: plugin only compatible with Content: alway throws exception since package has been moved or refactored",
          "Title: led model returns algorithmerror when using smp training; Content: system info who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction create huggingface estimator seq seqtrainingarguments error get: file line in raise file line in output file line in forward return file line in raise file line in output file line in forward bsz, :valueerror: not enough values to unpack primary job terminated normally, but process returned non zero exit code. per user direction, the job has been aborted. detected that one or more processes exited with non zero status, thus causing the job to be terminated. the first process to do so was: process name: exit code: expected behavior",
          "Title: broken link in aml doc to Content: document details do not edit this section. it is required for github issue id: da version independent id: cc faa ee cf fb content: content source: service: machine learning sub service: core github login: microsoft alias: debfro",
          "Title: helm fetch command for ai engine,sdk helper and includes the release instead of Content: version which installation method does this occur on? describe the bug. ai engine fetch command at the guide: helm fetch username '$oauthtoken' password untar helm fetch username '$oauthtoken' password untar helm fetch username '$oauthtoken' password untar minimum reproducible example relevant log output full env printout other code of conduct agree to follow morpheus' code of conduct have searched the and have found no duplicates for this bug report",
          "Title: eval crashes int not json serializable Content:the evaluation is crashing. after investigation, the bug was introduced by the bug: to reproduce: posted by in",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          7.942196369171143,
          7.681750774383545,
          9.294102668762207,
          6.928512096405029,
          7.288203716278076,
          5.567336082458496,
          7.990054607391357,
          9.210737228393555,
          7.287456035614014,
          7.270445346832275,
          4.983482837677002,
          7.657840251922607,
          7.569004058837891,
          8.53514289855957,
          8.21358585357666,
          7.938666820526123,
          7.91452169418335,
          6.727005958557129,
          9.56464958190918,
          7.75756311416626,
          5.729647636413574,
          5.469388484954834,
          7.291597366333008,
          5.57317590713501,
          7.545417785644531,
          7.923773288726807,
          6.787093639373779,
          6.012082576751709,
          5.633234024047852,
          7.194360256195068,
          8.060483932495117,
          7.087023735046387,
          8.568175315856934,
          5.543116569519043,
          7.102333068847656,
          9.268267631530762,
          7.299769401550293,
          7.8918890953063965,
          7.644892692565918,
          7.7987236976623535,
          8.529659271240234,
          6.587852954864502,
          6.416944980621338,
          8.096580505371094,
          9.245052337646484,
          5.861381530761719,
          7.3433966636657715,
          9.661020278930664,
          6.3240580558776855,
          7.1602911949157715,
          7.01987361907959,
          7.7058610916137695,
          8.502408027648926,
          7.580818176269531,
          7.988977909088135,
          5.52485466003418,
          9.288575172424316,
          7.580653667449951,
          6.567886829376221,
          7.676959037780762,
          5.725298881530762,
          7.751484394073486,
          6.24945592880249,
          6.729598522186279,
          5.360464096069336,
          8.821052551269531,
          8.555346488952637,
          7.992198467254639,
          9.249184608459473,
          6.758148670196533,
          8.667015075683594,
          7.426324367523193
         ],
         "y": [
          0.26761525869369507,
          2.8202919960021973,
          1.8284817934036255,
          0.8748565316200256,
          1.9749460220336914,
          1.8198364973068237,
          3.6311147212982178,
          1.6839288473129272,
          0.5399115085601807,
          2.339090585708618,
          2.504596710205078,
          4.727482795715332,
          0.1343279480934143,
          4.274812698364258,
          4.5518083572387695,
          3.53604793548584,
          2.4552528858184814,
          2.702040672302246,
          0.17280781269073486,
          1.4671756029129028,
          2.3838324546813965,
          2.2355196475982666,
          3.5763301849365234,
          3.3827662467956543,
          2.649005651473999,
          2.0970590114593506,
          1.9336920976638794,
          2.7319514751434326,
          3.8252530097961426,
          1.2349070310592651,
          1.0654592514038086,
          1.480370283126831,
          4.265182018280029,
          3.7669973373413086,
          3.0894293785095215,
          2.94291615486145,
          1.8815381526947021,
          1.9574395418167114,
          -0.01724938116967678,
          4.756913661956787,
          4.266801834106445,
          3.6600868701934814,
          1.7181429862976074,
          3.5469472408294678,
          2.1721954345703125,
          2.8542673587799072,
          1.6384004354476929,
          -0.044723909348249435,
          1.3484162092208862,
          3.1564488410949707,
          4.162866592407227,
          2.123441219329834,
          0.8239114880561829,
          3.7474422454833984,
          0.2870938777923584,
          3.8687920570373535,
          2.9340860843658447,
          3.915639877319336,
          2.1332836151123047,
          -0.024642523378133774,
          3.8180713653564453,
          1.718570590019226,
          1.4518942832946777,
          2.415057897567749,
          3.860232353210449,
          0.7723715901374817,
          4.270279407501221,
          0.3323282301425934,
          2.960157871246338,
          2.3583672046661377,
          0.6024176478385925,
          2.3717517852783203
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: raise errors with long parameters and Content: raises error if length of key exceeds if the length of gbdt parameters or is long, will raise an exception. possible option: catch and ignore all errors from truncate logging parameters automatically",
          "Title: richprogressbar doesn't display progress bar when using Content: bug richprogressbar doesn't display progress bar when using logger. verified it works correctly with tensorboard and to reproduce environment pytorch lightning version pytorch version python version os ubuntu cc",
          "Title: test metrics are no longer pushed to Content: bug pytorch lightning used to publish test metrics to commit has broken this functionality. to reproduce steps to reproduce the behavior: run fast run of training and observe test metrics not being submitted to environment cc",
          "Title: logger cannot be pickled after creating an experiment; Content: bug the logger cannot be pickled after an experiment has been created. to reproduce steps to reproduce the behavior: initialize the logger object initialize trainer object with the logger access the attribute which creates the offlineexperiment object expected behavior we should be able to pickle loggers for distributed training. environment cuda: gpu: available: false version: none packages: numpy: false pytorch lightning: tensorboard: tqdm: system: os: darwin architecture: bit processor: python: version: darwin kernel version thu jan pst",
          "Title: using without an writer configured appears to fail silently; Content: summary profiling with and without an writer fails silently. steps to reproduce it use with session and no files are written. example there are examples of how to configure writer config here: whylogs should mention the missing writer in warning. maybe we can automatically add the writer so that it works and draws attention to where the behavior can be modified. what is the current bug behavior? logging with and default configuration appears to fail silently. what is the expected correct behavior? integration should write to by default and warn if missing or inconsistent config is set.",
          "Title: only logs top val loss; Content:",
          "Title: upgrading from to causes the pytorch logger to produce multiple Content: bug when running ddp multi gpu experiment on slurm cluster, but not creates multiple experiments, one for each gpu. only one of them logs any metrics, the others just sit. here is an experiment from the 'main' gpu, the one that actually logs the metrics. here is the same run, gpu that just announces itself and does not log anything else: please reproduce using the boringmodel to reproduce do not know how to make reproducible example, since you cannot do multi gpu ddp in colab and would need authentication, which cannot paste here. expected behavior single experiment for single call to this was the behavior in lightning environment note are solved faster should be made please, use our python template. please copy and paste the output from our you can get the script and run it with: pytorch version os linux how you installed pytorch pip build command you used python version: python cuda version: gpu models and configuration: geforce ti any other relevant information: slurm hpc cluster, single node. additional context problem appears after upgrading to from believe it is related to the thought behind this so post:",
          "Title: hydra clash; Content: bug when using the logger with hydra, because the parameters passed to the lightningmodule is the condition in the is not met. to reproduce use hydra and together. expected behavior check whether the instance if or in the given line.",
          "Title: fix logging of parameters on Content:logging of parameters on works as expected with default parameters set with hydra; however hydra allows modification of parameters per experiment run, but modified parameters are not logged on",
          "Title: logger overrides env variable; Content:after there is changed logger behavior. it starts using but it doesn't respect it if it is set already. so the bug is in the following. already set this variable then logger overwrites my value here then it deletes this variable at all here this way it ignores my variable and deletes it at all later moreover in version function it also ignores my set variable will create pull request to fix it",
          "Title: logger complains about missing Content: bug when using logger, in in fit results in train train or test results return results in results else: results return results in train run train epoch if and when returning from we end epoch early in optimizer, in backward lightning module hook result hiddens) if result is none: in with args hiddens) in output else: output return output in step batch args batch output return output in for key, val in return typeerror: function code sample environment",
          "Title: logger fail when logging long parameters; Content: bug please reproduce using the boringmodel to reproduce log anything parameters longer than characters expected behavior logger not sending parameters longer than characters to and log warning to user environment pytorch version os how you installed pytorch pip build command you used python version: cuda version: gpu models and configuration: any other relevant information: additional context only allow paramters to be at most bytes their limit in database is characters:",
          "Title: logger can modify logged metrics in place Content:when is called with may be modified in place. this can lead to confusing errors. if the user does then will have all the tensors moved to the cpu and their gradients detached, leading to an error like when backprop is attempted. none of the other loggers change in place when is called. all of them except say that they just accept though some others have code to handle or other types as well. the uses the following for handling tensors: the similarly has in the the current tensor conversion code is but then the entire dictionary is copied later in the function anyway, so it doesn't really make sense to do in place modification then copy everything. i'm happy to submit pr to fix this so that the doesn't modify the original dictionary. just wanted to ask for couple of opinions before changing things: should keep the current tensor conversion behavior for .detach or switch to using my preference would be the latter, though this does change the behavior should update the other loggers to all accept and have them all use the same method to convert to don't know the other loggers, so i'm not sure if tensors are actually not supported or if the type annotation isn't precise and the conversion is happening in third party code vs sort of has support for tensors with element, so using the first method will make logging such tensors valid while the second method would throw an error. however, don't think anybody would be using this behavior on purpose. if you do you get the metric itself doesn't even appear in the web interface for ml, so assume you can only access it if you query for it directly through their api.",
          "Title: does not update its status when failed; Content: bug when an error is raised during training with status of object should be updated to be 'failed', while it remains 'running'. due to the problem, when you look at tracking server screen, it seams as if training is still in progress even though it has been terminated with an error. to reproduce expected behavior status of each 's run is correctly updated when failed. environment pytorch lightning version: version: additional context",
          "Title: pickle error from when using logger and distributed data parallel without slurm; Content: bug fails with pickle error when the logger is logger, and 'ddp' on gpus but without slurm. to reproduce steps to reproduce the behavior: instantiate logger in pytorch with pytorch and the execution environment has environment variables and also and to connect to the tracking server with http basic authentication. the tracking server is also instantiate trainer with logger instance as logger, 'ddp' and with the gpus parameter on machine with nvidia gpus but without slurm. run from the error output, it looks like multiprocessing is attempting to pickle the nested function in function code sample sample code tested with very simple test model ): expected behavior runs without error. environment",
          "Title: training extremely slow with Content: environment nni version: nni mode remote client os: windows server os linux python version: pytorch version: is conda used?: conda is running in docker?: no log message info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info dispatcher started info took seconds info tpe using trials info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss info took seconds info tpe using trials with best loss nnictl stdout and stderr: experiment start time experiment start time maxlistenersexceededwarning: possible eventemitter memory leak detected. message listeners added. use to increase limit maxlistenersexceededwarning: possible eventemitter memory leak detected. error listeners added. use to increase limit maxlistenersexceededwarning: possible eventemitter memory leak detected. close listeners added. use to increase limit what issue meet, what's expected? the example training with azure ml is unreasonably slow, each trial take about to mins. the entire experiment took nearly mins. was expecting it to be much faster given that it's using with gpu nvidia tesla how to reproduce it? follow this doc additional information tried adding gpunum: and useactivegpu: true in config file, only made it even slower with trials spending more time in waiting status, also instead of doing all trials in run, each trial take run.",
          "Title: training loss not reported until end of run; Content:i think i'm logging correctly, this is my result loss) return result and result loss) return result the validation loss is updated in each epoch, however the training loss isn't displayed until training has finished. then it's available for every step. this may be rather than pytorch lighting issue somewhere along the line it seems to be buffered? versions: edit: logging trainresult with true results in the metric appearing in during training, it's only the default train logging which gets delayed. acc, true) is fine",
          "Title: logger failing without Content: bug mllogger with api key and without save dir results in error. this happens due to this if dir is not set and later train loop tries to read it and fails. this can be fixed by setting dir to none. will supply pr in moment to reproduce steps to reproduce the behavior: traceback file line in result fn file line in fit results file line in train results file line in file line in train file line in file line in return fn file line in or file line in return additional context",
          "Title: logging always disabled for training models; Content: describe the bug when training reader model, user might want to log training statistics and metrics to however, when initializing we initialize an there, we call on which disables all logging to therefore, when user is calling the reader's method after initializing the reader, no tranining statistics wil be logged. as workaround, the user can manually set before calling the method.",
          "Title: log only run when using ddp and multirun; Content:when use ddp, and multirun in like this does not record runs, but only one run.",
          "Title: logging: auxiliary values are not logged; Content:none",
          "Title: improve logging for population; Content:separate each individuals performance into its own graph. graphs for each individual sub runs on",
          "Title: pytorch container stderr output; Content:in pytorch images all the prints in stderr are not catched and are ignored: describe the problem minimal repro logs logs creating tmpqp gd attaching to tmpqp gd mdone algo gd containers info imported framework algo gd containers info no gpus detected algo gd info block until all host dns lookups succeed. algo gd info invoking user training script. algo gd containers info module entrypoint does not provide algo gd generating algo gd containers info generating algo gd containers info generating algo gd containers info installing module with the following command: algo gd pip install algo gd processing algo gd building wheels for collected packages: entrypoint algo gd running for entrypoint done algo gd stored in directory: algo gd successfully built entrypoint algo gd installing collected packages: entrypoint algo gd successfully installed algo gd you are using pip version however version is available. algo gd you should consider upgrading via the 'pip install upgrade pip' command. algo gd containers info no gpus detected algo gd containers info invoking user script algo gd algo gd training env: algo gd algo gd algo gd algo gd algo gd algo gd algo gd hosts algo gd hyperparameters algo gd algo gd algo gd }, algo gd algo gd true, algo gd pytorch algo gd algo gd algo gd algo gd algo gd algo gd entrypoint algo gd eth algo gd algo gd algo gd algo gd algo gd algo gd algo gd algo gd algo gd algo gd environment variables: algo gd algo gd algo gd name eth algo gd algo gd algo gd algo gd algo gd config algo gd dir algo gd algo gd algo gd algo gd entrypoint algo gd algo gd algo gd algo gd dir algo gd algo gd algo gd algo gd algo gd algo gd algo gd algo gd dir algo gd algo gd algo gd algo gd invoking script with the following command: algo gd algo gd entrypoint algo gd algo gd algo gd coucou stdout containers info reporting training success tmpqp gd exited with code aborting on container job complete as you see the coucou stdout has been printed, stderr has been ignored. in distant mode same result.",
          "Title: logger; Content:none",
          "Title: use tensorboard as default logger and get optional within the project Content:none",
          "Title: question: how to save hydra config to Content:hello, i'm using logger found recently config no longer save to file. before: now: this may related to: any idea how to restore to previous state?",
          "Title: fix writing of checkpoints to Content: what clear and concise description of what the bug is. how to reproduce reproduce by starting non dry run via notebook start the run look at files on the interface. there are no checkpoints expected checkpoints should be uploaded to whenever there is better one available during training. additional context thought fixed but it seems that don't understand the symlinking model of apparently you need to have checkpoints under the project root? but this would mean that you can't run multiple experiements at the same time.",
          "Title: logging issue in of Content: logging issue in of check localhost: all the runs fail in parameters are logged but metrics and artifacts didn't. cannot reproduce this with it means works just fine!",
          "Title: permission denied when log models to on mac; Content: environment: macos",
          "Title: local logging is borked; Content:our current logging assumes the presence of an api key, which you don't need if you're running locally. we should configure it so it works with locally, too.",
          "Title: warning when training pytorch Content: printed after every epoch!",
          "Title: logger not working; Content:hi there, thank you for this powerful template! run into problem while trying to use as logger used the callbacks branch and after get logger:",
          "Title: error running on ddp with logger; Content:i have the following problem running on ddp mode with logger. when detach the logger from the trainer the code runs.",
          "Title: run context is not logged when using logger; Content: bug when we use the basic logging via context manager, we get better supplementary info about the run rendered in the tracking ui but when we use as logger in this info is not logged. as user, i'd like to have mirrored functionality out of the box. inspected the method of and deduced that the only thing is left while creating the run via client is to add from the package: think it's better idea to add those tags internally as first it's as seamless as in the default api, secondly it's the that manages the 's run anyways. pr is following",
          "Title: weird memory problem with sweeps colab Content: i'm running into this issue with specific model if runs truly aren't cleared then sweeps could be corrupting subsequent runs. this behavior hasn't been observed previously however.",
          "Title: logger does not work unless pytorch is installed Content: bug report logger throws error while import if etna is not installed. expected behavior logger should work no matter pytorch installation how to reproduce create new env install etna and etna import logger environment additional context checklist bug appears at the latest library version",
          "Title: the learning rate plot in is not the expected one; Content:hi! i've been trying the integration and must say this has been great addition to the framework. wanted to exploit it to keep track of the learning rate updates, but the lr being plot is not the one that expected, especially when trying the epochs option, which set to as suggested. the learning rate that is plot on is the one set in and it's constant for the first epochs. could this be related to this error? to reproduce setup set epochs option to expected behavior expected to see the lr increase in the first epochs, reach the lr set in and eventually decrease, as set also actual behavior the lr is equal to the set in the first epochs, and eventually decreases due to",
          "Title: checkpoints in the wrong location Content:i'm not sure if i'm doing something wrong, i'm using instead of tensorboard as logger. i've used the defaults i'm ending up with the following folder structure the checkpoints are in the wrong location, they should be in the folder. perhaps this is an rather than pytorch lightning issue? i'm using pytorch lightning on macos running in python",
          "Title: dumps computation at the start of validation loop when using logger during multi core tpu training; Content: bug am training resnet model on multi core tpus on kaggle. get this error: this text goes on and on for several pages. the first epoch runs fine at first and just as the validation loop starts, the training crashes and this text is printed as output. note that this only happens when using logger and everything works fine when do or normal as evident in this have also tried adding very small batch sizes so this probably isn't memory issue to reproduce see this that uses and with expected behavior training should run normally with no issues and logging should work. environment cuda: gpu: available: false version: none packages: numpy: false pytorch lightning: tqdm: pytorch xla system: os: linux architecture: bit processor: python: additional context none cc",
          "Title: logging issue when activating contrib; Content: describe the bug when activating the contrib, most of ludwig log message disappears. to reproduce steps to reproduce the behavior: launch: you won't see the following output: expected behavior the log messages should be displayed when the contrib is activated. environment os: fedora version python version: ludwig version: additional context think the issue is that ludwig is using the root level logger configured through the contrib integration contains some logging calls, for example, those calls happen before any call the issue with calling the root level and so on is that they will call on their own if the root logger is not configured yet the direct effect is that the first call to will configure the root logger with no configuration which will create streamhandler pointing to the unfortunate side effect is that calling will do nothing as the root handler as already handler so the root logger will not be set to the right log level and the stream handler will not point to the right device. would recommend moving from using the root logger and configure the logger through to using logger and configure it manually, it's not that more complex. can help if wanted. one last issue with using the root logger is when configuring the root logger to the debug level, all libraries which are logging will start displaying their log messages. that includes requests and is polluting the output. using separate logger would also solve this issue.",
          "Title: unable to create logger when using pytorch lightning Content: bug unable to create logger when using pytorch lightning cli. to reproduce expected behavior run model. environment cuda: gpu: tesla available: true version: packages: numpy: false pytorch lightning: tqdm: system: os: linux architecture: bit processor: python: version: smp tue dec pst additional context error message: for some reason, there has cc io kaczmarek",
          "Title: show lightgbm logs in the logs in Content:current execution lets lightgbm handle its own logs, they are likely printed in stdout, but don't show up in",
          "Title: logging does not differentiate between modes; Content:logging using does not differentiate between training and testing modes in",
          "Title: logger throws jsondecodeerror; Content: bug to reproduce steps to reproduce the behavior: code sample throws exception. expected behavior environment environment details pytorch version pytorch lightning version: os linux how you installed pytorch conda build command you used python version: cuda version: not relevant gpu models and configuration: not relevant any other relevant information: not relevant additional context",
          "Title: test set metrics overwrite validation set metrics in tensorboard and are rejected for logging by Content: describe the bug at model train completion, the test set loss is written as iteration to the tensorboard w&b chart and the test set perplexity is written as iteration to the chart as the validation loss and perplexity has already been written to this chart, this results in tensorboard deleting all the validation metrics, overwriting them with the test loss and perplexity values. w&b refuses to add the test metrics to the charts at all, throwing warning that looks like to reproduce steps to reproduce the behavior: pip install and setup tensorboard and w&b begin training model with train, validation, and test set observe in both tensorboard and w&b that validation metrics are being logged allow the model to train to completion observe that the tensorboard validation metrics are now gone, overwritten by the test set metrics observe the w&b error in the text logs program output expected behavior test metrics should be written to their own charts. proposed solution test loss and perplexity should be written to their own charts and respectively. screenshots environment gpus: gb configs: additional context have bug fix ready, will follow up with it.",
          "Title: config type in logger; Content:this is more like suggestion than bug. the parameter to the logger is supposed to be of type therefore it converts it to dictionary inside its function using this might be restrictive in some cases if someone wants to pass configs directly as dictionary wouldn't it be better to do the conversion outside the logger to make it more general in terms of config input? thanks :)",
          "Title: logger makes new run when resuming from hpc checkpoint; Content: bug currently the creates new run when resuming from an hpc checkpoint, after preemption by slurm and requeuing. runs are an concept that groups things in their ui, so when resuming after requeue, it should really be reusing the run id. think this can be patched into the hpc checkpoint using the logger which believe exposes the run id. this can also be seen on the on the progress bar which changes after preemption i'm happy to attempt to pr this if the owners agree that it's bug. to reproduce use on slurm cluster and watch the ui when preemption happens, there will be new run created. expected behavior runs are grouped neatly on the ui environment cuda: gpu: available: false version: packages: numpy: false pytorch lightning: tqdm: system: os: linux architecture: bit elf processor: python: version: smp thu jan est cc",
          "Title: memory utilization metrics are not correctly visible in Content:run in experiment master in radiomicsnn: only metrics for out of the gpus are visible the memallocated and memreserved metrics are all zero and hence meaningless.",
          "Title: using with logger causes an Content: bug using with logger causes an error. it appears the name of the metric is not supported by exception: invalid metric name: '. names may only contain alphanumerics, underscores dashes periods spaces and slashes to reproduce reproduced the bug with the boringmodel, in the link bellow: expected behavior should log gpu memory correctly when using an logger. environment colab environment: cuda: gpu: tesla available: true version: packages: numpy: false pytorch lightning: tqdm: system: os: linux architecture: bit processor: python: version: smp thu jul pdt",
          "Title: when pretrained model is not found, falls into an infinite silent loop; Content:i mistakenly put my model in pretrained folder but outside the model subfolder. in such case an exception is caught silently and then sleep is called only to retry the exact behaviour. while did not fix the issue, added logging to make it verbose. will try to upload patch.",
          "Title: logger slows training steps dramatically, despite only setting metrics to be logged on epoch; Content: bug when using the logger, with remote server, logging per step introduces latency which slows the training loop. have tried to configure logging of metrics only per epoch, however it seems this still results in much slower performance. suspect the logger is still communicating with the server on each training step. to reproduce start an server locally run the minimal code example below as is, uncomment out the to use the local server and run the code again. you will see times drop in the iterations per second. code sample expected behavior when using the trainresult and evalresult, or manually handling metric logging using the and callbacks. it should be possible to avoid the logger from communicating with the server in each training loop. this would make it feasible to implement the when remote server is used for experiment tracking. environment additional context we host instance in aws and would like to be able to track experiments without affecting the training speed. it appears that in general the logger is much less performant than the default tensorboard logger, but this would not be much of problem if we could avoid calls to the logger during the training loop. solution i've done bit of debugging in the codebase and have been able to isolate the cause in two places here is called regardless of whether exists. if we add an here we avoid calling on each step. however we still call it each time we log metrics to mflow, because of the property here if we store within the logger and only call when it does not exist, we eliminate all overhead, it runs as fast as fast as the tensorboard logger and all the logging appears to be working as expected. i'd be happy to raise pr for this fix.",
          "Title: logger does not implement name class methods; Content:explicitly creating logger instance and passing it to trainer using trainer raises notimplementederror because logger does not implement the name class methods. below is the traceback:",
          "Title: attributeerror: module 'live' has no attribute 'log'; Content:i try to follow this checkpoints tutorial and documentation page however, after adding in the file with this code: import the live package with the other imports: got an error: only could run the example with the following trick: are there any updated in api? system info fiy",
          "Title: unexpected argument error; Content: bug the mentions there is an argument called for the logger, where the of given experiment can be provided. although, is an unknown argument to the logger please reproduce using the boringmodel colab link: to reproduce environment colab",
          "Title: test metrics not logging to after training; Content: bug when testing model with metrics are not logged to if the model was previously trained using while training metrics are logged correctly. code sample expected behavior test metrics should also be logged in to environment additional context believe the issue is caused because at the is called. this in turn calls inside the logger and the object doesn't expect to send more information after this. an alternative is to create another object, with another logger but this means that the metrics will be logged into different experiment from the original. this issue can be solved using the object form the sdk, but the solution seems little hacky and the currently doesn't support this kind of experiment.",
          "Title: in random agent script full episode data logging skips few steps; Content: problem in random agent script full episode data logging skips few steps. this is because counts the epsiode reward logging steps made prior to the full data logging. potential solution add another metric to log that shows timestep and day",
          "Title: fails to log to tracking server; Content: system info python packaged by conda forge who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction install configure vanilla training job to use tracking server run the job you should see an error similar to: training script: expected behavior would expect logging to work :)",
          "Title: inconsistency in within steps; Content: inconsistency in within steps the for logger states that it has method which signature is as follows: where metrics dictionary with metric names as keys and measured quantities as values and step step number at which the metrics should be recorded. when within training method of lightningmodule: setting results in the fit method raising setting results in the fit method raising setting results in the fit method raising found the behavior from the last two options by luck because of typo. the logger would expect despite the documentation saying the method is called even if use the method expects parameters other than the dict stated in the documentation. to reproduce this is the minimum code found that reproduces the bug: expected behavior the code should work with the signature from the documentation. environment cuda: gpu: available: false version: none packages: numpy: false pytorch lightning: tqdm: system: os: linux architecture: bit elf processor: python: version: ubuntu smp sat may utc",
          "Title: bug when running train long; Content:when running this code from colab notebook views the entire thing as one training session and continue gradient steps indefinitely. training session should be forced to end when that model stops training not when the meta training loop finishes. should only be training steps not",
          "Title: logger: connection remotedisconnected error; Content: describe the bug try to do multi label classification with it worked at first. however when it came to it stopped and report: have checked that the internet connection was ok. so was confused why this error occured error message error that was thrown expected behavior clear and concise description of what you expected to happen. additional context add any other context about the problem here, like type of downstream task, part of to reproduce steps to reproduce the behavior system: os: gpu farm version:",
          "Title: logger doesn't seem to log with Content: bug please reproduce using the boringmodel to reproduce use following and post here expected behavior environment note are solved faster should be made please, use our python template. please copy and paste the output from our you can get the script and run it with: pytorch version os how you installed pytorch build command you used python version: cuda version: gpu models and configuration: any other relevant information: additional context cc",
          "Title: external logging failures cause training job to fail; Content: bug am using during training, with the tracking uri hosted in databricks. when databricks updates, we sometimes lose access to for brief period. when this happens, logging to fails with the following error: not only does logging fail, but with pytorch lightning, an error logging means the entire training pipeline will also fail, losing progress on potentially long running job with limited error handling options currently available. ideally, there would be flexibility in pytorch lightning to allow users to handle logging errors such that it will not always kill the training job. please reproduce using the boringmodel to reproduce attempt to use logger that fails to log. the training job will fail, losing all progress. expected behavior there is an option to handle exceptions from the logger such that the job does not automatically die if logging parameter fails. environment cuda: gpu: tesla available: true version: packages: numpy: false pytorch lightning: tqdm: system: os: linux architecture: bit processor: python: version: smp thu jul pdt additional context",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_pytorch_loss_training",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_pytorch_loss_training"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.090116500854492,
          9.09108829498291,
          9.157243728637695,
          8.778294563293457,
          9.770486831665039,
          10.065126419067383,
          8.669581413269043,
          10.004267692565918,
          10.099105834960938,
          9.827778816223145,
          9.517012596130371,
          9.047045707702637,
          9.557557106018066,
          8.969924926757812,
          8.689881324768066,
          8.63377857208252,
          9.080217361450195,
          9.502058029174805,
          9.347502708435059,
          10.088566780090332,
          10.003378868103027,
          10.060952186584473,
          8.711870193481445,
          10.04989242553711,
          9.715949058532715,
          10.044384002685547,
          8.239336013793945,
          9.722967147827148,
          9.843839645385742,
          9.826115608215332,
          8.594590187072754,
          9.817800521850586,
          8.789299964904785,
          9.746999740600586,
          8.587848663330078,
          8.96761417388916,
          8.686713218688965,
          8.371885299682617,
          8.799062728881836,
          9.678318977355957,
          8.940452575683594,
          9.951340675354004,
          10.124011039733887,
          8.933760643005371,
          9.066622734069824,
          9.722464561462402,
          8.60570240020752,
          9.051098823547363,
          9.11955738067627,
          8.598548889160156,
          9.252300262451172,
          9.009922981262207,
          8.294921875,
          8.956681251525879,
          9.357348442077637,
          9.650514602661133,
          9.048583030700684,
          9.413395881652832,
          8.59272575378418,
          8.709016799926758,
          9.06734848022461,
          9.115920066833496,
          9.255284309387207
         ],
         "y": [
          -0.8069677352905273,
          -1.0557031631469727,
          -0.273608535528183,
          -0.8861651420593262,
          -0.526190459728241,
          -0.7030671238899231,
          -0.9463751316070557,
          -1.1064682006835938,
          -1.1247090101242065,
          -1.2462767362594604,
          -0.9838855862617493,
          -0.992623507976532,
          -0.7380473017692566,
          0.024750087410211563,
          -0.8860394358634949,
          -0.2830826938152313,
          -0.27696144580841064,
          -1.0008301734924316,
          -0.5257484912872314,
          -0.5662033557891846,
          -0.8056896328926086,
          -0.5273938775062561,
          -0.9850285649299622,
          -0.7805227041244507,
          -0.9509103894233704,
          -1.0926984548568726,
          -0.9943629503250122,
          -0.46603766083717346,
          -0.8640283942222595,
          -0.8520913124084473,
          -0.33466196060180664,
          -0.9682190418243408,
          -0.8312689065933228,
          -0.645054042339325,
          -0.3143768012523651,
          -1.1532089710235596,
          -0.28068798780441284,
          -1.0628938674926758,
          -0.5906931161880493,
          -1.1376780271530151,
          -1.1203703880310059,
          -0.7567470669746399,
          -0.3953605890274048,
          -1.1240874528884888,
          -0.20170211791992188,
          -1.1286022663116455,
          -0.726195752620697,
          -0.5128024220466614,
          -0.904840886592865,
          0.5366219878196716,
          -0.5940434336662292,
          -1.1068741083145142,
          -1.0494616031646729,
          -0.812770426273346,
          -0.41832998394966125,
          -0.41552290320396423,
          -1.3051141500473022,
          -0.7504417896270752,
          -0.2779332101345062,
          -0.37432247400283813,
          -0.9951155185699463,
          -1.0077359676361084,
          -0.7416687607765198
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: xdeepfm error in test; Content: description in which platform does it happen? how do we replicate the issue? see expected behavior other comments",
          "Title: post gen hook shouldn't configure remote if no name is provided; Content:if the remote name is left blank, the post gen hook shouldn't try to set one. currently this raises error.",
          "Title: data loading bug with Content: function from hugging face can't access the tracked data directory oserror: read only file system:",
          "Title: remove contrib from Content: description the product team mentioned that contrib package is not recomended for production, we need to remove contrib from here and check that all the tests pass in which platform does it happen? dsvm, db expected behavior everything runs other comments question to are we using contrib anywhere",
          "Title: error: is Content: in causes exceptions at running benchmark. delete this line solves this problem. and because of maybe we need some better ways to deal with",
          "Title: does not add params to Content:when only without is used in node the will not depend on the",
          "Title: resolve bad request with minio;",
          "Title: requirements: update Content:after we do not allow ignoring lockfile. is running currently on some older version of though it would be good to adjust it so that it works with",
          "Title: example get started is broken with latest Content:> from",
          "Title: minimal launcher link points to full launcher; Content: describe the bug guide's quicklaunch link points to the full launcher expected behavior should point to the minimal launcher",
          "Title: issue with branch; Content:if in setup set true then it is giving error in as for plot in typeerror: 'bool' object is not iterable",
          "Title: znnodes not working with Content: fix docstring test with node that has and",
          "Title: api fails with Content: if you run in python you get an output that looks like this: file line in trial file line in elif and not in result: typeerror: unhashable type: 'list' ray reproduction in python run the sections that are commented out.",
          "Title: plots are not saving through Content:this is the error get () got an unexpected keyword argument 'system'",
          "Title: provide guidance on how to obtain subscription id in notebook; Content: description users need to modify the third code cell to specific subscription id and the names that will be used for creating resource group, workspace, etc. some guidance within the notebook on how to obtain these values and fill in the strings would be helpful. it would also be nice to throw an error in this code cell if users forget to fill in the values, so that users don't encounter cryptic error from the call to later on. expected behavior with the suggested feature users who forget to fill in the string values in this code cell are alerted to the issue by an error message from this code cell. novice users receive some guidance on how to obtain their azure subscription id without having to reference other notebooks. other comments",
          "Title: and checks inconsistent in linter; Content: describe the bug those two linting functions caused the template create wfs to fail expected behavior they should pass. we should discuss why they fail and how to fix! so currently they are outcommented!",
          "Title: error in some of the tests; Content: description there are some errors: in which platform does it happen? how do we replicate the issue? expected behavior other comments",
          "Title: ml notebooks have incorrect genre stated in the text; Content:for the notebooks for ml the text in the notebook incorrectly specifies that the genre returned for node classification task on is when it should be",
          "Title: unhandled training job status 'stopped' causing infinite loop; Content: what steps did you take code gets stuck in infinite loop is training job gets stopped what happened: above code only caters for training job status or so if the training job status is marked as it causes an infinite loop in below code what did you expect to happen: training job status to be catered for environment: anything else you would like to add: labels impacted by this bug? give it we prioritise the issues with the most",
          "Title: widget error in Content: describe the bug starting in version the widget is having an issue where the json values being passed in are getting the following error to reproduce steps to reproduce the behavior: run through the introduction to node classification gremlin notebook when you get to the export step the error occurs additional context this is not problem in version",
          "Title: may need to be updated Content: description the current version of is little dated",
          "Title: not compatible with Content:when run workflow: work fine,but failed when with think the new mflow feature cause this limit param valu lengh to ,by read code ,it can not be overwrite. maybe relate with this",
          "Title: missing params field for evaluate stage in Content:none",
          "Title: not working fine with nested directories;",
          "Title: ml export widget throwing error; Content: describe the bug when using the ml widget to export data like the command below from the node classification notebook: the following error is thrown expected behavior the export should run to completion",
          "Title: value doesn't update; lr value list",
          "Title: on param value had length which exceeded length limit of Content: bug description when do the example: qrun qrun got the error info: info client. info experiment manager uri is at info qlib successfully initialized based on client settings. info info info experiment starts running info recorder bad starts running under experiment 'git' info fail to log the uncommitted code of $cwd when run 'git' info fail to log the uncommitted code of $cwd when run 'git' info fail to log the uncommitted code of $cwd when run exception in thread thread traceback file line in param) file line in file line in param file line in raise exception file line in inner file line in run file line in run data file line in key, value) file line in raise exception param value info gats pytorch info gats parameters setting: dropout lr metric loss optimizer adam mse lstm none true seed none info model: gatmodel lstm linear linear linear softmax then the program re run again. am wondering how to fix it. thanks lot. to reproduce steps to reproduce the behavior: expected behavior screenshot environment note user could run under project directory to get system information and paste them here directly. qlib version: python version: os windows commit number additional notes",
          "Title: refused to frame because an ancestor violates the following content security policy directive: frame ancestors Content: bug refused to frame because an ancestor violates the following content security policy directive: frame ancestors 'self' to reproduce code sample expected behavior environment additional context",
          "Title: add dependencies; Content: what is the current behavior? how can we reproduce it? the file does not have the entire dependency tree defined possible fixes modify the file so that it has the complete tree of dependencies and their respective versions steps make sure that the has been followed.",
          "Title: limit issue Content:hi as per the below code it is allowing only default limit as and the limit is not working and throwing error for introduction to node classification gremlin %%gremlin 'toy story error can some one suggest is there something wrong with the code which was mentioned in the document",
          "Title: fix import issue; Content:",
          "Title: combine and might not work; Content:none",
          "Title: fails; Content:seems that the is failing. perhaps there is some type as it seems to be missing the object.",
          "Title: leaking dependency; Content:",
          "Title: cannot run benchmark for Content:when tried to run benchmark on with anubis, it showed processing benchmark submission request and then cannot execute the requested benchmark. also tried to run the sample for and it showed with the same error btw, when we wanna run with besides specify and framework is there anything else we need to specify or change?",
          "Title: attributeerror: 'workspace' object has no attribute uri'; Content:i receive the following error when running the following",
          "Title: error loading Content:",
          "Title: need to rebuild get started with the latest version; Content:experience is broken since every command changes now makes it very annoying to jump between branches.",
          "Title: highlight incorrect field in screenshot of importing workspace; Content: describe the bug clear and concise description of what the bug is. should highlight field the field also is required. to reproduce steps to reproduce the behavior: go to click on scroll down to see error expected behavior clear and concise description of what you expected to happen. screenshots if applicable, add screenshots to help explain your problem. versions release version installed additional context add any other context about the problem here.",
          "Title: exception in backtest with when using Content: bug report program fails when backtest with is used inside with everything is fine. exception happens in while constructing it can't make exception was caught in but it looks like this bug also appears in class. expected behavior no error. how to reproduce run backtest with wandlogger while setting environment additional context checklist bug appears at the latest library version bug description added steps to reproduce added expected behavior added",
          "Title: probably broke deployment; Content:",
          "Title: how to make Content:has anyone figured out an easy way to make i've tried the following code without success: %pip install python dev %pip install graphviz %pip install libgraphviz dev %pip install pkg config %pip install pygraphviz thanks for the help!",
          "Title: dependencies; Content:hi, good day. could you add to the section?: from keep up the good work!",
          "Title: view and plots don't load in Content:update: summary in cloned setup the ide workspace so the extension is active. haven't run any experiments: check out the branch. the view and plots dashboard never load. the experiments table says no experiments to other components do load. virtual env is loaded via ms python extension. the same happens in the included project if set up the extension with in",
          "Title: sasrec integration test unusually long time on compute cluster; Content: description runtime of varies lot on the following platforms: as part of ado pipeline, it takes sec to complete. when run as an experiment on compute cluster triggered using it takes sec. we need to investigate why this happens. in which platform does it happen? both the machines are of same type and use the same cuda and cudnn versions: how do we replicate the issue? trigger the manually and take look at pytest logs in the dashboard to see the execution times. expected behavior other comments",
          "Title: pytorch lightning requires new version; Content:keep it in mind before mindlessly updating",
          "Title: defaults not described Content: we need details description of we need this when deployment. in training, we usually use in deployment, is necessary heard includes but it is not documented. document details do not edit this section. it is required for github issue id: db efb version independent id: ac cc cb content: content source: service: machine learning sub service: core github login: microsoft alias: harnvir",
          "Title: reproduce feature doesn't work; Content:it fails at the apply patch stage",
          "Title: various issues in Content:> these are reported by i'm moving here to discuss and follow: was running experiments by following the docs and encountered the following issues. sharing here for any required action. is not installed by so, if someone is trying to use new virtual env, they need to install separately. would be good to include in gave this error: lists all the image when running the stage. would be good to remove from section in the doc is little unclear. does replace if yes, can we state this clearly? also would be great to change this statement to",
          "Title: pipeline notebook test linux cpu failing; Content: description in which platform does it happen? how do we replicate the issue? expected behavior other comments",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_title_comments_node",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_title_comments_node"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.978104591369629,
          8.84548568725586,
          6.776408672332764,
          8.757319450378418,
          8.878447532653809,
          9.024218559265137,
          8.751351356506348,
          7.962531566619873,
          9.024239540100098,
          9.28996753692627,
          8.113870620727539,
          8.981581687927246,
          8.790019035339355,
          8.075610160827637,
          5.334109783172607,
          8.893270492553711,
          8.979063987731934,
          8.58765983581543,
          8.820172309875488,
          8.30627155303955,
          8.33981990814209,
          8.160104751586914,
          9.04856014251709,
          8.97032642364502,
          8.31749439239502,
          9.065448760986328,
          8.512266159057617,
          8.88366985321045,
          8.346343040466309,
          8.17587947845459,
          8.650548934936523,
          8.992063522338867,
          8.802909851074219,
          8.476088523864746,
          8.862667083740234,
          8.200200080871582,
          8.729153633117676,
          8.597305297851562,
          4.929193019866943,
          8.92605972290039,
          8.718348503112793,
          8.673182487487793,
          8.513284683227539,
          8.34677791595459,
          9.003210067749023,
          8.399356842041016,
          7.992093563079834,
          8.858238220214844,
          8.712372779846191,
          9.04926872253418,
          8.488438606262207
         ],
         "y": [
          2.459993600845337,
          3.6528892517089844,
          3.5211498737335205,
          2.8312017917633057,
          2.22293758392334,
          3.732969045639038,
          3.455685615539551,
          3.232069730758667,
          3.556320905685425,
          3.0211994647979736,
          2.1288387775421143,
          3.8243484497070312,
          3.4078047275543213,
          2.2894012928009033,
          3.3624918460845947,
          2.6406989097595215,
          2.4680984020233154,
          1.4871236085891724,
          1.4690111875534058,
          1.78461754322052,
          2.930999755859375,
          1.286077618598938,
          3.404604911804199,
          3.798849105834961,
          1.7140799760818481,
          3.6623096466064453,
          0.4196062684059143,
          3.0413177013397217,
          3.185231924057007,
          1.2650747299194336,
          3.158111333847046,
          3.8119187355041504,
          3.4255893230438232,
          3.191934823989868,
          2.2326979637145996,
          2.459108591079712,
          3.4175708293914795,
          3.000790596008301,
          4.360440731048584,
          2.4037132263183594,
          3.025272846221924,
          3.296755790710449,
          3.2542808055877686,
          4.384137153625488,
          2.207836627960205,
          2.899988889694214,
          2.784111499786377,
          2.6323654651641846,
          2.8936023712158203,
          2.2425129413604736,
          2.846794366836548
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: weird behavior with and confusion matrix; Content: describe the bug after running model evaluation suite and exprorint to using function, the confusion matrix appears in the w&b page without the values to reproduce steps to reproduce the behavior: expected behavior the confusion matrix in w&b should appear like the confusion matrix in the notebook which has it values shown environment os: linux python deepchecks",
          "Title: unable to open locfit package in Content:i have trained model locally using the package locfit. am now trying to run this in most guides questions appear to be in relation to although believe the process outlined in similar posts will be similar confirm upload is correct in the terminal then execute the following code: the following error message is then returned:",
          "Title: fix the definition of Content: bug description the pipeline is not correctly defined for this creates the following issues: the evaluation stage does not know how to pull the model the training stage does not know it has to run before the evaluation stage for the models and to reproduce this will give the error: after manually pulling this will give the error: expected behavior and should run without errors about missing files.",
          "Title: layoutlmv training on error: undefined value variadic; Content: system info who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction the error only comes when training on using huggingface. scripts to start training on folder organization: entrypoint scripts folder: expected behavior",
          "Title: input to the script for publishing models to is overly particular with inputs; Content: description when using the script, if the value given for the argument has trailing the script will bomb in interesting ways. triton information what version of triton are you using? are you using the triton container or did you build it yourself? container to reproduce this gives the following error: the model being used seems to have no effect on the error. expected behavior the input provided is syntactically identical to: and should provide the same outcome.",
          "Title: child models need to copy the files from the parent model when launching an experiment on Content:if parent model was trained with the alignment enhanced architecture and the dictionary on, preprocessing for the child model will look for the files from the parent model. those files are not currently being copied into the directory on the aqua server when the experiment is launched through so preprocessing fails on the child model. sample with this failure.",
          "Title: when using the name of the model saved in will be Content:when using the name of the model saved in will be dataparallel. expected behavior environment enchanter version: python version: os: ubuntu other libraries and their versions: error messages, stack traces, or logs steps to reproduce reproducible examples additional context",
          "Title: runtimeerror; Content:when training text classification models using xlnet large cased, albert base xlnet base cased and enabled:",
          "Title: wrong dataset file name; Content: tl;dr golden test dataset train/ validation training train wisdomify why? what? todos",
          "Title: double ensemble exception; Content:hi, so ran cn data on google colab. alstm worked fine but double ensemble keep giving issues, manage to solve some by cloning the repo and install via and uninstalling reinstalling numpy. but this one do not know how to solve: exception: got invalid value series for metric 'ic' please specify value as valid double if have only sh in my instruments, it's gonna produce the following value error: valueerror: bin edges must be unique: array you can drop duplicate edges by setting the 'duplicates' kwarg followed instructions on data collector's markdown page to download cn data up until my yaml file looks like this: region: cn market: &market benchmark: &benchmark sh instruments: strategy: class: topkdropoutstrategy kwargs: topk: backtest: verbose: true account: benchmark: benchmark close task: model: class: densemblemodel kwargs: gbm loss: mse true true alpha alpha decay: epochs: subsample: verbosity: dataset: class: dataseth kwargs: handler: class: alpha kwargs: segments: train: valid: test: record: class: signalrecord kwargs: class: siganarecord kwargs: false class: portanarecord kwargs: config: thanks for answering in advance.",
          "Title: pandas dataframes with array column values are not correctly persisted as datasets; Content:pandas dataframes with arrays as column values seem to be incorrectly persisted. an example:",
          "Title: check valid url when creating predictor; Content:at the moment, an byom predictor with arbitrary urls can be created. we should first check whether an actual model is served at that url before creating said model.",
          "Title: can not create model in catalog; Content:",
          "Title: typeerror: unsupported operand type for 'str' and 'str' when using artifactdataset with modelsaverdataset; Content: description occurs when is used with context logging locally and to in one step. steps to reproduce expected result the model should be saved locally and in run at the same time. actual result your environment include as many relevant details about the environment in which you experienced the bug: python macos catalina does the bug also happen with the last version on develop? yes.",
          "Title: pyfunc model can't be loaded; Content: describe the bug can't load model in the beta version of bentoml to reproduce train log pyfunc model to mflow load it into bentoml the model gets successfully stored in the local model store however the loading is failing to attributeerror expected behavior pyfunc model should load without issues screenshots environment: os: macos python version python bentoml version",
          "Title: run the example caused exception: invalid experiment id: Content: bug description when run the code below in caused exception: invalid experiment id: train model task }, dataset segments }, }, model initiaiton model config dataset config start exp to train model with rid the whole error message is below info time cost: loading data done info time cost: dropnalabel done settingwithcopywarning: value is trying to be set on copy of slice from dataframe. try using .loc value instead see the caveats in the documentation: df info time cost: cszscorenorm done info time cost: fit process data done info time cost: init data done info warning no valid experiment found. create new experiment with name exception traceback file in try: exp if exp is none or deleted file in name) retrieve an experiment by experiment name from the backend store active return file in name) :param name: the experiment name. :return: return file in fetch the experiment by name from the backend store. this is base implementation using derived classes may have :return: single object if it exists. for experiment in if file in try: trap and warn known issues, will raise unexpected exceptions to caller experiment if experiment: file in file in if is not none and is none: raise exception exception: invalid experiment id: the above exception was the direct cause of the following exception: valueerror traceback file in try: return false, except valueerror: file in except exception as e: raise valueerror from valueerror: no valid experiment has been found, please make sure the input experiment name is correct. during handling of the above exception, another exception occurred: exception traceback input in in start exp to train model with file in del try: return except stopiteration: raise runtimeerror from none file in uri, resume) def start resume: bool false, ): method to start an experiment. this method can only be called within python's statement. here is the example code: whether to resume the specific recorder with given name under the given experiment. run uri uri, resume resume, try: yield run file in uri, resume) def resume false, ): lower level method for starting an experiment. when use this method, one should end the experiment manually and the status of the recorder may not be handled properly. here is the example code: an experiment instance being started. return uri uri, resume resume, file in uri, resume) if is none: experiment, set up active experiment experiment file in if file with filelock )): pylint: disable return true note: for other schemes like http, we double check to avoid create exp conflicts try: file in if raise expalreadyexisterror file in init experiment try: except exception as e: if file in name, tags) def str: create an experiment. :param name: the experiment name. must be unique. active return tags) file in name, tags) return name name, tags if tags else file in name, tags) def get all existing experiments and find the one with largest numerical id. would not work when experiments are deleted. file in name) if name is none or name raise exception experiment if experiment is not none: if file in def name fetch the experiment by name from the backend store. this is base implementation using derived classes may have :return: single object if it exists. for experiment in if return experiment file in for in rsl: try: trap and warn known issues, will raise unexpected exceptions to caller experiment if experiment: file in def experiment if is none: file in check that is valid string or none, raise an exception if it if is not none and is none: raise exception exception: invalid experiment id: to reproduce steps to reproduce the behavior: just rerun the code in my envirment expected behavior screenshot environment note user could run under project directory to get system information and paste them here directly. darwin arm darwin kernel version wed jan pst python version: qlib version: additional notes installed qlib from source, and my conda env is the version for arm",
          "Title: endpoint appears unable to load model file use image paths as features; Content: have checked that this bug exists on the latest stable version of autogluon and have checked that this bug exists on the latest mainline of autogluon via source installation describe the bug it appears that the endpoint isn't able to find open the model file. was able to use the example code in the tutorial and managed to deploy an endpoint to but get this error when go to make predictions with test data. wonder if this might be related to transition from mxnet to pytorch and how their artifacts are typically stored? i'm using but the predictor object is this discrepancy in framework seems supported be related error that found in github issue note also that am attempting to adapt the example model trained in the because i'm ultimately try to deploy multi modal model and figure out how to pass to the endpoint. here's the full traceback: expected behavior clear and concise description of what you expected to happen. to reproduce train multi modal model, using code adapted from deploy the pet finder model: screenshots na installed versions which version of autogluon are you are using? additional context am attempting to follow the however, adapting to use the example model trained in the",
          "Title: ml not installed error in trainer Content: system info who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction install ml create trainingarguments with",
          "Title: scikit learn model feature definition doesn't work on Content: description scikit learn model in doesn't work in prediction environment, since it assumes the input as pandas dataframe and cannot handle json from web api. after deploying the model following the labs, this issue can be reproduced with this code snippet. returns: approach rewrite feature definition part of from: to: and it should run with this output: target files should be update.",
          "Title: error: no kind trainingjob is registered for version in scheme Content:error: no kind trainingjob is registered for version in scheme",
          "Title: exception with Content:hi! when trying to download registered model from the amls workspace, i'm getting the following traceback. the file shows up in the however the size is bytes, so it is making the file, however no data is being transferred into it.",
          "Title: unable to kick off the job; Content: deployed the sample mnist training job but seems its not getting invoked on the",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_experiment_model_exception",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_experiment_model_exception"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.106693267822266,
          7.702054977416992,
          7.039236068725586,
          8.00913143157959,
          7.225111484527588,
          6.749477863311768,
          7.31581974029541,
          7.896910667419434,
          7.632049083709717,
          7.878181457519531,
          7.052175045013428,
          6.884112358093262,
          7.005616664886475,
          7.103513717651367,
          6.573515892028809,
          7.83370304107666,
          6.569896221160889,
          7.729686737060547,
          7.005184173583984,
          7.678747177124023,
          6.754175662994385,
          7.857242107391357,
          7.3001017570495605
         ],
         "y": [
          0.8658499121665955,
          0.7003041505813599,
          1.1136893033981323,
          0.23141410946846008,
          0.9446375370025635,
          1.3593721389770508,
          0.9121608138084412,
          0.7674887180328369,
          0.7962095737457275,
          0.8193074464797974,
          1.0414409637451172,
          1.151661992073059,
          1.467684030532837,
          1.0707855224609375,
          1.0141125917434692,
          1.097145676612854,
          1.3996719121932983,
          0.6313731074333191,
          0.9973711967468262,
          0.7375860810279846,
          1.4476395845413208,
          0.5690548419952393,
          0.9607255458831787
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: remote storage is not publicly accessible Content: needs mantis creds so reader will not be able to follow. we need to make the bucket public and read only.",
          "Title: databuilder constructs wrong iam role arn for aws other than global; Content:for uploading data to aws we use which internally uses the current configuration uses config key which provides name of iam role for the loader to be able to use and the issue is that constructs iam role arn from name as follows: whereas, can be currently: aws regions china regions aws govcloud regions since we use amundsen also in aws china, the above arn is not valid. expected behavior iam role arn either takes into account aws partition or there is possibility of passing iam role arn instead of name directly. current behavior iam role arn is constructed incorrectly outside of aws global. possible solutions iam role arn should take partition into account. there are two solutions: add partition into current code add option of passing iam role arn directly which supersedes iam role name solution since didn't know or found any good way to get the aws partition, we can use caller identity and arn there to get the partition, this is smaller fix but it is bit hacky and i'm not sure it'll work in all situation, but it should guess. solution add config key which either supersedes in way that in constructor we would have something like: or even replace with which is imo cleaner, but would be not backward compatible. steps to reproduce deploy amundsen in aws china with and try to use databuilder to upload csv data from screenshots context currently we are unable to load data into as the iam role arn setting is hidden and we get an error: your environment amunsen version used: data warehouse stores: aws deployment aws step functions link to your fork or repository:",
          "Title: aws credentials not populating; Content:when notebook is launched with an associated study, the study folders are not mounted. digging into this, see that in the folder there is no credentials file, which is generated by the script. to reproduce create new data source select it and create new instance using those studies. after the instance launches, connect to it and see if the study folders are connected. if not, open terminal and run to see if the credential file is there. expected behavior the study folders are mounted using the assumed roles in the aws credentials file, generated by script. screenshots versions versions additional context this may or may not be associated with the other bug noted with mounting studies folders, swb study permission it seems both of these issues are new, within the last couple weeks. and the environment has had no new deployments or changes within that time. previous to these last couple weeks we had no issues with and study folders mounting.",
          "Title: example dag to use aws session token; Content: describe the bug currently the example dag for just uses access key and secret key. we need to use temporary access token to reproduce steps to reproduce the behavior: go to click on scroll down to see error expected behavior clear and concise description of what you expected to happen. screenshots if applicable, add screenshots to help explain your problem. desktop os: browser version smartphone device: os: browser version additional context add any other context about the problem here.",
          "Title: problems using gpu with on aws instance Content: description using on an aws gpu instance was not able to run the example script on gpu. to reproduce after starting the instance: next cell: paste the slightly modified script with little modification: error message other in addition, before installing gluonts after installing gluonts: environment running on aws instance gluonts version: installed using pip. kernel:",
          "Title: hardcoded bucket name impossible to use with aws the name of the bucket for is hardcoded. this is big issue because this makes using minio in gateway mode impossible on aws it's good first issue :)",
          "Title: resourcelimitexceeded for when running studio demo in new aws account; Content:when walking through the studio tour for the first time in new aws account, the usual service limit issue is hit when running code cell to create an endpoint to host the model. suggestions: the prerequistes section could address this proactively, with link to the service limit increase page, the notebook could be changed to use an instance type for the endpoint that does not have default service limit of please lmk which is preferable and will submit pr",
          "Title: aws templates for fail to start; Content: describe the bug cloud formation for fails on and yet succeeds on dn reported by user to reproduce run through tutorial and use expected behavior it launches actual behavior formation template stalls out and auto deletes working on getting logs. after min, gpu services failed to start. issue? screenshots browser environment all pygraphistry environment all additional context current graph app kit",
          "Title: unable to train on multiple gpus in notebook terminal; Content: have checked that this bug exists on the latest stable version of autogluon and have checked that this bug exists on the latest mainline of autogluon via source installation describe the bug autogluon textpredictor training on gpu instance in notebook terminal, with setting. get an error in spawning multiprocessing. when train with everything the same, but only on single gpu within the same instance and setup, it trains without problem. expected behavior train across all gpus in the instance with no errors. to reproduce notebook instance python pip install awswrangler pandas python code: in file screenshots error: installed versions which version of autogluon are you are using? if you are using and newer, please run the following code snippet: additional context add any other context about the problem here.",
          "Title: configuration options not being set correctly when using cn region endpoint as host; Content: describe the bug there are several areas in the code where we have an explicit check for the dns suffix; this is used to determine if we need to use specific configuration options and request uri elements. however, these checks misidentify endpoints of clusters in aws cn regions, which use the dns suffix instead, as non aws endpoints. as result, required config options such as and are not set correctly. all of the following checks need to be changed to",
          "Title: no documentation on how to connect local notebook to remote ssl; Content: ssl connection to remote not working am unable to figure out how can specify the correct certificate when running queries against ssl enabled to reproduce steps to reproduce the behavior: set up ssh tunnel via bastion to the cluster ec user :yourendpoint: _' start graph notebook as notebook notebook this gives me the output notebook is running at: open my notebook and run the following magic commands _'%% '_ run the command _%%sparql select where limit it gives me the error {'error': port ): max retries exceeded with url: macos catalina browser chrome version additional context add any other context about the problem",
          "Title: getting an error from table. please see the detail Content: describe the bug create notebook instance in one of the configured region. ran the below query and got that error steampipe version plugin version aws:",
          "Title: malformedqueryexception; Content: started to use amundsen metadata with database. initially used the metadata docker image to interact with the database, but every tested route gave me internal server error. so tested it locally, using vpn to connect to db, and found problems. i'll do pr linked to the issue that solves the problems expected behavior when calling route of the metadata api for the service, the server should respond without problem current behavior when calling the api to retrieve table description, there's an error this error has already be identified in after the correction of another error during the same request possible solution initialize class properly, removing and in file move to for and functions in file. the and are deprecated and don't work with steps to reproduce call the metadata route using the gremlin metadata service with aws db screenshots context your environment amunsen version used: last data warehouse stores: snowflake deployment link to your fork or repository:",
          "Title: can not add extention on openshift cluster Content:error when adding extetnion az extension create name extension extension type config enabletraining cluster type conneced cluster name resource group scope cluster request url: request method: 'get' request headers: 'x ms client request id': 'f bf dc ec abda d' 'commandname': 'k extension create' 'parametersetname': name extension type cluster type cluster name resource group name auto upgrade scope debug config' 'user agent': 'authorization': request body: this request has no body get none response status: response headers: 'cache control': 'no cache' 'pragma': 'no cache' 'transfer encoding': 'chunked' 'content type': 'application charset utf 'content encoding': 'gzip' 'expires': 'vary': 'accept encoding' 'x ms ratelimit remaining subscription reads': 'strict transport security': 'max age includesubdomains' 'api supported versions': preview, preview, preview, preview, preview, preview' 'x content type options': 'nosniff' 'x ms request id': bef 'x ms correlation request id': bef 'x ms routing request id': 'swedencentral: z: bef 'date': 'wed, may gmt' response content: }} is called with an exception: traceback file line in run file line in operation failed or canceled during handling of the above exception, another exception occurred: traceback file line in invoke file line in execute file line in file line in job file line in file line in file line in result file line in file line in wait file line in file line in run error: unable to get the status from the local crd with the error code: extensioncreationfailed message: error: unable to get the status from the local crd with the error error: unable to get the status from the local crd with the error code: extensioncreationfailed message: error: unable to get the status from the local crd with the error logger: error: unable to get the status from the local crd with the error code: extensioncreationfailed message: error: unable to get the status from the local crd with the error event: logger: exit code: command ran in seconds save telemetry record of length in cache returns positive. begin creating telemetry upload process. creating upload process: files files return from creating process finish creating telemetry upload process.",
          "Title: airflow not working with astrocloud; Content:raised by ocurate: description am trying to run simple spaceflights example with astrocloud. wasn't sure if anyone has been able to get it to work. here is the dockerfile: from run pip install user ignore requires python context am trying to use airflow with astrocloud. steps to reproduce follow directions here replace the dockerfile with the above mentioned image. expected result complete run on local airflow image. actual result failure in local airflow image. info not implemented for assuming empty store. warning unable to git describe info task exited with return code your environment include as many relevant details about the environment you experienced the bug in: airflow plugin version used airflow version version used python version used operating system and version: ubuntu linux",
          "Title: issue with installing glounts on notebook instance from github; Content: description am following the instructions on but at first step when ran got the following error, error message or code output environment note: previously, installed gluon ts using and if do can see the package is installed but when ran it says operating system: notebook instance with kernel. python version: gluonts version: is already installed. mxnet",
          "Title: can't configure profile with aws cli for using aws built in algorithms Content:hi everybody, am trying to use aws built in algorithms in studio lab. for that need an execution role and region etc. when try to run my code it outputs valueerror: must setup local aws configuration with region supported by is it even possible to link access aws resources in studiolab? many thanks in advance!",
          "Title: the data path inside notebook does not work; Content:the bucket of processed data does not exist reproduction steps aws ls error log an error occurred when calling the listobjectsv operation: the specified bucket does not exist environment cdk cli version: framework version: not installed version: not installed os other this is :bug: bug report",
          "Title: missing documentation on connecting to from macos; Content: describe the bug there are some missing details for how to connect to from macos device, we should add them to our doc on connecting to via ssh tunnel found one main piece that we are missing is that host alias needs to be made in order to get things working properly. additional context this is coming from bug report from connectivity not working as found in",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_aws_request_cluster",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_aws_request_cluster"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.118611812591553,
          5.7415900230407715,
          5.734889030456543,
          5.790392875671387,
          5.6460442543029785,
          5.792999267578125,
          5.639237880706787,
          5.710714340209961,
          5.62699031829834,
          5.507849216461182,
          6.35550594329834,
          5.871391296386719,
          5.872127532958984,
          5.160820960998535,
          6.104734897613525,
          5.461219787597656,
          5.585516929626465,
          5.797420501708984,
          7.247546672821045,
          5.829768180847168
         ],
         "y": [
          3.4669454097747803,
          3.28713059425354,
          3.4165618419647217,
          2.972635507583618,
          2.544795036315918,
          3.3884682655334473,
          3.128507614135742,
          2.7339560985565186,
          2.3564395904541016,
          3.2853453159332275,
          2.944124698638916,
          3.0020809173583984,
          2.945086717605591,
          2.9792728424072266,
          2.6101536750793457,
          2.272827625274658,
          3.1452760696411133,
          3.2852296829223633,
          2.900022506713867,
          2.98236083984375
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: bad artifact folder by default; Content:the artifact folder by default is not reemplacing the env var",
          "Title: deployment fails from ui; Content:none",
          "Title: fails if is not none and is specified; Content: description when you try to specify an artifact path and in an you get an error. this works: while this raises the following error:",
          "Title: ui deployment error; Content: we need to review which configuration param is being sent here",
          "Title: entity is hardcoded; Content: icenet version: has the entity hardcoded, oops make this default to $user, or be overridden by command line do the same for the project too",
          "Title: dataset fails to log on remote storage when underlying dataset filepath is converted as pureposixpath; Content:when register dataset in the and run got when the local path is linux and the is an azure blob storage don't know really why this append, but it can be fied by replacing by in these locations: did you experience some issues with too? edit it is",
          "Title: fsd clone for non repos throws an error; Content:when using for non repo it throws the following error: cloning non repo using fds can be common use case, cloning dagshub repo containing many files, but none of them are tracked by nur the repo contains config files. suggest that after cloning the git server, fds will check if the repo contains files. if it contains files: echo 'starting fds will start wizard to set the user name and password for each remote storage in the local config. fds will pull all the files from the remotes and show progress bar it doesn't contain files: fds will initialize if the git server url is dagshub's: fds will set dagshub storage as the remote using the git url fds will start wizard to set the remote user name, password, and name. else: fds will start wizard asking do you want to set remote if yes: with the wizard, the user will set the remote url, name, username, and password.",
          "Title: use move instead of system's mv in rename action; Content:the current implementation of the rename action includes the actual rename of the base image using the shutils' mv command. this rename is to be committed afterwards so that the rename of the base image is applied to the main branch. however, this approach is invalid: if only the actual file is renamed, when pull is performed, the file with the previous name will be pulled. we will get two identical files with different names. nor can we just rename the pointer as the pointer file name is irrelevant to the property inside the pointer is what determines the filename of the pulled file. the right, convenient way to implement the file rename action is using the rename command that performs all these actions: rename the actual file rename the pointer update the property for consistency, we should use our wrapper. if the move command is not wrapped there, we can do it as part of this issue.",
          "Title: fds fails to pull on windows; Content:when running pull command on dagshub remote. receive pull failure, so have to manually pull again. this issue permanent issue on windows. it is not urgent issue, but in annoyance category.",
          "Title: make one click not working after make destroy because of undeleted bucket; Content: describe the bug problem encountered by running is not working after because of the artifacts' bucket which still exists. got the following error: should work",
          "Title: pull does not work in the result branch if sshfs connection is mounted; Content: describe the bug entsprechend dem tutorial habe ich mit sshfs den data ordner gemountet, um externe daten verwenden zu knnen, was soweit auch funktioniert. wenn ich dann aber nach erfolgreich abgeschlossenem job die ergebnisse ansehen will bekomme ich eine fehlermeldung: rmdir: data: das gert oder die ressource ist belegt wenn ich vorher mit fusermount data den dataordner wieder unmounte, funktioniert alles wie erwartet. ist das das zu erwartende verhalten? muss ich also data unmounten, um die ergebnisse ansehen zu knnen? und dann erneut mounten, um einen neuen job zu starten? faice cc",
          "Title: use remove instead of just removing the base image file; Content:the problem described in this issue es very similar to currently, the delete action just removes the base image file. this is not correct for some reasons: the base images are under control by the right way to remove file that has been previously added to is using its remove command, which removes the file pointer. the deletion of the base image is not needed because it is not actually in the repository: it is pushed to the remote storage during the base image generation and does not persist after this finishes. in case that the file were in the working tree because it was pulled at the beginning of some workflow execution, we can remove it just for good practices, but it would be removed at the end of the execution anyhow. to summarize: the right way to do the deletion would be using command, which is already available in the wrapper, and is how it must be implemented in the action.",
          "Title: artifact store fails trying to create new bucket; Content: contact details system information zenml what happened? zenml is trying to create bucket and fails due to incorrect regex in its name. reproduction steps create pipeline. create artifact store. run the pipeline relevant log output code of conduct agree to follow this project's code of conduct",
          "Title: remove data/ and directories and rewrite history; Content:the subdirectory slipped through and is now part of the repo's history. these binary files should be removed. there's an open source tool available to do that called at the end of the cleaning process, we need to delete our local clones and clone fresh, cleaned version from upstream. let's do that once we have committed all local changes.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_pull_artifact_repo",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_pull_artifact_repo"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.324725151062012,
          7.674173355102539,
          7.40413761138916,
          7.683010578155518,
          7.861588478088379,
          6.441653251647949,
          6.691226959228516,
          6.850021839141846,
          6.718778133392334,
          7.1940836906433105,
          6.683366775512695,
          6.81234073638916,
          7.2324066162109375,
          6.801442623138428,
          7.0980682373046875
         ],
         "y": [
          3.9198837280273438,
          3.0685760974884033,
          3.661452054977417,
          3.0665886402130127,
          3.4378602504730225,
          3.5921337604522705,
          3.9700534343719482,
          4.164971351623535,
          3.847078323364258,
          3.6773922443389893,
          3.849357843399048,
          4.159656524658203,
          3.4897165298461914,
          4.164103031158447,
          3.7192018032073975
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: sdk downgrades pyarrow to which breaks cudf; Content: steps to reproduce create fresh rapids conda environment shows installed launch python and should work launch python and fails shows installed error:",
          "Title: prompts twice to login when vs code loads; Content: expected behavior if the user is logged out, the aml extension should not prompt to login until the user specifically tries to run an command. prompting when vs code loads is disruptive and unnecessary, and no other extensions for aws or azure do this. actual behavior if you are signed out of the azure ml extension and reload vs code, you are prompted to login when it loads if you click cancel, you are prompted again steps to reproduce the problem install the azure ml extension login logout reload vs code click cancel when prompted to login specifications azure ml extension version version: commit: da ca aaa date: electron: chromium: os: darwin",
          "Title: 'clientrequesterror' when trying to use azure computer vision api from notebook; Content:i'm trying to use azure computer vision's ocr api in an notebook. however there seems to be an error when trying to call the computer vision api from an notebook. the same code works when i'm running it on local machine. i'm following azure computer vision's ocr quickstart: when running the following code, does not return but throws an exception. exception: code: used azure packages: maybe related to",
          "Title: unable to import aiplatform module when running matching engine sample notebook; Content: expected behavior expect the notebook here to work actual behavior but for some reason whenever try to import the module inside cell of the notebook get the following error: steps to reproduce the problem clone the sample notebook import it into workbench running the python image try to run through the steps and get stuck in installation issues specifications version: platform:",
          "Title: notebooks raise error for Content: description the conda environment for in notebooks cannot find context i'm wanting to use as my development environment. however, cannot get to run as expected in both the notebooks and the terminal steps to reproduce startup instance with defaults terminal success: in the terminal a. for name b. for example project success! notebook fail: create new notebook in in notebook the environments for the terminal and notebooks are separate by design in load the context as described note that i've started to use the code below; without checking if exists, you need to restart the kernel if you want to reload the context as something in the last lines of code causes the next invocation of to point to the root dir not as intended. run expected result the notebook should print: actual result full trace. investigations so far upon changing the yaml type for from to we get success on both the terminal and the notebook. however, this is not my desired outcome; the transition to using makes it easier, for me at least, to use both and local datasets. output from notebook output from terminal your environment include as many relevant details about the environment in which you experienced the bug: environment terminal notebook version version python :: anaconda, inc. python :: anaconda, os",
          "Title: nameerror; Content:when don't have the optional dependency installed get the following exception the first time try to import the the second time run the import, everything works just fine.",
          "Title: import failure; Content: describe the bug from import mapping, sequence modulenotfounderror: no module named to reproduce run on 's server. expected behavior should be properly imported. server os: centos",
          "Title: connecting to vscode to Content: does this occur consistently? repro steps: action: error type: error message: unknown error retrieving susbcriptions from azure account extension version: os: win os release: product: visual studio code product version: language: en call stack",
          "Title: bug: failure while loading providers; Content:in fresh conda environment, get several warnings that halt the script execution: my environment is specified by: the fix is to specify perhaps, there are some wrong deps checks somewhere. document details do not edit this section. it is required for github issue id: eb bec version independent id: fe efc dc content: content source: service: machine learning sub service: core github login: microsoft alias: trbye",
          "Title: azure credentials module should lazy import any modules; Content:a regression was introduced in where this import statement causes to be loaded when it's not needed if you only have the default set of ml dependencies installed. the following import statement could be added around right before is called: then this could be removed from the top:",
          "Title: keep on getting this error continuously for extension; Content: does this occur consistently? repro steps: azure sign in sign in using azure portal. you get the sign in successful, you may close the window message, but azure asks to sign in again. action: error type: error message: unknown error retrieving susbcriptions from azure account extension version: os: win os release: product: visual studio code insiders product version: language: en call stack",
          "Title: warning while loading the Content:hi, have installed the azure ml using below environment yml, installation happened without any issues but when import the am getting exception. conda environment yml exception import azure ml sdk version: please help. thanks",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_azure_import_terminal",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_azure_import_terminal"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.82321310043335,
          4.70175313949585,
          4.759596824645996,
          5.220981121063232,
          4.812894344329834,
          5.371866703033447,
          5.45779275894165,
          4.743022441864014,
          4.83721399307251,
          4.769834518432617,
          4.7812180519104,
          4.80894660949707,
          4.924027919769287
         ],
         "y": [
          2.1917548179626465,
          2.7269341945648193,
          2.562105894088745,
          2.068272829055786,
          2.350740432739258,
          1.9409370422363281,
          1.8963202238082886,
          2.8174071311950684,
          2.326592445373535,
          2.536564826965332,
          2.8185908794403076,
          2.3688852787017822,
          2.383758783340454
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: compare models exception; Content:hi. just upgraded to pycaret when ran the function with the titanic dataset, got the following error: exception: unable to map type to datatype. canbe mapped iff all values have identical data type which is one of int, float) the same code worked fine in pycaret",
          "Title: some types plot types are not getting saved to the experiment artifacts dir; Content: describe the bug thank you for creating such helpful tool! the problem i'm facing is that some types plot types are not getting saved to the experiment artifacts dir. think the issue is with inconsistent naming for the saved png for certain plot types. thank you for your help! to reproduce expected behavior expect all of the plot types to be logged under the artifacts dir number} however, and are saved to the working directory. additional context think the issue is with inconsistent naming of the file. here is printout of the log when it tries to save the calibration plot: so you can see that it is looking for 'calibration but what actually gets produced is versions python pycaret",
          "Title: incorrectly logging models lasso least angle regression and least angle regression Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the master branch of pycaret issue description logs the name of both models least angle regression and lasso least angle regression as least angle regression when looking into the you can see both of those models have unique but both have the same python version: pycaret version: pandas version: reproducible example python traceback when looking into the you can see they are all unique but least angle regression is there twice and lasso least angle regression isn't there at all. could this be logged incorrectly? gradient boosting regressor catboost regressor light gradient boosting machine extreme gradient boosting lasso regression ridge regression linear regression lasso least angle regression least angle regression extra trees regressor random forest regressor adaboost regressor decision tree regressor orthogonal matching pursuit elastic net huber regressor bayesian ridge neighbors regressor dummy regressor passive aggressive regressor installed versions system: python: executable: machine: pycaret required dependencies: pip: setuptools: pycaret: ipython: ipywidgets: tqdm: numpy: pandas: jinja scipy: joblib: sklearn: pyod: installed but version unavailable imblearn: lightgbm: numba: requests: matplotlib: scikitplot: yellowbrick: plotly: kaleido: statsmodels: sktime: tbats: installed but version unavailable pmdarima: psutil:",
          "Title: runs recorded in nests all recursively; Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the master branch of pycaret issue description as started runs in logger are never ended, all runs shown in dashboard seem to be nested recursively. fixed the display of deeply nested runs correctly, so the bug is now problematic. reproducible example expected behavior expected display: actual display: actual results installed versions",
          "Title: ui doesn't show any models; Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the develop branch of pycaret issue description have tried both the nightly and the release branch, and read the issues posted here: do not see any models in the during training while several models have already converged and logged to the file system. see some models have already reported auc, mse, etc. but as shows below, nothing is present in the dashboard thanks! reproducible example expected behavior being able to see the models that have already converged actual results installed versions",
          "Title: doesn't save model artifact and some plots clustering; Content:i'm using clustering module of pycaret and the integration with but have problems because think it doesn't save all artifacs and the status is always failed. this is my code: my logs are the following i'm using pycaret version",
          "Title: pycaret integration does not allow probabilities for classification and binary response models; Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the master branch of pycaret issue description we have been using pycaret for the model training procedure and registration to the server. my company uses managed version of this in azure databricks. after the registration has been completed, we call the calibrated algorithm in separate notebook and are trying to score new data with binary response we would also like to leverage the scikit learn function to create the probabilities in addition to the predicted value. this is not working in pycaret and appears to be bug of some sort. it is also important to note that we are able to see the during the model training but not when we call the algorithm for separate scoring function. reproducible example expected behavior we should see the probabilities but this code errors out. another example would be the following: actual results installed versions system: python: executable: machine: pycaret required dependencies: pip: setuptools: pycaret: ipython: ipywidgets: tqdm: numpy: pandas: jinja scipy: joblib: sklearn: pyod: installed but version unavailable imblearn: lightgbm: numba: requests: matplotlib: scikitplot: yellowbrick: plotly: kaleido: statsmodels: sktime: tbats: installed but version unavailable pmdarima: psutil:",
          "Title: not logging metrics; Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the master branch of pycaret issue description hi, am trying to integrate pycaret with using your parameter in when set it to true, everything is stores as planned in my local server, but not the metrics. in the documentation is says the should control everything. so am not sure if do something wrong here of if it is bug from your side. would be glad if you could help! reproducible example expected behavior should log metrics actual results installed versions pycaret",
          "Title: runs recorded in nests all recursively when installed; Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the master branch of pycaret issue description when pycaret is installed with all runs executed in one script are shown nested recursively in dashboard. this happens only with installation. reproducible example expected behavior expected display: actual display: actual results installed versions system: python: executable: machine: pycaret required dependencies: pip: setuptools: pycaret: ipython: ipywidgets: tqdm: numpy: pandas: jinja scipy: joblib: sklearn: pyod: imblearn: lightgbm: numba: requests: matplotlib: scikitplot: yellowbrick: plotly: kaleido: statsmodels: sktime: tbats: pmdarima: psutil: pycaret optional dependencies: shap: interpret: umap: explainerdashboard: autoviz: fairlearn: xgboost: catboost: kmodes: mlxtend: statsforecast: ray: hyperopt: optuna: skopt: gradio: fastapi: uvicorn: cgen: evidently: nltk: pyldavis: not installed gensim: not installed spacy: not installed wordcloud: textblob: fugue: streamlit: not installed prophet: not installed",
          "Title: server integration; Content: pycaret version checks have checked that this issue has not already been reported have confirmed this bug exists on the of pycaret. have confirmed this bug exists on the master branch of pycaret issue description have problem saving xgboost run in server. the run has status of unfinished, no metrics or artifacts are created. when use everything is fine, but when run server with sqlite as backend store the problem occurs. command used to run server reproducible example expected behavior artifacts and metrics should be crated. actual results installed versions pycaret version: version: xgboost version:",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_models_reproducible_branch",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_models_reproducible_branch"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.727160930633545,
          7.640402793884277,
          6.723784446716309,
          6.847965240478516,
          6.783960819244385,
          6.833493709564209,
          6.70535135269165,
          6.753937721252441,
          6.822030067443848,
          6.7493977546691895,
          6.858748435974121
         ],
         "y": [
          -0.31556785106658936,
          1.5165549516677856,
          -0.3096266984939575,
          -0.450655460357666,
          -0.3835740387439728,
          -0.11467131227254868,
          -0.27233588695526123,
          -0.32103005051612854,
          -0.4064842462539673,
          -0.30306169390678406,
          -0.13604523241519928
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: ui does not use arguments from Content: description as described in the command does not use the options context steps to reproduce create project call modify the port in to launch expected result the ui should open in port actual result it opens on port your environment include as many relevant details about the environment in which you experienced the bug: version: version: python version used operating system and version: windows does the bug also happen with the last version on master? yes solution we should pass the arguments in the command:",
          "Title: ui gets filenotfounderror; Content:firstly i'd like to apologize if this is dummy question. i'm following the tutorial to get introduced to ,; after running the command init tried to run the command mlflofw ui but get an error: info the key in is relative it is converted to valid uri: 'file: after the traceback get an error: filenotfounderrror",
          "Title: telemetry breaks packaged projects due to wrongly assuming exists; Content: description telemetry installed alongside packaged and installed project breaks the project by assuming that the file exists. the is only recipe for building the project and should not be assumed to be existing in the current folder in all cases. the problem was introduced with context when deploying projects and if you have installed telemetry, it breaks your project. steps to reproduce create project add dependency on telemetry package it through install it in different environment run the project through in folder where only the is expected result the project should run. actual result an exception is thrown. your environment include as many relevant details about the environment in which you experienced the bug: version used plugin and plugin version used python version used not relevant operating system and version: not relevant",
          "Title: cli is broken if configuration is declared in Content: description enable to declare configuration either in or in we cl to support both, but the cli commands are not accessible if the project contains only steps to reproduce call inside project with no file but only expected result the cli commands should be available actual result only the command is available. this is not considered as project. your environment and version used python version used operating system and version: windows does the bug also happen with the last version on develop? yes solution the error comes from the function which does not consider that folder is the root of kdro project if it does not contain",
          "Title: ui gets filenotfounderror; Content:firstly i'd like to apologize if this is dummy question. i'm following the tutorial to get introduced to ,; after running the command init tried to run the command mlflofw ui but get an error: info the key in is relative it is converted to valid uri: 'file: after the traceback get an error: filenotfounderrror",
          "Title: cli is unavailable inside project; Content: description try to reproduce the minimal example from the docs: project using the starter using the functinality. do not arrive at initializing the project, since the cli commands are not available. context it is unclear to me if this is connected to wanted to start looking into but got immediatle blocked by the initialization of the project. therefore any advice on where to look to fix this would also be appreciated. steps to reproduce expected result is available in project directory, gives the same output inside the folder as before actual result inside the project folder the command is unknown to your environment ubuntu python does the bug also happen with the last version on master? yes",
          "Title: ui never runs; Content: describe the bug getting error filenotfounderror: the system cannot find the file specified while running ui to reproduce run ui expected behavior it should run without any issues versions not sure if this is the right forum to post this issue. if it is not, please ignore.",
          "Title: cli is unavailable inside project; Content: description try to reproduce the minimal example from the docs: project using the starter using the functinality. do not arrive at initializing the project, since the cli commands are not available. context it is unclear to me if this is connected to wanted to start looking into but got immediatle blocked by the initialization of the project. therefore any advice on where to look to fix this would also be appreciated. steps to reproduce expected result is available in project directory, gives the same output inside the folder as before actual result inside the project folder the command is unknown to your environment ubuntu python does the bug also happen with the last version on master? yes",
          "Title: ui does not use arguments from Content: description as described in the command does not use the options context steps to reproduce create project call modify the port in to launch expected result the ui should open in port actual result it opens on port your environment include as many relevant details about the environment in which you experienced the bug: version: version: python version used operating system and version: windows does the bug also happen with the last version on master? yes solution we should pass the arguments in the command:",
          "Title: cli is broken if configuration is declared in Content: description enable to declare configuration either in or in we cl to support both, but the cli commands are not accessible if the project contains only steps to reproduce call inside project with no file but only expected result the cli commands should be available actual result only the command is available. this is not considered as project. your environment and version used python version used operating system and version: windows does the bug also happen with the last version on develop? yes solution the error comes from the function which does not consider that folder is the root of kdro project if it does not contain",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_project_cli_port",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_project_cli_port"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.1080322265625,
          7.814836025238037,
          8.179658889770508,
          8.1958589553833,
          7.858637809753418,
          8.195659637451172,
          7.906750679016113,
          8.23181438446045,
          8.083929061889648,
          8.205585479736328,
          8.078076362609863
         ],
         "y": [
          5.212506294250488,
          5.496006965637207,
          5.251492023468018,
          5.2586750984191895,
          5.436508655548096,
          5.276832580566406,
          5.4172749519348145,
          5.300983905792236,
          5.179002285003662,
          5.291233062744141,
          5.312051296234131
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: typeerror in when debugging run in vscode; Content: happens when suggested is used for debugging. the error is due to commandline arguments being when running pipeline directly through",
          "Title: pipelinemodel requires unnecessary pipeline input dependencies to be executed; Content:hi galilei description the pipelinemodel has property which causes some problems. this can contain some datasets but it's not necessary to log them when you train your model. because of this property can't load my model anymore. have to train it again. explain when trained my model used home made plugin to load specific dataset after that, updated this plugin independently of my ml project. today, want to load my model but can't because the load function uses the old catalog with my old plugin version which is not in my environnement anymore. context it would be great if we can update the catalog without having to retrain our models. possible implementation log in what is only necessary. hope my issue is clear. thank you",
          "Title: add support for namespaces in data catalog; Content:since there have been introduced namespaces which cause issues in kfp artifacts, as they are not properly handled. unless the function to create kfp artifacts is disabled in config: it causes issues like: when trying to run or update the pipeline.",
          "Title: python package contrib pipeline steps not working Content: describe the issue version of python package contrib pipeline steps throws file line in run pipeline pipeline file line in wrapper return file line in steps, finalize false) file line in build graph steps) file line in construct file line in file line in file line in return file line in node file line in return super got an unexpected keyword argument 'command' minimal example additional context am using aml sdk no type errors with version of contrib pipeline steps.",
          "Title: pipelinemodel cannot be loaded from if its catalog contains non deepcopy able datasets; Content: description tried to load pipelinemodel from and got cannot pickle context artifacts error, which is due do the context cannot load previously saved pipelinemodel generated by steps to reproduce save pipelinemodel with dataset that contains an object which cannot be deepcopied expected result the model should be loaded actual result an error is raised your environment include as many relevant details about the environment in which you experienced the bug: and version used: and python version used windows centos were tested does the bug also happen with the last version on develop? yes potential solution the faulty line is:",
          "Title: pipelinemodel cannot be loaded from if its catalog contains non deepcopy able datasets; Content: description tried to load pipelinemodel from and got cannot pickle context artifacts error, which is due do the context cannot load previously saved pipelinemodel generated by steps to reproduce save pipelinemodel with dataset that contains an object which cannot be deepcopied expected result the model should be loaded actual result an error is raised your environment include as many relevant details about the environment in which you experienced the bug: and version used: and python version used windows centos were tested does the bug also happen with the last version on develop? yes potential solution the faulty line is:",
          "Title: pipelineml objects in breaks all viz versions with Content: description if create pipelineml objects and return it in the run viz pipeline list hooks;py viz pip show pip show python file instead of does the bug also happen with the last version on develop? yes potential solution: it seems the method of the class must be implemented.",
          "Title: running pipeline dp results in character maps to error; Content: description running the pipeline dp via cli with run pipeline dp results in the following error: steps to reproduce python function to parse documentation data: thanks! :)",
          "Title: pipelines: expected steprun object but received Content:i am running lightly edited version of this pipeline example: and it is yielding me this error am also getting this same warning in other pipelines make and cannot figure out what is causing it. here is slightly reduced mwe for clarity:",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_pipeline_catalog_plugin",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "8_pipeline_catalog_plugin"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.73288106918335,
          6.255963325500488,
          6.270058631896973,
          5.742642879486084,
          6.177371978759766,
          6.245298862457275,
          5.978147506713867,
          5.815821170806885,
          5.898462772369385,
          6.012960910797119
         ],
         "y": [
          1.1756595373153687,
          0.9191450476646423,
          0.9056689739227295,
          1.130091667175293,
          0.9500299692153931,
          0.9334065318107605,
          0.988653302192688,
          1.1076050996780396,
          1.066197156906128,
          1.019606351852417
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: runstatus of run is finished instead of failed when the run fails; Content: description when launch and the run fails, the closes all the runs context cannot distinguish failed runs from sucessful ones in the ui. steps to reproduce launch failing pipeline with run. expected result the ui should display the run with red cross actual result the ui displays the run with green tick does the bug also happen with the last version on develop? yes. potential solution: replace these lines: with or even better, retrieve current run status from",
          "Title: close run when pipeline fails in interactive mode; Content: context today, you can execute pipeline interactively. the logic would be to load the context, and then to run the pipeline. description if the execution fails for some reason the run is not closed. this creates unintended side effects: for instance, if you rerun the pipeline, the new run will be nested in the failing runs and the mllflow database will become very messy. this bug does not occur when running from the command line since the run is automatically closed when exiting. possible implementation implement to close the run when the pipeline fails.",
          "Title: incorrect check for active run in callback; Content: system info who can help? should be fixed by information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction steps to reproduce: follow training tutorial as per change the training arguments to use on the ui should report run with run name of which is not currently the case. cause of the issue: in the line need to be replaced by expected behavior pr introduce support for in the callback. though, this does not work as expected since the active run is checked using method reference that always returns true. bug introduced by",
          "Title: not sectioning by train and overrides runs by checks; Content: describe the bug not sectioning by train and overrides runs by checks to reproduce run suite with train checks and duplicate checks in suite expected behavior sections for each dataset and being able to run suite with couple of checks screenshots if applicable, add screenshots to help explain your problem.",
          "Title: metricsdataset ignores when prefix is not specified; Content: description when has no prefix specified, the name in the catalog is used instead. however, when the is specified, it is overriden by the current run id when the prefix is automatically set. steps to reproduce create run interactively: and browse the ui to retrieve the declare in the with no prefix and an existing launch the pipeline which saves this catalog: expected result metric should be loggedin run actual result the metric is logged is new run. does the bug also happen with the last version on develop? yes",
          "Title: failed ert runs are not registered correctly in Content:if an ert subprocess has failed for any other reason than what is hard coded in the subprocess call, returncode larger than is ignored. this will then lead to successful run in whereas it should be registered as failed run.",
          "Title: test process is not failing if there is an error in the tests; Content: description tests execute the code, but if the process fail, we are not getting signal that is failing, which makes difficult to identify errors in which platform does it happen? how do we replicate the issue? see expected behavior we want to send back signal to github so if the tests fail, the badge is red and we are notified other comments",
          "Title: runstatus of run is finished instead of failed when the run fails; Content: description when launch and the run fails, the closes all the runs context cannot distinguish failed runs from sucessful ones in the ui. steps to reproduce launch failing pipeline with run. expected result the ui should display the run with red cross actual result the ui displays the run with green tick does the bug also happen with the last version on develop? yes. potential solution: replace these lines: with or even better, retrieve current run status from",
          "Title: callback changes the train step's unique id, but does not change the results; Content:none",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_run_ui_pipeline",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "9_run_ui_pipeline"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.215048789978027,
          9.254302024841309,
          8.900300025939941,
          8.399418830871582,
          9.137877464294434,
          9.181970596313477,
          9.36174201965332,
          9.192068099975586,
          8.966339111328125,
          9.06767463684082
         ],
         "y": [
          0.6973605751991272,
          0.7036615610122681,
          0.8238917589187622,
          0.8789306879043579,
          0.8640556931495667,
          0.6854235529899597,
          0.7577621340751648,
          0.6901870965957642,
          0.9517406225204468,
          0.7836682200431824
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: instances can't be launched due to missing tags permission; Content: describe the bug service workbench appears to be unable to launch notebook instances at all, due to missing permission for this seems to also be the case when custom tags aren't included in the workspace configuration. to reproduce steps to reproduce the behavior: install service workbench from the latest version. create workspace configuration for notebook. launch workspace using the new configuration. wait few minutes and observe the error. expected behavior expected the notebook to launch :) screenshots versions additional context add any other context about the problem here.",
          "Title: null is not an object while trying to connect to Content: describe the bug occasionally after starting workspace, clicking 'connect' gives an error in the bottom right hand corner of the screen: we have problem! null is not an object in little red box on the bottom right of the screen. the notebook window is not opened after clicking on 'connect'. to reproduce the error is intermittent. think it may happen after the sw window has been open while, because noticed that the sw window automatically logged me out shortly after seeing this error. click 'start' for workspace and wait for the status to change to 'available'. click 'connections', then 'connect' see error when logged out and back into service workbench, and was able to connect to the workspace successfully. expected behavior new window should open with jupyter notebook in new window. versions",
          "Title: blank page on workspace connect; Content: describe the bug when connecting to workspaces, there is an intermittent issue where blank browser launches instead of the issue presents for workspaces that are newly created as well as for workspaces that were already created, but were stopped and are being restarted. to reproduce steps to reproduce the behavior: step login as an admin step create workspace step start the workspace step click connect step new blank web browser tab opens step click connect again, another blank web browser tab opens user receives something went wrong general error in swb at step in the client logs for the browser, there is also this error noted: name cache value error from cloudfront expected behavior workspace launch in browser screenshots if applicable, add screenshots to help explain your problem. versions release version installed additional context user has cleared cache and it solved the issue, but for one of her employees clearing the cache did not solve the issue. the issue is experienced approximately once week. sometimes clearing cache solves the issue. other times going to incognito, and it does not solve the issue.",
          "Title: in hongkong region, after user stop workspace manually, web console show unknown status; Content: describe the bug clear and concise description of what the bug is. to reproduce steps to reproduce the behavior: deploy swb in hongkong reigon create workspace click stop button. workspace status show unknown",
          "Title: template, after auto stoped, workspace env status is not updated; Content: describe the bug after workspace stopped automatically, workspace env status is not updated. to reproduce steps to reproduce the behavior: set workspace config's autostopidletimeinminutes as minutes create workspace and wait for more than minutes, check notebook instances to confirm the instance status is stopped check service workbench workspace status, it is still available expected behavior above step workspace status should be stopped screenshots if applicable, add screenshots to help explain your problem. versions release version installed additional context add any other context about the problem here.",
          "Title: more descriptive error message for null is not an object while trying to connect to notebook. Content: describe the bug users get the error null is not an object when pop ups are enabled in swb this error is illegible to the user and causes confusion. can we make the error message more clear such as: service workbench is encountering an error showing content. please enable pop ups and refresh the to reproduce steps to reproduce the behavior: diable pop ups connect to workspace expected behavior if the workspace is unable to open, more legible error message should be shown, such as service workbench is encountering an error showing content. please enable pop ups and refresh the screenshots if applicable, add screenshots to help explain your problem. versions release version installed additional context add any other context about the problem here.",
          "Title: example: close session error; Content: summary steps to reproduce it used binder to run the above notebook example",
          "Title: notebook workspace changed to unknown status and cannot connect anymore; Content: describe the bug notebook workspace that was working fine on friday today appears with the status as unknown when clicking on connect the new window pop up but is empty, and when going back to the swb page, we see the message, we have problem! something went wrong to reproduce steps to reproduce the behavior: go to 'workspaces' look for the workspace that was expected to be stoped click on 'connect' see error expected behavior that the workspace was stopped and when clicking on connect we can access to the workspace. screenshots versions release version installed: additional context the workspace was working fine all previous week, autostop and connect without any issue. unknown status found today.",
          "Title: instance does not stop automatically; Content: describe the bug idle notebook instances do not stop after specified time. swb runs script to automatically stop notebook instance. the script is used by lifecycle rule of the instance cfn template. according to lifecycleconfigonstart logs, some packages are missing and autostop script doesnt work. to reproduce steps to reproduce the behavior: make sure autostopidletimeinminutes parameter in workspace type config is set to required time create new workspace with notebook instance leave the instance idle for the time specified after the specified time see that the instance is not stopped expected behavior idle notebook instance automatically stops after specified time. screenshots versions release version installed additional context add any other context about the problem here.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_workspace_connect_stopped",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "10_workspace_connect_stopped"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.05357551574707,
          5.037596225738525,
          5.04022216796875,
          4.97904634475708,
          5.0218095779418945,
          4.942994117736816,
          5.4720635414123535,
          4.980076789855957,
          5.152073383331299,
          5.075494766235352
         ],
         "y": [
          4.258231163024902,
          4.27941370010376,
          4.260855674743652,
          4.301647186279297,
          4.2445454597473145,
          4.332626819610596,
          3.8534467220306396,
          4.3057403564453125,
          4.0883073806762695,
          4.213868141174316
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: unable to open database file, unexpected error while saving file: unable to open database file; Content: describe the bug to reproduce i've deleted some of the unwanted notebooks from studio lab's files and now am getting this error. cannot install libraries with pip, cannot create new files, cannot even start kernel",
          "Title: open in in studio lab button process fails when attempting to copy notebooks only Content: describe the bug cloning single notebook using the open in in studio lab fails. cloning the whole repo works. using 's sample, get this error: to reproduce steps to reproduce the behavior: create md cell with and run it click on the button that appears once you run the cell. will open new tab in browser in the new pop up tab, click copy to project will open new tab in browser in the new pop up tab's modal, select copy notebook only error will now appear expected behavior my notebook will open and appear, just as it would with cloning directory screenshots desktop os: browser version",
          "Title: inability to reimage studio lab instance to get the space back; Content:hello, after tried to build conda environment using was ran out of space with no environment created. after deleted all files from my home folder still had of my space used. there is no way to reimage my studio lab instance and get back the initial gb of space. followed the aws machine learning university course and cloned the examples for tabular data course: after that was stupid enough to try creating the conda environment using the file. the environment creation ate all my space available and creation was failed. currently have space usage of my folder with no files in it. how can reimage studio lab instance to get the space back or uninstall all libraries installed by creating the conda environment? os: windows browser: chrome",
          "Title: just wonder if can initialize my studio lab? Content:as the title suggests",
          "Title: study fail to mount in swb jupyter notebook; Content: describe the bug swb version jupyter notebook workspace can not mount study. see error in mounting file system: mount: mount: running fusermount: exec: fusermount executable file not found in $path stderr: looks like the fuse package failed to install during on start. if run sudo yum install fuse then you can run to mount the study. to reproduce steps to reproduce the behavior: go to click on scroll down to see error expected behavior clear and concise description of what you expected to happen. screenshots if applicable, add screenshots to help explain your problem. versions release version installed is the deployment from forked version of the repository? additional context add any other context about the problem here.",
          "Title: fix Content: what happened what you expected to happen notebook is broken due to missing permission first, maybe more issues down the road. looked into it earlier and we're creating this issue to keep track of it. versions dependencies master reproduction script issue severity medium: it is significant difficulty but can work around it.",
          "Title: couldn't open project on studio lab; Content: describe the bug studio lab is not opening jupyter notebook. it is loading indefinitely at preparing project run time after that am getting please try again later. it's been almost week and it still hasn't been resolved. even though tried shifting the runtime from cpu to gpu but issue still persists. any help would be appreciated. the error am getting is",
          "Title: we are experiencing elevated fault rate in start runtime api. the studio lab team is working to restore the Content:its been more than days and im still getting this issue, cant run cpu or even gpu runtimes in how long is this going to even take man",
          "Title: can't open project on Content:hello, can't open my project on when am clicking the 'open project' button, it is loading indefinitely, and can't do anything with the files. have restarted my project, browser, laptop, cleared cache, tried from other browsers, changed the env from gpu to cpu but nothing did work. can you please take look into my account and resolve the issue? screenshot is attached here to understand better. thanks!",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_lab_jupyter_cloning",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "11_lab_jupyter_cloning"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.7022528648376465,
          5.722280502319336,
          5.889513969421387,
          6.060829162597656,
          5.666999816894531,
          5.527769565582275,
          6.026376724243164,
          6.136386871337891,
          6.289295196533203,
          5.891300678253174
         ],
         "y": [
          3.9742188453674316,
          4.1828107833862305,
          4.030060768127441,
          4.260741710662842,
          3.9443979263305664,
          3.941293239593506,
          4.19570779800415,
          4.079233169555664,
          4.212942600250244,
          4.0912675857543945
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: extra args broken; Content: describe the bug clear and concise description of what the bug is. the new staticprefix argument being under extraargs breaks the chart for users that need to use the extraargs what's your helm version? gitcommit: cb af df ac dd ad gittreestate: clean what's your kubectl version? client version: minor: gitcommit: ac ff ca bc gittreestate: clean builddate: compiler: gc platform: darwin server version: minor: gitcommit: ab cff eccca gittreestate: clean builddate: compiler: gc platform: linux which chart? what's the chart version? what happened? the newly added staticprefix parameter under extraargs breaks the chart when used because it tries to add an extra argument to the server command that doesnt exist. what you expected to happen? how to reproduce it? enter the changed values of enter the command that you execute and failing helm install anything else we need to know? am just creating pull request to address this in bit different way and havent tested it yet. just wanted to create request to highlight solution. you could also handle the staticprefix as separate argument in the extraenv when starting up the server to make this work smoother for final user, but this solution should work as well.",
          "Title: migration job should run before upgrade; Content: describe the bug clear and concise description of what the bug is. when trying to install chart i'm trying to migrate from old version to the new one. i'm using value for that. but pod failed to start with error: from the looks of things migration job should have hooks instead of but can be wrong here. running job from the chart manually with kubectl fixed this issue for me, but it will probably appear with the next release. thanks! what's your helm version? what's your kubectl version? which chart? what's the chart version? what happened? what you expected to happen? db migration job should run before pod upgrade. how to reproduce it? install with old db schema try to upgrade with helm chart enter the changed values of enter the command that you execute and failing helm upgrade install values wait create namespace atomic timeout shared services anything else we need to know? chart was installed as part of another umbrella chart",
          "Title: model artifacts not saved in remote artifact store; Content: describe the bug clear and concise description of what the bug is. have local minikube cluster. installed the helm chart with some changed settings. see below for the changed values. everthing else is same as per default values yaml file. for db backend am using and for storage minio instance. also have created initial bucket named in minio. and then created simple pod to run the simple training example from docs. this pod has env variables set as is the link to that code. can see the metadata about the model in ui however artifact section in ui is empty and also the bucket is empty. what's your helm version? gitcommit: ceeda cd gittreestate: clean what's your kubectl version? server version: minor: gitcommit: ab cff eccca gittreestate: clean builddate: compiler: gc platform: linux which chart? what's the chart version? latest what happened? what you expected to happen? would expect the artifacts in minio bucket. how to reproduce it? install the helm chart with minio and postgresql config. run simple exmple frpom docs. enter the changed values of enter the command that you execute and failing helm install release community charts values anything else we need to know?",
          "Title: project operator image tag is set to latest Content:on chart release the default value for is set to latest when it should be set to check",
          "Title: run chart testing step returns error validating maintainer not found error; Content: describe the bug clear and concise description of what the bug is. when we open pull request, chart testing step in file getting the following error. because of maintainer name for the command must be github username rather than real name. what's your helm version? what's your kubectl version? which chart? what's the chart version? what happened? what you expected to happen? how to reproduce it? enter the changed values of enter the command that you execute and failing ct lint debug config lint conf anything else we need to know?",
          "Title: custom training job error: unable to locate Content: what steps did you take: run custom image using the training operator and it ran fine. am using and the objects from are being correctly copied over to the specified local channel path. the problem arises however if inside the custom script use boto to manually download an object from then get an error: unable to locate credentials what happened: below is copy of the component's logs notice the very first log statement says that the boto credentials are found in environment variables but somehow they never make their way to the boto client that is instantiated inside the custom image what did you expect to happen: would have expected the credentials to be passed to the image that the training operator is running but it is not the case environment: how did you deploy kubeflow pipelines deployed kubeflow pipelines as part of my kubeflow deployment on aws eks: kfp version: build commit: kfp sdk version: bug",
          "Title: use port name instead of port number in servicemonitor Content: describe the bug clear and concise description of what the bug is. first of all, thanks to everyone creating this helm chart as it is really good and easy to use. however, encountered problem when choosing to include servicemonitor and prometheus metrics along the deployment. generally, the created servicemonitor for is correct, yet in the current form it does not work for me. use the latest prometheus deployed using the official helm chart and the metrics did not show up in the targets, yet it was visible in service discovery panel in prometheus dashboard, but appeared as after couple of hours of educated debugging changed manually the to in the deployed servicemonitor manifest. it worked straightaway! what propose is simple fix: according to official prometheus troubleshooting docs the port specified in servicemonitor should use instead of port number simple fix would be to change to in port name is already hardcoded, so can be used directly or new parameter could be introduced to give the freedom to choose port name. am aware that port number of type integer should also what's your helm version? what's your kubectl version? which chart? what's the chart version? what happened? what you expected to happen? how to reproduce it? enter the changed values of enter the command that you execute and failing helm install namespace tracking server community charts set anything else we need to know?",
          "Title: deployments create can fail Content: describe the bug for some reason, can fail unexpectedly. fix is to delete the pod and start over. steps to reproduce bug follow steps in expected behavior successful deployment as described at environment overview environment location: launchpad method of morpheus install: kubernetes environment details launchpad helm deployment on unfortunately, unable to capture the output from ipykernel there. additional context sqlite db likely gets corrupted or otherwise confused possibly an issue in tritonclient? triton logging complains about unable to read",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_chart_port_upgrade",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "12_chart_port_upgrade"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.34840726852417,
          7.349344253540039,
          7.209868431091309,
          7.691551685333252,
          7.465732097625732,
          6.979579448699951,
          7.377162456512451,
          7.216369152069092,
          7.329751968383789
         ],
         "y": [
          2.4542462825775146,
          2.431720018386841,
          2.3455843925476074,
          2.514295816421509,
          2.488534688949585,
          2.2493162155151367,
          2.4325196743011475,
          2.3651773929595947,
          2.4101743698120117
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: init displays wrong sucess message when the env folder does not exist; Content: description when running success message is displayed even if the env xxx folder does not exist, instead of an error message. we should move this code inside the try block above.",
          "Title: make init work when configuration is in Content: description since project can instead of at the root of the projects. this breaks the command which is only compatible with configuration file. context we should remove the util function in and use as suggested in beware: this will break retrocompatibilty and work only with steps to reproduce launch with no config file in your project but valid expected result the file should be created actual result an error is raised.",
          "Title: servername and url not found by calling cc run Content: describe the bug if the file is created with whitespaces cc cann't read the config file. to reproduce create file like this: remote url true additional context faice cc",
          "Title: cc init just take three letters for the folder name?; Content:call cc init just takes the first three letters of the repo name??? here you can enter the folder where you want to store the files on the storage server. the remote folder that you want use the username with that you can access the storage server",
          "Title: running from examples after install needs directory Content:after installing graphnet from scratch and signing up to running from examples yields the following error: which can be fixed by creating folder called in the place where you are running the file from. would it make sense to automatically create such folder, if it is not already present?",
          "Title: init displays wrong sucess message when the env folder does not exist; Content: description when running success message is displayed even if the env xxx folder does not exist, instead of an error message. we should move this code inside the try block above.",
          "Title: and git services don't correctly detect the repo root directory; Content:it seems they both assume that the current working dir is where they can find the and dirs. we should correctly detect those paths, as it affects all our logic to automatically init on behalf of the user. relevant resources:",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_init_cc_folder",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "13_init_cc_folder"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.291165828704834,
          7.362874984741211,
          7.277492046356201,
          7.144840240478516,
          7.02869987487793,
          7.260382175445557,
          7.029453277587891,
          7.199272632598877
         ],
         "y": [
          4.583032131195068,
          4.616175651550293,
          4.538851261138916,
          4.458534240722656,
          4.376914978027344,
          4.527003765106201,
          4.338076591491699,
          4.491226673126221
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: pip install fails on Content: system specs operating system: windows python version: bit when run the command: get an error during the installation, specifically on the package. guess the first question have is there any reason we are restricted to that specific version of was able to install the latest version no problem, so if we could use later version that would be the easiest fix. partial log full log",
          "Title: pip installing datasets causes different dependencies to installing Content: description installing installs different set of dependencies than it appears that is installing the superset of requirements for all datasets. context this is currently blocking steps to reproduce compare the requirements",
          "Title: pip install breaks on studio; Content: system info who can help? information the official example scripts my own modified scripts tasks an officially supported task in the folder my own task or dataset reproduction open an sm studio notebook run the following cell: the obvious workaround for now is expected behavior",
          "Title: install as pip wheel in Content: description in you copy the whole directory in order to make use of the this is bit cumbersome and unecesarily copies things around. you can create pip wheel package of your and add it as dependency see here",
          "Title: pip install stepfunctions fails in studio notebook; Content: what did you do? pip install stepfunctions fails in studio notebook notebook is using the python kernel. reproduction steps pip install stepfunctions what did you expect to happen? expected to be able to install aws stepfunctions. what actually happened? cryptographydeprecationwarning: is deprecated, use instead from import cryptographydeprecationwarning: is deprecated, use instead from import collecting stepfunctions using cached preparing metadata error error: subprocess exited with error python did not run successfully. exit code: userwarning: usage of dash separated 'description file' will not be supported in future versions. please use the underscore name instead traceback file line in file line in file line in ipython file line in setup return file line in setup distribution dist klass file line in for k, in file line in file line in for ep in sorted file line in loaded map filtered) file line in load return attrs, module) attributeerror: type object 'distribution' has no attribute note: this error originates from subprocess, and is likely not problem with pip. error: metadata generation failed encountered error while generating package metadata. see above for output. note: this is an issue with the package mentioned above, not pip. hint: see above for details. environment aws step functions data science python sdk version python version: other this is :bug: bug report",
          "Title: markdown in install prompt isn't rendered as markdown; Content: pip install",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "14_install_line_metadata",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "14_install_line_metadata"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.064678192138672,
          5.119938850402832,
          5.121013164520264,
          5.066797733306885,
          5.270080089569092,
          5.125008583068848,
          5.127919673919678
         ],
         "y": [
          1.3472225666046143,
          1.382474660873413,
          1.411534070968628,
          1.349873661994934,
          1.3426035642623901,
          1.390949010848999,
          1.3707762956619263
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: typeerror: deploy model when am trying to update the endpoint that already exists piece of code used to update the endpoint. deploy the pipeline prediction compiling the pipeline what happened: am getting this error typeerror: deploy model file line in file line in compile file line in workflow file line in workflow file line in prediction got an unexpected keyword argument what did you expect to happen: to update the endpoint without any issue environment: using kfp how did you deploy kubeflow pipelines kfp version: kfp sdk version: anything else you would like to add: please help me out bug",
          "Title: operator types fails kubebuilder pattern validation check; Content: what happened operator types, when included as part of kubebuilder custom crd definition fail due to validation errors of unescaped regex patterns. what you expected to happen kubebuilder should generate crd specification which includes aws operator types how to reproduce it anything else we need to know? tried copying the above types and escaped the regex pattern with quotes and everything worked environment kubernetes version :version: gitcommit: abeb edf ca aa builddate: goos: unknown goarch: unknown operator version os kernel installation method: others:",
          "Title: kubeflow pipeline running with aws throws an error passing mean and parameters; Content:hi, have copied the git code for aws to execute through the kubeflow pipeline while executing the kubeflow pipeline, am getting the error of assigning the hyperparameters, although in pipeline parameters there are no such parameters define. error: training failed with the following error: clienterror: no value were specified for 'k', which are required hyperparameter pipeline parameters are: .pipeline def please let me know why this error is appeared and how should it get resolved regards, varun",
          "Title: error building types due to missing types in common Content: what happened error building types due to missing types in common afccd :example nj$ make all go: creating new module tmp go: found in go fmt go vet undefined make: error what you expected to happen packaged types refer to types in which are missing how to reproduce it import of types in go client fails build import anything else we need to know? environment kubernetes version operator version os kernel installation method: others:",
          "Title: want to create any model and do batch transform in without training in Content: what steps did you take: removed the hpo and training jobs only creating the model and batch transforming in what happened: getting output properly in kubefow. but want to to see custom model output without hpo and model training in what did you expect to happen: without hpo and batch job in anything else you would like to add: any open source loan data model using kf would be appriciated bug",
          "Title: can not compile examples; Content:trying our your kubeflow notebook in your workshop and received pipeline compile error.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "15_kubeflow_parameters_batch",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "15_kubeflow_parameters_batch"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.599271297454834,
          6.610040187835693,
          6.716378688812256,
          6.648778438568115,
          6.7065839767456055,
          6.860385894775391,
          6.690239429473877
         ],
         "y": [
          2.2394633293151855,
          2.3159730434417725,
          2.2387735843658447,
          2.156322956085205,
          2.197547674179077,
          2.096763849258423,
          2.2074739933013916
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: warning message appears when calling Content:the warning cls that the project is not initialised yet, and that you must call before calling any command while you are calling it can be safely ignored because the command works as intended. this bug is due to the dynamic creation of command.",
          "Title: use the working directory instead of given path when called within Content:this may lead to strange behaviour when called in interactive mode in another place thant the project root.",
          "Title: warning message about hyperdrive loading with providers; Content:if you run any command that uses it prints out this strange warning message: expected behavior no warning message should be printed. steps to reproduce the issue from latest master branch in fresh virtualenv run: observe the warning message above. environment details: os: macos ml version: master branch rev fe fc efde afbfb python version:",
          "Title: resume error in Content:forgot to create an issue in recent days. when tested with argument in encountered this error. here's the log: guess because of the arg is both repeated in and maybe it also happens with",
          "Title: translate is trying to use even though it was not requested. preventing translation on local Content:i tried to translate with the following command line and trace. the command is meant to run locally, but there is an error about credentials. the argument was not set in the command line.",
          "Title: warning message appears when calling Content:the warning cls that the project is not initialised yet, and that you must call before calling any command while you are calling it can be safely ignored because the command works as intended. this bug is due to the dynamic creation of command.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "16_warning_calling_command",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "16_warning_calling_command"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.696258068084717,
          7.784241199493408,
          7.5677385330200195,
          7.69439697265625,
          7.709146976470947,
          7.682508945465088,
          7.689048767089844
         ],
         "y": [
          4.829841613769531,
          4.808473110198975,
          4.760594844818115,
          4.7900238037109375,
          4.78080415725708,
          4.760494709014893,
          4.788372039794922
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Title: error with in lambda Content: describe the bug when making the natural deployment of the framework, and deploying the framework, there is an error related to numpy in the lambda of createmodel when run the pipeline from scratch. the error is: to reproduce the only steps took was to unfold it as it naturally comes. this bug prevented me from creating model for both the batch and realtime pipelines. expected behavior the ideal and expected behavior is that this error does not occur and you can create the model. solution to that moment try to fix the numpy versions issue by re creating the layer, via pip installation of the libraries. however, there were conflicts with other modified libraries at the time of for this reason, had to choose to use the default aws library that comes with numpy awslambda python scipy for this, had to modify the code as follows: in add the layer: arn:aws:lambda:us east :layer:awslambda python scipy x: with this, stop throwing that error at me. think it is likely that due to library or version incompatibility issues, this error is by default in the mlops framework solution. please check if it still exists in the new versions. please complete the following information about the solution: version: to get the version of the solution, you can look at the description of the created cloudformation stack. for example, aws mlops framework. version region: was the solution modified from the version published on this repository? no if the answer to the previous question was yes, are the changes available on github? have you checked your for the sevices this solution uses? were there any errors in the cloudwatch logs? yes additional context am solution architect of an advanced aws partner company, and we are running proof of concept with real client.",
          "Title: unable to start dfp production server; Content: version which installation method does this occur on? docker describe the bug. unable to start the server when using but it works fine with downgrading version to works fine. minimum reproducible example relevant log output full env printout other code of conduct agree to follow morpheus' code of conduct have searched the and have found no duplicates for this bug report",
          "Title: endpoint fail to deploy or time out server error bug; Content:invoke endpoint response time out. reproduction steps instancetype timeoutinseconds error log in inference lambda cloudwatch: task timed out after seconds in training cloudwatch: main loading initial models: main etag ff de bed fb bc fe ff main model model loaded. main initialize inference server with: epollserversocketchannel. main inference api bind to: main initialize metrics server with: epollserversocketchannel. main metrics api bind to: model server started. stdout listening on port: stdout stdout torch worker started. stdout python runtime: connecting to: stdout connection accepted: pool thread pool thread pool thread pool thread pool thread pool thread pool thread stdout setting the default backend to pytorch you can change it in the file or export the dglbackend environment variable. valid options are: pytorch, mxnet, tensorflow stdout loading model stdout backend worker process died. stdout traceback stdout file line in stdout stdout file line in stdout stdout file line in stdout service, result, code stdout file line in stdout service handler, gpu, stdout file line in load stdout stdout file line in initialize stdout stdout file line in initialize stdout stdout file line in stdout stdout file line in stdout stdout file line in stdout stdout runtimeerror: error in loading for heterorgcn: stdout size mismatch for copying param with shape ]) from checkpoint, the shape in current model is ]). stdout size mismatch for copying param with shape from checkpoint, the shape in current model is stdout size mismatch for copying param with shape ]) from checkpoint, the shape in current model is ]). stdout size mismatch for copying param with shape from checkpoint, the shape in current model is stdout size mismatch for copying param with shape ]) from checkpoint, the shape in current model is ]). stdout size mismatch for copying param with shape from checkpoint, the shape in current model is environment cdk cli version: framework version: version: os other cause of this bug: backend worker process died. endpoint deployment code and model training code parameter conflict on hidden and this is :bug: bug report",
          "Title: endpoint prediction error, deadline exceeded; Content: environment details os: mac pro version: npm version: version: steps to reproduce i've run this demo on my local computer: the process paused and shows in the line: thanks!",
          "Title: renaming of mxnet model server in inference package causing entrypoint with command to fail; Content: describe the bug recently released which included updating the name of the model server artifact and command from to all containers defined in this repository install as dependency of this repo itself, on lines and this repo's has an which includes as result, installed. so while the 's value will succeed, attempts to use the with as build arg will fail with message: to reproduce build any container mount model and into expected behavior tensorflow serving serves the mounted model system information description of your system. please provide: toolkit version but should apply to all versions framework version but should apply to all versions python version cpu or gpu cpu, but should apply to both custom docker image",
          "Title: bug: failed to containerize when using Content:trying to integrate with my current bentoml workflow and following this example but getting error when try to deploy model with docker, when run to reproduce bug recreation steps: clone the repo goto the folder works fine` environment bentoml version python version docker engine",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "17_checkpoint_param_docker",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "17_checkpoint_param_docker"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.000118732452393,
          6.443912506103516,
          6.237293243408203,
          6.163473129272461,
          6.352800369262695,
          6.447942733764648,
          6.274256229400635
         ],
         "y": [
          2.1141436100006104,
          1.7215313911437988,
          1.9080817699432373,
          1.9574209451675415,
          1.7400121688842773,
          1.7308862209320068,
          1.8620127439498901
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": 3.996490168571472,
          "y": 2.4097633689641955,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 7.819551432132721,
          "xshift": 10,
          "y": 6.320408010482788
         }
        ],
        "height": 750,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 7.819551432132721,
          "x1": 7.819551432132721,
          "y0": -1.5008812725543976,
          "y1": 6.320408010482788
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": 3.996490168571472,
          "x1": 11.64261269569397,
          "y0": 2.4097633689641955,
          "y1": 2.4097633689641955
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Documents and Topics",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "workspace_connect_stopped_screenshots_swb",
          "",
          "",
          "lab_jupyter_cloning_study_conda"
         ],
         "type": "scatter",
         "x": [
          0,
          1.0788071581428604,
          1.0788071581428604,
          0
         ],
         "xaxis": "x",
         "y": [
          -15,
          -15,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "azure_import_terminal_extension_ml",
          "",
          "",
          "install_line_metadata_markdown_bit"
         ],
         "type": "scatter",
         "x": [
          0,
          1.3061407200038024,
          1.3061407200038024,
          1.0788071581428604
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -20,
          -20
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "aws_request_cluster_study_unable",
          "",
          "",
          "title_comments_node_limit_classification"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1427105397511885,
          1.1427105397511885,
          0
         ],
         "xaxis": "x",
         "y": [
          -35,
          -35,
          -45,
          -45
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pytorch_loss_training_gpu_results",
          "",
          "",
          "experiment_model_exception_resume_uri"
         ],
         "type": "scatter",
         "x": [
          0,
          1.0492116474711777,
          1.0492116474711777,
          0
         ],
         "xaxis": "x",
         "y": [
          -55,
          -55,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "aws_content_title_request_limit",
          "",
          "",
          "experiment_logging_pytorch_exception_resume"
         ],
         "type": "scatter",
         "x": [
          1.0492116474711777,
          1.071009702947564,
          1.071009702947564,
          0
         ],
         "xaxis": "x",
         "y": [
          -60,
          -60,
          -75,
          -75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "checkpoint_param_docker_line_numpy",
          "",
          "",
          "experiment_title_aws_behavior_pytorch"
         ],
         "type": "scatter",
         "x": [
          1.1427105397511885,
          1.4266481653251804,
          1.4266481653251804,
          1.071009702947564
         ],
         "xaxis": "x",
         "y": [
          -40,
          -40,
          -67.5,
          -67.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "text": [
          "experiment_aws_title_error_pytorch",
          "",
          "",
          "models_reproducible_branch_checked_pandas"
         ],
         "type": "scatter",
         "x": [
          0,
          0.9849709930862837,
          0.9849709930862837,
          0
         ],
         "xaxis": "x",
         "y": [
          -95,
          -95,
          -105,
          -105
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "azure_import_notebook_installing_line",
          "",
          "",
          "model_experiment_aws_installed_training"
         ],
         "type": "scatter",
         "x": [
          0.9849709930862837,
          1.1060143579081545,
          1.1060143579081545,
          0
         ],
         "xaxis": "x",
         "y": [
          -100,
          -100,
          -115,
          -115
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "kubeflow_parameters_batch_deploy_kfp",
          "",
          "",
          "chart_port_upgrade_minio_db"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1749497894690684,
          1.1749497894690684,
          1.1060143579081545
         ],
         "xaxis": "x",
         "y": [
          -85,
          -85,
          -107.5,
          -107.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "text": [
          "version_title_experiment_error_python",
          "",
          "",
          "chart_types_kubeflow_kfp_changed"
         ],
         "type": "scatter",
         "x": [
          0,
          0.9035277730307956,
          0.9035277730307956,
          0
         ],
         "xaxis": "x",
         "y": [
          -135,
          -135,
          -145,
          -145
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "workspace_browser_screenshots_swb_jupyter",
          "",
          "",
          "version_title_error_aws_chart"
         ],
         "type": "scatter",
         "x": [
          0,
          1.1307266594343963,
          1.1307266594343963,
          0.9035277730307956
         ],
         "xaxis": "x",
         "y": [
          -125,
          -125,
          -140,
          -140
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pipeline_catalog_plugin_artifacts_datasets",
          "",
          "",
          "project_cli_port_does_arguments"
         ],
         "type": "scatter",
         "x": [
          1.1307266594343963,
          1.1761229463498655,
          1.1761229463498655,
          0
         ],
         "xaxis": "x",
         "y": [
          -132.5,
          -132.5,
          -155,
          -155
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "run_ui_pipeline_tests_fails",
          "",
          "",
          "project_cli_pipeline_version_ui"
         ],
         "type": "scatter",
         "x": [
          1.1749497894690684,
          1.345233869230329,
          1.345233869230329,
          1.1761229463498655
         ],
         "xaxis": "x",
         "y": [
          -96.25,
          -96.25,
          -143.75,
          -143.75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pull_artifact_repo_image_bucket",
          "",
          "",
          "init_cc_folder_success_examples"
         ],
         "type": "scatter",
         "x": [
          1.4266481653251804,
          1.473178464603269,
          1.473178464603269,
          1.345233869230329
         ],
         "xaxis": "x",
         "y": [
          -53.75,
          -53.75,
          -120,
          -120
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "init_storage_cc_remote_pull",
          "",
          "",
          "warning_calling_command_branch_days"
         ],
         "type": "scatter",
         "x": [
          0,
          1.0823354788968282,
          1.0823354788968282,
          0
         ],
         "xaxis": "x",
         "y": [
          -165,
          -165,
          -175,
          -175
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "pipeline_project_catalog_cli_steps",
          "",
          "",
          "warning_init_cc_remote_repo"
         ],
         "type": "scatter",
         "x": [
          1.473178464603269,
          1.515528023003211,
          1.515528023003211,
          1.0823354788968282
         ],
         "xaxis": "x",
         "y": [
          -86.875,
          -86.875,
          -170,
          -170
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "text": [
          "version_error_title_aws_workspace",
          "",
          "",
          "project_pipeline_folder_cc_remote"
         ],
         "type": "scatter",
         "x": [
          1.3061407200038024,
          1.6037957409570884,
          1.6037957409570884,
          1.515528023003211
         ],
         "xaxis": "x",
         "y": [
          -12.5,
          -12.5,
          -128.4375,
          -128.4375
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "aws_content_title_request_limit",
          "checkpoint_param_docker_line_numpy",
          "azure_import_notebook_installing_line",
          "pipeline_catalog_plugin_artifacts_datasets",
          "run_ui_pipeline_tests_fails",
          "pull_artifact_repo_image_bucket",
          "pipeline_project_catalog_cli_steps",
          "version_error_title_aws_workspace"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.0492116474711777,
          1.1427105397511885,
          0.9849709930862837,
          1.1307266594343963,
          1.1749497894690684,
          1.4266481653251804,
          1.473178464603269,
          1.3061407200038024
         ],
         "y": [
          -60,
          -40,
          -100,
          -132.5,
          -96.25,
          -53.75,
          -86.875,
          -12.5
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "install_line_metadata_markdown_bit",
          "experiment_title_aws_behavior_pytorch",
          "chart_port_upgrade_minio_db",
          "version_title_error_aws_chart",
          "project_cli_pipeline_version_ui",
          "init_cc_folder_success_examples",
          "warning_init_cc_remote_repo",
          "project_pipeline_folder_cc_remote"
         ],
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.0788071581428604,
          1.071009702947564,
          1.1060143579081545,
          0.9035277730307956,
          1.1761229463498655,
          1.345233869230329,
          1.0823354788968282,
          1.515528023003211
         ],
         "y": [
          -20,
          -67.5,
          -107.5,
          -140,
          -143.75,
          -120,
          -170,
          -128.4375
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 470,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -180,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "16_warning_calling_command",
          "13_init_cc_folder",
          "4_pull_artifact_repo",
          "12_chart_port_upgrade",
          "15_kubeflow_parameters_batch",
          "7_project_cli_port",
          "8_pipeline_catalog_plugin",
          "9_run_ui_pipeline",
          "6_models_reproducible_branch",
          "0_pytorch_loss_training",
          "2_experiment_model_exception",
          "17_checkpoint_param_docker",
          "5_azure_import_terminal",
          "1_title_comments_node",
          "3_aws_request_cluster",
          "14_install_line_metadata",
          "11_lab_jupyter_cloning",
          "10_workspace_connect_stopped"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125,
          -135,
          -145,
          -155,
          -165,
          -175
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.028049928264447545,
          0.03171754167692014,
          0.04495268262126179,
          0.0506960697433753,
          0.06627645445357479
         ],
         "xaxis": "x",
         "y": [
          "results  ",
          "gpu  ",
          "training  ",
          "loss  ",
          "pytorch  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.026279548192406813,
          0.03167216160277933,
          0.03672973554483777,
          0.03821639282484869,
          0.04456754832045289
         ],
         "xaxis": "x2",
         "y": [
          "classification  ",
          "limit  ",
          "node  ",
          "comments  ",
          "title  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.036761870587323144,
          0.05747816103734059,
          0.06033408924239925,
          0.07634808977466005,
          0.12209996632567485
         ],
         "xaxis": "x3",
         "y": [
          "uri  ",
          "resume  ",
          "exception  ",
          "model  ",
          "experiment  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.03078121455138713,
          0.03302500760326138,
          0.03571507928535231,
          0.05000863282614906,
          0.0846826724333857
         ],
         "xaxis": "x4",
         "y": [
          "unable  ",
          "study  ",
          "cluster  ",
          "request  ",
          "aws  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.04853631993191595,
          0.05091820646692371,
          0.057194882717881826,
          0.059197359101572075,
          0.08720678814508843
         ],
         "xaxis": "x5",
         "y": [
          "bucket  ",
          "image  ",
          "repo  ",
          "artifact  ",
          "pull  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.05095064602464138,
          0.07874680264529113,
          0.08454472832976302,
          0.09434041822516426,
          0.12997317102679207
         ],
         "xaxis": "x6",
         "y": [
          "ml  ",
          "extension  ",
          "terminal  ",
          "import  ",
          "azure  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.051151385754374994,
          0.06302456306114197,
          0.06451542016838689,
          0.0709549099165549,
          0.08118811668361803
         ],
         "xaxis": "x7",
         "y": [
          "pandas  ",
          "checked  ",
          "branch  ",
          "reproducible  ",
          "models  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.05635905894035695,
          0.05642042289025008,
          0.06461908504451651,
          0.09388261196417293,
          0.13124325245706583
         ],
         "xaxis": "x8",
         "y": [
          "arguments  ",
          "does  ",
          "port  ",
          "cli  ",
          "project  "
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_pytorch_loss_training",
          "1_title_comments_node",
          "2_experiment_model_exception",
          "3_aws_request_cluster",
          "4_pull_artifact_repo",
          "5_azure_import_terminal",
          "6_models_reproducible_branch",
          "7_project_cli_port",
          "8_pipeline_catalog_plugin",
          "9_run_ui_pipeline",
          "10_workspace_connect_stopped",
          "11_lab_jupyter_cloning",
          "12_chart_port_upgrade",
          "13_init_cc_folder",
          "14_install_line_metadata",
          "15_kubeflow_parameters_batch",
          "16_warning_calling_command",
          "17_checkpoint_param_docker"
         ],
         "xaxis": "x",
         "y": [
          "0_pytorch_loss_training",
          "1_title_comments_node",
          "2_experiment_model_exception",
          "3_aws_request_cluster",
          "4_pull_artifact_repo",
          "5_azure_import_terminal",
          "6_models_reproducible_branch",
          "7_project_cli_port",
          "8_pipeline_catalog_plugin",
          "9_run_ui_pipeline",
          "10_workspace_connect_stopped",
          "11_lab_jupyter_cloning",
          "12_chart_port_upgrade",
          "13_init_cc_folder",
          "14_install_line_metadata",
          "15_kubeflow_parameters_batch",
          "16_warning_calling_command",
          "17_checkpoint_param_docker"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           0.659267370399582,
           0.6499365997177234,
           0.6432552123665336,
           0.590692002240213,
           0.6734458089689501,
           0.6210699752725024,
           0.6070374125358136,
           0.6692779908588842,
           0.678521314478382,
           0.6433705602736752,
           0.682731968937909,
           0.5796156297050159,
           0.6401107479830972,
           0.6151911210808205,
           0.6601736440240573,
           0.6124288707152576,
           0.6508252077939268
          ],
          [
           0.659267370399582,
           1.0000000000000002,
           0.7271340168612341,
           0.6448302482272934,
           0.6778601887628528,
           0.6527133598648543,
           0.6649564830970297,
           0.6952352940060351,
           0.6775186001745552,
           0.6800488501035735,
           0.6420270760589069,
           0.6320260940780448,
           0.6095659152942733,
           0.670282879297312,
           0.6677299695775533,
           0.6575150225146246,
           0.6918393176293872,
           0.6834236787823114
          ],
          [
           0.6499365997177234,
           0.7271340168612341,
           0.9999999999999997,
           0.5975334175768028,
           0.6452327707231436,
           0.5924274134809044,
           0.661171479938445,
           0.6369622478319461,
           0.6643051208471974,
           0.7159110891596852,
           0.6072404324194786,
           0.6865485361138928,
           0.5671108066439102,
           0.6050360315003784,
           0.6124760192352746,
           0.6209179345356252,
           0.639479500003642,
           0.6108260697464507
          ],
          [
           0.6432552123665336,
           0.6448302482272934,
           0.5975334175768028,
           0.9999999999999992,
           0.6455213395483708,
           0.744322973415924,
           0.6391186372781504,
           0.632605591480145,
           0.6382696724607316,
           0.6361049256326657,
           0.677843993666024,
           0.6893071579415828,
           0.6132174645895091,
           0.6278338988235859,
           0.6067255090591467,
           0.65957954089239,
           0.6030914034234135,
           0.637702283867055
          ],
          [
           0.590692002240213,
           0.6778601887628528,
           0.6452327707231436,
           0.6455213395483708,
           0.9999999999999996,
           0.6571643387560615,
           0.6832554302029545,
           0.6741016964318773,
           0.7087770211175395,
           0.667180948433327,
           0.602233682077962,
           0.6124119944147132,
           0.6543669105017489,
           0.6610164346334368,
           0.6372956542630439,
           0.6126690261924794,
           0.6480090032635795,
           0.6250743734958553
          ],
          [
           0.6734458089689501,
           0.6527133598648543,
           0.5924274134809044,
           0.744322973415924,
           0.6571643387560615,
           1,
           0.6783035586192521,
           0.7308889654096937,
           0.7206439727849934,
           0.6772315113335351,
           0.6811777983409392,
           0.7249643688262809,
           0.6466618871690386,
           0.66437734122732,
           0.6984190517182831,
           0.658992291548747,
           0.5935883040767916,
           0.7327593874611198
          ],
          [
           0.6210699752725024,
           0.6649564830970297,
           0.661171479938445,
           0.6391186372781504,
           0.6832554302029545,
           0.6783035586192521,
           0.9999999999999999,
           0.6836979984791876,
           0.750202940034824,
           0.7116391775430448,
           0.6425994448441166,
           0.6621917947092222,
           0.6588219573481735,
           0.641351304743174,
           0.6571324791215396,
           0.6450641636164003,
           0.6458384296102883,
           0.6609810910144399
          ],
          [
           0.6070374125358136,
           0.6952352940060351,
           0.6369622478319461,
           0.632605591480145,
           0.6741016964318773,
           0.7308889654096937,
           0.6836979984791876,
           0.9999999999999998,
           0.7250272453559226,
           0.697230419897276,
           0.6989625363076656,
           0.6977148641190181,
           0.620211015089255,
           0.6951469611170479,
           0.7214251564931251,
           0.6395786627634313,
           0.6623095483181283,
           0.7062632442487506
          ],
          [
           0.6692779908588842,
           0.6775186001745552,
           0.6643051208471974,
           0.6382696724607316,
           0.7087770211175395,
           0.7206439727849934,
           0.750202940034824,
           0.7250272453559226,
           1,
           0.7796077927335088,
           0.6517028403911358,
           0.6780750607456746,
           0.6943188481677622,
           0.6481327135412422,
           0.7164181284296608,
           0.6965900493639442,
           0.594420525952224,
           0.6956508320653229
          ],
          [
           0.678521314478382,
           0.6800488501035735,
           0.7159110891596852,
           0.6361049256326657,
           0.667180948433327,
           0.6772315113335351,
           0.7116391775430448,
           0.697230419897276,
           0.7796077927335088,
           1.0000000000000004,
           0.6703816692828165,
           0.6620383016291076,
           0.6453792266474919,
           0.6454244436100344,
           0.6968847931997408,
           0.6677668494300025,
           0.6486509637207667,
           0.6479364286769818
          ],
          [
           0.6433705602736752,
           0.6420270760589069,
           0.6072404324194786,
           0.677843993666024,
           0.602233682077962,
           0.6811777983409392,
           0.6425994448441166,
           0.6989625363076656,
           0.6517028403911358,
           0.6703816692828165,
           1.0000000000000004,
           0.6743788684436152,
           0.6231721618084235,
           0.6817873491532236,
           0.6360434868168606,
           0.6115811100120572,
           0.6242704227385208,
           0.6408244099910505
          ],
          [
           0.682731968937909,
           0.6320260940780448,
           0.6865485361138928,
           0.6893071579415828,
           0.6124119944147132,
           0.7249643688262809,
           0.6621917947092222,
           0.6977148641190181,
           0.6780750607456746,
           0.6620383016291076,
           0.6743788684436152,
           0.9999999999999993,
           0.5824779775411096,
           0.6237037160410854,
           0.6145131965422136,
           0.6245726874445432,
           0.5813863489724775,
           0.654188201503483
          ],
          [
           0.5796156297050159,
           0.6095659152942733,
           0.5671108066439102,
           0.6132174645895091,
           0.6543669105017489,
           0.6466618871690386,
           0.6588219573481735,
           0.620211015089255,
           0.6943188481677622,
           0.6453792266474919,
           0.6231721618084235,
           0.5824779775411096,
           1.0000000000000002,
           0.556195345565558,
           0.6435241637652263,
           0.6486559901962972,
           0.5887954477006605,
           0.6230689246536455
          ],
          [
           0.6401107479830972,
           0.670282879297312,
           0.6050360315003784,
           0.6278338988235859,
           0.6610164346334368,
           0.66437734122732,
           0.641351304743174,
           0.6951469611170479,
           0.6481327135412422,
           0.6454244436100344,
           0.6817873491532236,
           0.6237037160410854,
           0.556195345565558,
           1.0000000000000004,
           0.668850445891414,
           0.6022926352618118,
           0.636921363494587,
           0.6561527635798731
          ],
          [
           0.6151911210808205,
           0.6677299695775533,
           0.6124760192352746,
           0.6067255090591467,
           0.6372956542630439,
           0.6984190517182831,
           0.6571324791215396,
           0.7214251564931251,
           0.7164181284296608,
           0.6968847931997408,
           0.6360434868168606,
           0.6145131965422136,
           0.6435241637652263,
           0.668850445891414,
           1.0000000000000004,
           0.5959350456074578,
           0.6059349145022681,
           0.6935761052755658
          ],
          [
           0.6601736440240573,
           0.6575150225146246,
           0.6209179345356252,
           0.65957954089239,
           0.6126690261924794,
           0.658992291548747,
           0.6450641636164003,
           0.6395786627634313,
           0.6965900493639442,
           0.6677668494300025,
           0.6115811100120572,
           0.6245726874445432,
           0.6486559901962972,
           0.6022926352618118,
           0.5959350456074578,
           1,
           0.6252054843617644,
           0.7491950700869356
          ],
          [
           0.6124288707152576,
           0.6918393176293872,
           0.639479500003642,
           0.6030914034234135,
           0.6480090032635795,
           0.5935883040767916,
           0.6458384296102883,
           0.6623095483181283,
           0.594420525952224,
           0.6486509637207667,
           0.6242704227385208,
           0.5813863489724775,
           0.5887954477006605,
           0.636921363494587,
           0.6059349145022681,
           0.6252054843617644,
           1.0000000000000004,
           0.611709174046316
          ],
          [
           0.6508252077939268,
           0.6834236787823114,
           0.6108260697464507,
           0.637702283867055,
           0.6250743734958553,
           0.7327593874611198,
           0.6609810910144399,
           0.7062632442487506,
           0.6956508320653229,
           0.6479364286769818,
           0.6408244099910505,
           0.654188201503483,
           0.6230689246536455,
           0.6561527635798731,
           0.6935761052755658,
           0.7491950700869356,
           0.611709174046316,
           1.0000000000000002
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertext": "<b>Topic -1</b>:variable_job_script_add_upload_exp",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.5476172984708723,
          -1.5790486037499698,
          -1.6395139943202428,
          -1.6639704184926605,
          -1.6649304278019106,
          -1.6720207717633493,
          -1.728136916283757,
          -1.7963191422690432,
          -1.7995062203773482,
          -1.812521969371954
         ]
        },
        {
         "hovertext": "<b>Topic 0</b>:pytorch_loss_training_gpu_results_t",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.1786407327879178,
          -1.295025708416701,
          -1.3472443859586205,
          -1.4987004807971118,
          -1.5520682450814178,
          -1.6402374599928762,
          -1.6460042427911912,
          -1.6857215099503586,
          -1.7243099143690597,
          -1.7282161820589574
         ]
        },
        {
         "hovertext": "<b>Topic 1</b>:title_comments_node_limit_classific",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.350981255978539,
          -1.4177503076052935,
          -1.4349821985763271,
          -1.4993222953232843,
          -1.5803821055974667,
          -1.6021442442678426,
          -1.602434093978121,
          -1.6106029727352476,
          -1.6231762855110359,
          -1.6505773425240964
         ]
        },
        {
         "hovertext": "<b>Topic 2</b>:experiment_model_exception_resume_u",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9132844558305115,
          -1.1172018244975734,
          -1.2194372386613128,
          -1.2404971351813634,
          -1.4346023981269673,
          -1.453628368248446,
          -1.5167265070671676,
          -1.60924156752084,
          -1.689752888430078,
          -1.6948092119562872
         ]
        },
        {
         "hovertext": "<b>Topic 3</b>:aws_request_cluster_study_unable_lo",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0722054448807918,
          -1.3009550183612597,
          -1.447148381430443,
          -1.4811570737269377,
          -1.5117142479691636,
          -1.5184690549077355,
          -1.5202344132815286,
          -1.581447802111933,
          -1.6171296976426093,
          -1.6344648769518353
         ]
        },
        {
         "hovertext": "<b>Topic 4</b>:pull_artifact_repo_image_bucket_clo",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0594497084250754,
          -1.2276976674864952,
          -1.2426428262210278,
          -1.2931269022539729,
          -1.3139331553598763,
          -1.3628657343387198,
          -1.460232785537101,
          -1.488667987118356,
          -1.4912561103180673,
          -1.5112957615001568
         ]
        },
        {
         "hovertext": "<b>Topic 5</b>:azure_import_terminal_extension_ml_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8861462852124093,
          -1.0253022027937468,
          -1.072913467057024,
          -1.103767070829751,
          -1.2928503050204947,
          -1.3408457198931791,
          -1.3509633473548708,
          -1.5973016035424195,
          -1.6095381654779166,
          -1.6170988776904114
         ]
        },
        {
         "hovertext": "<b>Topic 6</b>:models_reproducible_branch_checked_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0905075327835099,
          -1.14901754698751,
          -1.1903364699593553,
          -1.200490156532798,
          -1.2911425962171943,
          -1.3583099366986564,
          -1.3878849104353637,
          -1.3922881205283109,
          -1.396289023373213,
          -1.465028947256405
         ]
        },
        {
         "hovertext": "<b>Topic 7</b>:project_cli_port_does_arguments_ver",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8819230155105124,
          -1.02741483613941,
          -1.1896391955435497,
          -1.2485636629836698,
          -1.24903626716705,
          -1.2664403251856238,
          -1.3660215543895864,
          -1.4904559642370148,
          -1.4970915324265568,
          -1.5006747564798635
         ]
        },
        {
         "hovertext": "<b>Topic 8</b>:pipeline_catalog_plugin_artifacts_d",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0597025422260284,
          -1.1464810813902322,
          -1.3450632995054561,
          -1.3516566708054683,
          -1.355984956558566,
          -1.40413968503845,
          -1.4053194033505068,
          -1.4060990557861193,
          -1.4746216379862944,
          -1.515842197668129
         ]
        },
        {
         "hovertext": "<b>Topic 9</b>:run_ui_pipeline_tests_fails_develop",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9504799422506255,
          -1.0883384654198056,
          -1.24214275635911,
          -1.2467789302107117,
          -1.2868303385813722,
          -1.3769062521686952,
          -1.3958712853498505,
          -1.4323785463710996,
          -1.4401328330763687,
          -1.5160079388804586
         ]
        },
        {
         "hovertext": "<b>Topic 10</b>:workspace_connect_stopped_screensh",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.6800823272031635,
          -0.8633766547822391,
          -1.128976288060219,
          -1.2232520886577012,
          -1.276939823396371,
          -1.299992951203652,
          -1.3376035851628842,
          -1.3762001786509375,
          -1.385476754382914,
          -1.4934386585014967
         ]
        },
        {
         "hovertext": "<b>Topic 11</b>:lab_jupyter_cloning_study_conda_no",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.8472035872980471,
          -1.2440594201372759,
          -1.292713476127537,
          -1.3069215091001196,
          -1.3378288442019404,
          -1.375962072032154,
          -1.4726738106650052,
          -1.501682590646675,
          -1.5246991679995145,
          -1.5271761019556302
         ]
        },
        {
         "hovertext": "<b>Topic 12</b>:chart_port_upgrade_minio_db_failin",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7266672248419703,
          -1.2208754344972192,
          -1.3047396483947515,
          -1.3151155511580437,
          -1.3408179779991105,
          -1.4122399654736655,
          -1.4446025911655267,
          -1.5317613890017214,
          -1.5567755919124522,
          -1.5784478689849075
         ]
        },
        {
         "hovertext": "<b>Topic 13</b>:init_cc_folder_success_examples_co",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.7984547611813171,
          -0.9221499020015093,
          -0.929281460106079,
          -1.222349216446237,
          -1.2738599772692043,
          -1.3750237948838056,
          -1.3753828160337882,
          -1.3870393244609058,
          -1.3924313644116915,
          -1.4048330114102066
         ]
        },
        {
         "hovertext": "<b>Topic 14</b>:install_line_metadata_markdown_bit",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0319364321885505,
          -1.1284148433847396,
          -1.1821176863358833,
          -1.2424818811518106,
          -1.3510281177767014,
          -1.3742754181083483,
          -1.4123732877050916,
          -1.46887950477521,
          -1.501539461632133,
          -1.5068530538660276
         ]
        },
        {
         "hovertext": "<b>Topic 15</b>:kubeflow_parameters_batch_deploy_k",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.9611979201332691,
          -1.0995858418307591,
          -1.1622556914587634,
          -1.1898742646746132,
          -1.1961020453737845,
          -1.2773175717560967,
          -1.3039805127945403,
          -1.3564294215276038,
          -1.3790053633275214,
          -1.465007740721202
         ]
        },
        {
         "hovertext": "<b>Topic 16</b>:warning_calling_command_branch_day",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -0.6845923329005258,
          -0.7307873346589036,
          -0.8589726080295994,
          -1.201618326538079,
          -1.263291462976832,
          -1.299501714385141,
          -1.3167902821461124,
          -1.324546402600591,
          -1.3457007522089264,
          -1.3604419748965089
         ]
        },
        {
         "hovertext": "<b>Topic 17</b>:checkpoint_param_docker_line_numpy",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          -1.0990433215268762,
          -1.1848683565213785,
          -1.2757224246105354,
          -1.3604047811497428,
          -1.435565141577521,
          -1.4500960540833299,
          -1.4905650009213898,
          -1.5355817034035628,
          -1.5848974806483274,
          -1.6104295161354427
         ]
        }
       ],
       "layout": {
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Term score decline per Topic</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "dtick": 2,
         "range": [
          0,
          10
         ],
         "tick0": 1,
         "title": {
          "text": "Term Rank"
         }
        },
        "yaxis": {
         "title": {
          "text": "c-TF-IDF score (log scale)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example No.4: feed the issue content (without code) to topic model and get the topics\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = TfidfVectorizer(min_df=3, stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "  diversity=0.5,                      # Step 6 - Diversify topic words\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "# preprocess the content of the issues\n",
    "df_issues = pd.read_json(os.path.join(path_labeling_issue, 'issues_preprocessed_without_code.json'))\n",
    "topic_model = topic_model.fit(df_issues['Issue_content_preprocessed'].tolist())\n",
    "topic_model.get_topic_info()\n",
    "topic_model.visualize_topics()\n",
    "topic_model.visualize_documents(df_issues['Issue_content_preprocessed'].tolist())\n",
    "hierarchical_topics = topic_model.hierarchical_topics(df_issues['Issue_content_preprocessed'].tolist())\n",
    "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "topic_model.visualize_barchart()\n",
    "topic_model.visualize_heatmap()\n",
    "topic_model.visualize_term_rank(log_scale=True)\n",
    "topic_model.save(os.path.join(path_labeling_issue_native_text, 'topic_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Theme:  Problems with AzureML\n",
      "\n",
      "\n",
      "The GPU memory utilization metrics are not correctly visible in AzureML Run 2236 in experiment \"master\" in RadiomicsNN, with only metrics for 3 out of the 4 GPUs visible and all MemAllocated and MemReserved metrics being zero.\n",
      "\n",
      "\n",
      "Runtime of SASRec integration test is unusually long on AzureML compute cluster.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 1 Theme:  BrokenThe plugin does not work with projects created with a previous version of the plugin.\n",
      "\n",
      "\n",
      "The plugin does not work with projects created with ``kedro==0.18.1``.\n",
      "\n",
      "\n",
      "The kedro mlflow cli is broken if configuration is declared in pyproject.toml.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 2 Theme:  Bug report requesting an update to a software package.\n",
      "\n",
      "\n",
      "Pytorch Lightning 1.2.0 requires a newer version of MLflow in order to work properly.\n",
      "\n",
      "\n",
      "The bug report is requesting an update to the TrainingPipeline class to accommodate the new sagemaker.tensorflow.serving.Model from the Tensorflow package.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 3 Theme:  Error\n",
      "The SageMaker SMP training algorithm returned an AlgorithmError due to a ValueError caused by not enough values being unpacked.\n",
      "The Sagemaker Endpoint deployment failed due to a conflict between the code and model training parameters, resulting in a timeout error.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 4 Theme:  Problems with data\n",
      "\n",
      "The learning rate plot in Comet is not the expected one, as the learning_rate_warmup_epochs option is not being taken into account.\n",
      "\n",
      "\n",
      "The Wandb callback is printing a warning when a training run is resumed, indicating that the step count is not increasing as expected.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 5 Theme:  The document is incomplete or incorrect.\n",
      "\n",
      "\n",
      "The Amazon SageMaker Studio Tour walkthrough document does not reference the first 7 code cells in the notebook, and skips from cell 8 to cell 11 without running cells 9 and 10.\n",
      "\n",
      "\n",
      "Apt-get is failing in sagemaker-local-test builds due to an active process using the dpkg frontend lock.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 6 Theme:  The command failed because of an invalid input.\n",
      "\n",
      "The dbx deploy command fails due to an invalid experiment ID being returned.\n",
      "\n",
      "\n",
      "The MLflow session was closed prematurely, resulting in a RuntimeError when attempting to create a logger.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 7 Theme:  Bug report\n",
      "\n",
      "\n",
      "The `dvc.<...>` syntax is not working with ZnNodes, and the docstring needs to be fixed and tested with a Node that has `dvc.params` and `dvc.outs`.\n",
      "\n",
      "\n",
      "The bug report states that the current version of `dvc-bench` does not work with versions of `dvc` greater than 2.0.0, and that it should be adjusted to work with newer versions.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 8 Theme:  Technical\n",
      "\n",
      "\n",
      "This bug report proposes to use the DVC move command instead of the system's mv command in the rename action to ensure that the base image is properly renamed and the pointer file is updated accordingly.\n",
      "\n",
      "\n",
      "DVC and Git services do not correctly detect the repository root directory, which affects their logic for automatically initializing the repo.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 9 Theme:  fixing a problem.\n",
      "\n",
      "A regression was introduced in a2ml which caused azureml.core.authentication to be loaded when it was not needed, resulting in a ModuleNotFoundError.\n",
      "\n",
      "\n",
      "Removing the contrib package from the azureml-sdk to ensure that all tests pass.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 10 Theme:  Error\n",
      "\n",
      "\n",
      "A warning message appears when calling ``kedro mlflow init``, which can be safely ignored as the command works as intended.\n",
      "\n",
      "\n",
      "A warning message appears when calling ``kedro mlflow init``, which can be safely ignored as the command works as intended.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 11 Theme:  BugBoth reports state that there is a bug with MLflow.\n",
      "\n",
      "MLFlowLogger does not update its status when `trainer.fit` failed.\n",
      "\n",
      "The bug report states that the MLflow artifact folder is not replacing the `$ARTIFACTS_BUCKET` environment variable by default.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 12 Theme:  The two summaries share a common theme - that something in the described system is not working as expected.\n",
      "\n",
      "\n",
      "The `ui` command of `kedro mlflow` does not use the options specified in `mlflow.yml`.\n",
      "\n",
      "\n",
      "The helm fetch command for ai-engine, sdk-helper and mlflow includes the 22.09 release instead of the 22.11 release.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 13 Theme:  Logging and PyTorchBoth reports share the common theme of a problem with logging causing a failure in a PyTorch training job.\n",
      "\n",
      "\n",
      "The Mlflow Timeseries_beta branch is giving a TypeError when log_plot is set to True in the setup.\n",
      "\n",
      "\n",
      "When using MLFlow logging with PyTorch Lightning, an error in logging will cause the entire training job to fail, losing all progress.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 14 Theme:  Neptune-specific configuration issues\n",
      "\n",
      "The Neptune guide's quicklaunch link points to the full launcher instead of the minimal launcher.\n",
      "\n",
      "\n",
      "The code checks for the `neptune.amazonaws.com` DNS suffix to determine if we need to use Neptune-specific configuration options and request URI elements, but this fails to identify endpoints of Neptune clusters in AWS CN regions, which use the `neptune.<region>.amazonaws.com.cn` DNS suffix instead.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 15 Theme:  Bug reports\n",
      "\n",
      "A bug report is a document that describes a problem with a software product and provides information to help developers identify and fix the issue.\n",
      "\n",
      "\n",
      "This bug report describes an issue with the MNIST data directory being included in the repo's history, and provides a solution to remove it using the BFG repo cleaner.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 16 Theme:  Missing required dependencies\n",
      "\n",
      "\n",
      "Bug report requesting the ability to execute the `silnlp.nmt.translate` script without creating a ClearML task.\n",
      "\n",
      "\n",
      "The bug report is about an error that occurs when trying to import the numbertracker module from whylogs.core.statistics without the optional MLFlow dependency installed.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 17 Theme:  The command \"kedro mlflow ui\" in the kedro mlflow tutorial throws a FileNotFoundError.\n",
      "\n",
      "When running the command \"kedro mlflow ui\" in the kedro mlflow tutorial, a FileNotFoundError is thrown.\n",
      "\n",
      "When running the command \"kedro mlflow ui\" in the kedro mlflow tutorial, a FileNotFoundError is thrown.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 18 Theme:  Code Issues\n",
      "\n",
      "The kubeflow pipeline sagemaker component does not have idempotency, which causes the job to hang/fail when the node scales/up down.\n",
      "\n",
      "The code does not handle the SageMaker training job status 'stopped', causing an infinite loop.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 19 Theme:  Problems with MLflowThe following summary has two common problems:1. The mlflow CLI is throwing a UniqueViolation error when attempting to start a new experiment. This is preventing tests from passing.2. The MLflow API request to deploy jobs with the --assets-only option is\n",
      "MLFlow API request to deploy jobs with --assets-only option is resulting in a 409 Conflict error.\n",
      "The mlflow CLI is throwing a UniqueViolation error when attempting to start a new experiment, which is preventing tests from passing.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 20 Theme:  MLflow and GPUs\n",
      "When using MLFlowLogger with distributed data parallel on GPUs without SLURM, Trainer.fit fails with a pickle error due to an attempt to pickle the nested function in MLflow's _get_rest_store.\n",
      "\n",
      "\n",
      "The MLFlowCallback is not correctly checking for an active run, resulting in the run_name argument not being respected.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 21 Theme:  The two items have something in common - they both mention the WandBLogger's \"config\" parameter.\n",
      "\n",
      "The WandBLogger's `config` parameter is restricted to type `args.namespace`, which may be restrictive when passing configs as a dictionary.\n",
      "\n",
      "\n",
      "WandbLogger throws an error when imported if pytorch is not installed.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 22 Theme:  The two summaries share a common theme of difficulty in identifying errors.\n",
      "\n",
      "\n",
      "Setting the mlflow experiment does not work in interactive mode.\n",
      "\n",
      "\n",
      "AzureML tests are not failing if there is an error in the tests, which makes difficult to identify errors.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 23 Theme:  Broken software\n",
      "\n",
      "\n",
      "The `hooks.py` breaks all kedro-viz versions with kedro template>=0.16.5 when a PipelineML object is returned.\n",
      "\n",
      "\n",
      "The `is_mlflow_enabled()` function in the kedro-mlflow plugin is not compatible with versions of kedro-mlflow greater than 0.8.0, as it throws an ImportError when attempting to import the `context` package.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 24 Theme:  Workflow\n",
      "\n",
      "\n",
      "The Sagemaker workspace status in HongKong region shows \"UNKNOWN\" after manually stopping the workspace.\n",
      "\n",
      "Sagemaker workspace status is not updated after auto stopped.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 25 Theme: The Trainer is not being created despite comet-ml being installed, resulting in a \"comet-ml not installed\" error.\n",
      "\n",
      "\n",
      "The Trainer is not being created despite comet-ml being installed, resulting in a \"comet-ml not installed\" error.\n",
      "\n",
      "\n",
      "RichProgressBar does not display progress bar when using Comet logger.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 26 Theme:  Service LimitsBoth of these summaries mention that there is a service limit issue with something. In the first, the service limit issue is with the demo notebook, and in the second, the service limit issue is with the Graph tab not rendering correctly.\n",
      "\n",
      "\n",
      "The SageMaker Studio tour demo notebook is hitting a service limit issue when creating an endpoint to host the model, due to the default service limit of 0 for the ml.m4.xlarge instance type.\n",
      "\n",
      "\n",
      "The Graph tab does not render correctly in Amazon SageMaker Studio - Jupyter Lab when running a .path() query.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 27 Theme:  Metrics are not logged to Comet when testing a model with `Trainer.test` if the model was previously trained using `Trainer.fit`.\n",
      "\n",
      "\n",
      "PyTorch Lightning 0.7.2 no longer publishes test metrics to Comet.ML (and possibly other logging destinations).\n",
      "\n",
      "\n",
      "Metrics are not logged to Comet when testing a model with `Trainer.test` if the model was previously trained using `Trainer.fit`.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 28 Theme:  Error\n",
      "This bug report is related to an error that occurs when deploying ACI and AKS resources in AzureML notebooks.\n",
      "The AzureML extension cannot be added to an OpenShift cluster due to an error retrieving the status from the local CRD.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cluster 29 Theme:  The notebook example for using SigOpt with Tune is broken due to missing permissions.\n",
      "\n",
      "\n",
      "The notebook example for using SigOpt with Tune is broken due to missing permissions.\n",
      "\n",
      "Wandb golden test dataset의 파일 이름이 training이 아닌 train으로 변경되어 wisdomify에 제대로 적용되지 않는 문제가 발생하였다.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Reading a review which belong to each group.\n",
    "rev_per_cluster = 2\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    print(f\"Cluster {i} Theme:\", end=\" \")\n",
    "\n",
    "    reviews = \"\\n\".join(\n",
    "        issue_github[issue_github['Issue_cluster'] == i]['Issue_summary'].sample(rev_per_cluster, random_state=42).values\n",
    "    )\n",
    "    # response = openai.Completion.create(\n",
    "    #     engine=\"text-curie-001\",\n",
    "    #     prompt=f'What do the following summary have in common?\\n\\nSummary:\\n\"\"\"\\n{reviews}\\n\"\"\"\\n\\nTheme:',\n",
    "    #     temperature=0,\n",
    "    #     max_tokens=64,\n",
    "    #     top_p=1,\n",
    "    #     frequency_penalty=0,\n",
    "    #     presence_penalty=0,\n",
    "    # )\n",
    "    \n",
    "    # print(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\"))\n",
    "    print(reviews)\n",
    "\n",
    "    sample_cluster_rows = issue_github[issue_github['Issue_cluster'] == i].sample(rev_per_cluster, random_state=42)\n",
    "    for j in range(rev_per_cluster):\n",
    "        print(sample_cluster_rows['Issue_summary'].values[j])\n",
    "\n",
    "    print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

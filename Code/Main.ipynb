{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from GHMiner import GitHubMiner\n",
    "from GLMiner import GitLabMiner\n",
    "import pandas as pd\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_repo = {\n",
    "    'Aim': 'aimhubio/aim',\n",
    "    'Amazon SageMaker': 'aws/sagemaker-python-sdk',\n",
    "    'Azure Machine Learning': 'Azure/azure-sdk-for-python',\n",
    "    'ClearML': 'allegroai/clearml',\n",
    "    'Codalab': 'codalab/codalab-worksheets',\n",
    "    'DVC': 'iterative/dvc',\n",
    "    'Determined': 'determined-ai/determined',\n",
    "    'Domino': 'dominodatalab/python-domino',\n",
    "    'Guild AI': 'guildai/guildai',\n",
    "    'Kedro': 'kedro-org/kedro',\n",
    "    'MLflow': 'mlflow/mlflow',\n",
    "    'MLRun': 'mlrun/mlrun',\n",
    "    'ModelDB': 'VertaAI/modeldb',\n",
    "    'Neptune': 'neptune-ai/neptune-client',\n",
    "    'Polyaxon': 'polyaxon/polyaxon',\n",
    "    'Sacred': 'IDSIA/sacred',\n",
    "    'Valohai': 'valohai/valohai-cli',\n",
    "    'Weights & Biases': 'wandb/wandb'\n",
    "}\n",
    "\n",
    "tools_release_date = {\n",
    "    'Amazon SageMaker': '2017-11-19',\n",
    "    'Azure Machine Learning': '2015-02-18',\n",
    "    'cnvrg.io': '2020-03-31',\n",
    "    'Comet': '2017-01-01',\n",
    "    'Iterative Studio': '2021-05-12',\n",
    "    'Polyaxon': '2018-10-16',\n",
    "    'SigOpt': '2014-11-01',\n",
    "    'Vertex AI': '2019-03-01'\n",
    "}\n",
    "\n",
    "tools_link = {\n",
    "    'cnvrg.io': 'https://github.com/cnvrg',\n",
    "    'Comet': 'https://github.com/comet-ml',\n",
    "    'Iterative Studio': 'https://studio.iterative.ai',\n",
    "    'SigOpt': 'https://github.com/sigopt',\n",
    "    'Vertex AI': 'https://cloud.google.com/vertex-ai'\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Aim': {'aim'},\n",
    "    'Amazon SageMaker': {'sagemaker'},\n",
    "    'Azure Machine Learning': {'azure'},\n",
    "    'ClearML': {'clearml'},\n",
    "    'cnvrg.io': {'cnvrg'},\n",
    "    'Codalab': {'codalab'},\n",
    "    'Comet': {'comet'},\n",
    "    'Determined': {'determined'},\n",
    "    'Domino': {'domino'},\n",
    "    'DVC': {'dvc'},\n",
    "    'Guild AI': {'guild ai'},\n",
    "    'Kedro': {'kedro'},\n",
    "    'MLflow': {'mlflow'},\n",
    "    'MLRun': {'mlrun'},\n",
    "    'ModelDB': {'modeldb'},\n",
    "    'Neptune': {'neptune'},\n",
    "    'Polyaxon': {'polyaxon'},\n",
    "    'Sacred': {'sacred'},\n",
    "    'SigOpt': {'sigopt'},\n",
    "    'Valohai': {'valohai'},\n",
    "    'Vertex AI': {'vertex ai'},\n",
    "    'Weights & Biases': {'wandb', 'weights & biases', 'weights and biases'}\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "\n",
    "}\n",
    "\n",
    "issue_labels = {\n",
    "    'bug',\n",
    "    'invalid',\n",
    "    'looking into it',\n",
    "    'waiting feedback',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "path_labels = os.path.join(path_dataset, 'Labels')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_repo_raw = os.path.join(path_github_repo, 'Raw')\n",
    "path_gitlab_repo_raw = os.path.join(path_gitlab_repo, 'Raw')\n",
    "path_github_repo_scraped = os.path.join(path_github_repo, 'Scraped')\n",
    "path_gitlab_repo_scraped = os.path.join(path_gitlab_repo, 'Scraped')\n",
    "\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "path_github_issue_raw = os.path.join(path_github_issue, 'Raw')\n",
    "path_gitlab_issue_raw = os.path.join(path_gitlab_issue, 'Raw')\n",
    "path_github_issue_filtered = os.path.join(path_github_issue, 'Filtered')\n",
    "path_gitlab_issue_filtered = os.path.join(path_gitlab_issue, 'Filtered')\n",
    "path_github_issue_sampled = os.path.join(path_github_issue, 'Sampled')\n",
    "path_gitlab_issue_sampled = os.path.join(path_gitlab_issue, 'Sampled')\n",
    "path_gitlab_repo_labelled = os.path.join(path_gitlab_issue, 'Labelled')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_labels):\n",
    "    os.makedirs(path_labels)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)\n",
    "\n",
    "if not os.path.exists(path_github_repo_raw):\n",
    "    os.makedirs(path_github_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_raw):\n",
    "    os.makedirs(path_gitlab_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_raw):\n",
    "    os.makedirs(path_github_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_raw):\n",
    "    os.makedirs(path_gitlab_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_sampled):\n",
    "    os.makedirs(path_github_issue_sampled)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_sampled):\n",
    "    os.makedirs(path_gitlab_issue_sampled)\n",
    "\n",
    "if not os.path.exists(path_github_issue_filtered):\n",
    "    os.makedirs(path_github_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_filtered):\n",
    "    os.makedirs(path_gitlab_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_github_repo_scraped):\n",
    "    os.makedirs(path_github_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_scraped):\n",
    "    os.makedirs(path_gitlab_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_labelled):\n",
    "    os.makedirs(path_gitlab_repo_labelled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = os.environ['GITHUB_TOKEN']\n",
    "GITLAB_TOKEN = os.environ['GITLAB_TOKEN']\n",
    "\n",
    "github_miner = GitHubMiner(private_token=GITHUB_TOKEN)\n",
    "gitlab_miner = GitLabMiner(private_token=GITLAB_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo</th>\n",
       "      <th>Link</th>\n",
       "      <th>Repo Creation Date</th>\n",
       "      <th>Last Commit Date</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Language</th>\n",
       "      <th>Size</th>\n",
       "      <th>#Star</th>\n",
       "      <th>#Watch</th>\n",
       "      <th>#Fork</th>\n",
       "      <th>#Contributors</th>\n",
       "      <th>#Branches</th>\n",
       "      <th>#Releases</th>\n",
       "      <th>#Commits</th>\n",
       "      <th>#Pull Requests</th>\n",
       "      <th>#Pull Requests (Open)</th>\n",
       "      <th>#Issues</th>\n",
       "      <th>#Issues (Open)</th>\n",
       "      <th>Name</th>\n",
       "      <th>First Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aimhubio/aim</td>\n",
       "      <td>https://github.com/aimhubio/aim</td>\n",
       "      <td>2019-05-31 18:25:07</td>\n",
       "      <td>2023-01-31 12:13:08</td>\n",
       "      <td>[python, ai, data-science, data-visualization,...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>59947.0</td>\n",
       "      <td>3065.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>Aim</td>\n",
       "      <td>2022-01-22 13:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws/sagemaker-python-sdk</td>\n",
       "      <td>https://github.com/aws/sagemaker-python-sdk</td>\n",
       "      <td>2017-11-14 01:03:33</td>\n",
       "      <td>2023-01-31 01:53:20</td>\n",
       "      <td>[aws, mxnet, tensorflow, machine-learning, pyt...</td>\n",
       "      <td>Python</td>\n",
       "      <td>108723.0</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2017-11-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure/azure-sdk-for-python</td>\n",
       "      <td>https://github.com/Azure/azure-sdk-for-python</td>\n",
       "      <td>2012-04-24 16:46:12</td>\n",
       "      <td>2023-02-01 02:54:36</td>\n",
       "      <td>[python, azure, azure-sdk, hacktoberfest]</td>\n",
       "      <td>Python</td>\n",
       "      <td>537971.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>2186.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>13516.0</td>\n",
       "      <td>20859.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>28484.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>2015-02-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegroai/clearml</td>\n",
       "      <td>https://github.com/allegroai/clearml</td>\n",
       "      <td>2019-06-10 08:18:32</td>\n",
       "      <td>2023-01-26 17:11:47</td>\n",
       "      <td>[version-control, experiment-manager, version,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>42437.0</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>2019-06-11 17:27:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codalab/codalab-worksheets</td>\n",
       "      <td>https://github.com/codalab/codalab-worksheets</td>\n",
       "      <td>2014-11-30 22:33:18</td>\n",
       "      <td>2023-01-29 22:07:50</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>28204.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>4541.0</td>\n",
       "      <td>2242.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4366.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>Codalab</td>\n",
       "      <td>2017-05-14 00:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iterative/dvc</td>\n",
       "      <td>https://github.com/iterative/dvc</td>\n",
       "      <td>2017-03-04 08:16:33</td>\n",
       "      <td>2023-02-01 03:25:50</td>\n",
       "      <td>[data-science, machine-learning, reproducibili...</td>\n",
       "      <td>Python</td>\n",
       "      <td>17626.0</td>\n",
       "      <td>11008.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>8365.0</td>\n",
       "      <td>4544.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8652.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>DVC</td>\n",
       "      <td>2017-05-04 08:03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>determined-ai/determined</td>\n",
       "      <td>https://github.com/determined-ai/determined</td>\n",
       "      <td>2020-04-07 16:12:29</td>\n",
       "      <td>2023-02-01 03:19:51</td>\n",
       "      <td>[deep-learning, machine-learning, ml-platform,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>108561.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4923.0</td>\n",
       "      <td>5637.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5891.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Determined</td>\n",
       "      <td>2020-04-08 20:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dominodatalab/python-domino</td>\n",
       "      <td>https://github.com/dominodatalab/python-domino</td>\n",
       "      <td>2016-05-16 22:58:02</td>\n",
       "      <td>2023-01-17 21:37:32</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>488.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Domino</td>\n",
       "      <td>2020-08-05 05:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>guildai/guildai</td>\n",
       "      <td>https://github.com/guildai/guildai</td>\n",
       "      <td>2017-09-27 18:57:50</td>\n",
       "      <td>2023-01-25 14:47:47</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>16971.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5382.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Guild AI</td>\n",
       "      <td>2022-04-28 14:31:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kedro-org/kedro</td>\n",
       "      <td>https://github.com/kedro-org/kedro</td>\n",
       "      <td>2019-04-18 10:29:56</td>\n",
       "      <td>2023-01-30 10:11:12</td>\n",
       "      <td>[pipeline, kedro, hacktoberfest, mlops, experi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>165970.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>2019-06-03 16:15:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow</td>\n",
       "      <td>2018-06-05 16:05:58</td>\n",
       "      <td>2023-01-31 21:19:34</td>\n",
       "      <td>[machine-learning, ai, ml, mlflow, apache-spar...</td>\n",
       "      <td>Python</td>\n",
       "      <td>123966.0</td>\n",
       "      <td>13546.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3166.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3683.0</td>\n",
       "      <td>4920.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>7632.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>2018-06-27 16:19:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlrun/mlrun</td>\n",
       "      <td>https://github.com/mlrun/mlrun</td>\n",
       "      <td>2019-09-01 16:59:19</td>\n",
       "      <td>2023-01-31 19:23:02</td>\n",
       "      <td>[mlops, python, data-science, machine-learning...</td>\n",
       "      <td>Python</td>\n",
       "      <td>45313.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>2751.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>MLRun</td>\n",
       "      <td>2019-09-08 21:21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VertaAI/modeldb</td>\n",
       "      <td>https://github.com/VertaAI/modeldb</td>\n",
       "      <td>2016-10-19 01:07:26</td>\n",
       "      <td>2023-01-31 19:56:03</td>\n",
       "      <td>[machine-learning, model-management, modeldb, ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>47335.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3653.0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>ModelDB</td>\n",
       "      <td>2020-04-01 03:47:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neptune-ai/neptune-client</td>\n",
       "      <td>https://github.com/neptune-ai/neptune-client</td>\n",
       "      <td>2019-02-11 11:25:57</td>\n",
       "      <td>2023-01-31 12:58:06</td>\n",
       "      <td>[pytorch, keras, lightgbm, xgboost, optuna, te...</td>\n",
       "      <td>Python</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>2019-04-02 11:58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polyaxon/polyaxon</td>\n",
       "      <td>https://github.com/polyaxon/polyaxon</td>\n",
       "      <td>2016-12-26 12:48:47</td>\n",
       "      <td>2023-02-01 00:59:26</td>\n",
       "      <td>[deep-learning, machine-learning, artificial-i...</td>\n",
       "      <td>None</td>\n",
       "      <td>126260.0</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10038.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>2018-10-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IDSIA/sacred</td>\n",
       "      <td>https://github.com/IDSIA/sacred</td>\n",
       "      <td>2014-03-31 18:05:29</td>\n",
       "      <td>2023-01-28 22:28:19</td>\n",
       "      <td>[python, machine-learning, infrastructure, rep...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6166.0</td>\n",
       "      <td>3989.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>2016-01-13 18:56:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>valohai/valohai-cli</td>\n",
       "      <td>https://github.com/valohai/valohai-cli</td>\n",
       "      <td>2017-02-08 12:46:54</td>\n",
       "      <td>2023-01-18 12:30:37</td>\n",
       "      <td>[machine-learning, client, api, command-line, ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>624.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Valohai</td>\n",
       "      <td>2019-07-26 10:05:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wandb/wandb</td>\n",
       "      <td>https://github.com/wandb/wandb</td>\n",
       "      <td>2017-03-24 05:46:23</td>\n",
       "      <td>2023-02-01 00:10:44</td>\n",
       "      <td>[machine-learning, experiment-track, deep-lear...</td>\n",
       "      <td>Python</td>\n",
       "      <td>63315.0</td>\n",
       "      <td>5382.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>5046.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>2018-11-11 21:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/cnvrg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnvrg.io</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/comet-ml</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comet</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://studio.iterative.ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iterative Studio</td>\n",
       "      <td>2021-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/sigopt</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>2014-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cloud.google.com/vertex-ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repo  \\\n",
       "0                  aimhubio/aim   \n",
       "1      aws/sagemaker-python-sdk   \n",
       "2    Azure/azure-sdk-for-python   \n",
       "3             allegroai/clearml   \n",
       "4    codalab/codalab-worksheets   \n",
       "5                 iterative/dvc   \n",
       "6      determined-ai/determined   \n",
       "7   dominodatalab/python-domino   \n",
       "8               guildai/guildai   \n",
       "9               kedro-org/kedro   \n",
       "10                mlflow/mlflow   \n",
       "11                  mlrun/mlrun   \n",
       "12              VertaAI/modeldb   \n",
       "13    neptune-ai/neptune-client   \n",
       "14            polyaxon/polyaxon   \n",
       "15                 IDSIA/sacred   \n",
       "16          valohai/valohai-cli   \n",
       "17                  wandb/wandb   \n",
       "18                          NaN   \n",
       "19                          NaN   \n",
       "20                          NaN   \n",
       "21                          NaN   \n",
       "22                          NaN   \n",
       "\n",
       "                                              Link  Repo Creation Date  \\\n",
       "0                  https://github.com/aimhubio/aim 2019-05-31 18:25:07   \n",
       "1      https://github.com/aws/sagemaker-python-sdk 2017-11-14 01:03:33   \n",
       "2    https://github.com/Azure/azure-sdk-for-python 2012-04-24 16:46:12   \n",
       "3             https://github.com/allegroai/clearml 2019-06-10 08:18:32   \n",
       "4    https://github.com/codalab/codalab-worksheets 2014-11-30 22:33:18   \n",
       "5                 https://github.com/iterative/dvc 2017-03-04 08:16:33   \n",
       "6      https://github.com/determined-ai/determined 2020-04-07 16:12:29   \n",
       "7   https://github.com/dominodatalab/python-domino 2016-05-16 22:58:02   \n",
       "8               https://github.com/guildai/guildai 2017-09-27 18:57:50   \n",
       "9               https://github.com/kedro-org/kedro 2019-04-18 10:29:56   \n",
       "10                https://github.com/mlflow/mlflow 2018-06-05 16:05:58   \n",
       "11                  https://github.com/mlrun/mlrun 2019-09-01 16:59:19   \n",
       "12              https://github.com/VertaAI/modeldb 2016-10-19 01:07:26   \n",
       "13    https://github.com/neptune-ai/neptune-client 2019-02-11 11:25:57   \n",
       "14            https://github.com/polyaxon/polyaxon 2016-12-26 12:48:47   \n",
       "15                 https://github.com/IDSIA/sacred 2014-03-31 18:05:29   \n",
       "16          https://github.com/valohai/valohai-cli 2017-02-08 12:46:54   \n",
       "17                  https://github.com/wandb/wandb 2017-03-24 05:46:23   \n",
       "18                        https://github.com/cnvrg                 NaT   \n",
       "19                     https://github.com/comet-ml                 NaT   \n",
       "20                     https://studio.iterative.ai                 NaT   \n",
       "21                       https://github.com/sigopt                 NaT   \n",
       "22              https://cloud.google.com/vertex-ai                 NaT   \n",
       "\n",
       "      Last Commit Date                                             Topics  \\\n",
       "0  2023-01-31 12:13:08  [python, ai, data-science, data-visualization,...   \n",
       "1  2023-01-31 01:53:20  [aws, mxnet, tensorflow, machine-learning, pyt...   \n",
       "2  2023-02-01 02:54:36          [python, azure, azure-sdk, hacktoberfest]   \n",
       "3  2023-01-26 17:11:47  [version-control, experiment-manager, version,...   \n",
       "4  2023-01-29 22:07:50                                                 []   \n",
       "5  2023-02-01 03:25:50  [data-science, machine-learning, reproducibili...   \n",
       "6  2023-02-01 03:19:51  [deep-learning, machine-learning, ml-platform,...   \n",
       "7  2023-01-17 21:37:32                                                 []   \n",
       "8  2023-01-25 14:47:47                                                 []   \n",
       "9  2023-01-30 10:11:12  [pipeline, kedro, hacktoberfest, mlops, experi...   \n",
       "10 2023-01-31 21:19:34  [machine-learning, ai, ml, mlflow, apache-spar...   \n",
       "11 2023-01-31 19:23:02  [mlops, python, data-science, machine-learning...   \n",
       "12 2023-01-31 19:56:03  [machine-learning, model-management, modeldb, ...   \n",
       "13 2023-01-31 12:58:06  [pytorch, keras, lightgbm, xgboost, optuna, te...   \n",
       "14 2023-02-01 00:59:26  [deep-learning, machine-learning, artificial-i...   \n",
       "15 2023-01-28 22:28:19  [python, machine-learning, infrastructure, rep...   \n",
       "16 2023-01-18 12:30:37  [machine-learning, client, api, command-line, ...   \n",
       "17 2023-02-01 00:10:44  [machine-learning, experiment-track, deep-lear...   \n",
       "18                 NaT                                                NaN   \n",
       "19                 NaT                                                NaN   \n",
       "20                 NaT                                                NaN   \n",
       "21                 NaT                                                NaN   \n",
       "22                 NaT                                                NaN   \n",
       "\n",
       "      Language      Size    #Star  #Watch   #Fork  #Contributors  #Branches  \\\n",
       "0   TypeScript   59947.0   3065.0    36.0   191.0           50.0       77.0   \n",
       "1       Python  108723.0   1770.0   132.0   926.0          309.0       15.0   \n",
       "2       Python  537971.0   3473.0   362.0  2186.0          398.0      583.0   \n",
       "3       Python   42437.0   4027.0    83.0   542.0           62.0        3.0   \n",
       "4       Python   28204.0    135.0    18.0    79.0           54.0      133.0   \n",
       "5       Python   17626.0  11008.0   136.0  1024.0          254.0       10.0   \n",
       "6       Python  108561.0   2024.0    62.0   276.0           73.0      182.0   \n",
       "7       Python     488.0     51.0    28.0    50.0           32.0       52.0   \n",
       "8       Python   16971.0    771.0    13.0    71.0           20.0       65.0   \n",
       "9       Python  165970.0   8041.0   102.0   760.0          169.0       32.0   \n",
       "10      Python  123966.0  13546.0   288.0  3166.0          456.0      208.0   \n",
       "11      Python   45313.0    893.0    25.0   170.0           58.0       24.0   \n",
       "12        Java   47335.0   1552.0    71.0   265.0           48.0      546.0   \n",
       "13      Python    8408.0    364.0    17.0    37.0           29.0       28.0   \n",
       "14        None  126260.0   3239.0    78.0   319.0           90.0       16.0   \n",
       "15      Python    6166.0   3989.0    70.0   366.0           93.0       11.0   \n",
       "16      Python     624.0     13.0     6.0     6.0            8.0        8.0   \n",
       "17      Python   63315.0   5382.0    38.0   414.0          117.0      576.0   \n",
       "18         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "19         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "20         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "21         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "22         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "\n",
       "    #Releases  #Commits  #Pull Requests  #Pull Requests (Open)  #Issues  \\\n",
       "0        46.0    2009.0          1708.0                   21.0   2491.0   \n",
       "1       479.0    2850.0          2294.0                   51.0   3458.0   \n",
       "2      2697.0   13516.0         20859.0                  145.0  28484.0   \n",
       "3        75.0    1979.0           180.0                    2.0    890.0   \n",
       "4       114.0    4541.0          2242.0                   30.0   4366.0   \n",
       "5       415.0    8365.0          4544.0                    8.0   8652.0   \n",
       "6        76.0    4923.0          5637.0                   65.0   5891.0   \n",
       "7        14.0     201.0           132.0                    4.0    167.0   \n",
       "8         2.0    5382.0            69.0                    1.0    467.0   \n",
       "9        34.0    2148.0           972.0                   16.0   2064.0   \n",
       "10       62.0    3683.0          4920.0                  137.0   7632.0   \n",
       "11      367.0    2751.0          2800.0                   31.0   3011.0   \n",
       "12        2.0    3653.0          3418.0                   92.0   3550.0   \n",
       "13      124.0    1269.0          1019.0                    7.0   1193.0   \n",
       "14        0.0   10038.0           398.0                    2.0   1462.0   \n",
       "15       12.0    1339.0           360.0                    1.0    909.0   \n",
       "16        2.0     532.0           184.0                    1.0    268.0   \n",
       "17      108.0    5046.0          2650.0                  188.0   4878.0   \n",
       "18        NaN       NaN             NaN                    NaN      NaN   \n",
       "19        NaN       NaN             NaN                    NaN      NaN   \n",
       "20        NaN       NaN             NaN                    NaN      NaN   \n",
       "21        NaN       NaN             NaN                    NaN      NaN   \n",
       "22        NaN       NaN             NaN                    NaN      NaN   \n",
       "\n",
       "    #Issues (Open)                    Name  First Release Date  \n",
       "0            223.0                     Aim 2022-01-22 13:45:58  \n",
       "1            455.0        Amazon SageMaker 2017-11-19 00:00:00  \n",
       "2            927.0  Azure Machine Learning 2015-02-18 00:00:00  \n",
       "3            333.0                 ClearML 2019-06-11 17:27:11  \n",
       "4            382.0                 Codalab 2017-05-14 00:32:55  \n",
       "5            626.0                     DVC 2017-05-04 08:03:08  \n",
       "6             86.0              Determined 2020-04-08 20:01:20  \n",
       "7             15.0                  Domino 2020-08-05 05:16:39  \n",
       "8            185.0                Guild AI 2022-04-28 14:31:07  \n",
       "9            245.0                   Kedro 2019-06-03 16:15:43  \n",
       "10          1011.0                  MLflow 2018-06-27 16:19:13  \n",
       "11            84.0                   MLRun 2019-09-08 21:21:26  \n",
       "12           172.0                 ModelDB 2020-04-01 03:47:14  \n",
       "13            19.0                 Neptune 2019-04-02 11:58:35  \n",
       "14           121.0                Polyaxon 2018-10-16 00:00:00  \n",
       "15            92.0                  Sacred 2016-01-13 18:56:23  \n",
       "16            17.0                 Valohai 2019-07-26 10:05:34  \n",
       "17           797.0        Weights & Biases 2018-11-11 21:54:26  \n",
       "18             NaN                cnvrg.io 2020-03-31 00:00:00  \n",
       "19             NaN                   Comet 2017-01-01 00:00:00  \n",
       "20             NaN        Iterative Studio 2021-05-12 00:00:00  \n",
       "21             NaN                  SigOpt 2014-11-01 00:00:00  \n",
       "22             NaN               Vertex AI 2019-03-01 00:00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_data = pd.DataFrame()\n",
    "\n",
    "# scrape open-source asset-management tools\n",
    "for tool_name, tool_repo in tools_repo.items():\n",
    "    if tool_name in tools_release_date:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name, release_date=pd.to_datetime(tools_release_date[tool_name]))\n",
    "    else:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name)\n",
    "\n",
    "    if not tool_data.empty:\n",
    "        tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "    else:\n",
    "        print(error_data)\n",
    "\n",
    "# add closed-source asset-management tools\n",
    "for tool_name in tools_link.keys():\n",
    "    tool_data = {\n",
    "        'Name': tool_name,\n",
    "        'Link': tools_link[tool_name],\n",
    "        'First Release Date': pd.to_datetime(tools_release_date[tool_name])\n",
    "    }\n",
    "    tool_data = pd.DataFrame([tool_data])\n",
    "    tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "tools_data.to_json(os.path.join(path_dataset, 'Tools.json'),\n",
    "                   indent=4, orient='records')\n",
    "tools_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependents = pd.DataFrame()\n",
    "\n",
    "# collect dependents for tools with coding patterns\n",
    "for tool_name in tools_keywords.keys():\n",
    "    github_dependents = []\n",
    "    gitlab_dependents = []\n",
    "\n",
    "    # collect Github dependents\n",
    "    file_name = os.path.join(path_github_repo_raw, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # either search by sourcegraph\n",
    "            if 'Results' in json_data:\n",
    "                for repo_file in json_data['Results']:\n",
    "                    # file name match pattern\n",
    "                    if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('github'):\n",
    "                        repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "                    # code usage match pattern\n",
    "                    elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('github'):\n",
    "                        repo_name = repo_file['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "            # or search by dependent graph\n",
    "            elif 'all_public_dependent_repos' in json_data:\n",
    "                for repo_file in json_data['all_public_dependent_repos']:\n",
    "                    github_dependents.append(repo_file['name'])\n",
    "\n",
    "    # collect Gitlab dependents\n",
    "    file_name = os.path.join(path_gitlab_repo_raw, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # search by sourcegraph exclusively\n",
    "            for repo_file in json_data['Results']:\n",
    "                # file name match pattern\n",
    "                if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                        'gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "                # code usage match pattern\n",
    "                elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['name'].removeprefix('gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "\n",
    "    # remove tool repo from dependents if any\n",
    "    if tool_name in tools_repo and tools_repo[tool_name] in github_dependents:\n",
    "        github_dependents.remove(tools_repo[tool_name])\n",
    "\n",
    "    # no need to add tools without dependents\n",
    "    if not len(github_dependents) and not len(gitlab_dependents):\n",
    "        continue\n",
    "\n",
    "    dependent = {\n",
    "        'Tool': tool_name,\n",
    "        'GitHub Dependents': github_dependents,\n",
    "        'GitLab Dependents': gitlab_dependents\n",
    "    }\n",
    "\n",
    "    dependents = pd.concat(\n",
    "        [dependents, pd.DataFrame([dependent])], ignore_index=True)\n",
    "\n",
    "dependents.to_json(os.path.join(\n",
    "    path_dataset, 'Dependents.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#GitHub Dependents</th>\n",
       "      <th>#GitLab Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aim</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codalab</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comet</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Determined</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Domino</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DVC</td>\n",
       "      <td>4229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLRun</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ModelDB</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Valohai</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>10730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool #GitHub Dependents #GitLab Dependents\n",
       "0                      Aim                 92                  1\n",
       "1         Amazon SageMaker                931                  3\n",
       "2   Azure Machine Learning                689                  0\n",
       "3                  ClearML                303                  0\n",
       "4                  Codalab                 30                  0\n",
       "5                    Comet                480                  0\n",
       "6               Determined                 44                  0\n",
       "7                   Domino                  2                  0\n",
       "8                      DVC               4229                  0\n",
       "9                 Guild AI                 53                  4\n",
       "10                   Kedro                838                  0\n",
       "11                  MLflow               1189                  3\n",
       "12                   MLRun                 17                  0\n",
       "13                 ModelDB                  7                  0\n",
       "14                 Neptune                280                  0\n",
       "15                Polyaxon                 35                  0\n",
       "16                  Sacred               1289                  0\n",
       "17                  SigOpt                 55                  0\n",
       "18                 Valohai                 31                  0\n",
       "19               Vertex AI                 96                  0\n",
       "20        Weights & Biases              10730                  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependents_summary = pd.DataFrame(\n",
    "    columns=['Tool', '#GitHub Dependents', '#GitLab Dependents'])\n",
    "for index, row in dependents.iterrows():\n",
    "    dependent_data = {\n",
    "        'Tool': row['Tool'],\n",
    "        '#GitHub Dependents': len(row['GitHub Dependents']),\n",
    "        '#GitLab Dependents': len(row['GitLab Dependents'])\n",
    "    }\n",
    "    dependent_data = pd.DataFrame([dependent_data])\n",
    "    dependents_summary = pd.concat(\n",
    "        [dependents_summary, dependent_data], ignore_index=True)\n",
    "# dependents_summary.sort_values(by=['#GitHub Dependents', '#GitLab Dependents'], ascending=False, inplace=True)\n",
    "dependents_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents = pd.read_json(os.path.join(path_dataset, 'Dependents.json'))\n",
    "df_tools = pd.read_json(os.path.join(path_dataset, 'Tools.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gitlab dependents retrieval for labelling\n",
    "for index, row in df_dependents.iterrows():\n",
    "    if not row['GitLab Dependents']:\n",
    "        continue\n",
    "    dependent = ['gitlab.com/' +\n",
    "                 repo_name for repo_name in row['GitLab Dependents']]\n",
    "    dependent = pd.DataFrame({'Link': dependent})\n",
    "    dependent.to_json(os.path.join(path_gitlab_repo_labelled,\n",
    "                      f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Gitlab valid dependents general information for each tool\n",
    "project_categories = {'Project', 'Toolkit', 'Research'}\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_repo_labelled, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    repos_name = []\n",
    "    for index, row in repos.iterrows():\n",
    "        if row['Label'] in project_categories:\n",
    "            repo_name = row['Link'].removeprefix('gitlab.com/')\n",
    "            repos_name.append(repo_name)\n",
    "\n",
    "    if not repos_name:\n",
    "        continue\n",
    "\n",
    "    repos_data, errors_data = gitlab_miner.scrape_repo_list(repos_name)\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_gitlab_repo_scraped, f'{tool_name}.json'), indent=4, orient='records')\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(\n",
    "            path_gitlab_repo_scraped, f'Discarded.{tool_name}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Gitlab dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_gitlab_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos without any issues\n",
    "        repos = repos[repos['#Issues'] > 0]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(f'{row[\"Name\"]}: {repos[\"#Issues\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = gitlab_miner.scrape_issue_list(repos['Repo'].tolist())\n",
    "        issues.to_json(os.path.join(path_gitlab_issue_raw,\n",
    "                       f'{row[\"Name\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_link</th>\n",
       "      <th>Issue_title</th>\n",
       "      <th>Issue_label</th>\n",
       "      <th>Issue_creation_time</th>\n",
       "      <th>Issue_closed_time</th>\n",
       "      <th>Issue_upvote_count</th>\n",
       "      <th>Issue_downvote_count</th>\n",
       "      <th>Issue_body</th>\n",
       "      <th>Tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>[Sorts] Add sagemaker dependencies</td>\n",
       "      <td>[arena::security, product::sorts, type::bug]</td>\n",
       "      <td>2022-12-19 20:28:18.985</td>\n",
       "      <td>2022-12-22 20:22:00.700999936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;!-- Issues are public, they should not contai...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>Enable sagemaker</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-04-21 18:40:24.230</td>\n",
       "      <td>2020-05-07 21:34:48.408000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://docs.aws.amazon.com/sagemaker/</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>Saving behave logs in MLflow</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-07-06 19:33:14.309</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Like we do in learn, we should also save the p...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>ML Database vs. MLflow</td>\n",
       "      <td>[learn]</td>\n",
       "      <td>2020-04-25 17:51:29.061</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am mainly working on the feature selection p...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>Namespacing polaris runs for logging purposes ...</td>\n",
       "      <td>[improvement, learn]</td>\n",
       "      <td>2020-01-31 21:57:59.518</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Background\\n==========\\n\\nEverytime analysis i...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Issue_link  \\\n",
       "0  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "1  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "2  https://gitlab.com/librespacefoundation/polari...   \n",
       "3  https://gitlab.com/librespacefoundation/polari...   \n",
       "4  https://gitlab.com/librespacefoundation/polari...   \n",
       "\n",
       "                                         Issue_title  \\\n",
       "0                 [Sorts] Add sagemaker dependencies   \n",
       "1                                   Enable sagemaker   \n",
       "2                       Saving behave logs in MLflow   \n",
       "3                             ML Database vs. MLflow   \n",
       "4  Namespacing polaris runs for logging purposes ...   \n",
       "\n",
       "                                    Issue_label     Issue_creation_time  \\\n",
       "0  [arena::security, product::sorts, type::bug] 2022-12-19 20:28:18.985   \n",
       "1                                            [] 2020-04-21 18:40:24.230   \n",
       "2                                            [] 2021-07-06 19:33:14.309   \n",
       "3                                       [learn] 2020-04-25 17:51:29.061   \n",
       "4                          [improvement, learn] 2020-01-31 21:57:59.518   \n",
       "\n",
       "              Issue_closed_time  Issue_upvote_count  Issue_downvote_count  \\\n",
       "0 2022-12-22 20:22:00.700999936                   0                     0   \n",
       "1 2020-05-07 21:34:48.408000000                   0                     0   \n",
       "2                           NaT                   0                     0   \n",
       "3                           NaT                   1                     0   \n",
       "4                           NaT                   0                     0   \n",
       "\n",
       "                                          Issue_body              Tool  \n",
       "0  <!-- Issues are public, they should not contai...  Amazon SageMaker  \n",
       "1             https://docs.aws.amazon.com/sagemaker/  Amazon SageMaker  \n",
       "2  Like we do in learn, we should also save the p...            MLflow  \n",
       "3  I am mainly working on the feature selection p...            MLflow  \n",
       "4  Background\\n==========\\n\\nEverytime analysis i...            MLflow  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude Gitlab issues that are not related to each tool\n",
    "valid_issues_all = pd.DataFrame()\n",
    "valid_fixes_all = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    valid_fixes = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    for index, issue in issues.iterrows():\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if keyword in issue['Issue_title'].lower():\n",
    "                valid_issue = pd.DataFrame([issue])\n",
    "                valid_issues = pd.concat(\n",
    "                    [valid_issues, valid_issue], ignore_index=True)\n",
    "                if not pd.isnull(issue['Issue_closed_time']):\n",
    "                    valid_fixes = pd.concat(\n",
    "                        [valid_fixes, valid_issue], ignore_index=True)\n",
    "                break\n",
    "\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues['Tool'] = tool_name\n",
    "        valid_issues_all = pd.concat(\n",
    "            [valid_issues_all, valid_issues], ignore_index=True)\n",
    "        if not valid_fixes.empty:\n",
    "            valid_fixes['Tool'] = tool_name\n",
    "            valid_fixes_all = pd.concat(\n",
    "                [valid_fixes_all, valid_fixes], ignore_index=True)\n",
    "\n",
    "valid_issues_all = valid_issues_all[~valid_issues_all['Tool'].isin(\n",
    "    ignore_tools)]\n",
    "valid_fixes_all = valid_fixes_all[~valid_fixes_all['Tool'].isin(ignore_tools)]\n",
    "valid_issues_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arena::security', 'improvement', 'learn', 'product::sorts', 'type::bug'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "final = set()\n",
    "for _, row in valid_issues_all['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "valid_issues_filtered = []\n",
    "valid_fixes_filtered = []\n",
    "\n",
    "for index, row in valid_issues_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "       \n",
    "    if not len(row['Issue_label']):\n",
    "        valid_issues_filtered.append(row)\n",
    "    else:\n",
    "        break_sign = False\n",
    "        for label_repo in row['Issue_label']:\n",
    "            for label_question in issue_labels:\n",
    "                if not break_sign and label_question in label_repo.lower():\n",
    "                    valid_issues_filtered.append(row)\n",
    "                    break_sign = True\n",
    "\n",
    "for index, row in valid_fixes_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "       \n",
    "    if not len(row['Issue_label']):\n",
    "        valid_fixes_filtered.append(row)\n",
    "    else:\n",
    "        break_sign = False\n",
    "        for label_repo in row['Issue_label']:\n",
    "            for label_question in issue_labels:\n",
    "                if not break_sign and label_question in label_repo.lower():\n",
    "                    valid_fixes_filtered.append(row)\n",
    "                    break_sign = True\n",
    "\n",
    "valid_issues_filtered = pd.concat(valid_issues_filtered, axis=1).T\n",
    "valid_fixes_filtered = pd.concat(valid_fixes_filtered, axis=1).T\n",
    "\n",
    "valid_issues_filtered.to_json(os.path.join(\n",
    "    path_gitlab_issue_filtered, 'issues.json'), indent=4, orient='records')\n",
    "valid_fixes_filtered.to_json(os.path.join(\n",
    "    path_gitlab_issue_filtered, 'fixes.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tool  #Issue  #Closed\n",
       "0  Amazon SageMaker       2        2\n",
       "1            MLflow       1        0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_fixes = valid_fixes_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_fixes.rename(columns={'Issue_title': '#Closed'}, inplace=True)\n",
    "summary_github = summary_issues.merge(\n",
    "    summary_fixes, on='Tool', how='outer').fillna(0)\n",
    "summary_github = summary_github.astype({'#Issue': 'int32', '#Closed': 'int32'})\n",
    "summary_github.to_csv(os.path.join(\n",
    "    path_gitlab_issue, 'summary.csv'), index=False)\n",
    "summary_github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "      <th>#Sample Issue</th>\n",
       "      <th>#Sample Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tool  #Issue  #Closed  #Sample Issue  #Sample Closed\n",
       "0  Amazon SageMaker       2        2              2               2\n",
       "1            MLflow       1        0              1               0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_gitlab_issue, 'summary.csv'))\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Gitlab issues and fixes accordingly\n",
    "df_issue_samples = pd.DataFrame()\n",
    "df_fix_samples = pd.DataFrame()\n",
    "\n",
    "for index, row in df_summary.iterrows():\n",
    "    df_issue_sample = valid_issues_filtered[valid_issues_filtered['Tool'] == row['Tool']].sample(\n",
    "        n=row['#Sample Issue'], random_state=0)\n",
    "    df_fix_sample = valid_fixes_filtered[valid_fixes_filtered['Tool'] == row['Tool']].sample(\n",
    "        n=row['#Sample Closed'], random_state=0)\n",
    "    df_issue_samples = pd.concat(\n",
    "        [df_issue_samples, df_issue_sample], ignore_index=True)\n",
    "    df_fix_samples = pd.concat(\n",
    "        [df_fix_samples, df_fix_sample], ignore_index=True)\n",
    "\n",
    "df_issue_samples.to_json(os.path.join(\n",
    "    path_gitlab_issue_sampled, 'issues.json'), indent=4, orient='records')\n",
    "df_fix_samples.to_json(os.path.join(\n",
    "    path_gitlab_issue_sampled, 'fixes.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate Gitlab fixed and unfixed posts\n",
    "df_issue_samples = pd.read_json(os.path.join(path_gitlab_issue_sampled, 'issues.json'))\n",
    "df_fix_samples = pd.read_json(os.path.join(path_gitlab_issue_sampled, 'fixes.json'))\n",
    "\n",
    "df_issue_samples.drop(['Issue_label'], axis=1, inplace=True)\n",
    "df_fix_samples.drop(['Issue_label'], axis=1, inplace=True)\n",
    "\n",
    "df_issue_samples_gitlab = pd.merge(df_issue_samples, df_fix_samples, on=df_issue_samples.columns.tolist(), how='outer')\n",
    "df_issue_samples_gitlab.to_json(os.path.join(path_labels, 'issues_gitlab.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Github dependents general information for each tool\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(f'{index}: {row[\"Tool\"]}')\n",
    "    repos_data, errors_data = github_miner.scrape_repo_list(\n",
    "        row['GitHub Dependents'])\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_github_repo_scraped, f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n",
    "\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(path_github_repo_scraped,\n",
    "                            f'Discarded.{row[\"Tool\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_github_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos with only pr-based issues\n",
    "        repos = repos[repos['#Issues'] > repos['#Pull Requests']]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(\n",
    "            f'{row[\"Name\"]}: {repos[\"#Issues\"].sum() - repos[\"#Pull Requests\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = github_miner.scrape_issue_list(repos['Repo'].tolist())\n",
    "        if not issues.empty:\n",
    "            issues.to_json(os.path.join(path_github_issue_raw,\n",
    "                           f'{row[\"Name\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_link</th>\n",
       "      <th>Issue_title</th>\n",
       "      <th>Issue_label</th>\n",
       "      <th>Issue_creation_time</th>\n",
       "      <th>Issue_closed_time</th>\n",
       "      <th>Issue_upvote_count</th>\n",
       "      <th>Issue_downvote_count</th>\n",
       "      <th>Issue_comment_count</th>\n",
       "      <th>Issue_body</th>\n",
       "      <th>Tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/h2oai/dai-deployment-templa...</td>\n",
       "      <td>[Feature Request] Propagate mojo scorer images...</td>\n",
       "      <td>[WIP - Susankha]</td>\n",
       "      <td>2021-11-10 19:28:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>### Request:\\r\\nThis request is a follow up to...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/h2oai/dai-deployment-templa...</td>\n",
       "      <td>[AWS/Sagemaker] Reduce Code Base</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-13 21:07:27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>After research stemming from gcp deployment me...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/utterworks/fast-bert/issues...</td>\n",
       "      <td>Issue with finetuning  pretraining Language mo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-21 14:28:14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi Iam using the container_lm code base to fin...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/utterworks/fast-bert/issues...</td>\n",
       "      <td>Error for training job failed. reason: algorit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-03 13:37:14</td>\n",
       "      <td>2020-10-09 17:13:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello, \\r\\n\\r\\nI was training a DistilBERT mod...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/utterworks/fast-bert/issues...</td>\n",
       "      <td>Using multiple training instances in AWS Sagem...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-04-23 12:22:33</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Is it possible to speedup BERT training by usi...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Issue_link  \\\n",
       "0  https://github.com/h2oai/dai-deployment-templa...   \n",
       "1  https://github.com/h2oai/dai-deployment-templa...   \n",
       "2  https://github.com/utterworks/fast-bert/issues...   \n",
       "3  https://github.com/utterworks/fast-bert/issues...   \n",
       "4  https://github.com/utterworks/fast-bert/issues...   \n",
       "\n",
       "                                         Issue_title       Issue_label  \\\n",
       "0  [Feature Request] Propagate mojo scorer images...  [WIP - Susankha]   \n",
       "1                   [AWS/Sagemaker] Reduce Code Base                []   \n",
       "2  Issue with finetuning  pretraining Language mo...                []   \n",
       "3  Error for training job failed. reason: algorit...                []   \n",
       "4  Using multiple training instances in AWS Sagem...                []   \n",
       "\n",
       "  Issue_creation_time   Issue_closed_time  Issue_upvote_count  \\\n",
       "0 2021-11-10 19:28:00                 NaT                   0   \n",
       "1 2020-02-13 21:07:27                 NaT                   0   \n",
       "2 2020-10-21 14:28:14                 NaT                   0   \n",
       "3 2020-10-03 13:37:14 2020-10-09 17:13:38                   0   \n",
       "4 2020-04-23 12:22:33                 NaT                   0   \n",
       "\n",
       "   Issue_downvote_count  Issue_comment_count  \\\n",
       "0                     0                    2   \n",
       "1                     0                    0   \n",
       "2                     0                    0   \n",
       "3                     0                    1   \n",
       "4                     0                    4   \n",
       "\n",
       "                                          Issue_body              Tool  \n",
       "0  ### Request:\\r\\nThis request is a follow up to...  Amazon SageMaker  \n",
       "1  After research stemming from gcp deployment me...  Amazon SageMaker  \n",
       "2  Hi Iam using the container_lm code base to fin...  Amazon SageMaker  \n",
       "3  Hello, \\r\\n\\r\\nI was training a DistilBERT mod...  Amazon SageMaker  \n",
       "4  Is it possible to speedup BERT training by usi...  Amazon SageMaker  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude Github issues that are not related to each tool\n",
    "valid_issues_all = pd.DataFrame()\n",
    "valid_fixes_all = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_github_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    valid_fixes = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    for index, issue in issues.iterrows():\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if keyword in issue['Issue_title'].lower():\n",
    "                valid_issue = pd.DataFrame([issue])\n",
    "                valid_issues = pd.concat(\n",
    "                    [valid_issues, valid_issue], ignore_index=True)\n",
    "                if not pd.isnull(issue['Issue_closed_time']):\n",
    "                    valid_fixes = pd.concat(\n",
    "                        [valid_fixes, valid_issue], ignore_index=True)\n",
    "                break\n",
    "\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues['Tool'] = tool_name\n",
    "        valid_issues_all = pd.concat(\n",
    "            [valid_issues_all, valid_issues], ignore_index=True)\n",
    "        if not valid_fixes.empty:\n",
    "            valid_fixes['Tool'] = tool_name\n",
    "            valid_fixes_all = pd.concat(\n",
    "                [valid_fixes_all, valid_fixes], ignore_index=True)\n",
    "\n",
    "valid_issues_all = valid_issues_all[~valid_issues_all['Tool'].isin(\n",
    "    ignore_tools)]\n",
    "valid_fixes_all = valid_fixes_all[~valid_fixes_all['Tool'].isin(ignore_tools)]\n",
    "valid_issues_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"experiments\"',\n",
       " '0.4.6',\n",
       " '1.1',\n",
       " '1.4',\n",
       " '1.6',\n",
       " '1.7',\n",
       " '2.0',\n",
       " '3 - Quality of Life',\n",
       " '3rd party',\n",
       " '3rd party update',\n",
       " ':bridge_at_night:  Bridge',\n",
       " ':bug: bug',\n",
       " ':rotating_light:',\n",
       " '? - Needs Triage',\n",
       " 'A: example-dvc-experiments',\n",
       " 'A: example-get-started',\n",
       " 'ADO',\n",
       " 'AI\\u202fFrameworks/ONNX',\n",
       " 'AKS',\n",
       " 'AML Compute Instance',\n",
       " 'API',\n",
       " 'API & Doc',\n",
       " 'Arc',\n",
       " 'ArcBox',\n",
       " 'Auto\\u202fML',\n",
       " 'Azure Kubernetes',\n",
       " 'Bug',\n",
       " 'Cloud',\n",
       " 'CloudLabs',\n",
       " 'Community',\n",
       " 'Community Contribution Needed',\n",
       " 'Compute',\n",
       " 'Core UI',\n",
       " 'DRL',\n",
       " 'Data Labeling',\n",
       " 'Data4ML',\n",
       " 'Data\\u202fDrift',\n",
       " 'Data\\u202fPrep\\u202fServices',\n",
       " 'Deployments/Operationalization',\n",
       " 'Documentation',\n",
       " 'ERRATA_CANDIDATE',\n",
       " 'Enhancement',\n",
       " 'Environments',\n",
       " 'Evaluation',\n",
       " 'Experimentation UI',\n",
       " 'FAQ',\n",
       " 'Feature - Medium Priority',\n",
       " 'HCIBox',\n",
       " 'HIGH',\n",
       " 'HPO',\n",
       " 'Hyperdrive',\n",
       " 'Important',\n",
       " 'In the roadmap',\n",
       " 'Inf1',\n",
       " 'Inference',\n",
       " 'Ingestion',\n",
       " 'Issue: Bug Report 🐞',\n",
       " 'Issue: Feature Request',\n",
       " 'L',\n",
       " 'LOE: S',\n",
       " 'Localized',\n",
       " 'MLCompute',\n",
       " 'MLOps',\n",
       " 'Machine Learning',\n",
       " 'NLP',\n",
       " 'NUM',\n",
       " 'Needs Triage',\n",
       " 'Needs: Author Feedback',\n",
       " 'Needs: Investigation :mag:',\n",
       " 'Not related to PyCaret',\n",
       " 'Notebook',\n",
       " 'OCV',\n",
       " 'Optional',\n",
       " 'P0',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'Percept',\n",
       " 'Pipelines',\n",
       " 'Priority 1',\n",
       " 'Product Feedback',\n",
       " 'Reinforcement Learning',\n",
       " 'RepoOfficiel',\n",
       " 'Review One',\n",
       " 'Review Two',\n",
       " 'SDK',\n",
       " 'Source Issue',\n",
       " 'Stage: Technical Design 🎨',\n",
       " 'Stale',\n",
       " 'SupportNeeded',\n",
       " 'TA',\n",
       " 'TODO',\n",
       " 'TODO before 1.0',\n",
       " 'Training',\n",
       " 'Training Service',\n",
       " 'Translating',\n",
       " 'Trn1',\n",
       " 'Unsupported',\n",
       " 'Usage',\n",
       " 'VISION',\n",
       " 'WIP',\n",
       " 'WIP - Susankha',\n",
       " 'Workspace Management',\n",
       " '[module] pipeline',\n",
       " 'accelerator: tpu',\n",
       " 'accessibility',\n",
       " 'ai',\n",
       " 'aiplatform',\n",
       " 'air',\n",
       " 'alonet',\n",
       " 'api: aiplatform',\n",
       " 'api: vertex-ai',\n",
       " 'api:CSharp',\n",
       " 'app-ui',\n",
       " 'apply',\n",
       " 'arc_app_svc',\n",
       " 'arc_data',\n",
       " 'arc_k8s',\n",
       " 'arc_lighthouse',\n",
       " 'arc_ml',\n",
       " 'arc_servers',\n",
       " 'arc_sqlsrv',\n",
       " 'arc_vmware_vsphere',\n",
       " 'architecture',\n",
       " 'area / SDK-storage',\n",
       " 'area / integrations',\n",
       " 'area-getting-started',\n",
       " 'area-ml-resource-management',\n",
       " 'area-remote-desktop',\n",
       " 'area-remote-web',\n",
       " 'area-sign-in',\n",
       " 'area-subscription-management',\n",
       " 'area-telemetry',\n",
       " 'area-treeview',\n",
       " 'area-yaml',\n",
       " 'area/async',\n",
       " 'area/backend',\n",
       " 'area/components',\n",
       " 'area/components/aws/sagemaker',\n",
       " 'area/example/mnist',\n",
       " 'area/examples',\n",
       " 'area/operator',\n",
       " 'area/registry',\n",
       " 'area/samples',\n",
       " 'area/sdk',\n",
       " 'area:databuilder',\n",
       " 'assigned',\n",
       " 'assigned-to-author',\n",
       " 'august-rewrite',\n",
       " 'automation',\n",
       " 'automations',\n",
       " 'automl',\n",
       " 'automl-nlp',\n",
       " 'awaiting response',\n",
       " 'awaiting-product-team-response',\n",
       " 'aws',\n",
       " 'az_stack_hci',\n",
       " 'azure',\n",
       " 'azure-provider',\n",
       " 'azureml',\n",
       " 'backlog',\n",
       " 'benchmark',\n",
       " 'bittensor',\n",
       " 'blocked',\n",
       " 'blocker',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'bug',\n",
       " 'bug-bash',\n",
       " 'build',\n",
       " 'chapter: appendix-tools',\n",
       " 'checkpointing',\n",
       " 'chore',\n",
       " 'cleanup',\n",
       " 'close-as-overdue',\n",
       " 'closing-soon-if-no-response',\n",
       " 'cluster',\n",
       " 'code',\n",
       " 'code quality',\n",
       " 'concerns: agents',\n",
       " 'concerns: documentation',\n",
       " 'concerns: main API',\n",
       " 'configs',\n",
       " 'confirmed-event',\n",
       " 'confirmed-in-sharepoint',\n",
       " 'connectors',\n",
       " 'contribution welcomed',\n",
       " 'core/subsvc',\n",
       " 'customer-inquiry',\n",
       " 'customer-issue',\n",
       " 'cxp',\n",
       " 'data',\n",
       " 'data-sync',\n",
       " 'debt',\n",
       " 'demo',\n",
       " 'dependencies',\n",
       " 'dependency',\n",
       " 'deploy',\n",
       " 'design',\n",
       " 'dev',\n",
       " 'dev workflow',\n",
       " 'devflows',\n",
       " 'discussion',\n",
       " 'diy_container',\n",
       " 'doc',\n",
       " 'doc-bug',\n",
       " 'doc-enhancement',\n",
       " 'docker images',\n",
       " 'docs',\n",
       " 'documentation',\n",
       " 'dotnet',\n",
       " 'duplicate',\n",
       " 'engineering',\n",
       " 'enhancement',\n",
       " 'enhancement request',\n",
       " 'env: new',\n",
       " 'env: sagemaker',\n",
       " 'environment',\n",
       " 'environment: slurm',\n",
       " 'ep:CUDA',\n",
       " 'epic',\n",
       " 'error',\n",
       " 'evaluate_model',\n",
       " 'example issue',\n",
       " 'example request',\n",
       " 'experimental',\n",
       " 'explore',\n",
       " 'feature',\n",
       " 'feature request',\n",
       " 'feature-request',\n",
       " 'fixme',\n",
       " 'forum',\n",
       " 'functionality',\n",
       " 'fundamental',\n",
       " 'future release',\n",
       " 'git',\n",
       " 'global-twitch-event',\n",
       " 'good first issue',\n",
       " 'graphistry',\n",
       " 'gui',\n",
       " 'guides',\n",
       " 'help wanted',\n",
       " 'help-wanted',\n",
       " 'hi-ml-azure',\n",
       " 'high priority',\n",
       " 'high-priority',\n",
       " 'idea',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in progress',\n",
       " 'inference',\n",
       " 'inferencing-benchmark',\n",
       " 'info-needed',\n",
       " 'infrastructure',\n",
       " 'installation',\n",
       " 'integration',\n",
       " 'integration test',\n",
       " 'invalid',\n",
       " 'investigate',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'iteration-candidate',\n",
       " 'journey:intermediate',\n",
       " 'jumpstart enhancement',\n",
       " 'keep fresh',\n",
       " 'kind/bug',\n",
       " 'kind/feature',\n",
       " 'kind/question',\n",
       " 'known issue',\n",
       " 'kubeflow',\n",
       " 'lifecycle/frozen',\n",
       " 'lifecycle/stale',\n",
       " 'lightning',\n",
       " 'linting / formatting / cleaning',\n",
       " 'logger',\n",
       " 'logger: comet',\n",
       " 'logger: mlflow',\n",
       " 'logger: wandb',\n",
       " 'logging',\n",
       " 'looking into it',\n",
       " 'low priority',\n",
       " 'machine-learning',\n",
       " 'machine-learning/svc',\n",
       " 'major',\n",
       " 'metrics',\n",
       " 'missing_info',\n",
       " 'ml',\n",
       " 'ml-engineering',\n",
       " 'mlflow',\n",
       " 'model',\n",
       " 'module: text',\n",
       " 'must have',\n",
       " 'need info',\n",
       " 'need-design-decision',\n",
       " 'needs discussion',\n",
       " 'needs owner help',\n",
       " 'needs triage',\n",
       " 'needs-more-info',\n",
       " 'needs-tests',\n",
       " 'needs-triage',\n",
       " 'neptune',\n",
       " 'new',\n",
       " 'new feature',\n",
       " 'new table',\n",
       " 'new_scenario',\n",
       " 'nnidev',\n",
       " 'no-issue-activity',\n",
       " 'normal',\n",
       " 'notebook',\n",
       " 'on hold',\n",
       " 'open for contribution',\n",
       " 'operationalization',\n",
       " 'optimization',\n",
       " 'organizational',\n",
       " 'p0-critical',\n",
       " 'p1',\n",
       " 'p1-important',\n",
       " 'p2-medium',\n",
       " 'p3-nice-to-have',\n",
       " 'parnter',\n",
       " 'pdf',\n",
       " 'phase / shipped',\n",
       " 'pinned',\n",
       " 'pipeline',\n",
       " 'pipeline 6: infer',\n",
       " 'platform/aws',\n",
       " 'platform/azure',\n",
       " 'platform/gcp',\n",
       " 'platform/other',\n",
       " 'plot_model',\n",
       " 'practice',\n",
       " 'pri/medium',\n",
       " 'priority 3 - nice to have',\n",
       " 'priority-p0',\n",
       " 'priority-p1',\n",
       " 'priority/important-longterm',\n",
       " 'priority/p1',\n",
       " 'priority/p2',\n",
       " 'priority: 1',\n",
       " 'priority: 2',\n",
       " 'priority: high',\n",
       " 'priority: medium',\n",
       " 'priority: p2',\n",
       " 'priority:high',\n",
       " 'priority:medium',\n",
       " 'priority_high',\n",
       " 'product-feedback',\n",
       " 'product-gap',\n",
       " 'product-issue',\n",
       " 'product-question',\n",
       " 'progress bar: rich',\n",
       " 'provider',\n",
       " 'python',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick-fix',\n",
       " 'refactor',\n",
       " 'refactoring',\n",
       " 'regulatory compliance',\n",
       " 'reporting and diagnostics',\n",
       " 'research',\n",
       " 'roadmap',\n",
       " 'sagemaker',\n",
       " 'sagemaker-dsk-v2',\n",
       " 'sagemaker_container',\n",
       " 'samples',\n",
       " 'scenario',\n",
       " 'sdk-docs',\n",
       " 'section',\n",
       " 'service update',\n",
       " 'service:executor',\n",
       " 'service:sm-executor',\n",
       " 'setup',\n",
       " 'snippets-request',\n",
       " 'spark',\n",
       " 'stale',\n",
       " 'stale :zzz:',\n",
       " 'status/triaged',\n",
       " 'status: phase 1',\n",
       " 'status: phase 2',\n",
       " 'status:completed',\n",
       " 'status:needs_reproducing',\n",
       " 'status:needs_votes',\n",
       " 'streaming',\n",
       " 'studio',\n",
       " 'support',\n",
       " 't-must-fix',\n",
       " 't-nice-to-have-fix',\n",
       " 't-unknown-sub-error',\n",
       " 'task',\n",
       " 'technical debt',\n",
       " 'template',\n",
       " 'test',\n",
       " 'tests',\n",
       " 'time_series',\n",
       " 'timecodes',\n",
       " 'to refine',\n",
       " 'todo',\n",
       " 'tooling and CI',\n",
       " 'topic:dependencies',\n",
       " 'topic:eval',\n",
       " 'topic:models',\n",
       " 'topic:reader',\n",
       " 'training-benchmark',\n",
       " 'triage',\n",
       " 'triage me',\n",
       " 'triage-needed',\n",
       " 'triaged',\n",
       " 'tune',\n",
       " 'type / bug',\n",
       " 'type / code-health',\n",
       " 'type / enhancement',\n",
       " 'type/maintenance',\n",
       " 'type: bug',\n",
       " 'type: docs',\n",
       " 'type: enhancement',\n",
       " 'type: feature request',\n",
       " 'type: question',\n",
       " 'type:bug',\n",
       " 'type:feature',\n",
       " 'type:maintenance',\n",
       " 'type:question',\n",
       " 'up-for-grabs',\n",
       " 'upstream related',\n",
       " 'upstream-azml',\n",
       " 'urgent',\n",
       " 'user raised',\n",
       " 'ux',\n",
       " 'waiting',\n",
       " 'waiting feedback',\n",
       " 'waiting user confirm',\n",
       " \"won't fix\",\n",
       " 'wontfix',\n",
       " 'work-item',\n",
       " 'workflow',\n",
       " 'working as intended',\n",
       " '✨ feat',\n",
       " '민지',\n",
       " '찬국',\n",
       " '🐛 bug fix',\n",
       " '🐞 bug',\n",
       " '🐥 experiment',\n",
       " '🐺 Tracker',\n",
       " '👨\\u200d👩\\u200d👧\\u200d👧 discussion',\n",
       " '💎 New Component',\n",
       " '📜 Paper',\n",
       " '🔤 named-entity-recognition',\n",
       " '🔥 New Feature',\n",
       " '🛂 checkpoint',\n",
       " '🦉 dvc',\n",
       " '🧪 testing',\n",
       " '🪲bug'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "final = set()\n",
    "for _, row in valid_issues_all['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "valid_issues_filtered = []\n",
    "valid_fixes_filtered = []\n",
    "\n",
    "for index, row in valid_issues_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "    \n",
    "    if not len(row['Issue_label']):\n",
    "        valid_issues_filtered.append(row)\n",
    "    else:\n",
    "        break_sign = False\n",
    "        for label_repo in row['Issue_label']:\n",
    "            for label_question in issue_labels:\n",
    "                if not break_sign and label_question in label_repo.lower():\n",
    "                    valid_issues_filtered.append(row)\n",
    "                    break_sign = True\n",
    "\n",
    "for index, row in valid_fixes_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "       \n",
    "    if not len(row['Issue_label']):\n",
    "        valid_fixes_filtered.append(row)\n",
    "    else:\n",
    "        break_sign = False\n",
    "        for label_repo in row['Issue_label']:\n",
    "            for label_question in issue_labels:\n",
    "                if not break_sign and label_question in label_repo.lower():\n",
    "                    valid_fixes_filtered.append(row)\n",
    "                    break_sign = True\n",
    "\n",
    "valid_issues_filtered = pd.concat(valid_issues_filtered, axis=1).T\n",
    "valid_fixes_filtered = pd.concat(valid_fixes_filtered, axis=1).T\n",
    "\n",
    "valid_issues_filtered.to_json(os.path.join(\n",
    "    path_github_issue_filtered, 'issues.json'), indent=4, orient='records')\n",
    "valid_fixes_filtered.to_json(os.path.join(\n",
    "    path_github_issue_filtered, 'fixes.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>340</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>982</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>174</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Determined</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>102</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>327</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>219</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Issue  #Closed\n",
       "0         Amazon SageMaker     340      210\n",
       "1   Azure Machine Learning     982      698\n",
       "2                  ClearML      19       12\n",
       "3                    Comet      43       34\n",
       "4                      DVC     174      109\n",
       "5               Determined       1        0\n",
       "6                    Kedro     102       58\n",
       "7                   MLflow     327      233\n",
       "8                  Neptune      38       32\n",
       "9                   Sacred      41       19\n",
       "10                  SigOpt      10        7\n",
       "11               Vertex AI      18        9\n",
       "12        Weights & Biases     219      177"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_fixes = valid_fixes_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_fixes.rename(columns={'Issue_title': '#Closed'}, inplace=True)\n",
    "summary_github = summary_issues.merge(\n",
    "    summary_fixes, on='Tool', how='outer').fillna(0)\n",
    "summary_github = summary_github.astype({'#Issue': 'int32', '#Closed': 'int32'})\n",
    "summary_github.to_csv(os.path.join(\n",
    "    path_github_issue, 'summary.csv'), index=False)\n",
    "summary_github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "      <th>#Sample Issue</th>\n",
       "      <th>#Sample Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>340</td>\n",
       "      <td>210</td>\n",
       "      <td>181</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>982</td>\n",
       "      <td>698</td>\n",
       "      <td>277</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>174</td>\n",
       "      <td>109</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Determined</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>102</td>\n",
       "      <td>58</td>\n",
       "      <td>81</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>327</td>\n",
       "      <td>233</td>\n",
       "      <td>177</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>219</td>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Issue  #Closed  #Sample Issue  #Sample Closed\n",
       "0         Amazon SageMaker     340      210            181             137\n",
       "1   Azure Machine Learning     982      698            277             249\n",
       "2                  ClearML      19       12             19              12\n",
       "3                    Comet      43       34             39              32\n",
       "4                      DVC     174      109            120              86\n",
       "5               Determined       1        0              1               0\n",
       "6                    Kedro     102       58             81              51\n",
       "7                   MLflow     327      233            177             146\n",
       "8                  Neptune      38       32             35              30\n",
       "9                   Sacred      41       19             38              19\n",
       "10                  SigOpt      10        7             10               7\n",
       "11               Vertex AI      18        9             18               9\n",
       "12        Weights & Biases     219      177            140             122"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_github_issue, 'summary.csv'))\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Github issues and fixes accordingly\n",
    "df_issue_samples = pd.DataFrame()\n",
    "df_fix_samples = pd.DataFrame()\n",
    "\n",
    "for index, row in df_summary.iterrows():\n",
    "    df_issue_sample = valid_issues_filtered[valid_issues_filtered['Tool'] == row['Tool']].sample(\n",
    "        n=row['#Sample Issue'], random_state=0)\n",
    "    df_fix_sample = valid_fixes_filtered[valid_fixes_filtered['Tool'] == row['Tool']].sample(\n",
    "        n=row['#Sample Closed'], random_state=0)\n",
    "    df_issue_samples = pd.concat(\n",
    "        [df_issue_samples, df_issue_sample], ignore_index=True)\n",
    "    df_fix_samples = pd.concat(\n",
    "        [df_fix_samples, df_fix_sample], ignore_index=True)\n",
    "\n",
    "df_issue_samples.to_json(os.path.join(\n",
    "    path_github_issue_sampled, 'issues.json'), indent=4, orient='records')\n",
    "df_fix_samples.to_json(os.path.join(\n",
    "    path_github_issue_sampled, 'fixes.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate Github fixed and unfixed issues\n",
    "df_issue_samples = pd.read_json(os.path.join(path_github_issue_sampled, 'issues.json'))\n",
    "df_fix_samples = pd.read_json(os.path.join(path_github_issue_sampled, 'fixes.json'))\n",
    "\n",
    "df_issue_samples.drop(['Issue_label'], axis=1, inplace=True)\n",
    "df_fix_samples.drop(['Issue_label'], axis=1, inplace=True)\n",
    "\n",
    "df_issue_samples_github = pd.merge(df_issue_samples, df_fix_samples, on=df_issue_samples.columns.tolist(), how='outer')\n",
    "df_issue_samples_github.to_json(os.path.join(path_labels, 'issues_github.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate Github and Gitlab issues\n",
    "df_issue_samples_gitlab = pd.read_json(os.path.join(path_labels, 'issues_gitlab.json'))\n",
    "df_issue_samples_github = pd.read_json(os.path.join(path_labels, 'issues_github.json'))\n",
    "\n",
    "df_fix_samples_gitlab = pd.read_json(os.path.join(path_gitlab_issue_sampled, 'fixes.json'))\n",
    "df_fix_samples_github = pd.read_json(os.path.join(path_github_issue_sampled, 'fixes.json'))\n",
    "\n",
    "df_issue_samples_all = pd.concat([df_issue_samples_gitlab, df_issue_samples_github], ignore_index=True)\n",
    "df_fix_samples_all = pd.concat([df_fix_samples_gitlab, df_fix_samples_github], ignore_index=True)\n",
    "\n",
    "df_issue_samples_all.to_json(os.path.join(path_labels, 'issues_all.json'), indent=4, orient='records')\n",
    "df_fix_samples_all.to_json(os.path.join(path_labels, 'fixes_all.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9e7b88a259684df50811b5249344f7cc06d54cdb1cf11111ce301ae44eac9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

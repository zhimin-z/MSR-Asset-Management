{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_repo_raw = os.path.join(path_github_repo, 'Raw')\n",
    "path_gitlab_repo_raw = os.path.join(path_gitlab_repo, 'Raw')\n",
    "path_github_repo_scraped = os.path.join(path_github_repo, 'Scraped')\n",
    "path_gitlab_repo_scraped = os.path.join(path_gitlab_repo, 'Scraped')\n",
    "\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "path_github_issue_raw = os.path.join(path_github_issue, 'Raw')\n",
    "path_gitlab_issue_raw = os.path.join(path_gitlab_issue, 'Raw')\n",
    "path_github_issue_filtered = os.path.join(path_github_issue, 'Filtered')\n",
    "path_gitlab_issue_filtered = os.path.join(path_gitlab_issue, 'Filtered')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_labeling):\n",
    "    os.makedirs(path_labeling)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)\n",
    "\n",
    "if not os.path.exists(path_github_repo_raw):\n",
    "    os.makedirs(path_github_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_raw):\n",
    "    os.makedirs(path_gitlab_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_raw):\n",
    "    os.makedirs(path_github_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_raw):\n",
    "    os.makedirs(path_gitlab_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_filtered):\n",
    "    os.makedirs(path_github_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_filtered):\n",
    "    os.makedirs(path_gitlab_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_github_repo_scraped):\n",
    "    os.makedirs(path_github_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_scraped):\n",
    "    os.makedirs(path_gitlab_repo_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_repo = {\n",
    "    'Aim': 'aimhubio/aim',\n",
    "    'Amazon SageMaker': 'aws/sagemaker-python-sdk',\n",
    "    'Azure Machine Learning': 'Azure/azure-sdk-for-python',\n",
    "    'ClearML': 'allegroai/clearml',\n",
    "    'Codalab': 'codalab/codalab-worksheets',\n",
    "    'DVC': 'iterative/dvc',\n",
    "    'Determined': 'determined-ai/determined',\n",
    "    'Domino': 'dominodatalab/python-domino',\n",
    "    'Guild AI': 'guildai/guildai',\n",
    "    'Kedro': 'kedro-org/kedro',\n",
    "    'MLflow': 'mlflow/mlflow',\n",
    "    'MLRun': 'mlrun/mlrun',\n",
    "    'ModelDB': 'VertaAI/modeldb',\n",
    "    'Neptune': 'neptune-ai/neptune-client',\n",
    "    'Optuna': 'optuna/optuna',\n",
    "    'Polyaxon': 'polyaxon/polyaxon',\n",
    "    'Sacred': 'IDSIA/sacred',\n",
    "    'Valohai': 'valohai/valohai-cli',\n",
    "    'Weights & Biases': 'wandb/wandb'\n",
    "}\n",
    "\n",
    "tools_release_date = {\n",
    "    'Amazon SageMaker': '2017-11-19',\n",
    "    'Azure Machine Learning': '2015-02-18',\n",
    "    'cnvrg.io': '2020-03-31',\n",
    "    'Comet': '2017-01-01',\n",
    "    'Iterative Studio': '2021-05-12',\n",
    "    'Polyaxon': '2018-10-16',\n",
    "    'SigOpt': '2014-11-01',\n",
    "    'Vertex AI': '2019-03-01'\n",
    "}\n",
    "\n",
    "tools_link = {\n",
    "    'cnvrg.io': 'https://github.com/cnvrg',\n",
    "    'Comet': 'https://github.com/comet-ml',\n",
    "    'Iterative Studio': 'https://studio.iterative.ai',\n",
    "    'SigOpt': 'https://github.com/sigopt',\n",
    "    'Vertex AI': 'https://cloud.google.com/vertex-ai'\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Aim': ['aim'],\n",
    "    'Amazon SageMaker': ['amazon sagemaker', 'aws sagemaker', 'sagemaker'],\n",
    "    'Azure Machine Learning': ['microsoft azure machine learning', 'azure machine learning', 'microsoft azure ml', 'microsoft azureml', 'azure ml', 'azureml'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'cnvrg.io': ['cnvrg'],\n",
    "    'Codalab': ['codalab'],\n",
    "    'Comet': ['comet'],\n",
    "    'Determined': ['determined'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'MLRun': ['mlrun'],\n",
    "    'ModelDB': ['modeldb'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Optuna': ['optuna'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Valohai': ['valohai'],\n",
    "    'Vertex AI': ['google vertex ai', 'vertex ai'],\n",
    "    'Weights & Biases': ['weights & biases', 'weights&biases', 'W & B', 'W&B', 'weights and biases', 'wandb']\n",
    "}\n",
    "\n",
    "ignore_tools = {\n",
    "\n",
    "}\n",
    "\n",
    "issue_labels = {\n",
    "    'bug',\n",
    "    'error',\n",
    "    'invalid',\n",
    "    'looking into it',\n",
    "    'waiting feedback',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scrape.GHMiner import GitHubMiner\n",
    "from Scrape.GLMiner import GitLabMiner\n",
    "\n",
    "github_miner = GitHubMiner(private_token=os.getenv('GITHUB_TOKEN'))\n",
    "gitlab_miner = GitLabMiner(private_token=os.getenv('GITLAB_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo</th>\n",
       "      <th>Link</th>\n",
       "      <th>Repo Creation Date</th>\n",
       "      <th>Last Commit Date</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Language</th>\n",
       "      <th>Size</th>\n",
       "      <th>#Star</th>\n",
       "      <th>#Watch</th>\n",
       "      <th>#Fork</th>\n",
       "      <th>#Contributors</th>\n",
       "      <th>#Branches</th>\n",
       "      <th>#Releases</th>\n",
       "      <th>#Commits</th>\n",
       "      <th>#Pull Requests</th>\n",
       "      <th>#Pull Requests (Open)</th>\n",
       "      <th>#Issues</th>\n",
       "      <th>#Issues (Open)</th>\n",
       "      <th>Name</th>\n",
       "      <th>First Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aimhubio/aim</td>\n",
       "      <td>https://github.com/aimhubio/aim</td>\n",
       "      <td>2019-05-31 18:25:07</td>\n",
       "      <td>2023-03-20 22:41:11</td>\n",
       "      <td>[python, ai, data-science, data-visualization,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>63726.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>Aim</td>\n",
       "      <td>2022-01-22 13:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws/sagemaker-python-sdk</td>\n",
       "      <td>https://github.com/aws/sagemaker-python-sdk</td>\n",
       "      <td>2017-11-14 01:03:33</td>\n",
       "      <td>2023-03-21 05:48:29</td>\n",
       "      <td>[aws, mxnet, tensorflow, machine-learning, pyt...</td>\n",
       "      <td>Python</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>2941.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3573.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2017-11-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure/azure-sdk-for-python</td>\n",
       "      <td>https://github.com/Azure/azure-sdk-for-python</td>\n",
       "      <td>2012-04-24 16:46:12</td>\n",
       "      <td>2023-03-21 20:55:01</td>\n",
       "      <td>[python, azure, azure-sdk, hacktoberfest]</td>\n",
       "      <td>Python</td>\n",
       "      <td>558786.0</td>\n",
       "      <td>3555.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>2807.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>21583.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>29413.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>2015-02-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegroai/clearml</td>\n",
       "      <td>https://github.com/allegroai/clearml</td>\n",
       "      <td>2019-06-10 08:18:32</td>\n",
       "      <td>2023-03-17 12:35:36</td>\n",
       "      <td>[version-control, experiment-manager, version,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>42846.0</td>\n",
       "      <td>4218.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>2019-06-11 17:27:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codalab/codalab-worksheets</td>\n",
       "      <td>https://github.com/codalab/codalab-worksheets</td>\n",
       "      <td>2014-11-30 22:33:18</td>\n",
       "      <td>2023-03-17 05:11:06</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>27818.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>4562.0</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4424.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>Codalab</td>\n",
       "      <td>2017-05-14 00:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iterative/dvc</td>\n",
       "      <td>https://github.com/iterative/dvc</td>\n",
       "      <td>2017-03-04 08:16:33</td>\n",
       "      <td>2023-03-21 21:33:53</td>\n",
       "      <td>[data-science, machine-learning, reproducibili...</td>\n",
       "      <td>Python</td>\n",
       "      <td>18209.0</td>\n",
       "      <td>11241.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>8569.0</td>\n",
       "      <td>4739.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8925.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>DVC</td>\n",
       "      <td>2017-05-04 08:03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>determined-ai/determined</td>\n",
       "      <td>https://github.com/determined-ai/determined</td>\n",
       "      <td>2020-04-07 16:12:29</td>\n",
       "      <td>2023-03-21 22:42:13</td>\n",
       "      <td>[deep-learning, machine-learning, ml-platform,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>114547.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5250.0</td>\n",
       "      <td>6044.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6304.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Determined</td>\n",
       "      <td>2020-04-08 20:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dominodatalab/python-domino</td>\n",
       "      <td>https://github.com/dominodatalab/python-domino</td>\n",
       "      <td>2016-05-16 22:58:02</td>\n",
       "      <td>2023-03-21 16:11:30</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>507.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Domino</td>\n",
       "      <td>2020-08-05 05:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>guildai/guildai</td>\n",
       "      <td>https://github.com/guildai/guildai</td>\n",
       "      <td>2017-09-27 18:57:50</td>\n",
       "      <td>2023-03-21 21:20:02</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>17387.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5561.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Guild AI</td>\n",
       "      <td>2022-04-28 14:31:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kedro-org/kedro</td>\n",
       "      <td>https://github.com/kedro-org/kedro</td>\n",
       "      <td>2019-04-18 10:29:56</td>\n",
       "      <td>2023-03-21 11:07:22</td>\n",
       "      <td>[pipeline, kedro, hacktoberfest, mlops, experi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>173129.0</td>\n",
       "      <td>8189.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2201.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>2019-06-03 16:15:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow</td>\n",
       "      <td>2018-06-05 16:05:58</td>\n",
       "      <td>2023-03-21 06:01:14</td>\n",
       "      <td>[machine-learning, ai, ml, mlflow, apache-spar...</td>\n",
       "      <td>Python</td>\n",
       "      <td>134182.0</td>\n",
       "      <td>13888.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>3258.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3827.0</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>7927.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>2018-06-27 16:19:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlrun/mlrun</td>\n",
       "      <td>https://github.com/mlrun/mlrun</td>\n",
       "      <td>2019-09-01 16:59:19</td>\n",
       "      <td>2023-03-21 13:52:55</td>\n",
       "      <td>[mlops, python, data-science, machine-learning...</td>\n",
       "      <td>Python</td>\n",
       "      <td>47768.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>MLRun</td>\n",
       "      <td>2019-09-08 21:21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VertaAI/modeldb</td>\n",
       "      <td>https://github.com/VertaAI/modeldb</td>\n",
       "      <td>2016-10-19 01:07:26</td>\n",
       "      <td>2023-03-21 22:15:38</td>\n",
       "      <td>[machine-learning, model-management, modeldb, ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>3546.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>ModelDB</td>\n",
       "      <td>2020-04-01 03:47:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neptune-ai/neptune-client</td>\n",
       "      <td>https://github.com/neptune-ai/neptune-client</td>\n",
       "      <td>2019-02-11 11:25:57</td>\n",
       "      <td>2023-03-21 20:17:39</td>\n",
       "      <td>[pytorch, keras, lightgbm, xgboost, optuna, te...</td>\n",
       "      <td>Python</td>\n",
       "      <td>8732.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>2019-04-02 11:58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>optuna/optuna</td>\n",
       "      <td>https://github.com/optuna/optuna</td>\n",
       "      <td>2018-02-21 06:12:56</td>\n",
       "      <td>2023-03-20 08:11:38</td>\n",
       "      <td>[python, machine-learning, parallel, distribut...</td>\n",
       "      <td>Python</td>\n",
       "      <td>18106.0</td>\n",
       "      <td>7795.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>15266.0</td>\n",
       "      <td>2998.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4378.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Optuna</td>\n",
       "      <td>2018-05-10 08:41:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>polyaxon/polyaxon</td>\n",
       "      <td>https://github.com/polyaxon/polyaxon</td>\n",
       "      <td>2016-12-26 12:48:47</td>\n",
       "      <td>2023-03-21 17:55:30</td>\n",
       "      <td>[deep-learning, machine-learning, artificial-i...</td>\n",
       "      <td>None</td>\n",
       "      <td>126377.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10077.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>2018-10-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IDSIA/sacred</td>\n",
       "      <td>https://github.com/IDSIA/sacred</td>\n",
       "      <td>2014-03-31 18:05:29</td>\n",
       "      <td>2023-02-24 14:28:50</td>\n",
       "      <td>[python, machine-learning, infrastructure, rep...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6168.0</td>\n",
       "      <td>4013.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>2016-01-13 18:56:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>valohai/valohai-cli</td>\n",
       "      <td>https://github.com/valohai/valohai-cli</td>\n",
       "      <td>2017-02-08 12:46:54</td>\n",
       "      <td>2023-03-14 11:44:04</td>\n",
       "      <td>[machine-learning, client, api, command-line, ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>627.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Valohai</td>\n",
       "      <td>2019-07-26 10:05:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wandb/wandb</td>\n",
       "      <td>https://github.com/wandb/wandb</td>\n",
       "      <td>2017-03-24 05:46:23</td>\n",
       "      <td>2023-03-20 20:45:48</td>\n",
       "      <td>[machine-learning, experiment-track, deep-lear...</td>\n",
       "      <td>Python</td>\n",
       "      <td>73890.0</td>\n",
       "      <td>5671.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>2867.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>5203.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>2018-11-11 21:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/cnvrg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnvrg.io</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/comet-ml</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comet</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://studio.iterative.ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iterative Studio</td>\n",
       "      <td>2021-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/sigopt</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>2014-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cloud.google.com/vertex-ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repo  \\\n",
       "0                  aimhubio/aim   \n",
       "1      aws/sagemaker-python-sdk   \n",
       "2    Azure/azure-sdk-for-python   \n",
       "3             allegroai/clearml   \n",
       "4    codalab/codalab-worksheets   \n",
       "5                 iterative/dvc   \n",
       "6      determined-ai/determined   \n",
       "7   dominodatalab/python-domino   \n",
       "8               guildai/guildai   \n",
       "9               kedro-org/kedro   \n",
       "10                mlflow/mlflow   \n",
       "11                  mlrun/mlrun   \n",
       "12              VertaAI/modeldb   \n",
       "13    neptune-ai/neptune-client   \n",
       "14                optuna/optuna   \n",
       "15            polyaxon/polyaxon   \n",
       "16                 IDSIA/sacred   \n",
       "17          valohai/valohai-cli   \n",
       "18                  wandb/wandb   \n",
       "19                          NaN   \n",
       "20                          NaN   \n",
       "21                          NaN   \n",
       "22                          NaN   \n",
       "23                          NaN   \n",
       "\n",
       "                                              Link  Repo Creation Date  \\\n",
       "0                  https://github.com/aimhubio/aim 2019-05-31 18:25:07   \n",
       "1      https://github.com/aws/sagemaker-python-sdk 2017-11-14 01:03:33   \n",
       "2    https://github.com/Azure/azure-sdk-for-python 2012-04-24 16:46:12   \n",
       "3             https://github.com/allegroai/clearml 2019-06-10 08:18:32   \n",
       "4    https://github.com/codalab/codalab-worksheets 2014-11-30 22:33:18   \n",
       "5                 https://github.com/iterative/dvc 2017-03-04 08:16:33   \n",
       "6      https://github.com/determined-ai/determined 2020-04-07 16:12:29   \n",
       "7   https://github.com/dominodatalab/python-domino 2016-05-16 22:58:02   \n",
       "8               https://github.com/guildai/guildai 2017-09-27 18:57:50   \n",
       "9               https://github.com/kedro-org/kedro 2019-04-18 10:29:56   \n",
       "10                https://github.com/mlflow/mlflow 2018-06-05 16:05:58   \n",
       "11                  https://github.com/mlrun/mlrun 2019-09-01 16:59:19   \n",
       "12              https://github.com/VertaAI/modeldb 2016-10-19 01:07:26   \n",
       "13    https://github.com/neptune-ai/neptune-client 2019-02-11 11:25:57   \n",
       "14                https://github.com/optuna/optuna 2018-02-21 06:12:56   \n",
       "15            https://github.com/polyaxon/polyaxon 2016-12-26 12:48:47   \n",
       "16                 https://github.com/IDSIA/sacred 2014-03-31 18:05:29   \n",
       "17          https://github.com/valohai/valohai-cli 2017-02-08 12:46:54   \n",
       "18                  https://github.com/wandb/wandb 2017-03-24 05:46:23   \n",
       "19                        https://github.com/cnvrg                 NaT   \n",
       "20                     https://github.com/comet-ml                 NaT   \n",
       "21                     https://studio.iterative.ai                 NaT   \n",
       "22                       https://github.com/sigopt                 NaT   \n",
       "23              https://cloud.google.com/vertex-ai                 NaT   \n",
       "\n",
       "      Last Commit Date                                             Topics  \\\n",
       "0  2023-03-20 22:41:11  [python, ai, data-science, data-visualization,...   \n",
       "1  2023-03-21 05:48:29  [aws, mxnet, tensorflow, machine-learning, pyt...   \n",
       "2  2023-03-21 20:55:01          [python, azure, azure-sdk, hacktoberfest]   \n",
       "3  2023-03-17 12:35:36  [version-control, experiment-manager, version,...   \n",
       "4  2023-03-17 05:11:06                                                 []   \n",
       "5  2023-03-21 21:33:53  [data-science, machine-learning, reproducibili...   \n",
       "6  2023-03-21 22:42:13  [deep-learning, machine-learning, ml-platform,...   \n",
       "7  2023-03-21 16:11:30                                                 []   \n",
       "8  2023-03-21 21:20:02                                                 []   \n",
       "9  2023-03-21 11:07:22  [pipeline, kedro, hacktoberfest, mlops, experi...   \n",
       "10 2023-03-21 06:01:14  [machine-learning, ai, ml, mlflow, apache-spar...   \n",
       "11 2023-03-21 13:52:55  [mlops, python, data-science, machine-learning...   \n",
       "12 2023-03-21 22:15:38  [machine-learning, model-management, modeldb, ...   \n",
       "13 2023-03-21 20:17:39  [pytorch, keras, lightgbm, xgboost, optuna, te...   \n",
       "14 2023-03-20 08:11:38  [python, machine-learning, parallel, distribut...   \n",
       "15 2023-03-21 17:55:30  [deep-learning, machine-learning, artificial-i...   \n",
       "16 2023-02-24 14:28:50  [python, machine-learning, infrastructure, rep...   \n",
       "17 2023-03-14 11:44:04  [machine-learning, client, api, command-line, ...   \n",
       "18 2023-03-20 20:45:48  [machine-learning, experiment-track, deep-lear...   \n",
       "19                 NaT                                                NaN   \n",
       "20                 NaT                                                NaN   \n",
       "21                 NaT                                                NaN   \n",
       "22                 NaT                                                NaN   \n",
       "23                 NaT                                                NaN   \n",
       "\n",
       "   Language      Size    #Star  #Watch   #Fork  #Contributors  #Branches  \\\n",
       "0    Python   63726.0   3276.0    36.0   206.0           54.0       81.0   \n",
       "1    Python  109008.0   1800.0   134.0   945.0          327.0       14.0   \n",
       "2    Python  558786.0   3555.0   367.0  2264.0          398.0      616.0   \n",
       "3    Python   42846.0   4218.0    86.0   567.0           69.0        3.0   \n",
       "4    Python   27818.0    138.0    18.0    79.0           53.0      137.0   \n",
       "5    Python   18209.0  11241.0   135.0  1038.0          259.0       22.0   \n",
       "6    Python  114547.0   2099.0    66.0   292.0           81.0      178.0   \n",
       "7    Python     507.0     53.0    28.0    53.0           33.0       53.0   \n",
       "8    Python   17387.0    781.0    13.0    71.0           21.0       68.0   \n",
       "9    Python  173129.0   8189.0   104.0   771.0          171.0       31.0   \n",
       "10   Python  134182.0  13888.0   287.0  3258.0          456.0      218.0   \n",
       "11   Python   47768.0    927.0    26.0   182.0           59.0       24.0   \n",
       "12     Java   49081.0   1559.0    71.0   268.0           49.0      580.0   \n",
       "13   Python    8732.0    372.0    14.0    38.0           30.0       41.0   \n",
       "14   Python   18106.0   7795.0   121.0   814.0          193.0       24.0   \n",
       "15     None  126377.0   3275.0    78.0   319.0           90.0       16.0   \n",
       "16   Python    6168.0   4013.0    70.0   370.0           94.0       11.0   \n",
       "17   Python     627.0     13.0     6.0     6.0            8.0        9.0   \n",
       "18   Python   73890.0   5671.0    47.0   448.0          120.0      612.0   \n",
       "19      NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "20      NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "21      NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "22      NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "23      NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "\n",
       "    #Releases  #Commits  #Pull Requests  #Pull Requests (Open)  #Issues  \\\n",
       "0        49.0    2042.0          1753.0                   25.0   2582.0   \n",
       "1       493.0    2941.0          2373.0                   49.0   3573.0   \n",
       "2      2807.0   14027.0         21583.0                  158.0  29413.0   \n",
       "3        77.0    2028.0           194.0                    2.0    945.0   \n",
       "4       116.0    4562.0          2269.0                   24.0   4424.0   \n",
       "5       429.0    8569.0          4739.0                   12.0   8925.0   \n",
       "6        79.0    5250.0          6044.0                   75.0   6304.0   \n",
       "7        15.0     203.0           135.0                    5.0    170.0   \n",
       "8         2.0    5561.0            71.0                    2.0    481.0   \n",
       "9        36.0    2201.0          1041.0                    8.0   2227.0   \n",
       "10       65.0    3827.0          5130.0                  148.0   7927.0   \n",
       "11      380.0    2989.0          3076.0                   50.0   3295.0   \n",
       "12        2.0    3729.0          3546.0                   96.0   3679.0   \n",
       "13      132.0    1395.0          1126.0                   18.0   1308.0   \n",
       "14       57.0   15266.0          2998.0                   22.0   4378.0   \n",
       "15        0.0   10077.0           398.0                    2.0   1463.0   \n",
       "16       12.0    1340.0           362.0                    2.0    912.0   \n",
       "17        2.0     544.0           190.0                    1.0    274.0   \n",
       "18      111.0    5191.0          2867.0                  214.0   5203.0   \n",
       "19        NaN       NaN             NaN                    NaN      NaN   \n",
       "20        NaN       NaN             NaN                    NaN      NaN   \n",
       "21        NaN       NaN             NaN                    NaN      NaN   \n",
       "22        NaN       NaN             NaN                    NaN      NaN   \n",
       "23        NaN       NaN             NaN                    NaN      NaN   \n",
       "\n",
       "    #Issues (Open)                    Name  First Release Date  \n",
       "0            249.0                     Aim 2022-01-22 13:45:58  \n",
       "1            476.0        Amazon SageMaker 2017-11-19 00:00:00  \n",
       "2            964.0  Azure Machine Learning 2015-02-18 00:00:00  \n",
       "3            305.0                 ClearML 2019-06-11 17:27:11  \n",
       "4            390.0                 Codalab 2017-05-14 00:32:55  \n",
       "5            595.0                     DVC 2017-05-04 08:03:08  \n",
       "6            100.0              Determined 2020-04-08 20:01:20  \n",
       "7             16.0                  Domino 2020-08-05 05:16:39  \n",
       "8            196.0                Guild AI 2022-04-28 14:31:07  \n",
       "9            274.0                   Kedro 2019-06-03 16:15:43  \n",
       "10          1051.0                  MLflow 2018-06-27 16:19:13  \n",
       "11           105.0                   MLRun 2019-09-08 21:21:26  \n",
       "12           177.0                 ModelDB 2020-04-01 03:47:14  \n",
       "13            33.0                 Neptune 2019-04-02 11:58:35  \n",
       "14           121.0                  Optuna 2018-05-10 08:41:56  \n",
       "15           121.0                Polyaxon 2018-10-16 00:00:00  \n",
       "16            94.0                  Sacred 2016-01-13 18:56:23  \n",
       "17            17.0                 Valohai 2019-07-26 10:05:34  \n",
       "18           738.0        Weights & Biases 2018-11-11 21:54:26  \n",
       "19             NaN                cnvrg.io 2020-03-31 00:00:00  \n",
       "20             NaN                   Comet 2017-01-01 00:00:00  \n",
       "21             NaN        Iterative Studio 2021-05-12 00:00:00  \n",
       "22             NaN                  SigOpt 2014-11-01 00:00:00  \n",
       "23             NaN               Vertex AI 2019-03-01 00:00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_data = pd.DataFrame()\n",
    "\n",
    "# scrape open-source asset-management tools\n",
    "for tool_name, tool_repo in tools_repo.items():\n",
    "    if tool_name in tools_release_date:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name, release_date=pd.to_datetime(tools_release_date[tool_name]))\n",
    "    else:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name)\n",
    "\n",
    "    if not tool_data.empty:\n",
    "        tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "    else:\n",
    "        print(error_data)\n",
    "\n",
    "# add closed-source asset-management tools\n",
    "for tool_name in tools_link.keys():\n",
    "    tool_data = {\n",
    "        'Name': tool_name,\n",
    "        'Link': tools_link[tool_name],\n",
    "        'First Release Date': pd.to_datetime(tools_release_date[tool_name])\n",
    "    }\n",
    "    tool_data = pd.DataFrame([tool_data])\n",
    "    tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "tools_data.to_json(os.path.join(path_dataset, 'Tools.json'),\n",
    "                   indent=4, orient='records')\n",
    "tools_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dependents = pd.DataFrame()\n",
    "\n",
    "# collect dependents for tools with coding patterns\n",
    "for tool_name in tools_keywords.keys():\n",
    "    github_dependents = []\n",
    "    gitlab_dependents = []\n",
    "\n",
    "    # collect Github dependents\n",
    "    file_name = os.path.join(path_github_repo_raw, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # either search by sourcegraph\n",
    "            if 'Results' in json_data:\n",
    "                for repo_file in json_data['Results']:\n",
    "                    # file name match pattern\n",
    "                    if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('github'):\n",
    "                        repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "                    # code usage match pattern\n",
    "                    elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('github'):\n",
    "                        repo_name = repo_file['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        github_dependents.append(repo_name)\n",
    "            # or search by dependent graph\n",
    "            elif 'all_public_dependent_repos' in json_data:\n",
    "                for repo_file in json_data['all_public_dependent_repos']:\n",
    "                    github_dependents.append(repo_file['name'])\n",
    "\n",
    "    # collect Gitlab dependents\n",
    "    file_name = os.path.join(path_gitlab_repo_raw, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # search by sourcegraph exclusively\n",
    "            for repo_file in json_data['Results']:\n",
    "                # file name match pattern\n",
    "                if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                        'gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "                # code usage match pattern\n",
    "                elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['name'].removeprefix('gitlab.com/')\n",
    "                    gitlab_dependents.append(repo_name)\n",
    "\n",
    "    # remove tool repo from dependents if any\n",
    "    if tool_name in tools_repo and tools_repo[tool_name] in github_dependents:\n",
    "        github_dependents.remove(tools_repo[tool_name])\n",
    "\n",
    "    # no need to add tools without dependents\n",
    "    if not len(github_dependents) and not len(gitlab_dependents):\n",
    "        continue\n",
    "\n",
    "    dependent = {\n",
    "        'Tool': tool_name,\n",
    "        'GitHub Dependents': github_dependents,\n",
    "        'GitLab Dependents': gitlab_dependents\n",
    "    }\n",
    "\n",
    "    dependents = pd.concat(\n",
    "        [dependents, pd.DataFrame([dependent])], ignore_index=True)\n",
    "\n",
    "dependents.to_json(os.path.join(\n",
    "    path_dataset, 'Dependents.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#GitHub Dependents</th>\n",
       "      <th>#GitLab Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aim</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codalab</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comet</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Determined</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Domino</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DVC</td>\n",
       "      <td>4229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLRun</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ModelDB</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>2606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Valohai</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>10730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool #GitHub Dependents #GitLab Dependents\n",
       "0                      Aim                 92                  1\n",
       "1         Amazon SageMaker                931                  3\n",
       "2   Azure Machine Learning                689                  0\n",
       "3                  ClearML                303                  0\n",
       "4                  Codalab                 30                  0\n",
       "5                    Comet                480                  0\n",
       "6               Determined                 44                  0\n",
       "7                   Domino                  2                  0\n",
       "8                      DVC               4229                  0\n",
       "9                 Guild AI                 53                  4\n",
       "10                   Kedro                838                  0\n",
       "11                  MLflow               1189                  3\n",
       "12                   MLRun                 17                  0\n",
       "13                 ModelDB                  7                  0\n",
       "14                 Neptune                280                  0\n",
       "15                  Optuna               2606                  0\n",
       "16                Polyaxon                 35                  0\n",
       "17                  Sacred               1289                  0\n",
       "18                  SigOpt                 55                  0\n",
       "19                 Valohai                 31                  0\n",
       "20               Vertex AI                 96                  0\n",
       "21        Weights & Biases              10730                  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependents_summary = pd.DataFrame(\n",
    "    columns=['Tool', '#GitHub Dependents', '#GitLab Dependents'])\n",
    "for index, row in dependents.iterrows():\n",
    "    dependent_data = {\n",
    "        'Tool': row['Tool'],\n",
    "        '#GitHub Dependents': len(row['GitHub Dependents']),\n",
    "        '#GitLab Dependents': len(row['GitLab Dependents'])\n",
    "    }\n",
    "    dependent_data = pd.DataFrame([dependent_data])\n",
    "    dependents_summary = pd.concat(\n",
    "        [dependents_summary, dependent_data], ignore_index=True)\n",
    "dependents_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents = pd.read_json(os.path.join(path_dataset, 'Dependents.json'))\n",
    "df_tools = pd.read_json(os.path.join(path_dataset, 'Tools.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Gitlab dependents general information for each tool\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(f'{index}: {row[\"Tool\"]}')\n",
    "    repos_data, errors_data = gitlab_miner.scrape_repo_list(\n",
    "        row['GitLab Dependents'])\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_gitlab_repo_scraped, f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n",
    "\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(path_gitlab_repo_scraped,\n",
    "                            f'Discarded.{row[\"Tool\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Gitlab dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_gitlab_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos without any issues\n",
    "        repos = repos[repos['#Issues'] > 0]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(f'{row[\"Name\"]}: {repos[\"#Issues\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = gitlab_miner.scrape_issue_list(repos['Repo'].tolist())\n",
    "        if not issues.empty:\n",
    "            issues.to_json(os.path.join(path_gitlab_issue_raw,\n",
    "                                        f'{row[\"Name\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_link</th>\n",
       "      <th>Issue_title</th>\n",
       "      <th>Issue_label</th>\n",
       "      <th>Issue_creation_time</th>\n",
       "      <th>Issue_closed_time</th>\n",
       "      <th>Issue_upvote_count</th>\n",
       "      <th>Issue_downvote_count</th>\n",
       "      <th>Issue_answer_count</th>\n",
       "      <th>Issue_body</th>\n",
       "      <th>Tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>[Sorts] Add sagemaker dependencies</td>\n",
       "      <td>[arena::security, product::sorts, type::bug]</td>\n",
       "      <td>2022-12-19 20:28:18.985</td>\n",
       "      <td>2023-02-03 19:22:14.148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;!-- Issues are public, they should not contai...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>Enable sagemaker</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-04-21 18:40:24.230</td>\n",
       "      <td>2020-05-07 21:34:48.408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>https://docs.aws.amazon.com/sagemaker/</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>Saving behave logs in MLflow</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-07-06 19:33:14.309</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Like we do in learn, we should also save the p...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>ML Database vs. MLflow</td>\n",
       "      <td>[learn]</td>\n",
       "      <td>2020-04-25 17:51:29.061</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>I am mainly working on the feature selection p...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://gitlab.com/librespacefoundation/polari...</td>\n",
       "      <td>Namespacing polaris runs for logging purposes ...</td>\n",
       "      <td>[improvement, learn]</td>\n",
       "      <td>2020-01-31 21:57:59.518</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Background\\n==========\\n\\nEverytime analysis i...</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Issue_link  \\\n",
       "0  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "1  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "2  https://gitlab.com/librespacefoundation/polari...   \n",
       "3  https://gitlab.com/librespacefoundation/polari...   \n",
       "4  https://gitlab.com/librespacefoundation/polari...   \n",
       "\n",
       "                                         Issue_title  \\\n",
       "0                 [Sorts] Add sagemaker dependencies   \n",
       "1                                   Enable sagemaker   \n",
       "2                       Saving behave logs in MLflow   \n",
       "3                             ML Database vs. MLflow   \n",
       "4  Namespacing polaris runs for logging purposes ...   \n",
       "\n",
       "                                    Issue_label     Issue_creation_time  \\\n",
       "0  [arena::security, product::sorts, type::bug] 2022-12-19 20:28:18.985   \n",
       "1                                            [] 2020-04-21 18:40:24.230   \n",
       "2                                            [] 2021-07-06 19:33:14.309   \n",
       "3                                       [learn] 2020-04-25 17:51:29.061   \n",
       "4                          [improvement, learn] 2020-01-31 21:57:59.518   \n",
       "\n",
       "        Issue_closed_time  Issue_upvote_count  Issue_downvote_count  \\\n",
       "0 2023-02-03 19:22:14.148                   0                     0   \n",
       "1 2020-05-07 21:34:48.408                   0                     0   \n",
       "2                     NaT                   0                     0   \n",
       "3                     NaT                   1                     0   \n",
       "4                     NaT                   0                     0   \n",
       "\n",
       "   Issue_answer_count                                         Issue_body  \\\n",
       "0                  13  <!-- Issues are public, they should not contai...   \n",
       "1                   4             https://docs.aws.amazon.com/sagemaker/   \n",
       "2                   1  Like we do in learn, we should also save the p...   \n",
       "3                   3  I am mainly working on the feature selection p...   \n",
       "4                   1  Background\\n==========\\n\\nEverytime analysis i...   \n",
       "\n",
       "               Tool  \n",
       "0  Amazon SageMaker  \n",
       "1  Amazon SageMaker  \n",
       "2            MLflow  \n",
       "3            MLflow  \n",
       "4            MLflow  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude Gitlab issues that are not related to each tool\n",
    "valid_issues_all = pd.DataFrame()\n",
    "valid_fixes_all = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    valid_fixes = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    for index, issue in issues.iterrows():\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if 'amazon' in keyword:\n",
    "                continue\n",
    "            if keyword in issue['Issue_title'].lower():\n",
    "                valid_issue = pd.DataFrame([issue])\n",
    "                valid_issues = pd.concat(\n",
    "                    [valid_issues, valid_issue], ignore_index=True)\n",
    "                if not pd.isnull(issue['Issue_closed_time']):\n",
    "                    valid_fixes = pd.concat(\n",
    "                        [valid_fixes, valid_issue], ignore_index=True)\n",
    "                break\n",
    "\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues['Tool'] = tool_name\n",
    "        valid_issues_all = pd.concat(\n",
    "            [valid_issues_all, valid_issues], ignore_index=True)\n",
    "        if not valid_fixes.empty:\n",
    "            valid_fixes['Tool'] = tool_name\n",
    "            valid_fixes_all = pd.concat(\n",
    "                [valid_fixes_all, valid_fixes], ignore_index=True)\n",
    "\n",
    "valid_issues_all = valid_issues_all[~valid_issues_all['Tool'].isin(\n",
    "    ignore_tools)]\n",
    "valid_fixes_all = valid_fixes_all[~valid_fixes_all['Tool'].isin(ignore_tools)]\n",
    "valid_issues_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arena::security', 'improvement', 'learn', 'product::sorts', 'type::bug'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = set()\n",
    "for _, row in valid_issues_all['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_link</th>\n",
       "      <th>Issue_title</th>\n",
       "      <th>Issue_label</th>\n",
       "      <th>Issue_creation_time</th>\n",
       "      <th>Issue_closed_time</th>\n",
       "      <th>Issue_upvote_count</th>\n",
       "      <th>Issue_downvote_count</th>\n",
       "      <th>Issue_answer_count</th>\n",
       "      <th>Issue_body</th>\n",
       "      <th>Tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://gitlab.com/fluidattacks/universe/-/iss...</td>\n",
       "      <td>[Sorts] Add sagemaker dependencies</td>\n",
       "      <td>[arena::security, product::sorts, type::bug]</td>\n",
       "      <td>2022-12-19 20:28:18.985</td>\n",
       "      <td>2023-02-03 19:22:14.148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;!-- Issues are public, they should not contai...</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Issue_link  \\\n",
       "0  https://gitlab.com/fluidattacks/universe/-/iss...   \n",
       "\n",
       "                          Issue_title  \\\n",
       "0  [Sorts] Add sagemaker dependencies   \n",
       "\n",
       "                                    Issue_label     Issue_creation_time  \\\n",
       "0  [arena::security, product::sorts, type::bug] 2022-12-19 20:28:18.985   \n",
       "\n",
       "        Issue_closed_time Issue_upvote_count Issue_downvote_count  \\\n",
       "0 2023-02-03 19:22:14.148                  0                    0   \n",
       "\n",
       "  Issue_answer_count                                         Issue_body  \\\n",
       "0                 13  <!-- Issues are public, they should not contai...   \n",
       "\n",
       "               Tool  \n",
       "0  Amazon SageMaker  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "valid_issues_filtered = []\n",
    "valid_fixes_filtered = []\n",
    "\n",
    "for index, row in valid_issues_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "\n",
    "    break_sign = False\n",
    "    title = row['Issue_title'].lower()\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for issue_label in issue_labels:\n",
    "            if not break_sign and issue_label in label_repo.lower():\n",
    "                valid_issues_filtered.append(row)\n",
    "                break_sign = True\n",
    "            elif not break_sign and issue_label in title:\n",
    "                valid_issues_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "for index, row in valid_fixes_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "\n",
    "    break_sign = False\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for label_question in issue_labels:\n",
    "            if not break_sign and label_question in label_repo.lower():\n",
    "                valid_fixes_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "valid_issues_filtered = pd.concat(valid_issues_filtered, axis=1).T\n",
    "if valid_fixes_filtered:\n",
    "    valid_fixes_filtered = pd.concat(valid_fixes_filtered, axis=1).T\n",
    "\n",
    "valid_issues_filtered.to_json(os.path.join(\n",
    "    path_gitlab_issue_filtered, 'issues.json'), indent=4, orient='records')\n",
    "valid_fixes_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tool  #Issue\n",
       "0  Amazon SageMaker       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_issues = summary_issues.astype({'#Issue': 'int32'})\n",
    "summary_issues.to_csv(os.path.join(\n",
    "    path_gitlab_issue, 'summary.csv'), index=False)\n",
    "summary_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Github dependents general information for each tool\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(f'{index}: {row[\"Tool\"]}')\n",
    "    repos_data, errors_data = github_miner.scrape_repo_list(\n",
    "        row['GitHub Dependents'])\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_github_repo_scraped, f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n",
    "\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(path_github_repo_scraped,\n",
    "                            f'Discarded.{row[\"Tool\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_github_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos with only pr-based issues\n",
    "        repos = repos[repos['#Issues'] > repos['#Pull Requests']]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(\n",
    "            f'{row[\"Name\"]}: {repos[\"#Issues\"].sum() - repos[\"#Pull Requests\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = github_miner.scrape_issue_list(repos['Repo'].tolist())\n",
    "        if not issues.empty:\n",
    "            issues.to_json(os.path.join(path_github_issue_raw,\n",
    "                           f'{row[\"Name\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Github issues that are not related to each tool\n",
    "valid_issues_all = pd.DataFrame()\n",
    "valid_fixes_all = pd.DataFrame()\n",
    "\n",
    "for file_name in glob.glob(os.path.join(path_github_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    valid_fixes = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    for index, issue in issues.iterrows():\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if keyword in issue['Issue_title'].lower():\n",
    "                valid_issue = pd.DataFrame([issue])\n",
    "                valid_issues = pd.concat(\n",
    "                    [valid_issues, valid_issue], ignore_index=True)\n",
    "                if pd.notna(issue['Issue_closed_time']):\n",
    "                    valid_fixes = pd.concat(\n",
    "                        [valid_fixes, valid_issue], ignore_index=True)\n",
    "                break\n",
    "\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues['Tool'] = tool_name\n",
    "        valid_issues_all = pd.concat(\n",
    "            [valid_issues_all, valid_issues], ignore_index=True)\n",
    "        if not valid_fixes.empty:\n",
    "            valid_fixes['Tool'] = tool_name\n",
    "            valid_fixes_all = pd.concat(\n",
    "                [valid_fixes_all, valid_fixes], ignore_index=True)\n",
    "\n",
    "valid_issues_all = valid_issues_all[~valid_issues_all['Tool'].isin(\n",
    "    ignore_tools)]\n",
    "valid_fixes_all = valid_fixes_all[~valid_fixes_all['Tool'].isin(ignore_tools)]\n",
    "valid_issues_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"experiments\"',\n",
       " '0.4.6',\n",
       " '1.1',\n",
       " '1.4',\n",
       " '1.6',\n",
       " '1.7',\n",
       " '2.0',\n",
       " '3 - Quality of Life',\n",
       " '3rd party',\n",
       " '3rd party update',\n",
       " ':bridge_at_night:  Bridge',\n",
       " ':bug: bug',\n",
       " ':rotating_light:',\n",
       " '? - Needs Triage',\n",
       " 'A: example-dvc-experiments',\n",
       " 'A: example-get-started',\n",
       " 'ADO',\n",
       " 'AI\\u202fFrameworks/ONNX',\n",
       " 'AML Compute Instance',\n",
       " 'API',\n",
       " 'API & Doc',\n",
       " 'Auto\\u202fML',\n",
       " 'BF',\n",
       " 'Cloud',\n",
       " 'Community',\n",
       " 'Compute',\n",
       " 'Core UI',\n",
       " 'DRL',\n",
       " 'Data Labeling',\n",
       " 'Data4ML',\n",
       " 'Data\\u202fDrift',\n",
       " 'Data\\u202fPrep\\u202fServices',\n",
       " 'Documentation',\n",
       " 'ERRATA_CANDIDATE',\n",
       " 'Enhancement',\n",
       " 'Environments',\n",
       " 'Evaluation',\n",
       " 'Experimentation UI',\n",
       " 'FAQ',\n",
       " 'Feature - Medium Priority',\n",
       " 'HIGH',\n",
       " 'HPO',\n",
       " 'Hyperdrive',\n",
       " 'Important',\n",
       " 'In the roadmap',\n",
       " 'Inf1',\n",
       " 'Inference',\n",
       " 'Ingestion',\n",
       " 'Issue: Bug Report 🐞',\n",
       " 'Issue: Feature Request',\n",
       " 'L',\n",
       " 'LOE: S',\n",
       " 'Localized',\n",
       " 'MLOps',\n",
       " 'NLP',\n",
       " 'NUM',\n",
       " 'Needs Triage',\n",
       " 'Not related to PyCaret',\n",
       " 'Notebook',\n",
       " 'Optional',\n",
       " 'P0',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'Pipelines',\n",
       " 'Priority 1',\n",
       " 'Reinforcement Learning',\n",
       " 'RepoOfficiel',\n",
       " 'Review One',\n",
       " 'Review Two',\n",
       " 'SDK',\n",
       " 'Stage: Technical Design 🎨',\n",
       " 'Stale',\n",
       " 'TA',\n",
       " 'TODO',\n",
       " 'TODO before 1.0',\n",
       " 'Training',\n",
       " 'Training Service',\n",
       " 'Trn1',\n",
       " 'Usage',\n",
       " 'VISION',\n",
       " 'WIP',\n",
       " 'WIP - Susankha',\n",
       " 'Workspace Management',\n",
       " '[module] pipeline',\n",
       " 'accelerator: tpu',\n",
       " 'accessibility',\n",
       " 'ai',\n",
       " 'aiplatform',\n",
       " 'air',\n",
       " 'alonet',\n",
       " 'api: aiplatform',\n",
       " 'api: vertex-ai',\n",
       " 'app-ui',\n",
       " 'apply',\n",
       " 'arc_ml',\n",
       " 'architecture',\n",
       " 'area / SDK-storage',\n",
       " 'area / integrations',\n",
       " 'area-getting-started',\n",
       " 'area-ml-resource-management',\n",
       " 'area-remote-desktop',\n",
       " 'area-remote-web',\n",
       " 'area-sign-in',\n",
       " 'area-telemetry',\n",
       " 'area-treeview',\n",
       " 'area-yaml',\n",
       " 'area/async',\n",
       " 'area/components',\n",
       " 'area/components/aws/sagemaker',\n",
       " 'area/operator',\n",
       " 'area/registry',\n",
       " 'area/samples',\n",
       " 'area:databuilder',\n",
       " 'assigned',\n",
       " 'assigned-to-author',\n",
       " 'audience/technical',\n",
       " 'august-rewrite',\n",
       " 'automations',\n",
       " 'automl',\n",
       " 'awaiting response',\n",
       " 'awaiting-product-team-response',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'azure-provider',\n",
       " 'azureml',\n",
       " 'backlog',\n",
       " 'benchmark',\n",
       " 'bittensor',\n",
       " 'blocked',\n",
       " 'blocker',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'bug',\n",
       " 'bug-bash',\n",
       " 'build',\n",
       " 'chapter: appendix-tools',\n",
       " 'checkpointing',\n",
       " 'chore',\n",
       " 'cleanup',\n",
       " 'closing-soon-if-no-response',\n",
       " 'code',\n",
       " 'concerns: agents',\n",
       " 'concerns: documentation',\n",
       " 'concerns: main API',\n",
       " 'configs',\n",
       " 'connectors',\n",
       " 'contribution welcomed',\n",
       " 'core/subsvc',\n",
       " 'customer-inquiry',\n",
       " 'customer-issue',\n",
       " 'cxp',\n",
       " 'data',\n",
       " 'data-sync',\n",
       " 'debt',\n",
       " 'dependencies',\n",
       " 'deploy',\n",
       " 'design',\n",
       " 'dev',\n",
       " 'dev workflow',\n",
       " 'devflows',\n",
       " 'discussion',\n",
       " 'diy_container',\n",
       " 'doc-bug',\n",
       " 'doc-enhancement',\n",
       " 'docker images',\n",
       " 'docs',\n",
       " 'documentation',\n",
       " 'duplicate',\n",
       " 'enhancement',\n",
       " 'enhancement request',\n",
       " 'env: new',\n",
       " 'env: sagemaker',\n",
       " 'environment',\n",
       " 'environment: slurm',\n",
       " 'ep:CUDA',\n",
       " 'epic',\n",
       " 'error',\n",
       " 'evaluate_model',\n",
       " 'example issue',\n",
       " 'example request',\n",
       " 'experimental',\n",
       " 'explore',\n",
       " 'feature',\n",
       " 'feature request',\n",
       " 'feature-request',\n",
       " 'fixme',\n",
       " 'forum',\n",
       " 'functionality',\n",
       " 'future release',\n",
       " 'good first issue',\n",
       " 'graphistry',\n",
       " 'gui',\n",
       " 'guides',\n",
       " 'help wanted',\n",
       " 'hi-ml-azure',\n",
       " 'high-priority',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in progress',\n",
       " 'inference',\n",
       " 'inferencing-benchmark',\n",
       " 'info-needed',\n",
       " 'infrastructure',\n",
       " 'integration',\n",
       " 'invalid',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'iteration-candidate',\n",
       " 'journey:intermediate',\n",
       " 'keep fresh',\n",
       " 'kind/bug',\n",
       " 'kind/enhancement',\n",
       " 'kind/feature',\n",
       " 'kind/question',\n",
       " 'kind/reproducibility',\n",
       " 'kind/usability',\n",
       " 'kubeflow',\n",
       " 'lifecycle/frozen',\n",
       " 'lifecycle/stale',\n",
       " 'lightning',\n",
       " 'linting / formatting / cleaning',\n",
       " 'logger',\n",
       " 'logger: comet',\n",
       " 'logger: mlflow',\n",
       " 'logger: wandb',\n",
       " 'logging',\n",
       " 'looking into it',\n",
       " 'low priority',\n",
       " 'machine-learning',\n",
       " 'machine-learning/svc',\n",
       " 'major',\n",
       " 'metrics',\n",
       " 'missing_info',\n",
       " 'ml',\n",
       " 'ml-engineering',\n",
       " 'mlflow',\n",
       " 'model',\n",
       " 'module: text',\n",
       " 'must have',\n",
       " 'need-design-decision',\n",
       " 'needs triage',\n",
       " 'needs-more-info',\n",
       " 'needs-tests',\n",
       " 'needs-triage',\n",
       " 'neptune',\n",
       " 'new',\n",
       " 'new feature',\n",
       " 'new table',\n",
       " 'nnidev',\n",
       " 'no-issue-activity',\n",
       " 'normal',\n",
       " 'notebook',\n",
       " 'on hold',\n",
       " 'open for contribution',\n",
       " 'operationalization',\n",
       " 'optimization',\n",
       " 'organizational',\n",
       " 'p0-critical',\n",
       " 'p1',\n",
       " 'p1-important',\n",
       " 'p2-medium',\n",
       " 'p3-nice-to-have',\n",
       " 'phase / shipped',\n",
       " 'pipeline',\n",
       " 'pipeline 6: infer',\n",
       " 'pl',\n",
       " 'platform/aws',\n",
       " 'platform/other',\n",
       " 'plot_model',\n",
       " 'practice',\n",
       " 'pri/medium',\n",
       " 'priority 3 - nice to have',\n",
       " 'priority-p0',\n",
       " 'priority-p1',\n",
       " 'priority/important-longterm',\n",
       " 'priority/p1',\n",
       " 'priority: 1',\n",
       " 'priority: 2',\n",
       " 'priority: high',\n",
       " 'priority: medium',\n",
       " 'priority: p2',\n",
       " 'priority:high',\n",
       " 'priority:medium',\n",
       " 'priority_high',\n",
       " 'product-feedback',\n",
       " 'product-gap',\n",
       " 'product-issue',\n",
       " 'product-question',\n",
       " 'progress bar: rich',\n",
       " 'python',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick-fix',\n",
       " 'refactor',\n",
       " 'refactoring',\n",
       " 'reporting and diagnostics',\n",
       " 'research',\n",
       " 'roadmap',\n",
       " 'sagemaker',\n",
       " 'sagemaker-dsk-v2',\n",
       " 'sagemaker_container',\n",
       " 'samples',\n",
       " 'scenario',\n",
       " 'sdk-docs',\n",
       " 'section',\n",
       " 'service update',\n",
       " 'service:executor',\n",
       " 'service:sm-executor',\n",
       " 'setup',\n",
       " 'snippets-request',\n",
       " 'spark',\n",
       " 'stale',\n",
       " 'stale :zzz:',\n",
       " 'status/triaged',\n",
       " 'status: phase 1',\n",
       " 'status: phase 2',\n",
       " 'status:completed',\n",
       " 'status:needs_reproducing',\n",
       " 'status:needs_votes',\n",
       " 'streaming',\n",
       " 'studio',\n",
       " 'support',\n",
       " 't-must-fix',\n",
       " 't-nice-to-have-fix',\n",
       " 't-unknown-sub-error',\n",
       " 'task',\n",
       " 'technical debt',\n",
       " 'test',\n",
       " 'tests',\n",
       " 'time_series',\n",
       " 'timecodes',\n",
       " 'to refine',\n",
       " 'todo',\n",
       " 'tooling and CI',\n",
       " 'topic:dependencies',\n",
       " 'topic:eval',\n",
       " 'topic:models',\n",
       " 'topic:reader',\n",
       " 'training-benchmark',\n",
       " 'triage',\n",
       " 'triage me',\n",
       " 'triage-needed',\n",
       " 'triage/intermediate-priotrity',\n",
       " 'triaged',\n",
       " 'tune',\n",
       " 'type / bug',\n",
       " 'type / code-health',\n",
       " 'type / enhancement',\n",
       " 'type/maintenance',\n",
       " 'type: bug',\n",
       " 'type: docs',\n",
       " 'type: enhancement',\n",
       " 'type: feature request',\n",
       " 'type: question',\n",
       " 'type:bug',\n",
       " 'type:feature',\n",
       " 'type:maintenance',\n",
       " 'type:question',\n",
       " 'up-for-grabs',\n",
       " 'upstream-azml',\n",
       " 'urgent',\n",
       " 'user raised',\n",
       " 'ux',\n",
       " 'v0.8.5',\n",
       " 'waiting',\n",
       " 'waiting feedback',\n",
       " \"won't fix\",\n",
       " 'wontfix',\n",
       " 'work-item',\n",
       " 'workflow',\n",
       " 'working as intended',\n",
       " '✨ feat',\n",
       " '민지',\n",
       " '찬국',\n",
       " '🐛 bug fix',\n",
       " '🐞 bug',\n",
       " '🐥 experiment',\n",
       " '🐺 Tracker',\n",
       " '👨\\u200d👩\\u200d👧\\u200d👧 discussion',\n",
       " '💎 New Component',\n",
       " '📜 Paper',\n",
       " '🔤 named-entity-recognition',\n",
       " '🔥 New Feature',\n",
       " '🛂 checkpoint',\n",
       " '🦉 dvc',\n",
       " '🧪 testing'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = set()\n",
    "for _, row in valid_issues_all['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "valid_issues_filtered = []\n",
    "valid_fixes_filtered = []\n",
    "\n",
    "for index, row in valid_issues_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "\n",
    "    break_sign = False\n",
    "    title = row['Issue_title'].lower()\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for issue_label in issue_labels:\n",
    "            if not break_sign and issue_label in label_repo.lower():\n",
    "                valid_issues_filtered.append(row)\n",
    "                break_sign = True\n",
    "            elif not break_sign and issue_label in title:\n",
    "                valid_issues_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "for index, row in valid_fixes_all.iterrows():\n",
    "    if not row['Issue_title'].isascii():\n",
    "        continue\n",
    "\n",
    "    break_sign = False\n",
    "    for label_repo in row['Issue_label']:\n",
    "        for issue_label in issue_labels:\n",
    "            if not break_sign and issue_label in label_repo.lower():\n",
    "                valid_fixes_filtered.append(row)\n",
    "                break_sign = True\n",
    "\n",
    "valid_issues_filtered = pd.concat(valid_issues_filtered, axis=1).T\n",
    "valid_fixes_filtered = pd.concat(valid_fixes_filtered, axis=1).T\n",
    "\n",
    "valid_issues_filtered.to_json(os.path.join(\n",
    "    path_github_issue_filtered, 'issues.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>113</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Issue  #Closed\n",
       "0         Amazon SageMaker      77       57\n",
       "1   Azure Machine Learning      75       27\n",
       "2                  ClearML       3        2\n",
       "3                    Comet      22       20\n",
       "4                      DVC      30       22\n",
       "5                    Kedro      19       14\n",
       "6                   MLflow     113       89\n",
       "7                  Neptune      14       10\n",
       "8                   Optuna       1        1\n",
       "9                   SigOpt       4        3\n",
       "10               Vertex AI       9        4\n",
       "11        Weights & Biases      42       39"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_fixes = valid_fixes_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_fixes.rename(columns={'Issue_title': '#Closed'}, inplace=True)\n",
    "summary_github = summary_issues.merge(\n",
    "    summary_fixes, on='Tool', how='outer').fillna(0)\n",
    "summary_github = summary_github.astype({'#Issue': 'int32', '#Closed': 'int32'})\n",
    "summary_github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comet</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVC</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>113</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool  #Issue  #Closed\n",
       "0         Amazon SageMaker      77       57\n",
       "1   Azure Machine Learning      75       27\n",
       "2                  ClearML       3        2\n",
       "3                    Comet      22       20\n",
       "4                      DVC      30       22\n",
       "5                    Kedro      19       14\n",
       "6                   MLflow     113       89\n",
       "7                  Neptune      14       10\n",
       "8                   SigOpt       4        3\n",
       "9                Vertex AI       9        4\n",
       "10        Weights & Biases      42       39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_issues = valid_issues_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_fixes = valid_fixes_filtered.groupby(\n",
    "    'Tool').count()['Issue_title'].reset_index()\n",
    "summary_issues.rename(columns={'Issue_title': '#Issue'}, inplace=True)\n",
    "summary_fixes.rename(columns={'Issue_title': '#Closed'}, inplace=True)\n",
    "summary_github = summary_issues.merge(\n",
    "    summary_fixes, on='Tool', how='outer').fillna(0)\n",
    "summary_github = summary_github.astype({'#Issue': 'int32', '#Closed': 'int32'})\n",
    "summary_github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine Github and Gitlab issues\n",
    "df_issue_github = pd.read_json(os.path.join(\n",
    "    path_github_issue_filtered, 'issues.json'))\n",
    "df_issue_gitlab = pd.read_json(os.path.join(\n",
    "    path_gitlab_issue_filtered, 'issues.json'))\n",
    "\n",
    "df_issue_github['Platform'] = 'Github'\n",
    "df_issue_gitlab['Platform'] = 'Gitlab'\n",
    "\n",
    "df_issues = pd.concat([df_issue_github, df_issue_gitlab], ignore_index=True)\n",
    "del df_issues['Issue_label']\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling, 'original.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from string import ascii_lowercase\n",
    "import re\n",
    "\n",
    "# issue content preprocessing patterns\n",
    "regex = r\"(<.*?>)|({.*?})|((!)?\\[.*?\\])|(\\(.*?\\))|(\\`{3}.+?\\`{3})|(\\`{2}.+?\\`{2})|(\\`{1}.+?\\`{1})|([^\\s]*[<=>]=[^\\s]+)|(@[^\\s]+)|((https?:\\/)?\\/[^\\s]+)|([^\\s]*\\\\[^\\s]+)|([^\\s]+\\/[^\\s]+)|([^\\s]+\\.[^\\s]+)|([^\\s]+-[^\\s]+)|([^\\s]+_[^\\s]+)|(_+[^\\s]+_*)|(_*[^\\s]+_+)|([0-9\\|\\-\\r\\n\\t\\\"\\-#*=~:{}\\(\\)\\[\\]<>]+)\"\n",
    "\n",
    "len_max = len('xxxxxxxxxxxxxxxx')\n",
    "\n",
    "def preprocess_text(text, remove_code=False):\n",
    "    text = text.lower().encode('ascii', errors='ignore').decode('ascii')\n",
    "\n",
    "    for tool_keywords in tools_keywords.values():\n",
    "        for tool_keyword in tool_keywords:\n",
    "            if tool_keyword in text:\n",
    "                text = text.replace(tool_keyword, '')\n",
    "\n",
    "    text = re.sub(regex, ' ', text, 0, re.DOTALL) if remove_code else text\n",
    "    \n",
    "    # remove repeated letters\n",
    "    for time in range(3, len_max + 1):\n",
    "        for letter in ascii_lowercase:\n",
    "            text = text.replace(letter * time, '')\n",
    "            \n",
    "    text = preprocess_string(text)\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt for gpt model\n",
    "import random\n",
    "prompt_issue = 'Please write a one-sentence summary of the user\\'s encountered challenges. For instance, you could begin with a sentence such as: \"The user XXXX\".\\n\"\"\"'\n",
    "\n",
    "\n",
    "def retry_with_backoff(fn, retries=2, backoff_in_seconds=1, *args, **kwargs):\n",
    "    x = 0\n",
    "\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except:\n",
    "            if x == retries:\n",
    "                raise\n",
    "\n",
    "            sleep = backoff_in_seconds * 2 ** x + random.uniform(0, 1)\n",
    "            time.sleep(sleep)\n",
    "            x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add potential field to issues for later filling\n",
    "df_issues = pd.read_json(os.path.join(path_labeling, 'original.json'))\n",
    "\n",
    "df_issues['Issue_original_content'] = ''\n",
    "df_issues['Issue_preprocessed_content'] = ''\n",
    "df_issues['Issue_gpt_summary_original'] = ''\n",
    "df_issues['Issue_gpt_summary'] = ''\n",
    "df_issues['Fix_original_content'] = ''\n",
    "df_issues['Fix_preprocessed_content'] = ''\n",
    "df_issues['Fix_gpt_summary_original'] = ''\n",
    "df_issues['Fix_gpt_summary'] = ''\n",
    "\n",
    "df_issues.to_json(os.path.join(path_labeling,\n",
    "                  'issues.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modulenotfounderror modul name tensorboard \n",
      "combin param param work \n",
      "error load \n",
      "deploy fail \n",
      "log val loss \n",
      "fix import issu \n",
      "logger \n"
     ]
    }
   ],
   "source": [
    "# Experiment 1\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    issue = preprocess_text(row['Issue_title']) + ' ' + preprocess_text(str(row['Issue_body']))\n",
    "    \n",
    "    if len(issue.split()) < 6 or len(issue) < 30:\n",
    "        df_issues.drop(index, inplace=True)\n",
    "        print(issue)\n",
    "    else:\n",
    "        df_issues.at[index, 'Issue_original_content'] = issue\n",
    "\n",
    "df_issues.to_json(os.path.join(path_labeling,\n",
    "                  'issues.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on question {index}')\n",
    "        df_issues.to_json(os.path.join(\n",
    "            path_labeling, 'issues.json'), indent=4, orient='records')\n",
    "\n",
    "    if row['Issue_gpt_summary_original']:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        issue = prompt_issue + 'Title: ' + row['Question_title'] + ' Body: ' + row['Question_body'] + '###\\n'\n",
    "        response = retry_with_backoff(\n",
    "            openai.ChatCompletion.create,\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful summarizer.\"},\n",
    "                {\"role\": \"user\", \"content\": issue},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        content = response['choices'][0]['message']['content'].strip()\n",
    "        df_issues.at[index, 'Issue_gpt_summary_original'] = content\n",
    "        df_issues.at[index, 'Issue_gpt_summary'] = preprocess_text(content)\n",
    "    except Exception as e:\n",
    "        # output unsuccesful requests\n",
    "        print(f'{e} on issue {row[\"Issue_link\"]}')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling, 'issues.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "assert df_issues.shape[0] == df_issues.dropna(\n",
    "    subset=['Issue_gpt_summary_original']).shape[0]\n",
    "\n",
    "# output the number of asset-management-related Git issues\n",
    "len(df_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    content = preprocess_text(row['Issue_title'], remove_code=True) + ' ' + preprocess_text(str(row['Issue_body']), remove_code=True)\n",
    "    df_issues.at[index, 'Issue_preprocessed_content'] = content\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling, 'issues.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    answers = ' '.join(row['Answer_list'])\n",
    "    df_issues.at[index, 'Fix_original_content'] = preprocess_text(answers)\n",
    "\n",
    "df_issues.to_json(os.path.join(path_labeling,\n",
    "                  'issues.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 6\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    answers = ' '.join(row['Answer_list'])\n",
    "    df_issues.at[index, 'Fix_preprocessed_content'] = preprocess_text(answers, remove_code=True)\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling, 'issues.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size is based on the recommendation from https://www.calculator.net/sample-size-calculator.html\n",
    "\n",
    "sample_size = 199\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "df_sample = df_issues.sample(n=sample_size, random_state=42)\n",
    "\n",
    "df_sample.to_json(os.path.join(\n",
    "    path_labeling, 'sample.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning-AI/lightning\n",
      "persisting on issue 0\n",
      "awsdocs/amazon-sagemaker-developer-guide\n",
      "aws/sagemaker-tensorflow-serving-container\n",
      "aws/amazon-sagemaker-operator-for-k8s\n",
      "aws/aws-step-functions-data-science-sdk-python\n",
      "aws/studio-lab-examples\n",
      "aws/sagemaker-training-toolkit\n",
      "aws/sagemaker-pytorch-inference-toolkit\n",
      "awslabs/service-workbench-on-aws-cn\n",
      "aws-deepracer-community/deepracer-core\n",
      "aws-samples/eks-kubeflow-workshop\n",
      "aws-samples/amazon-sagemaker-examples-jp\n",
      "aws-solutions/mlops-workload-orchestrator\n",
      "udacity/ML_SageMaker_Studies\n",
      "kubeflow/pipelines\n",
      "aws/deep-learning-containers\n",
      "autogluon/autogluon\n",
      "awslabs/gluonts\n",
      "kedro-org/kedro\n",
      "turbot/steampipe-plugin-aws\n",
      "persisting on issue 50\n",
      "zenml-io/zenml\n",
      "awslabs/service-workbench-on-aws\n",
      "awslabs/benchmark-ai\n",
      "awslabs/realtime-fraud-detection-with-gnn-on-dgl\n",
      "huggingface/accelerate\n",
      "astronomer/astronomer-providers\n",
      "awslabs/sagemaker-debugger\n",
      "aws/graph-notebook\n",
      "huggingface/transformers\n",
      "Azure/azureml-examples\n",
      "microsoft/recommenders\n",
      "Azure/MachineLearningNotebooks\n",
      "persisting on issue 100\n",
      "microsoft/vscode-tools-for-ai\n",
      "microsoft/azure_arc\n",
      "microsoft/hi-ml\n",
      "microsoft/computervision-recipes\n",
      "microsoft/InnerEye-DeepLearning\n",
      "augerai/a2ml\n",
      "microsoft/lightgbm-benchmark\n",
      "rapidsai/cloud-ml-examples\n",
      "microsoft/onnxruntime\n",
      "microsoft/nni\n",
      "persisting on issue 150\n",
      "sillsdev/silnlp\n",
      "huggingface/transformers\n",
      "Lightning-AI/lightning\n",
      "ultralytics/yolov5\n",
      "ludwig-ai/ludwig\n",
      "cc-ai/climategan\n",
      "khirotaka/enchanter\n",
      "BlueBrain/Search\n",
      "zincware/ZnTrack\n",
      "iterative/dvc-bench\n",
      "iterative/example-repos-dev\n",
      "DagsHub/fds\n",
      "Nautilus-Cyberneering/nautilus-librarian\n",
      "johannespischinger/senti_anal\n",
      "se4ai2122-cs-uniba/CT-COVID\n",
      "csia-pme/csia-pme\n",
      "deep-projects/dvc-cc\n",
      "persisting on issue 200\n",
      "iterative/dvc-checkpoints-mnist\n",
      "MantisAI/Rasa-MLOPs\n",
      "adamtupper/cookiecutter-lvsn-workflow\n",
      "iterative/checkpoints-tutorial\n",
      "Galileo-Galilei/kedro-mlflow\n",
      "getindata/kedro-kubeflow\n",
      "kedro-org/kedro-plugins\n",
      "quaseldoku/QuaselDoku\n",
      "whylabs/whylogs\n",
      "konstellation-io/kdl-server\n",
      "deepset-ai/FARM\n",
      "eto-ai/rikai\n",
      "mlf-core/mlf-core\n",
      "databrickslabs/dbx\n",
      "nv-morpheus/Morpheus\n",
      "equinor/flownet\n",
      "NRCan/geo-deep-learning\n",
      "Galileo-Galilei/kedro-mlflow\n",
      "persisting on issue 250\n",
      "omegaml/omegaml\n",
      "ugr-sail/sinergym\n",
      "prinz-nussknacker/prinz\n",
      "getindata/kedro-kubeflow\n",
      "nyanp/nyaggle\n",
      "artefactory/one-click-mlflow\n",
      "canonical/mlflow-operator\n",
      "community-charts/helm-charts\n",
      "PacktPublishing/Machine-Learning-Engineering-with-MLflow\n",
      "sash-a/es_pytorch\n",
      "huggingface/transformers\n",
      "Lightning-AI/lightning\n",
      "persisting on issue 300\n",
      "open-metadata/OpenMetadata\n",
      "triton-inference-server/server\n",
      "mindsdb/mindsdb\n",
      "deepset-ai/haystack\n",
      "bentoml/BentoML\n",
      "pycaret/pycaret\n",
      "aimhubio/aim\n",
      "Azure/azureml-examples\n",
      "Azure/MachineLearningNotebooks\n",
      "microsoft/qlib\n",
      "amundsen-io/amundsen\n",
      "aws/graph-notebook\n",
      "neptune-ai/examples\n",
      "graphistry/graph-app-kit\n",
      "ray-project/ray\n",
      "persisting on issue 350\n",
      "huggingface/transformers\n",
      "googleapis/python-aiplatform\n",
      "GoogleCloudPlatform/vertex-ai-samples\n",
      "zenml-io/zenml\n",
      "googleapis/java-aiplatform\n",
      "googleapis/nodejs-ai-platform\n",
      "GoogleCloudPlatform/asl-ml-immersion\n",
      "ThilinaRajapakse/simpletransformers\n",
      "deepchecks/deepchecks\n",
      "shagunsodhani/ml-logger\n",
      "vlievin/fz-openqa\n",
      "error on issue ('vlievin/fz-openqa', 216): 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/reference/issues#get-an-issue\"}\n",
      "MathisFederico/LearnRL\n",
      "allenai/tango\n",
      "kaylode/theseus\n",
      "feldberlin/wavenet\n",
      "ContinualAI/avalanche\n",
      "alvarobartt/wandbfsspec\n",
      "boostcampaitech2/semantic-segmentation-level2-cv-02\n",
      "AIStream-Peelout/flow-forecast\n",
      "pstage-ocr-team6/ocr-teamcode\n",
      "EleutherAI/gpt-neox\n",
      "Lightning-AI/lightning-hpo\n",
      "icenet-ai/icenet\n",
      "ezeeEric/DiVAE\n",
      "wisdomify/wisdomify\n",
      "johannespischinger/senti_anal\n",
      "tinkoff-ai/etna\n",
      "Visual-Behavior/aloception-oss\n",
      "ashleve/lightning-hydra-template\n",
      "graphnet-team/graphnet\n",
      "neuro-inc/mlops-wandb-bucket-ref\n",
      "rdnfn/beobench\n",
      "persisting on issue 400\n"
     ]
    }
   ],
   "source": [
    "from github import Github\n",
    "import numpy as np\n",
    "import gitlab\n",
    "\n",
    "gl = gitlab.Gitlab('https://gitlab.com', private_token='glpat-SvwyWD6pbPNvbsBSvxdy')\n",
    "\n",
    "g = Github('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')\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues.json'))\n",
    "\n",
    "df_issues['Answer_list'] = np.empty((len(df_issues), 0)).tolist()\n",
    "\n",
    "last_repo = ''\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    time.sleep(3)\n",
    "    if row['Platform'] == 'Github':\n",
    "        issue_link = row['Issue_link'].split('/')\n",
    "        issue_repo = issue_link[3] + '/' + issue_link[4]\n",
    "        issue_id = int(issue_link[-1])\n",
    "        try:\n",
    "            if issue_repo != last_repo:\n",
    "                print(issue_repo)\n",
    "                time.sleep(3)\n",
    "                repo = g.get_repo(issue_repo)\n",
    "            time.sleep(3)\n",
    "            issue = repo.get_issue(issue_id)\n",
    "            answer_list = []\n",
    "            for answer in issue.get_comments():\n",
    "                time.sleep(3)\n",
    "                answer_list.append(answer.body)\n",
    "            df_issues.at[index, 'Answer_list'] = answer_list\n",
    "            last_repo = issue_repo\n",
    "        except Exception as e:\n",
    "            print(f'error on issue {issue_repo, issue_id}: {e}')\n",
    "    if row['Platform'] == 'Gitlab':\n",
    "        issue_link = row['Issue_link'].split('/')\n",
    "        issue_repo = issue_link[3] + '/' + issue_link[4]\n",
    "        issue_id = int(issue_link[-1])\n",
    "        repo_g = gl.projects.get(issue_repo)\n",
    "        issue = repo_g.issues.get(issue_id)\n",
    "        comments = issue.notes.list(get_all=True)\n",
    "        answer_list = []\n",
    "        for answer in comments:\n",
    "            answer_list.append(answer.body)\n",
    "        df_issues.at[index, 'Answer_list'] = answer_list\n",
    "    if index % 50 == 0:\n",
    "        print(f'persisting on issue {index}')\n",
    "        df_issues.to_json(os.path.join(\n",
    "            path_labeling, 'issues_.json'), indent=4, orient='records')\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling, 'issues_.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_issues = pd.read_json(os.path.join(\n",
    "    path_labeling, 'issues__.json'))\n",
    "\n",
    "del df_issues['Fix_manual_summary_original']\n",
    "del df_issues['Fix_manual_summary']\n",
    "\n",
    "df_issues.to_json(os.path.join(\n",
    "    path_labeling, 'issues__.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "from Scrape.GHMiner import GitHubMiner\n",
    "from Scrape.GLMiner import GitLabMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "path_labeling = os.path.join(path_dataset, 'Labeling')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_discussion = os.path.join(path_github, 'Discussion')\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_labeling):\n",
    "    os.makedirs(path_labeling)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_discussion):\n",
    "    os.makedirs(path_github_discussion)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=False, nb_workers=multiprocessing.cpu_count())\n",
    "\n",
    "github_miner = GitHubMiner(private_token=os.getenv('GITHUB_TOKEN'))\n",
    "gitlab_miner = GitLabMiner(private_token=os.getenv('GITLAB_TOKEN'))\n",
    "\n",
    "tools_repo = {\n",
    "    'Aim': 'aimhubio/aim',\n",
    "    'Amazon SageMaker': 'aws/sagemaker-python-sdk',\n",
    "    'Azure Machine Learning': 'Azure/azure-sdk-for-python',\n",
    "    'ClearML': 'allegroai/clearml',\n",
    "    'Codalab': 'codalab/codalab-worksheets',\n",
    "    'DVC': 'iterative/dvc',\n",
    "    'Determined': 'determined-ai/determined',\n",
    "    'Domino': 'dominodatalab/python-domino',\n",
    "    'Guild AI': 'guildai/guildai',\n",
    "    'Kedro': 'kedro-org/kedro',\n",
    "    'MLflow': 'mlflow/mlflow',\n",
    "    'MLRun': 'mlrun/mlrun',\n",
    "    'Neptune': 'neptune-ai/neptune-client',\n",
    "    'Optuna': 'optuna/optuna',\n",
    "    'Polyaxon': 'polyaxon/polyaxon',\n",
    "    'Sacred': 'IDSIA/sacred',\n",
    "    'Valohai': 'valohai/valohai-cli',\n",
    "    'Verta': 'VertaAI/modeldb',\n",
    "    'Weights & Biases': 'wandb/wandb'\n",
    "}\n",
    "\n",
    "tools_release_date = {\n",
    "    'Amazon SageMaker': '2017-11-19',\n",
    "    'Azure Machine Learning': '2015-02-18',\n",
    "    'cnvrg.io': '2020-03-31',\n",
    "    'Comet': '2017-01-01',\n",
    "    'H2O AI Cloud': '2021-01-01',\n",
    "    'Iterative Studio': '2021-05-12',\n",
    "    'Polyaxon': '2018-10-16',\n",
    "    'SigOpt': '2014-11-01',\n",
    "    'Vertex AI': '2019-03-01'\n",
    "}\n",
    "\n",
    "tools_link = {\n",
    "    'cnvrg.io': 'https://github.com/cnvrg',\n",
    "    'Comet': 'https://github.com/comet-ml',\n",
    "    'H2O AI Cloud': 'https://h2o.ai/platform/ai-cloud',\n",
    "    'Iterative Studio': 'https://studio.iterative.ai',\n",
    "    'SigOpt': 'https://github.com/sigopt',\n",
    "    'Vertex AI': 'https://cloud.google.com/vertex-ai'\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Aim': ['aim'],\n",
    "    'Amazon SageMaker': ['sagemaker'],\n",
    "    'Azure Machine Learning': ['aml', 'azure machine learning', 'azure ml', 'azure-ml', 'azureml'],\n",
    "    'ClearML': ['clearml'],\n",
    "    'cnvrg.io': ['cnvrg'],\n",
    "    'Codalab': ['codalab'],\n",
    "    'Comet': ['comet'],\n",
    "    'Determined': ['determined'],\n",
    "    'Domino': ['domino'],\n",
    "    'DVC': ['dvc'],\n",
    "    'Guild AI': ['guild ai', 'guild-ai', 'guildai'],\n",
    "    'H2O AI Cloud': ['h2o ai', 'h2o.ai'],\n",
    "    'Kedro': ['kedro'],\n",
    "    'MLflow': ['mlflow'],\n",
    "    'MLRun': ['mlrun'],\n",
    "    'Neptune': ['neptune'],\n",
    "    'Optuna': ['optuna'],\n",
    "    'Polyaxon': ['polyaxon'],\n",
    "    'Sacred': ['sacred'],\n",
    "    'SigOpt': ['sigopt'],\n",
    "    'Valohai': ['valohai'],\n",
    "    'Verta': ['modeldb', 'verta'],\n",
    "    'Vertex AI': ['vertex ai', 'vertex-ai', 'vertexai'],\n",
    "    'Weights & Biases': ['weights and biases', 'wandb', 'weights & biases', 'weights&biases', 'w & b', 'w&b']\n",
    "}\n",
    "\n",
    "issue_labels = {\n",
    "    'bug',\n",
    "    'crash',\n",
    "    'error',\n",
    "    'invalid',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo</th>\n",
       "      <th>Link</th>\n",
       "      <th>Repo Created Date</th>\n",
       "      <th>Last Commit Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Language</th>\n",
       "      <th>Size</th>\n",
       "      <th>#Star</th>\n",
       "      <th>#Watch</th>\n",
       "      <th>#Fork</th>\n",
       "      <th>#Contributor</th>\n",
       "      <th>#Branch</th>\n",
       "      <th>#Release</th>\n",
       "      <th>#Commit</th>\n",
       "      <th>#Pull Requests</th>\n",
       "      <th>#Pull Requests (Open)</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Issue (Open)</th>\n",
       "      <th>Name</th>\n",
       "      <th>First Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aimhubio/aim</td>\n",
       "      <td>https://github.com/aimhubio/aim</td>\n",
       "      <td>2019-05-31 18:25:07</td>\n",
       "      <td>2023-08-14 14:02:51</td>\n",
       "      <td>[python, ai, data-science, data-visualization,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>64682.0</td>\n",
       "      <td>4109.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2932.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>Aim</td>\n",
       "      <td>2022-01-22 13:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws/sagemaker-python-sdk</td>\n",
       "      <td>https://github.com/aws/sagemaker-python-sdk</td>\n",
       "      <td>2017-11-14 01:03:33</td>\n",
       "      <td>2023-08-15 21:08:45</td>\n",
       "      <td>[aws, mxnet, tensorflow, machine-learning, pyt...</td>\n",
       "      <td>Python</td>\n",
       "      <td>112079.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>3213.0</td>\n",
       "      <td>2596.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3884.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2017-11-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure/azure-sdk-for-python</td>\n",
       "      <td>https://github.com/Azure/azure-sdk-for-python</td>\n",
       "      <td>2012-04-24 16:46:12</td>\n",
       "      <td>2023-08-16 16:03:51</td>\n",
       "      <td>[python, azure, azure-sdk, hacktoberfest]</td>\n",
       "      <td>Python</td>\n",
       "      <td>610773.0</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>2469.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>15223.0</td>\n",
       "      <td>23201.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>2015-02-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegroai/clearml</td>\n",
       "      <td>https://github.com/allegroai/clearml</td>\n",
       "      <td>2019-06-10 08:18:32</td>\n",
       "      <td>2023-08-15 10:54:04</td>\n",
       "      <td>[version-control, experiment-manager, version,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>43142.0</td>\n",
       "      <td>4623.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>2019-06-11 17:27:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codalab/codalab-worksheets</td>\n",
       "      <td>https://github.com/codalab/codalab-worksheets</td>\n",
       "      <td>2014-11-30 22:33:18</td>\n",
       "      <td>2023-08-06 20:02:30</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>27814.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4595.0</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>Codalab</td>\n",
       "      <td>2017-05-14 00:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iterative/dvc</td>\n",
       "      <td>https://github.com/iterative/dvc</td>\n",
       "      <td>2017-03-04 08:16:33</td>\n",
       "      <td>2023-08-16 02:51:20</td>\n",
       "      <td>[data-science, machine-learning, reproducibili...</td>\n",
       "      <td>Python</td>\n",
       "      <td>19169.0</td>\n",
       "      <td>11866.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>5107.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9523.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>DVC</td>\n",
       "      <td>2017-05-04 08:03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>determined-ai/determined</td>\n",
       "      <td>https://github.com/determined-ai/determined</td>\n",
       "      <td>2020-04-07 16:12:29</td>\n",
       "      <td>2023-08-16 17:15:49</td>\n",
       "      <td>[deep-learning, machine-learning, ml-platform,...</td>\n",
       "      <td>Go</td>\n",
       "      <td>215251.0</td>\n",
       "      <td>2414.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6263.0</td>\n",
       "      <td>7327.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7641.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Determined</td>\n",
       "      <td>2020-04-08 20:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dominodatalab/python-domino</td>\n",
       "      <td>https://github.com/dominodatalab/python-domino</td>\n",
       "      <td>2016-05-16 22:58:02</td>\n",
       "      <td>2023-08-09 15:37:51</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>479.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Domino</td>\n",
       "      <td>2020-08-05 05:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>guildai/guildai</td>\n",
       "      <td>https://github.com/guildai/guildai</td>\n",
       "      <td>2017-09-27 18:57:50</td>\n",
       "      <td>2023-08-12 20:19:05</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>24057.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5777.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>Guild AI</td>\n",
       "      <td>2022-04-28 14:31:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kedro-org/kedro</td>\n",
       "      <td>https://github.com/kedro-org/kedro</td>\n",
       "      <td>2019-04-18 10:29:56</td>\n",
       "      <td>2023-08-14 18:08:55</td>\n",
       "      <td>[pipeline, kedro, hacktoberfest, mlops, experi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>196681.0</td>\n",
       "      <td>8590.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2356.0</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>2019-06-03 16:15:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow</td>\n",
       "      <td>2018-06-05 16:05:58</td>\n",
       "      <td>2023-08-16 14:13:12</td>\n",
       "      <td>[machine-learning, ai, ml, mlflow, apache-spar...</td>\n",
       "      <td>Python</td>\n",
       "      <td>154390.0</td>\n",
       "      <td>15020.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4514.0</td>\n",
       "      <td>6106.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>9169.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>2018-06-27 16:19:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlrun/mlrun</td>\n",
       "      <td>https://github.com/mlrun/mlrun</td>\n",
       "      <td>2019-09-01 16:59:19</td>\n",
       "      <td>2023-08-16 15:02:06</td>\n",
       "      <td>[mlops, python, data-science, machine-learning...</td>\n",
       "      <td>Python</td>\n",
       "      <td>52298.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>3597.0</td>\n",
       "      <td>3865.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4093.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MLRun</td>\n",
       "      <td>2019-09-08 21:21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VertaAI/modeldb</td>\n",
       "      <td>https://github.com/VertaAI/modeldb</td>\n",
       "      <td>2016-10-19 01:07:26</td>\n",
       "      <td>2023-08-16 17:44:28</td>\n",
       "      <td>[machine-learning, model-management, modeldb, ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>53087.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3926.0</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4016.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>Verta</td>\n",
       "      <td>2020-04-01 03:47:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neptune-ai/neptune-client</td>\n",
       "      <td>https://github.com/neptune-ai/neptune-client</td>\n",
       "      <td>2019-02-11 11:25:57</td>\n",
       "      <td>2023-08-16 14:04:38</td>\n",
       "      <td>[pytorch, keras, lightgbm, xgboost, optuna, te...</td>\n",
       "      <td>Python</td>\n",
       "      <td>9124.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>2019-04-02 11:58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>optuna/optuna</td>\n",
       "      <td>https://github.com/optuna/optuna</td>\n",
       "      <td>2018-02-21 06:12:56</td>\n",
       "      <td>2023-08-14 07:39:10</td>\n",
       "      <td>[python, machine-learning, parallel, distribut...</td>\n",
       "      <td>Python</td>\n",
       "      <td>18739.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16386.0</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4657.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Optuna</td>\n",
       "      <td>2018-05-10 08:41:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>polyaxon/polyaxon</td>\n",
       "      <td>https://github.com/polyaxon/polyaxon</td>\n",
       "      <td>2016-12-26 12:48:47</td>\n",
       "      <td>2023-08-14 18:08:04</td>\n",
       "      <td>[deep-learning, machine-learning, artificial-i...</td>\n",
       "      <td>None</td>\n",
       "      <td>126443.0</td>\n",
       "      <td>3374.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10163.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>2018-10-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IDSIA/sacred</td>\n",
       "      <td>https://github.com/IDSIA/sacred</td>\n",
       "      <td>2014-03-31 18:05:29</td>\n",
       "      <td>2023-06-19 05:07:42</td>\n",
       "      <td>[python, machine-learning, infrastructure, rep...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6170.0</td>\n",
       "      <td>4077.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>2016-01-13 18:56:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>valohai/valohai-cli</td>\n",
       "      <td>https://github.com/valohai/valohai-cli</td>\n",
       "      <td>2017-02-08 12:46:54</td>\n",
       "      <td>2023-08-16 06:14:26</td>\n",
       "      <td>[machine-learning, client, api, command-line, ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>634.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Valohai</td>\n",
       "      <td>2019-07-26 10:05:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wandb/wandb</td>\n",
       "      <td>https://github.com/wandb/wandb</td>\n",
       "      <td>2017-03-24 05:46:23</td>\n",
       "      <td>2023-08-16 14:42:12</td>\n",
       "      <td>[machine-learning, experiment-track, deep-lear...</td>\n",
       "      <td>Python</td>\n",
       "      <td>76753.0</td>\n",
       "      <td>7081.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>5675.0</td>\n",
       "      <td>3416.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>6085.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>2018-11-11 21:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/cnvrg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnvrg.io</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/comet-ml</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comet</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://h2o.ai/platform/ai-cloud</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H2O AI Cloud</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://studio.iterative.ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iterative Studio</td>\n",
       "      <td>2021-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/sigopt</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>2014-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cloud.google.com/vertex-ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repo  \\\n",
       "0                  aimhubio/aim   \n",
       "1      aws/sagemaker-python-sdk   \n",
       "2    Azure/azure-sdk-for-python   \n",
       "3             allegroai/clearml   \n",
       "4    codalab/codalab-worksheets   \n",
       "5                 iterative/dvc   \n",
       "6      determined-ai/determined   \n",
       "7   dominodatalab/python-domino   \n",
       "8               guildai/guildai   \n",
       "9               kedro-org/kedro   \n",
       "10                mlflow/mlflow   \n",
       "11                  mlrun/mlrun   \n",
       "12              VertaAI/modeldb   \n",
       "13    neptune-ai/neptune-client   \n",
       "14                optuna/optuna   \n",
       "15            polyaxon/polyaxon   \n",
       "16                 IDSIA/sacred   \n",
       "17          valohai/valohai-cli   \n",
       "18                  wandb/wandb   \n",
       "19                          NaN   \n",
       "20                          NaN   \n",
       "21                          NaN   \n",
       "22                          NaN   \n",
       "23                          NaN   \n",
       "24                          NaN   \n",
       "\n",
       "                                              Link   Repo Created Date  \\\n",
       "0                  https://github.com/aimhubio/aim 2019-05-31 18:25:07   \n",
       "1      https://github.com/aws/sagemaker-python-sdk 2017-11-14 01:03:33   \n",
       "2    https://github.com/Azure/azure-sdk-for-python 2012-04-24 16:46:12   \n",
       "3             https://github.com/allegroai/clearml 2019-06-10 08:18:32   \n",
       "4    https://github.com/codalab/codalab-worksheets 2014-11-30 22:33:18   \n",
       "5                 https://github.com/iterative/dvc 2017-03-04 08:16:33   \n",
       "6      https://github.com/determined-ai/determined 2020-04-07 16:12:29   \n",
       "7   https://github.com/dominodatalab/python-domino 2016-05-16 22:58:02   \n",
       "8               https://github.com/guildai/guildai 2017-09-27 18:57:50   \n",
       "9               https://github.com/kedro-org/kedro 2019-04-18 10:29:56   \n",
       "10                https://github.com/mlflow/mlflow 2018-06-05 16:05:58   \n",
       "11                  https://github.com/mlrun/mlrun 2019-09-01 16:59:19   \n",
       "12              https://github.com/VertaAI/modeldb 2016-10-19 01:07:26   \n",
       "13    https://github.com/neptune-ai/neptune-client 2019-02-11 11:25:57   \n",
       "14                https://github.com/optuna/optuna 2018-02-21 06:12:56   \n",
       "15            https://github.com/polyaxon/polyaxon 2016-12-26 12:48:47   \n",
       "16                 https://github.com/IDSIA/sacred 2014-03-31 18:05:29   \n",
       "17          https://github.com/valohai/valohai-cli 2017-02-08 12:46:54   \n",
       "18                  https://github.com/wandb/wandb 2017-03-24 05:46:23   \n",
       "19                        https://github.com/cnvrg                 NaT   \n",
       "20                     https://github.com/comet-ml                 NaT   \n",
       "21                https://h2o.ai/platform/ai-cloud                 NaT   \n",
       "22                     https://studio.iterative.ai                 NaT   \n",
       "23                       https://github.com/sigopt                 NaT   \n",
       "24              https://cloud.google.com/vertex-ai                 NaT   \n",
       "\n",
       "      Last Commit Date                                              Topic  \\\n",
       "0  2023-08-14 14:02:51  [python, ai, data-science, data-visualization,...   \n",
       "1  2023-08-15 21:08:45  [aws, mxnet, tensorflow, machine-learning, pyt...   \n",
       "2  2023-08-16 16:03:51          [python, azure, azure-sdk, hacktoberfest]   \n",
       "3  2023-08-15 10:54:04  [version-control, experiment-manager, version,...   \n",
       "4  2023-08-06 20:02:30                                                 []   \n",
       "5  2023-08-16 02:51:20  [data-science, machine-learning, reproducibili...   \n",
       "6  2023-08-16 17:15:49  [deep-learning, machine-learning, ml-platform,...   \n",
       "7  2023-08-09 15:37:51                                                 []   \n",
       "8  2023-08-12 20:19:05                                                 []   \n",
       "9  2023-08-14 18:08:55  [pipeline, kedro, hacktoberfest, mlops, experi...   \n",
       "10 2023-08-16 14:13:12  [machine-learning, ai, ml, mlflow, apache-spar...   \n",
       "11 2023-08-16 15:02:06  [mlops, python, data-science, machine-learning...   \n",
       "12 2023-08-16 17:44:28  [machine-learning, model-management, modeldb, ...   \n",
       "13 2023-08-16 14:04:38  [pytorch, keras, lightgbm, xgboost, optuna, te...   \n",
       "14 2023-08-14 07:39:10  [python, machine-learning, parallel, distribut...   \n",
       "15 2023-08-14 18:08:04  [deep-learning, machine-learning, artificial-i...   \n",
       "16 2023-06-19 05:07:42  [python, machine-learning, infrastructure, rep...   \n",
       "17 2023-08-16 06:14:26  [machine-learning, client, api, command-line, ...   \n",
       "18 2023-08-16 14:42:12  [machine-learning, experiment-track, deep-lear...   \n",
       "19                 NaT                                                NaN   \n",
       "20                 NaT                                                NaN   \n",
       "21                 NaT                                                NaN   \n",
       "22                 NaT                                                NaN   \n",
       "23                 NaT                                                NaN   \n",
       "24                 NaT                                                NaN   \n",
       "\n",
       "   Language      Size    #Star  #Watch   #Fork  #Contributor  #Branch  \\\n",
       "0    Python   64682.0   4109.0    45.0   253.0          65.0     97.0   \n",
       "1    Python  112079.0   1903.0   133.0  1032.0         373.0     17.0   \n",
       "2    Python  610773.0   3779.0   367.0  2469.0         401.0    688.0   \n",
       "3    Python   43142.0   4623.0    87.0   603.0          78.0      4.0   \n",
       "4    Python   27814.0    144.0    18.0    79.0          53.0    145.0   \n",
       "5    Python   19169.0  11866.0   137.0  1087.0         262.0     13.0   \n",
       "6        Go  215251.0   2414.0    75.0   317.0          89.0    298.0   \n",
       "7    Python     479.0     54.0    29.0    54.0          34.0     56.0   \n",
       "8    Python   24057.0    813.0    14.0    78.0          25.0     70.0   \n",
       "9    Python  196681.0   8590.0   106.0   810.0         185.0     39.0   \n",
       "10   Python  154390.0  15020.0   292.0  3518.0         460.0    205.0   \n",
       "11   Python   52298.0   1040.0    25.0   195.0          63.0     27.0   \n",
       "12     Java   53087.0   1621.0    71.0   273.0          50.0    647.0   \n",
       "13   Python    9124.0    403.0    14.0    47.0          36.0     49.0   \n",
       "14   Python   18739.0   8500.0   123.0   853.0         201.0     29.0   \n",
       "15     None  126443.0   3374.0    79.0   321.0          90.0     16.0   \n",
       "16   Python    6170.0   4077.0    71.0   374.0          94.0     11.0   \n",
       "17   Python     634.0     13.0     8.0     6.0          10.0      9.0   \n",
       "18   Python   76753.0   7081.0    53.0   543.0         136.0    782.0   \n",
       "19      NaN       NaN      NaN     NaN     NaN           NaN      NaN   \n",
       "20      NaN       NaN      NaN     NaN     NaN           NaN      NaN   \n",
       "21      NaN       NaN      NaN     NaN     NaN           NaN      NaN   \n",
       "22      NaN       NaN      NaN     NaN     NaN           NaN      NaN   \n",
       "23      NaN       NaN      NaN     NaN     NaN           NaN      NaN   \n",
       "24      NaN       NaN      NaN     NaN     NaN           NaN      NaN   \n",
       "\n",
       "    #Release  #Commit  #Pull Requests  #Pull Requests (Open)   #Issue  \\\n",
       "0       55.0   2390.0          2016.0                   15.0   2932.0   \n",
       "1      532.0   3213.0          2596.0                   27.0   3884.0   \n",
       "2     3038.0  15223.0         23201.0                  133.0  31575.0   \n",
       "3       87.0   2181.0           226.0                    5.0   1081.0   \n",
       "4      117.0   4595.0          2309.0                   19.0   4512.0   \n",
       "5      474.0   8922.0          5107.0                   14.0   9523.0   \n",
       "6       90.0   6263.0          7327.0                   94.0   7641.0   \n",
       "7       16.0    206.0           138.0                    4.0    177.0   \n",
       "8        2.0   5777.0            77.0                    2.0    511.0   \n",
       "9       42.0   2356.0          1278.0                   25.0   2697.0   \n",
       "10      73.0   4514.0          6106.0                  199.0   9169.0   \n",
       "11     450.0   3597.0          3865.0                   24.0   4093.0   \n",
       "12       2.0   3926.0          3878.0                   74.0   4016.0   \n",
       "13     147.0   1588.0          1218.0                   18.0   1427.0   \n",
       "14      60.0  16386.0          3187.0                    4.0   4657.0   \n",
       "15       0.0  10163.0           398.0                    2.0   1465.0   \n",
       "16      12.0   1342.0           364.0                    2.0    918.0   \n",
       "17       2.0    550.0           193.0                    1.0    279.0   \n",
       "18     122.0   5675.0          3416.0                  265.0   6085.0   \n",
       "19       NaN      NaN             NaN                    NaN      NaN   \n",
       "20       NaN      NaN             NaN                    NaN      NaN   \n",
       "21       NaN      NaN             NaN                    NaN      NaN   \n",
       "22       NaN      NaN             NaN                    NaN      NaN   \n",
       "23       NaN      NaN             NaN                    NaN      NaN   \n",
       "24       NaN      NaN             NaN                    NaN      NaN   \n",
       "\n",
       "    #Issue (Open)                    Name  First Release Date  \n",
       "0           295.0                     Aim 2022-01-22 13:45:58  \n",
       "1           486.0        Amazon SageMaker 2017-11-19 00:00:00  \n",
       "2          1041.0  Azure Machine Learning 2015-02-18 00:00:00  \n",
       "3           365.0                 ClearML 2019-06-11 17:27:11  \n",
       "4           384.0                 Codalab 2017-05-14 00:32:55  \n",
       "5           568.0                     DVC 2017-05-04 08:03:08  \n",
       "6           125.0              Determined 2020-04-08 20:01:20  \n",
       "7            19.0                  Domino 2020-08-05 05:16:39  \n",
       "8           218.0                Guild AI 2022-04-28 14:31:07  \n",
       "9           347.0                   Kedro 2019-06-03 16:15:43  \n",
       "10         1192.0                  MLflow 2018-06-27 16:19:13  \n",
       "11           77.0                   MLRun 2019-09-08 21:21:26  \n",
       "12          158.0                 Verta 2020-04-01 03:47:14  \n",
       "13           34.0                 Neptune 2019-04-02 11:58:35  \n",
       "14          128.0                  Optuna 2018-05-10 08:41:56  \n",
       "15          122.0                Polyaxon 2018-10-16 00:00:00  \n",
       "16           96.0                  Sacred 2016-01-13 18:56:23  \n",
       "17           18.0                 Valohai 2019-07-26 10:05:34  \n",
       "18          954.0        Weights & Biases 2018-11-11 21:54:26  \n",
       "19            NaN                cnvrg.io 2020-03-31 00:00:00  \n",
       "20            NaN                   Comet 2017-01-01 00:00:00  \n",
       "21            NaN            H2O AI Cloud 2021-01-01 00:00:00  \n",
       "22            NaN        Iterative Studio 2021-05-12 00:00:00  \n",
       "23            NaN                  SigOpt 2014-11-01 00:00:00  \n",
       "24            NaN               Vertex AI 2019-03-01 00:00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_data = pd.DataFrame()\n",
    "\n",
    "# scrape open-source asset-management tools\n",
    "for tool_name, tool_repo in tools_repo.items():\n",
    "    if tool_name in tools_release_date:\n",
    "        tool_data = github_miner.scrape_repo(repo_name=tool_repo, real_name=tool_name, release_time=pd.to_datetime(tools_release_date[tool_name]))\n",
    "    else:\n",
    "        tool_data = github_miner.scrape_repo(repo_name=tool_repo, real_name=tool_name)\n",
    "\n",
    "    if not tool_data.empty:\n",
    "        tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "# add closed-source asset-management tools\n",
    "for tool_name in tools_link.keys():\n",
    "    tool_data = {\n",
    "        'Name': tool_name,\n",
    "        'Link': tools_link[tool_name],\n",
    "        'First Release Date': pd.to_datetime(tools_release_date[tool_name])\n",
    "    }\n",
    "    tool_data = pd.DataFrame([tool_data])\n",
    "    tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "tools_data.to_json(os.path.join(path_dataset, 'Tools.json'), indent=4, orient='records')\n",
    "tools_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37782\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "github_dependents = {}\n",
    "gitlab_dependents = {}\n",
    "\n",
    "# collect dependents for tools with coding patterns\n",
    "for tool_name in tools_keywords.keys():\n",
    "    # collect Github dependents\n",
    "    file_name = os.path.join(path_github_repo, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # either search by sourcegraph\n",
    "            if 'Results' in json_data:\n",
    "                for repo_file in json_data['Results']:\n",
    "                    # file name match pattern\n",
    "                    if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('github'):\n",
    "                        repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        if repo_name in github_dependents:\n",
    "                            github_dependents[repo_name].append(tool_name)\n",
    "                        else:\n",
    "                            github_dependents[repo_name] = [tool_name]\n",
    "                    # code usage match pattern\n",
    "                    elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('github'):\n",
    "                        repo_name = repo_file['name'].removeprefix(\n",
    "                            'github.com/')\n",
    "                        if repo_name in github_dependents:\n",
    "                            github_dependents[repo_name].append(tool_name)\n",
    "                        else:\n",
    "                            github_dependents[repo_name] = [tool_name]\n",
    "            # or search by dependent graph\n",
    "            elif 'all_public_dependent_repos' in json_data:\n",
    "                for repo_file in json_data['all_public_dependent_repos']:\n",
    "                    repo_name = repo_file['name']\n",
    "                    if repo_name in github_dependents:\n",
    "                        github_dependents[repo_name].append(tool_name)\n",
    "                    else:\n",
    "                        github_dependents[repo_name] = [tool_name]\n",
    "\n",
    "    # collect Gitlab dependents\n",
    "    file_name = os.path.join(path_gitlab_repo, tool_name + '.json')\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, encoding='utf8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            # search by sourcegraph exclusively\n",
    "            for repo_file in json_data['Results']:\n",
    "                # file name match pattern\n",
    "                if 'FileMatch' == repo_file['__typename'] and repo_file['repository']['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                        'gitlab.com/')\n",
    "                    if repo_name in gitlab_dependents:\n",
    "                        gitlab_dependents[repo_name].append(tool_name)\n",
    "                    else:\n",
    "                        gitlab_dependents[repo_name] = [tool_name]\n",
    "                # code usage match pattern\n",
    "                elif 'Repository' == repo_file['__typename'] and repo_file['name'].startswith('gitlab'):\n",
    "                    repo_name = repo_file['name'].removeprefix('gitlab.com/')\n",
    "                    if repo_name in gitlab_dependents:\n",
    "                        gitlab_dependents[repo_name].append(tool_name)\n",
    "                    else:\n",
    "                        gitlab_dependents[repo_name] = [tool_name]\n",
    "\n",
    "    # remove tool repo from dependents if any\n",
    "    if tool_name in tools_repo and tools_repo[tool_name] in github_dependents:\n",
    "        github_dependents.pop(tools_repo[tool_name], None)\n",
    "\n",
    "with open(os.path.join(path_github_repo, 'Dependents.pickle'), 'wb') as file:\n",
    "    pickle.dump(github_dependents, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(path_gitlab_repo, 'Dependents.pickle'), 'wb') as file:\n",
    "    pickle.dump(gitlab_dependents, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(len(github_dependents))\n",
    "print(len(gitlab_dependents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#GitHub Dependents</th>\n",
       "      <th>#GitLab Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>19952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>6370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DVC</td>\n",
       "      <td>6098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1573</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kedro</td>\n",
       "      <td>1184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>1113</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Comet</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aim</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Codalab</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Determined</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Valohai</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLRun</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Verta</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Domino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool #GitHub Dependents #GitLab Dependents\n",
       "2         Weights & Biases              19952                  0\n",
       "4                   Optuna               6370                  0\n",
       "9                      DVC               6098                  0\n",
       "5                   Sacred               1918                  0\n",
       "7                   MLflow               1573                  4\n",
       "1                    Kedro               1184                  0\n",
       "11        Amazon SageMaker               1113                  3\n",
       "6   Azure Machine Learning                826                  0\n",
       "8                    Comet                678                  0\n",
       "3                  ClearML                498                  0\n",
       "12                 Neptune                422                  0\n",
       "0                      Aim                189                  1\n",
       "13               Vertex AI                134                  0\n",
       "10                  SigOpt                 96                  0\n",
       "20                Guild AI                 67                  4\n",
       "17                 Codalab                 40                  0\n",
       "15                Polyaxon                 36                  0\n",
       "18              Determined                 36                  0\n",
       "14                 Valohai                 31                  0\n",
       "16                   MLRun                 27                  0\n",
       "21                 Verta                  9                  0\n",
       "19                  Domino                  1                  0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_repos = {}\n",
    "gitlab_repos = {}\n",
    "\n",
    "for repo_name, tool_list in github_dependents.items():\n",
    "    for tool_name in tool_list:\n",
    "        github_repos[tool_name] = github_repos.get(tool_name, 0) + 1\n",
    "\n",
    "for repo_name, tool_list in gitlab_dependents.items():\n",
    "    for tool_name in tool_list:\n",
    "        gitlab_repos[tool_name] = gitlab_repos.get(tool_name, 0) + 1\n",
    "\n",
    "dependents_summary = pd.DataFrame(columns=['Tool', '#GitHub Dependents', '#GitLab Dependents'])\n",
    "\n",
    "for tool_name, repo_num in github_repos.items():\n",
    "    if tool_name in gitlab_repos:\n",
    "        entry = {'Tool': tool_name, '#GitHub Dependents': repo_num, '#GitLab Dependents': gitlab_repos[tool_name]}\n",
    "    else:\n",
    "        entry = {'Tool': tool_name, '#GitHub Dependents': repo_num, '#GitLab Dependents': 0}\n",
    "    dependents_summary = pd.concat([dependents_summary, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "dependents_summary = dependents_summary.sort_values(by=['#GitHub Dependents', '#GitLab Dependents'], ascending=False)\n",
    "dependents_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37782\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(path_github_repo, 'Dependents.pickle'), 'rb') as file:\n",
    "    github_dependents = pickle.load(file)\n",
    "    print(len(github_dependents))\n",
    "\n",
    "with open(os.path.join(path_gitlab_repo, 'Dependents.pickle'), 'rb') as file:\n",
    "    gitlab_dependents = pickle.load(file)\n",
    "    print(len(gitlab_dependents))\n",
    "    \n",
    "df_tool = pd.read_json(os.path.join(path_dataset, 'Tools.json'))\n",
    "tools_release_date = pd.Series(pd.to_datetime(df_tool['First Release Date'].values), index=df_tool['Name']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape discussion posts of Github dependents for each tool\n",
    "\n",
    "df_posts = pd.DataFrame()\n",
    "\n",
    "for repo_name, tool_list in github_dependents.items():\n",
    "    repo_data = github_miner.scrape_repo(repo_name)\n",
    "    if repo_data.empty:\n",
    "        continue\n",
    "    invalid_repo = []\n",
    "    for tool_name in tool_list:\n",
    "        if repo_data['Repo Created Date'].values[0] < tools_release_date[tool_name]:\n",
    "            invalid_repo.append(tool_name)\n",
    "    tool_list = [tool for tool in tool_list if tool not in invalid_repo]\n",
    "    if tool_list:\n",
    "        posts = pd.DataFrame()\n",
    "        try:\n",
    "            posts = github_miner.scrape_discussion(repo_name)\n",
    "        except:\n",
    "            print(f'Crashed repo: {repo_name}')\n",
    "        if posts.empty:\n",
    "            continue\n",
    "        posts['Tools'] = [tool_list for _ in range(len(posts))]\n",
    "        df_posts = pd.concat([df_posts, posts], ignore_index=True)\n",
    "        df_posts.to_json(os.path.join(path_github_discussion, 'raw.json'), indent=4, orient='records')\n",
    "                \n",
    "df_posts.to_json(os.path.join(path_github_discussion, 'raw.json'), indent=4, orient='records')\n",
    "print(len(df_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude discussions that are not related to each tool\n",
    "# create discussion dataset\n",
    "\n",
    "df = pd.read_json(os.path.join(path_github_discussion, 'raw.json'))\n",
    "df['Platform'] = 'GitHub Discussion'\n",
    "df_discussion = pd.DataFrame()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tool_list = []\n",
    "    for tool_name in row['Tools']:\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if keyword in row['Question_title'].lower():\n",
    "                tool_list.append(tool_name)\n",
    "                break\n",
    "    if tool_list:\n",
    "        row['Tools'] = tool_list\n",
    "        df_discussion = pd.concat([df_discussion, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "df_discussion.to_json(os.path.join(path_labeling, 'discussions.json'), indent=4, orient='records')\n",
    "len(df_discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437652"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "\n",
    "df_issues = pd.DataFrame()\n",
    "\n",
    "for repo_name, tool_list in github_dependents.items():\n",
    "    repo_data = github_miner.scrape_repo(repo_name)\n",
    "    if repo_data.empty or (repo_data['#Issue'].values[0] - repo_data['#Pull Requests'].values[0] < 1):\n",
    "        continue\n",
    "    invalid_repo = []\n",
    "    for tool_name in tool_list:\n",
    "        if repo_data['Repo Created Date'].values[0] < tools_release_date[tool_name]:\n",
    "            invalid_repo.append(tool_name)\n",
    "    tool_list = [tool for tool in tool_list if tool not in invalid_repo]\n",
    "    if tool_list:\n",
    "        issues = github_miner.scrape_issue(repo_name)\n",
    "        issues['Tools'] = [tool_list for _ in range(len(issues))]\n",
    "        df_issues = pd.concat([df_issues, issues], ignore_index=True)\n",
    "        df_issues.to_json(os.path.join(path_github_issue, 'raw.json'), indent=4, orient='records')\n",
    "    \n",
    "df_issues.to_json(os.path.join(path_github_issue, 'raw.json'), indent=4, orient='records')\n",
    "len(df_issues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape issues of Gitlab dependents for each tool\n",
    "\n",
    "df_issues = pd.DataFrame()\n",
    "\n",
    "for repo_name, tool_list in github_dependents.items():\n",
    "    repo_data = gitlab_miner.scrape_repo(repo_name)\n",
    "    if repo_data.empty or (repo_data['#Issue'].values[0] < 1):\n",
    "        continue\n",
    "    invalid_repo = []\n",
    "    for tool_name in tool_list:\n",
    "        if repo_data['Repo Created Date'].values[0] < tools_release_date[tool_name]:\n",
    "            invalid_repo.append(tool_name)\n",
    "    tool_list = [tool for tool in tool_list if tool not in invalid_repo]\n",
    "    if tool_list:\n",
    "        issues = gitlab_miner.scrape_issue(repo_name)\n",
    "        issues['Tools'] = [tool_list for _ in range(len(issues))]\n",
    "        df_issues = pd.concat([df_issues, issues], ignore_index=True)\n",
    "        df_issues.to_json(os.path.join(path_gitlab_issue, 'raw.json'), indent=4, orient='records')\n",
    "    \n",
    "df_issues.to_json(os.path.join(path_gitlab_issue, 'raw.json'), indent=4, orient='records')\n",
    "len(df_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5178"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude issues that are not related to each tool\n",
    "\n",
    "df_issues_gitlab = pd.read_json(os.path.join(path_gitlab_issue, 'raw.json'))\n",
    "df_issues_github = pd.read_json(os.path.join(path_github_issue, 'raw.json'))\n",
    "\n",
    "df_issues_github['Platform'] = 'GitHub Issue'\n",
    "df_issues_gitlab['Platform'] = 'GitLab Issue'\n",
    "\n",
    "df_issues = pd.DataFrame()\n",
    "\n",
    "for index, row in df_issues_github.iterrows():\n",
    "    tool_list = []\n",
    "    for tool_name in row['Tools']:\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if keyword in row['Issue_title'].lower():\n",
    "                tool_list.append(tool_name)\n",
    "                break\n",
    "    if tool_list:\n",
    "        row['Tools'] = tool_list\n",
    "        df_issues = pd.concat([df_issues, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "for index, row in df_issues_gitlab.iterrows():\n",
    "    tool_list = []\n",
    "    for tool_name in row['Tools']:\n",
    "        for keyword in tools_keywords[tool_name]:\n",
    "            if keyword in row['Issue_title'].lower():\n",
    "                tool_list.append(tool_name)\n",
    "                break\n",
    "    if tool_list:\n",
    "        row['Tools'] = tool_list\n",
    "        df_issues = pd.concat([df_issues, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "len(df_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"experiments\"',\n",
       " '0.4.6',\n",
       " '1 - Critic',\n",
       " '1.1',\n",
       " '1.1.0',\n",
       " '1.4',\n",
       " '1.6',\n",
       " '1.7',\n",
       " '2.0',\n",
       " '3 - Quality of Life',\n",
       " '3rd party',\n",
       " '3rd party update',\n",
       " '3rd-party',\n",
       " ':bridge_at_night:  Bridge',\n",
       " ':bug: bug',\n",
       " ':rotating_light:',\n",
       " 'A: example-get-started',\n",
       " 'A: example-get-started-experiments',\n",
       " 'ADO',\n",
       " 'AI\\u202fFrameworks/ONNX',\n",
       " 'AML Compute Instance',\n",
       " 'API',\n",
       " 'Auto\\u202fML',\n",
       " 'BF',\n",
       " 'Bug',\n",
       " 'CXP Attention',\n",
       " 'CleanUp',\n",
       " 'Client',\n",
       " 'Cloud',\n",
       " 'Cognitive - Text Analytics',\n",
       " 'Cognitive Services',\n",
       " 'Community',\n",
       " 'Community Contribution Needed',\n",
       " 'Compute',\n",
       " 'Contributions welcome',\n",
       " 'Core UI',\n",
       " 'DRL',\n",
       " 'Data Labeling',\n",
       " 'Data4ML',\n",
       " 'Data\\u202fDrift',\n",
       " 'Data\\u202fPrep\\u202fServices',\n",
       " 'DeepSpeed',\n",
       " 'Defect',\n",
       " 'Design',\n",
       " 'Design Doc',\n",
       " 'Design: Research',\n",
       " 'Developer experience',\n",
       " 'Documentation',\n",
       " 'Done',\n",
       " 'ERRATA_CANDIDATE',\n",
       " 'Enhancement',\n",
       " 'Environments',\n",
       " 'Evaluation',\n",
       " 'Experiment Tracking',\n",
       " 'Experimentation UI',\n",
       " 'FAQ',\n",
       " 'Feature - Medium Priority',\n",
       " 'Feature request',\n",
       " 'Good First Issue',\n",
       " 'HIGH',\n",
       " 'HPO',\n",
       " 'Hackathon',\n",
       " 'Hyperdrive',\n",
       " 'Important',\n",
       " 'In the roadmap',\n",
       " 'Inf1',\n",
       " 'Inference',\n",
       " 'Ingestion',\n",
       " 'Issue: Bug Report',\n",
       " 'Issue: Feature Request',\n",
       " 'Javascript',\n",
       " 'Jupyter Notebooks',\n",
       " 'Kubeflow 1.7',\n",
       " 'L',\n",
       " 'LOE: S',\n",
       " 'Localized',\n",
       " 'MLOps',\n",
       " 'Machine Learning',\n",
       " 'Marathon',\n",
       " 'Mgmt',\n",
       " 'NLP',\n",
       " 'NNI SDK',\n",
       " 'NUM',\n",
       " 'Needs Triage',\n",
       " 'Not related to PyCaret',\n",
       " 'Notebook',\n",
       " 'OCV',\n",
       " 'Optional',\n",
       " 'P0',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'P3',\n",
       " 'PAI',\n",
       " 'Perception',\n",
       " 'Pipelines',\n",
       " 'Priority 1',\n",
       " 'Python',\n",
       " 'QS',\n",
       " 'Quick Win',\n",
       " 'Rebrand',\n",
       " 'Reinforcement Learning',\n",
       " 'RepoOfficiel',\n",
       " 'Research',\n",
       " 'Review One',\n",
       " 'Review Two',\n",
       " 'SDK',\n",
       " 'Service Attention',\n",
       " 'Should Fix',\n",
       " 'StackHub',\n",
       " 'Stage: Technical Design',\n",
       " 'Stage: Technical Design 🎨',\n",
       " 'Stale',\n",
       " 'TA',\n",
       " 'TODO',\n",
       " 'TODO before 1.0',\n",
       " 'Task',\n",
       " 'Tip💰',\n",
       " 'Training',\n",
       " 'Training Monitoring',\n",
       " 'Training Service',\n",
       " 'Trn1',\n",
       " 'Type: Brainstorm',\n",
       " 'Type: Discussion',\n",
       " 'Type: Documentation',\n",
       " 'Type: Enhancement',\n",
       " 'Type: Feature',\n",
       " 'Type: Idea',\n",
       " 'Type: Needs Investigation',\n",
       " 'Type: Technical Design',\n",
       " 'UI',\n",
       " 'UX',\n",
       " 'Usage',\n",
       " 'VISION',\n",
       " 'WIP',\n",
       " 'WIP - Susankha',\n",
       " 'Workspace Management',\n",
       " '[module] pipeline',\n",
       " 'accelerator: tpu',\n",
       " 'accessibility',\n",
       " 'ai',\n",
       " 'aiplatform',\n",
       " 'air',\n",
       " 'alonet',\n",
       " 'aml v2',\n",
       " 'api: aiplatform',\n",
       " 'api: datascienceonramp',\n",
       " 'api: vertex-ai',\n",
       " 'app-ui',\n",
       " 'apply',\n",
       " 'arc_data',\n",
       " 'arc_k8s',\n",
       " 'arc_ml',\n",
       " 'architecture',\n",
       " 'area / SDK-storage',\n",
       " 'area / integrations',\n",
       " 'area-getting-started',\n",
       " 'area-js-sdk',\n",
       " 'area-ml-resource-management',\n",
       " 'area-remote-desktop',\n",
       " 'area-remote-web',\n",
       " 'area-sign-in',\n",
       " 'area-telemetry',\n",
       " 'area-treeview',\n",
       " 'area-yaml',\n",
       " 'area/api',\n",
       " 'area/async',\n",
       " 'area/backend',\n",
       " 'area/components',\n",
       " 'area/components/aws/sagemaker',\n",
       " 'area/core',\n",
       " 'area/documentation',\n",
       " 'area/frontend',\n",
       " 'area/katib',\n",
       " 'area/learn',\n",
       " 'area/operator',\n",
       " 'area/perf',\n",
       " 'area/registry',\n",
       " 'area/samples',\n",
       " 'area/sdk',\n",
       " 'area/sdk/components',\n",
       " 'area/sdk/dsl',\n",
       " 'area/sdk/dsl/compiler',\n",
       " 'area/testing',\n",
       " 'area:core',\n",
       " 'area:databuilder',\n",
       " 'area:providers',\n",
       " 'area:serialization',\n",
       " 'arena::security',\n",
       " 'assigned',\n",
       " 'assigned-to-author',\n",
       " 'audience/technical',\n",
       " 'august-rewrite',\n",
       " 'auto:improvement',\n",
       " 'automations',\n",
       " 'automl',\n",
       " 'automl-forecasting',\n",
       " 'awaiting-feedback',\n",
       " 'awaiting-product-team-response',\n",
       " 'awaiting-response',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'azure feature request',\n",
       " 'azure-provider',\n",
       " 'azureml',\n",
       " 'backlog',\n",
       " 'benchmark',\n",
       " 'bittensor',\n",
       " 'blocked',\n",
       " 'blocker',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'bug',\n",
       " 'bug-bash',\n",
       " 'build',\n",
       " 'cannot reproduce',\n",
       " 'chapter: appendix-tools',\n",
       " 'checkpointing',\n",
       " 'chore',\n",
       " 'ci',\n",
       " 'classification',\n",
       " 'cleanup',\n",
       " 'closing-soon',\n",
       " 'closing-soon-if-no-response',\n",
       " 'cloud/aws',\n",
       " 'code',\n",
       " 'code/new-feature',\n",
       " 'colab',\n",
       " 'compat/breaking',\n",
       " 'component/kubeflow',\n",
       " 'concerns: agents',\n",
       " 'concerns: documentation',\n",
       " 'concerns: main API',\n",
       " 'configs',\n",
       " 'connectors',\n",
       " 'content-gap',\n",
       " 'contrib',\n",
       " 'contribution welcomed',\n",
       " 'contribution-welcome',\n",
       " 'core',\n",
       " 'core/subsvc',\n",
       " 'crash',\n",
       " 'customer-inquiry',\n",
       " 'customer-issue',\n",
       " 'customer-reported',\n",
       " 'customization',\n",
       " 'cxp',\n",
       " 'data',\n",
       " 'data-sync',\n",
       " 'debt',\n",
       " 'dependencies',\n",
       " 'deploy',\n",
       " 'design',\n",
       " 'design discussion',\n",
       " 'dev',\n",
       " 'dev workflow',\n",
       " 'devflows',\n",
       " 'discussion',\n",
       " 'diy_container',\n",
       " 'doc',\n",
       " 'doc-bug',\n",
       " 'doc-enhancement',\n",
       " 'docker images',\n",
       " 'docs',\n",
       " 'docs/website',\n",
       " 'documentation',\n",
       " 'dotnet',\n",
       " 'dotnet: xml-comment',\n",
       " 'duplicate',\n",
       " 'enhancement',\n",
       " 'enhancement request',\n",
       " 'environment',\n",
       " 'environment: slurm',\n",
       " 'ep:CUDA',\n",
       " 'epic',\n",
       " 'error',\n",
       " 'evaluate_model',\n",
       " 'example issue',\n",
       " 'example request',\n",
       " 'examples',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'exploratory',\n",
       " 'explore',\n",
       " 'extensibility',\n",
       " 'external package',\n",
       " 'feature',\n",
       " 'feature request',\n",
       " 'feature-request',\n",
       " 'feature_set',\n",
       " 'filed-by-team',\n",
       " 'first-timers-only',\n",
       " 'fix-error-msg',\n",
       " 'fixed',\n",
       " 'flaky-tracker',\n",
       " 'flakybot: flaky',\n",
       " 'flakybot: issue',\n",
       " 'forum',\n",
       " 'fundamental',\n",
       " 'future release',\n",
       " 'gcp',\n",
       " 'gitlab merge request',\n",
       " 'golden-scenario-web',\n",
       " 'good first issue',\n",
       " 'graphistry',\n",
       " 'guidance',\n",
       " 'guides',\n",
       " 'hacktoberfest',\n",
       " 'help wanted',\n",
       " 'hi-ml-azure',\n",
       " 'high priority',\n",
       " 'high-priority',\n",
       " 'idea',\n",
       " 'implementing framework',\n",
       " 'important',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in progress',\n",
       " 'in-progress',\n",
       " 'inference',\n",
       " 'inferencing-benchmark',\n",
       " 'info-needed',\n",
       " 'infra',\n",
       " 'infrastructure',\n",
       " 'integration',\n",
       " 'interfacing algorithms',\n",
       " 'invalid',\n",
       " 'investigate',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'issue-addressed',\n",
       " 'iteration-02',\n",
       " 'iteration-04',\n",
       " 'iteration-05',\n",
       " 'iteration-candidate',\n",
       " 'jetmet',\n",
       " 'journey:intermediate',\n",
       " 'keep fresh',\n",
       " 'keep-open',\n",
       " 'kind/bug',\n",
       " 'kind/discussion',\n",
       " 'kind/enhancement',\n",
       " 'kind/feature',\n",
       " 'kind/misc',\n",
       " 'kind/other',\n",
       " 'kind/question',\n",
       " 'kind/reproducibility',\n",
       " 'kind/usability',\n",
       " 'kind: new integration',\n",
       " 'kind: research',\n",
       " 'kind:bug',\n",
       " 'kind:feature',\n",
       " 'kind:task',\n",
       " 'kubeflow',\n",
       " 'launchers',\n",
       " 'learn',\n",
       " 'lifecycle/frozen',\n",
       " 'lifecycle/stale',\n",
       " 'lightning',\n",
       " 'linear',\n",
       " 'linting / formatting / cleaning',\n",
       " 'logger',\n",
       " 'logger: comet',\n",
       " 'logger: mlflow',\n",
       " 'logger: neptune',\n",
       " 'logger: wandb',\n",
       " 'loggers',\n",
       " 'logging',\n",
       " 'looking into it',\n",
       " 'low priority',\n",
       " 'machine-learning',\n",
       " 'machine-learning/svc',\n",
       " 'maintenance',\n",
       " 'major',\n",
       " 'manuscript',\n",
       " 'metrics',\n",
       " 'migrate: no',\n",
       " 'migrate: yes',\n",
       " 'missing_info',\n",
       " 'ml',\n",
       " 'ml-engineering',\n",
       " 'mlflow',\n",
       " 'model',\n",
       " 'model card',\n",
       " 'models',\n",
       " 'module: contrib',\n",
       " 'module:forecasting',\n",
       " 'module:probability&simulation',\n",
       " 'module:wandb',\n",
       " 'must have',\n",
       " 'need-design-decision',\n",
       " 'needs improved description',\n",
       " 'needs triage',\n",
       " 'needs-api',\n",
       " 'needs-discussion',\n",
       " 'needs-more-info',\n",
       " 'needs-repro-script',\n",
       " 'needs-team-attention',\n",
       " 'needs-tests',\n",
       " 'needs-triage',\n",
       " 'neptune',\n",
       " 'new',\n",
       " 'new feature',\n",
       " 'new table',\n",
       " 'new-data-source',\n",
       " 'new-resource',\n",
       " 'nice to have',\n",
       " 'nnidev',\n",
       " 'no-issue-activity',\n",
       " 'non-breaking',\n",
       " 'normal',\n",
       " 'notebook',\n",
       " 'notebook-migration',\n",
       " 'object detection',\n",
       " 'observability-ux',\n",
       " 'on hold',\n",
       " 'open for contribution',\n",
       " 'operationalization',\n",
       " 'optimization',\n",
       " 'optuna',\n",
       " 'organizational',\n",
       " 'p0-critical',\n",
       " 'p1',\n",
       " 'p1-high',\n",
       " 'p1-important',\n",
       " 'p2-medium',\n",
       " 'p3',\n",
       " 'p3-nice-to-have',\n",
       " 'partition/aws-us-gov',\n",
       " 'pending-signatures',\n",
       " 'performance',\n",
       " 'phase / shipped',\n",
       " 'pipeline',\n",
       " 'pipeline 6: infer',\n",
       " 'pl',\n",
       " 'planning',\n",
       " 'platform/aws',\n",
       " 'platform/other',\n",
       " 'plot_model',\n",
       " 'plugin',\n",
       " 'plugins',\n",
       " 'practice',\n",
       " 'pre-release',\n",
       " 'pri/medium',\n",
       " 'priority 3 - nice to have',\n",
       " 'priority-2-low',\n",
       " 'priority-p0',\n",
       " 'priority-p1',\n",
       " 'priority/important-longterm',\n",
       " 'priority/p0',\n",
       " 'priority/p1',\n",
       " 'priority/p2',\n",
       " 'priority: 0',\n",
       " 'priority: 1',\n",
       " 'priority: 2',\n",
       " 'priority: high',\n",
       " 'priority: medium',\n",
       " 'priority: p1',\n",
       " 'priority: p2',\n",
       " 'priority: p3',\n",
       " 'priority:high',\n",
       " 'priority:low',\n",
       " 'priority:medium',\n",
       " 'priority_high',\n",
       " 'priority_medium',\n",
       " 'product-feedback',\n",
       " 'product-gap',\n",
       " 'product-issue',\n",
       " 'product-question',\n",
       " 'product::sorts',\n",
       " 'progress bar: rich',\n",
       " 'proposal',\n",
       " 'provider:AWS',\n",
       " 'publishing',\n",
       " 'python',\n",
       " 'quality of life',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick-fix',\n",
       " 'ray-team-created',\n",
       " 'reconstruction-pending',\n",
       " 'refactor',\n",
       " 'refactoring',\n",
       " 'regression',\n",
       " 'related: Python SDK',\n",
       " 'release-blocker',\n",
       " 'reporting and diagnostics',\n",
       " 'reproducibility',\n",
       " 'research',\n",
       " 'response-requested',\n",
       " 'rllib',\n",
       " 'roadmap',\n",
       " 'sagemaker',\n",
       " 'sagemaker-dsk-v2',\n",
       " 'sagemaker_container',\n",
       " 'samples',\n",
       " 'scenario',\n",
       " 'scripts',\n",
       " 'sdk-docs',\n",
       " 'section',\n",
       " 'security',\n",
       " 'segmentation',\n",
       " 'seq2seq',\n",
       " 'serve',\n",
       " 'service-api',\n",
       " 'service/ec2',\n",
       " 'service/events',\n",
       " 'service/iam',\n",
       " 'service/s3',\n",
       " 'service/sagemaker',\n",
       " 'service/servicecatalog',\n",
       " 'service/vpc',\n",
       " 'service:executor',\n",
       " 'service:sm-executor',\n",
       " 'setup',\n",
       " 'sgd',\n",
       " 'size-small',\n",
       " 'size:small',\n",
       " 'snippets-request',\n",
       " 'spark',\n",
       " 'speech',\n",
       " 'stale',\n",
       " 'stale :zzz:',\n",
       " 'stat:awaiting response',\n",
       " 'stat:awaiting tensorflower',\n",
       " 'status/close',\n",
       " 'status/needs-proposal',\n",
       " 'status/new-issue',\n",
       " 'status/triaged',\n",
       " 'status: awaiting response',\n",
       " 'status: blocked',\n",
       " 'status: phase 1',\n",
       " 'status: phase 2',\n",
       " 'status: triage',\n",
       " 'status:completed',\n",
       " 'status:needs_reproducing',\n",
       " 'status:needs_triage',\n",
       " 'status:needs_votes',\n",
       " 'strategy: ddp',\n",
       " 'streaming',\n",
       " 'studio',\n",
       " 'support',\n",
       " 'suppress diff',\n",
       " 'sweep',\n",
       " 'sweeper',\n",
       " 't-must-fix',\n",
       " 't-nice-to-have-fix',\n",
       " 't-unknown-sub-error',\n",
       " 'task',\n",
       " 'technical',\n",
       " 'technical debt',\n",
       " 'technical-debt',\n",
       " 'template',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'tests',\n",
       " 'third party issue',\n",
       " 'third-party',\n",
       " 'time_series',\n",
       " 'timecodes',\n",
       " 'to refine',\n",
       " 'todo',\n",
       " 'tooling and CI',\n",
       " 'topic:dependencies',\n",
       " 'topic:eval',\n",
       " 'topic:modeling',\n",
       " 'topic:reader',\n",
       " 'train',\n",
       " 'trainer',\n",
       " 'training',\n",
       " 'training-benchmark',\n",
       " 'transformations',\n",
       " 'triage',\n",
       " 'triage me',\n",
       " 'triage-needed',\n",
       " 'triage/intermediate-priotrity',\n",
       " 'triaged',\n",
       " 'troubleshooting',\n",
       " 'tune',\n",
       " 'tune_model',\n",
       " 'type / bug',\n",
       " 'type / code-health',\n",
       " 'type / enhancement',\n",
       " 'type/bug',\n",
       " 'type/feature-request',\n",
       " 'type/maintenance',\n",
       " 'type: bug',\n",
       " 'type: cleanup',\n",
       " 'type: docs',\n",
       " 'type: enhancement',\n",
       " 'type: feature request',\n",
       " 'type: question',\n",
       " 'type::bug',\n",
       " 'type:bug',\n",
       " 'type:docs',\n",
       " 'type:feature',\n",
       " 'type:maintenance',\n",
       " 'type:question',\n",
       " 'ultralytics',\n",
       " 'up-for-grabs',\n",
       " 'upstream',\n",
       " 'upstream-azml',\n",
       " 'upstream_issue',\n",
       " 'user raised',\n",
       " 'utilities',\n",
       " 'utils',\n",
       " 'ux',\n",
       " 'v0.1.1',\n",
       " 'v0.8.5',\n",
       " 'v1',\n",
       " 'v2',\n",
       " 'ver: 2.0.x',\n",
       " 'ver: 2.1.x',\n",
       " 'vnext',\n",
       " 'waiting',\n",
       " 'waiting feedback',\n",
       " 'waiting on author',\n",
       " 'waiting on release',\n",
       " 'waiting-for-ci-fix',\n",
       " 'waiting-response',\n",
       " 'wandb',\n",
       " 'windows',\n",
       " 'wishlist',\n",
       " \"won't fix\",\n",
       " 'wontfix',\n",
       " 'work package: model training',\n",
       " 'work-item',\n",
       " 'workflow',\n",
       " 'workflow-experience',\n",
       " 'working as intended',\n",
       " '✨ feat',\n",
       " '민지',\n",
       " '찬국',\n",
       " '🐛 bug fix',\n",
       " '🐞 bug',\n",
       " '🐥 experiment',\n",
       " '🐺 Tracker',\n",
       " '👨\\u200d👩\\u200d👧\\u200d👧 discussion',\n",
       " '💎 New Component',\n",
       " '📜 Paper',\n",
       " '🔤 named-entity-recognition',\n",
       " '🔥 New Feature',\n",
       " '🛂 checkpoint',\n",
       " '🦉 dvc',\n",
       " '🧪 testing'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = set()\n",
    "for _, row in df_issues['Issue_label'].map(set).items():\n",
    "    final = final.union(row)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3332\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# filter out issues that are not related to challenges\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    if not row['Issue_label']:\n",
    "        df = pd.concat([df, row.to_frame().T], ignore_index =True)\n",
    "    else:\n",
    "        for label in row['Issue_label']:\n",
    "            for issue_label in issue_labels:\n",
    "                if issue_label in label.lower():\n",
    "                    df = pd.concat([df, row.to_frame().T], ignore_index =True)\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "print(len(df[df['Platform'] == 'GitHub Issue']))\n",
    "print(len(df[df['Platform'] == 'GitLab Issue']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create issue dataset\n",
    "\n",
    "df['Issue_score_count'] = df['Issue_upvote_count'] - df['Issue_downvote_count']\n",
    "df['Issue_comment_score'] = df['Issue_comment_upvote'] - df['Issue_comment_downvote']\n",
    "df['Issue_tag_count'] = df['Issue_label'].map(len)\n",
    "df['Issue_body'] = df['Issue_body'].fillna('')\n",
    "\n",
    "df.drop(columns=['Issue_upvote_count', 'Issue_downvote_count', 'Issue_comment_upvote', 'Issue_comment_downvote', 'Issue_label'], inplace=True)\n",
    "df.to_json(os.path.join(path_labeling, 'issues.json'), indent=4, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

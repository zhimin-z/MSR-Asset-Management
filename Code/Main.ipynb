{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from GHMiner import GitHubMiner\n",
    "from GLMiner import GitLabMiner\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "import glob\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_repo = {\n",
    "    'Aim': 'aimhubio/aim',\n",
    "    'Amazon SageMaker': 'aws/sagemaker-python-sdk',\n",
    "    'Azure Machine Learning': 'Azure/azure-sdk-for-python',\n",
    "    'ClearML': 'allegroai/clearml',\n",
    "    'Codalab': 'codalab/codalab-worksheets',\n",
    "    'DVC': 'iterative/dvc',\n",
    "    'Deep Lake': 'activeloopai/deeplake',\n",
    "    'Determined': 'determined-ai/determined',\n",
    "    'Domino': 'dominodatalab/python-domino',\n",
    "    'Guild AI': 'guildai/guildai',\n",
    "    'Keepsake': 'replicate/keepsake',\n",
    "    'MLflow': 'mlflow/mlflow',\n",
    "    'ModelDB': 'VertaAI/modeldb',\n",
    "    'Neptune': 'neptune-ai/neptune-client',\n",
    "    'Pachyderm': 'pachyderm/pachyderm',\n",
    "    'Polyaxon': 'polyaxon/polyaxon',\n",
    "    'Sacred': 'IDSIA/sacred',\n",
    "    'Valohai': 'valohai/valohai-cli',\n",
    "    'Weights & Biases': 'wandb/wandb'\n",
    "}\n",
    "\n",
    "tools_release_date = {\n",
    "    'Comet': '2017-01-01',\n",
    "    'Polyaxon': '2018-10-16',\n",
    "    'SigOpt': '2014-11-01',\n",
    "    'Vertex AI': '2019-03-01',\n",
    "    'cnvrg.io': '2020-03-31'\n",
    "}\n",
    "\n",
    "tools_link = {\n",
    "    'Comet': 'https://github.com/comet-ml',\n",
    "    'SigOpt': 'https://github.com/sigopt',\n",
    "    'Vertex AI': 'https://cloud.google.com/vertex-ai',\n",
    "    'cnvrg.io': 'https://github.com/cnvrg'\n",
    "}\n",
    "\n",
    "tools_keywords = {\n",
    "    'Aim': 'aim',\n",
    "    'Amazon SageMaker': 'sagemaker',\n",
    "    'Azure Machine Learning': 'azure',\n",
    "    'ClearML': 'clearml',\n",
    "    'Codalab': 'codalab',\n",
    "    'Comet': 'comet',\n",
    "    'Deep Lake': 'deeplake',\n",
    "    'Determined': 'determined',\n",
    "    'Domino': 'domino',\n",
    "    'DVC': 'dvc',\n",
    "    'Guild AI': 'guildai',\n",
    "    'Keepsake': 'keepsake',\n",
    "    'MLflow': 'mlflow',\n",
    "    'ModelDB': 'modeldb',\n",
    "    'Neptune': 'neptune',\n",
    "    'Pachyderm': 'pachyderm',\n",
    "    'Polyaxon': 'polyaxon',\n",
    "    'Sacred': 'sacred',\n",
    "    'SigOpt': 'sigopt',\n",
    "    'Valohai': 'valohai',\n",
    "    'Vertex AI': 'vertex',\n",
    "    'Weights & Biases': 'wandb'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../Dataset'\n",
    "\n",
    "path_github = os.path.join(path_dataset, 'GitHub')\n",
    "path_gitlab = os.path.join(path_dataset, 'GitLab')\n",
    "\n",
    "path_github_repo = os.path.join(path_github, 'Repo')\n",
    "path_gitlab_repo = os.path.join(path_gitlab, 'Repo')\n",
    "path_github_repo_raw = os.path.join(path_github_repo, 'Raw')\n",
    "path_gitlab_repo_raw = os.path.join(path_gitlab_repo, 'Raw')\n",
    "path_github_repo_scraped = os.path.join(path_github_repo, 'Scraped')\n",
    "path_gitlab_repo_scraped = os.path.join(path_gitlab_repo, 'Scraped')\n",
    "path_gitlab_repo_labelled = os.path.join(path_gitlab_repo, 'labelled')\n",
    "\n",
    "path_github_issue = os.path.join(path_github, 'Issue')\n",
    "path_gitlab_issue = os.path.join(path_gitlab, 'Issue')\n",
    "path_github_issue_raw = os.path.join(path_github_issue, 'Raw')\n",
    "path_gitlab_issue_raw = os.path.join(path_gitlab_issue, 'Raw')\n",
    "path_github_issue_filtered = os.path.join(path_github_issue, 'Filtered')\n",
    "path_gitlab_issue_filtered= os.path.join(path_gitlab_issue, 'Filtered')\n",
    "path_github_issue_sampled = os.path.join(path_github_issue, 'Sampled')\n",
    "path_gitlab_issue_sampled = os.path.join(path_gitlab_issue, 'Sampled')\n",
    "path_github_issue_sampled_all = os.path.join(path_github_issue_sampled, 'All')\n",
    "path_gitlab_issue_sampled_all = os.path.join(path_gitlab_issue_sampled, 'All')\n",
    "path_github_issue_sampled_closed = os.path.join(path_github_issue_sampled, 'Closed')\n",
    "path_gitlab_issue_sampled_closed = os.path.join(path_gitlab_issue_sampled, 'Closed')\n",
    "\n",
    "if not os.path.exists(path_github):\n",
    "    os.makedirs(path_github)\n",
    "\n",
    "if not os.path.exists(path_gitlab):\n",
    "    os.makedirs(path_gitlab)\n",
    "\n",
    "if not os.path.exists(path_github_repo):\n",
    "    os.makedirs(path_github_repo)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo):\n",
    "    os.makedirs(path_gitlab_repo)\n",
    "\n",
    "if not os.path.exists(path_github_issue):\n",
    "    os.makedirs(path_github_issue)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue):\n",
    "    os.makedirs(path_gitlab_issue)\n",
    "\n",
    "if not os.path.exists(path_github_repo_raw):\n",
    "    os.makedirs(path_github_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_raw):\n",
    "    os.makedirs(path_gitlab_repo_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_raw):\n",
    "    os.makedirs(path_github_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_raw):\n",
    "    os.makedirs(path_gitlab_issue_raw)\n",
    "\n",
    "if not os.path.exists(path_github_issue_sampled):\n",
    "    os.makedirs(path_github_issue_sampled)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_sampled):\n",
    "    os.makedirs(path_gitlab_issue_sampled)\n",
    "\n",
    "if not os.path.exists(path_github_issue_filtered):\n",
    "    os.makedirs(path_github_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_filtered):\n",
    "    os.makedirs(path_gitlab_issue_filtered)\n",
    "\n",
    "if not os.path.exists(path_github_issue_sampled_all):\n",
    "    os.makedirs(path_github_issue_sampled_all)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_sampled_all):\n",
    "    os.makedirs(path_gitlab_issue_sampled_all)\n",
    "\n",
    "if not os.path.exists(path_github_issue_sampled_closed):\n",
    "    os.makedirs(path_github_issue_sampled_closed)\n",
    "\n",
    "if not os.path.exists(path_gitlab_issue_sampled_closed):\n",
    "    os.makedirs(path_gitlab_issue_sampled_closed)\n",
    "\n",
    "if not os.path.exists(path_github_repo_scraped):\n",
    "    os.makedirs(path_github_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_scraped):\n",
    "    os.makedirs(path_gitlab_repo_scraped)\n",
    "\n",
    "if not os.path.exists(path_gitlab_repo_labelled):\n",
    "    os.makedirs(path_gitlab_repo_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_token1 = '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'\n",
    "github_token2 = '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'\n",
    "github_token3 = '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'\n",
    "github_token4 = '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'\n",
    "github_token5 = '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'\n",
    "github_token6 = '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'\n",
    "github_token7 = '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'\n",
    "gitlab_token1 = 'glpat-LFsxferBHR75dL9XKvos'\n",
    "\n",
    "github_miner = GitHubMiner(github_token1)\n",
    "gitlab_miner = GitLabMiner(gitlab_token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = os.environ['GITHUB_TOKEN']\n",
    "GITLAB_TOKEN = os.environ['GITLAB_TOKEN']\n",
    "\n",
    "github_miner = GitHubMiner(private_token=GITHUB_TOKEN)\n",
    "gitlab_miner = GitLabMiner(private_token=GITLAB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tracker_url = 'https://seladb.github.io/StarTrack-js/#/preload?r=mlflow,mlflow&r=iterative,dvc&r=pachyderm,pachyderm&r=activeloopai,deeplake&r=wandb,wandb&r=allegroai,clearml&r=IDSIA,sacred&r=polyaxon,polyaxon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo</th>\n",
       "      <th>Link</th>\n",
       "      <th>Repo Creation Date</th>\n",
       "      <th>Last Commit Date</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Language</th>\n",
       "      <th>Size</th>\n",
       "      <th>#Star</th>\n",
       "      <th>#Watch</th>\n",
       "      <th>#Fork</th>\n",
       "      <th>#Contributors</th>\n",
       "      <th>#Branches</th>\n",
       "      <th>#Releases</th>\n",
       "      <th>#Commits</th>\n",
       "      <th>#Pull Requests</th>\n",
       "      <th>#Pull Requests (Open)</th>\n",
       "      <th>#Issues</th>\n",
       "      <th>#Issues (Open)</th>\n",
       "      <th>Name</th>\n",
       "      <th>First Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aimhubio/aim</td>\n",
       "      <td>https://github.com/aimhubio/aim</td>\n",
       "      <td>2019-05-31 18:25:07</td>\n",
       "      <td>2022-12-20 18:12:39</td>\n",
       "      <td>[python, ai, data-science, data-visualization,...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>57830.0</td>\n",
       "      <td>2931.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2415.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>Aim</td>\n",
       "      <td>2022-01-22 13:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws/sagemaker-python-sdk</td>\n",
       "      <td>https://github.com/aws/sagemaker-python-sdk</td>\n",
       "      <td>2017-11-14 01:03:33</td>\n",
       "      <td>2022-12-20 04:29:15</td>\n",
       "      <td>[aws, mxnet, tensorflow, machine-learning, pyt...</td>\n",
       "      <td>Python</td>\n",
       "      <td>108299.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3395.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>2017-12-02 02:09:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure/azure-sdk-for-python</td>\n",
       "      <td>https://github.com/Azure/azure-sdk-for-python</td>\n",
       "      <td>2012-04-24 16:46:12</td>\n",
       "      <td>2022-12-20 22:01:43</td>\n",
       "      <td>[python, azure, azure-sdk, hacktoberfest]</td>\n",
       "      <td>Python</td>\n",
       "      <td>527746.0</td>\n",
       "      <td>3358.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>13214.0</td>\n",
       "      <td>20437.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>27933.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>2014-08-26 20:37:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegroai/clearml</td>\n",
       "      <td>https://github.com/allegroai/clearml</td>\n",
       "      <td>2019-06-10 08:18:32</td>\n",
       "      <td>2022-12-18 21:02:29</td>\n",
       "      <td>[version-control, experiment-manager, version,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>38832.0</td>\n",
       "      <td>3863.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>2019-06-11 17:27:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codalab/codalab-worksheets</td>\n",
       "      <td>https://github.com/codalab/codalab-worksheets</td>\n",
       "      <td>2014-11-30 22:33:18</td>\n",
       "      <td>2022-12-19 21:05:40</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>28441.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>4534.0</td>\n",
       "      <td>2229.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4339.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>Codalab</td>\n",
       "      <td>2017-05-14 00:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iterative/dvc</td>\n",
       "      <td>https://github.com/iterative/dvc</td>\n",
       "      <td>2017-03-04 08:16:33</td>\n",
       "      <td>2022-12-16 01:19:14</td>\n",
       "      <td>[data-science, machine-learning, reproducibili...</td>\n",
       "      <td>Python</td>\n",
       "      <td>16913.0</td>\n",
       "      <td>10810.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>8236.0</td>\n",
       "      <td>4422.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8471.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>DVC</td>\n",
       "      <td>2017-05-04 08:03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>activeloopai/deeplake</td>\n",
       "      <td>https://github.com/activeloopai/deeplake</td>\n",
       "      <td>2019-08-09 06:17:59</td>\n",
       "      <td>2022-12-20 15:30:30</td>\n",
       "      <td>[datasets, deep-learning, machine-learning, da...</td>\n",
       "      <td>Python</td>\n",
       "      <td>63614.0</td>\n",
       "      <td>5098.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6586.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Deep Lake</td>\n",
       "      <td>2020-12-15 18:46:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>determined-ai/determined</td>\n",
       "      <td>https://github.com/determined-ai/determined</td>\n",
       "      <td>2020-04-07 16:12:29</td>\n",
       "      <td>2022-12-20 20:14:00</td>\n",
       "      <td>[deep-learning, machine-learning, ml-platform,...</td>\n",
       "      <td>Python</td>\n",
       "      <td>105070.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4725.0</td>\n",
       "      <td>5386.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5632.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>Determined</td>\n",
       "      <td>2020-04-08 20:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dominodatalab/python-domino</td>\n",
       "      <td>https://github.com/dominodatalab/python-domino</td>\n",
       "      <td>2016-05-16 22:58:02</td>\n",
       "      <td>2022-12-13 17:50:04</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>469.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Domino</td>\n",
       "      <td>2020-08-05 05:16:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>guildai/guildai</td>\n",
       "      <td>https://github.com/guildai/guildai</td>\n",
       "      <td>2017-09-27 18:57:50</td>\n",
       "      <td>2022-12-16 23:23:43</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>17471.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>Guild AI</td>\n",
       "      <td>2022-04-28 14:31:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>replicate/keepsake</td>\n",
       "      <td>https://github.com/replicate/keepsake</td>\n",
       "      <td>2020-07-01 04:37:44</td>\n",
       "      <td>2022-05-24 23:48:09</td>\n",
       "      <td>[version-control, machine-learning]</td>\n",
       "      <td>Python</td>\n",
       "      <td>15268.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Keepsake</td>\n",
       "      <td>2021-01-08 16:11:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow</td>\n",
       "      <td>2018-06-05 16:05:58</td>\n",
       "      <td>2022-12-20 21:32:27</td>\n",
       "      <td>[machine-learning, ai, ml, mlflow, apache-spar...</td>\n",
       "      <td>Python</td>\n",
       "      <td>120341.0</td>\n",
       "      <td>13242.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>4792.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>2018-06-27 16:19:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VertaAI/modeldb</td>\n",
       "      <td>https://github.com/VertaAI/modeldb</td>\n",
       "      <td>2016-10-19 01:07:26</td>\n",
       "      <td>2022-12-20 16:25:03</td>\n",
       "      <td>[machine-learning, model-management, modeldb, ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>46901.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>ModelDB</td>\n",
       "      <td>2020-04-01 03:47:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neptune-ai/neptune-client</td>\n",
       "      <td>https://github.com/neptune-ai/neptune-client</td>\n",
       "      <td>2019-02-11 11:25:57</td>\n",
       "      <td>2022-12-13 11:52:00</td>\n",
       "      <td>[pytorch, keras, lightgbm, xgboost, optuna, te...</td>\n",
       "      <td>Python</td>\n",
       "      <td>8195.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>2019-04-02 11:58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pachyderm/pachyderm</td>\n",
       "      <td>https://github.com/pachyderm/pachyderm</td>\n",
       "      <td>2014-09-04 07:50:02</td>\n",
       "      <td>2022-12-20 17:51:00</td>\n",
       "      <td>[go, pachyderm, docker, analytics, big-data, c...</td>\n",
       "      <td>Go</td>\n",
       "      <td>306684.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>21497.0</td>\n",
       "      <td>5384.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>Pachyderm</td>\n",
       "      <td>2014-11-26 22:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>polyaxon/polyaxon</td>\n",
       "      <td>https://github.com/polyaxon/polyaxon</td>\n",
       "      <td>2016-12-26 12:48:47</td>\n",
       "      <td>2022-11-11 00:27:56</td>\n",
       "      <td>[deep-learning, machine-learning, artificial-i...</td>\n",
       "      <td>Python</td>\n",
       "      <td>126225.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>2018-10-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IDSIA/sacred</td>\n",
       "      <td>https://github.com/IDSIA/sacred</td>\n",
       "      <td>2014-03-31 18:05:29</td>\n",
       "      <td>2022-11-30 10:00:22</td>\n",
       "      <td>[python, machine-learning, infrastructure, rep...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6112.0</td>\n",
       "      <td>3963.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>2016-01-13 18:56:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>valohai/valohai-cli</td>\n",
       "      <td>https://github.com/valohai/valohai-cli</td>\n",
       "      <td>2017-02-08 12:46:54</td>\n",
       "      <td>2022-12-07 11:05:49</td>\n",
       "      <td>[machine-learning, client, api, command-line, ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>617.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Valohai</td>\n",
       "      <td>2019-07-26 10:05:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wandb/wandb</td>\n",
       "      <td>https://github.com/wandb/wandb</td>\n",
       "      <td>2017-03-24 05:46:23</td>\n",
       "      <td>2022-12-20 22:07:49</td>\n",
       "      <td>[machine-learning, experiment-track, deep-lear...</td>\n",
       "      <td>Python</td>\n",
       "      <td>60132.0</td>\n",
       "      <td>5086.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>2018-11-11 21:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/comet-ml</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comet</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/sigopt</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>2014-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cloud.google.com/vertex-ai</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/cnvrg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnvrg.io</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repo  \\\n",
       "0                  aimhubio/aim   \n",
       "1      aws/sagemaker-python-sdk   \n",
       "2    Azure/azure-sdk-for-python   \n",
       "3             allegroai/clearml   \n",
       "4    codalab/codalab-worksheets   \n",
       "5                 iterative/dvc   \n",
       "6         activeloopai/deeplake   \n",
       "7      determined-ai/determined   \n",
       "8   dominodatalab/python-domino   \n",
       "9               guildai/guildai   \n",
       "10           replicate/keepsake   \n",
       "11                mlflow/mlflow   \n",
       "12              VertaAI/modeldb   \n",
       "13    neptune-ai/neptune-client   \n",
       "14          pachyderm/pachyderm   \n",
       "15            polyaxon/polyaxon   \n",
       "16                 IDSIA/sacred   \n",
       "17          valohai/valohai-cli   \n",
       "18                  wandb/wandb   \n",
       "19                          NaN   \n",
       "20                          NaN   \n",
       "21                          NaN   \n",
       "22                          NaN   \n",
       "\n",
       "                                              Link  Repo Creation Date  \\\n",
       "0                  https://github.com/aimhubio/aim 2019-05-31 18:25:07   \n",
       "1      https://github.com/aws/sagemaker-python-sdk 2017-11-14 01:03:33   \n",
       "2    https://github.com/Azure/azure-sdk-for-python 2012-04-24 16:46:12   \n",
       "3             https://github.com/allegroai/clearml 2019-06-10 08:18:32   \n",
       "4    https://github.com/codalab/codalab-worksheets 2014-11-30 22:33:18   \n",
       "5                 https://github.com/iterative/dvc 2017-03-04 08:16:33   \n",
       "6         https://github.com/activeloopai/deeplake 2019-08-09 06:17:59   \n",
       "7      https://github.com/determined-ai/determined 2020-04-07 16:12:29   \n",
       "8   https://github.com/dominodatalab/python-domino 2016-05-16 22:58:02   \n",
       "9               https://github.com/guildai/guildai 2017-09-27 18:57:50   \n",
       "10           https://github.com/replicate/keepsake 2020-07-01 04:37:44   \n",
       "11                https://github.com/mlflow/mlflow 2018-06-05 16:05:58   \n",
       "12              https://github.com/VertaAI/modeldb 2016-10-19 01:07:26   \n",
       "13    https://github.com/neptune-ai/neptune-client 2019-02-11 11:25:57   \n",
       "14          https://github.com/pachyderm/pachyderm 2014-09-04 07:50:02   \n",
       "15            https://github.com/polyaxon/polyaxon 2016-12-26 12:48:47   \n",
       "16                 https://github.com/IDSIA/sacred 2014-03-31 18:05:29   \n",
       "17          https://github.com/valohai/valohai-cli 2017-02-08 12:46:54   \n",
       "18                  https://github.com/wandb/wandb 2017-03-24 05:46:23   \n",
       "19                     https://github.com/comet-ml                 NaT   \n",
       "20                       https://github.com/sigopt                 NaT   \n",
       "21              https://cloud.google.com/vertex-ai                 NaT   \n",
       "22                        https://github.com/cnvrg                 NaT   \n",
       "\n",
       "      Last Commit Date                                             Topics  \\\n",
       "0  2022-12-20 18:12:39  [python, ai, data-science, data-visualization,...   \n",
       "1  2022-12-20 04:29:15  [aws, mxnet, tensorflow, machine-learning, pyt...   \n",
       "2  2022-12-20 22:01:43          [python, azure, azure-sdk, hacktoberfest]   \n",
       "3  2022-12-18 21:02:29  [version-control, experiment-manager, version,...   \n",
       "4  2022-12-19 21:05:40                                                 []   \n",
       "5  2022-12-16 01:19:14  [data-science, machine-learning, reproducibili...   \n",
       "6  2022-12-20 15:30:30  [datasets, deep-learning, machine-learning, da...   \n",
       "7  2022-12-20 20:14:00  [deep-learning, machine-learning, ml-platform,...   \n",
       "8  2022-12-13 17:50:04                                                 []   \n",
       "9  2022-12-16 23:23:43                                                 []   \n",
       "10 2022-05-24 23:48:09                [version-control, machine-learning]   \n",
       "11 2022-12-20 21:32:27  [machine-learning, ai, ml, mlflow, apache-spar...   \n",
       "12 2022-12-20 16:25:03  [machine-learning, model-management, modeldb, ...   \n",
       "13 2022-12-13 11:52:00  [pytorch, keras, lightgbm, xgboost, optuna, te...   \n",
       "14 2022-12-20 17:51:00  [go, pachyderm, docker, analytics, big-data, c...   \n",
       "15 2022-11-11 00:27:56  [deep-learning, machine-learning, artificial-i...   \n",
       "16 2022-11-30 10:00:22  [python, machine-learning, infrastructure, rep...   \n",
       "17 2022-12-07 11:05:49  [machine-learning, client, api, command-line, ...   \n",
       "18 2022-12-20 22:07:49  [machine-learning, experiment-track, deep-lear...   \n",
       "19                 NaT                                                NaN   \n",
       "20                 NaT                                                NaN   \n",
       "21                 NaT                                                NaN   \n",
       "22                 NaT                                                NaN   \n",
       "\n",
       "      Language      Size    #Star  #Watch   #Fork  #Contributors  #Branches  \\\n",
       "0   TypeScript   57830.0   2931.0    35.0   183.0           48.0       76.0   \n",
       "1       Python  108299.0   1749.0   131.0   905.0          296.0       14.0   \n",
       "2       Python  527746.0   3358.0   356.0  2131.0          398.0      549.0   \n",
       "3       Python   38832.0   3863.0    82.0   520.0           58.0        3.0   \n",
       "4       Python   28441.0    135.0    19.0    78.0           54.0      129.0   \n",
       "5       Python   16913.0  10810.0   136.0  1011.0          253.0       11.0   \n",
       "6       Python   63614.0   5098.0    66.0   413.0           88.0      107.0   \n",
       "7       Python  105070.0   1987.0    61.0   265.0           66.0      181.0   \n",
       "8       Python     469.0     50.0    27.0    50.0           32.0       48.0   \n",
       "9       Python   17471.0    759.0    13.0    69.0           19.0       60.0   \n",
       "10      Python   15268.0   1596.0    11.0    67.0           17.0       11.0   \n",
       "11      Python  120341.0  13242.0   285.0  3091.0          455.0      201.0   \n",
       "12        Java   46901.0   1537.0    71.0   263.0           48.0      531.0   \n",
       "13      Python    8195.0    350.0    16.0    36.0           29.0       27.0   \n",
       "14          Go  306684.0   5729.0   167.0   540.0          154.0     1171.0   \n",
       "15      Python  126225.0   3218.0    77.0   316.0           90.0       16.0   \n",
       "16      Python    6112.0   3963.0    70.0   362.0           90.0        8.0   \n",
       "17      Python     617.0     12.0     6.0     6.0            8.0        9.0   \n",
       "18      Python   60132.0   5086.0    38.0   387.0          117.0      531.0   \n",
       "19         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "20         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "21         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "22         NaN       NaN      NaN     NaN     NaN            NaN        NaN   \n",
       "\n",
       "    #Releases  #Commits  #Pull Requests  #Pull Requests (Open)  #Issues  \\\n",
       "0        45.0    1980.0          1663.0                   20.0   2415.0   \n",
       "1       473.0    2810.0          2251.0                   47.0   3395.0   \n",
       "2      2648.0   13214.0         20437.0                  122.0  27933.0   \n",
       "3        73.0    1927.0           166.0                    2.0    847.0   \n",
       "4       112.0    4534.0          2229.0                   24.0   4339.0   \n",
       "5       408.0    8236.0          4422.0                   21.0   8471.0   \n",
       "6        76.0    6586.0          1635.0                   14.0   2035.0   \n",
       "7        74.0    4725.0          5386.0                   88.0   5632.0   \n",
       "8        13.0     198.0           127.0                    3.0    162.0   \n",
       "9         2.0    5238.0            66.0                    1.0    458.0   \n",
       "10        7.0     791.0           940.0                   14.0   1118.0   \n",
       "11       60.0    3592.0          4792.0                  132.0   7449.0   \n",
       "12        2.0    3593.0          3326.0                  103.0   3458.0   \n",
       "13      123.0    1222.0           995.0                    6.0   1164.0   \n",
       "14      360.0   21497.0          5384.0                  194.0   8460.0   \n",
       "15        0.0   10010.0           398.0                    2.0   1458.0   \n",
       "16       11.0    1326.0           349.0                    2.0    893.0   \n",
       "17        2.0     526.0           173.0                    2.0    257.0   \n",
       "18      106.0    4949.0          2521.0                  190.0   4670.0   \n",
       "19        NaN       NaN             NaN                    NaN      NaN   \n",
       "20        NaN       NaN             NaN                    NaN      NaN   \n",
       "21        NaN       NaN             NaN                    NaN      NaN   \n",
       "22        NaN       NaN             NaN                    NaN      NaN   \n",
       "\n",
       "    #Issues (Open)                    Name  First Release Date  \n",
       "0            199.0                     Aim 2022-01-22 13:45:58  \n",
       "1            440.0        Amazon SageMaker 2017-12-02 02:09:07  \n",
       "2            904.0  Azure Machine Learning 2014-08-26 20:37:21  \n",
       "3            310.0                 ClearML 2019-06-11 17:27:11  \n",
       "4            370.0                 Codalab 2017-05-14 00:32:55  \n",
       "5            664.0                     DVC 2017-05-04 08:03:08  \n",
       "6             62.0               Deep Lake 2020-12-15 18:46:17  \n",
       "7            107.0              Determined 2020-04-08 20:01:20  \n",
       "8             15.0                  Domino 2020-08-05 05:16:39  \n",
       "9            181.0                Guild AI 2022-04-28 14:31:07  \n",
       "10           127.0                Keepsake 2021-01-08 16:11:54  \n",
       "11           996.0                  MLflow 2018-06-27 16:19:13  \n",
       "12           183.0                 ModelDB 2020-04-01 03:47:14  \n",
       "13            21.0                 Neptune 2019-04-02 11:58:35  \n",
       "14           888.0               Pachyderm 2014-11-26 22:49:29  \n",
       "15           117.0                Polyaxon 2018-10-16 00:00:00  \n",
       "16            93.0                  Sacred 2016-01-13 18:56:23  \n",
       "17            18.0                 Valohai 2019-07-26 10:05:34  \n",
       "18           760.0        Weights & Biases 2018-11-11 21:54:26  \n",
       "19             NaN                   Comet 2017-01-01 00:00:00  \n",
       "20             NaN                  SigOpt 2014-11-01 00:00:00  \n",
       "21             NaN               Vertex AI 2019-03-01 00:00:00  \n",
       "22             NaN                cnvrg.io 2020-03-31 00:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_data = pd.DataFrame()\n",
    "\n",
    "# scrape open-source asset-management tools\n",
    "for tool_name, tool_repo in tools_repo.items():\n",
    "    if tool_name in tools_release_date:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name, release_date=pd.to_datetime(tools_release_date[tool_name]))\n",
    "    else:\n",
    "        tool_data, error_data = github_miner.scrape_repo(\n",
    "            repo_name=tool_repo, real_name=tool_name)\n",
    "\n",
    "    if not tool_data.empty:\n",
    "        tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "    else:\n",
    "        print(error_data)\n",
    "\n",
    "# add closed-source asset-management tools\n",
    "for tool_name in tools_link.keys():\n",
    "    tool_data = {\n",
    "        'Name': tool_name,\n",
    "        'Link': tools_link[tool_name],\n",
    "        'First Release Date': pd.to_datetime(tools_release_date[tool_name])\n",
    "    }\n",
    "    tool_data = pd.DataFrame([tool_data])\n",
    "    tools_data = pd.concat([tools_data, tool_data], ignore_index=True)\n",
    "\n",
    "tools_data.to_json(os.path.join(path_dataset, 'Tools.json'),\n",
    "                   indent=4, orient='records')\n",
    "tools_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependents = None\n",
    "\n",
    "# collect dependents for tools with coding patterns\n",
    "for tool_name in tools_keywords.keys():\n",
    "    github_dependents = []\n",
    "    gitlab_dependents = []\n",
    "\n",
    "    # collect Github dependents\n",
    "    file_name = os.path.join(path_github_repo_raw, tool_name + '.json')\n",
    "    with open(file_name) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        # either search by sourcegraph\n",
    "        if 'Results' in json_data:\n",
    "            for repo_file in json_data['Results']:\n",
    "                # file name match pattern\n",
    "                if 'FileMatch' in repo_file['__typename'] and 'github.com' in repo_file['repository']['name']:\n",
    "                    repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                        'github.com/')\n",
    "                    github_dependents.append(repo_name)\n",
    "                # code usage match pattern\n",
    "                elif 'Repository' in repo_file['__typename'] and 'github.com' in repo_file['name']:\n",
    "                    repo_name = repo_file['name'].removeprefix('github.com/')\n",
    "                    github_dependents.append(repo_name)\n",
    "        # or search by dependent graph\n",
    "        elif 'all_public_dependent_repos' in json_data:\n",
    "            for repo_file in json_data['all_public_dependent_repos']:\n",
    "                github_dependents.append(repo_file['name'])\n",
    "\n",
    "    # collect Gitlab dependents\n",
    "    file_name = os.path.join(path_gitlab_repo_raw, tool_name + '.json')\n",
    "    with open(file_name) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        # search by sourcegraph exclusively\n",
    "        for repo_file in json_data['Results']:\n",
    "            # file name match pattern\n",
    "            if 'FileMatch' in repo_file['__typename'] and 'gitlab.com' in repo_file['repository']['name']:\n",
    "                repo_name = repo_file['repository']['name'].removeprefix(\n",
    "                    'gitlab.com/')\n",
    "                gitlab_dependents.append(repo_name)\n",
    "            # code usage match pattern\n",
    "            elif 'Repository' in repo_file['__typename'] and 'gitlab.com' in repo_file['name']:\n",
    "                repo_name = repo_file['name'].removeprefix('gitlab.com/')\n",
    "                gitlab_dependents.append(repo_name)\n",
    "\n",
    "    # remove tool repo from dependents if any\n",
    "    if tool_name in tools_repo and tools_repo[tool_name] in github_dependents:\n",
    "        github_dependents.remove(tools_repo[tool_name])\n",
    "\n",
    "    # no need to add tools without dependents\n",
    "    if not len(github_dependents) and not len(gitlab_dependents):\n",
    "        continue\n",
    "\n",
    "    dependent = {\n",
    "        'Tool': tool_name,\n",
    "        'GitHub Dependents': github_dependents,\n",
    "        'GitLab Dependents': gitlab_dependents\n",
    "    }\n",
    "\n",
    "    dependents = pd.concat(\n",
    "        [dependents, pd.DataFrame([dependent])], ignore_index=True)\n",
    "\n",
    "dependents.to_json(os.path.join(\n",
    "    path_dataset, 'Dependents.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#GitHub Dependents</th>\n",
       "      <th>#GitLab Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>10730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DVC</td>\n",
       "      <td>4229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sacred</td>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>1189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comet</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClearML</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neptune</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aim</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SigOpt</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Guild AI</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Determined</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Valohai</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codalab</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pachyderm</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ModelDB</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep Lake</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Keepsake</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Domino</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tool #GitHub Dependents #GitLab Dependents\n",
       "21        Weights & Biases              10730                  0\n",
       "9                      DVC               4229                  0\n",
       "17                  Sacred               1289                  0\n",
       "12                  MLflow               1189                  3\n",
       "1         Amazon SageMaker                931                  3\n",
       "2   Azure Machine Learning                689                  0\n",
       "5                    Comet                480                  0\n",
       "3                  ClearML                303                  0\n",
       "14                 Neptune                280                  0\n",
       "20               Vertex AI                 96                  0\n",
       "0                      Aim                 92                  1\n",
       "18                  SigOpt                 55                  0\n",
       "10                Guild AI                 53                  4\n",
       "7               Determined                 44                  0\n",
       "16                Polyaxon                 35                  0\n",
       "19                 Valohai                 31                  0\n",
       "4                  Codalab                 30                  0\n",
       "15               Pachyderm                 10                  0\n",
       "13                 ModelDB                  7                  0\n",
       "6                Deep Lake                  3                  0\n",
       "11                Keepsake                  3                  0\n",
       "8                   Domino                  2                  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependents_summary = pd.DataFrame(\n",
    "    columns=['Tool', '#GitHub Dependents', '#GitLab Dependents'])\n",
    "for index, row in dependents.iterrows():\n",
    "    dependent_data = {\n",
    "        'Tool': row['Tool'],\n",
    "        '#GitHub Dependents': len(row['GitHub Dependents']),\n",
    "        '#GitLab Dependents': len(row['GitLab Dependents'])\n",
    "    }\n",
    "    dependent_data = pd.DataFrame([dependent_data])\n",
    "    dependents_summary = pd.concat(\n",
    "        [dependents_summary, dependent_data], ignore_index=True)\n",
    "dependents_summary.sort_values(by=['#GitHub Dependents', '#GitLab Dependents'], ascending=False, inplace=True)\n",
    "dependents_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents = pd.read_json(os.path.join(path_dataset, 'Dependents.json'))\n",
    "df_tools = pd.read_json(os.path.join(path_dataset, 'Tools.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gitlab dependents retrieval for labelling\n",
    "for index, row in df_dependents.iterrows():\n",
    "    if not row['GitLab Dependents']:\n",
    "        continue\n",
    "    dependent = ['gitlab.com/' +\n",
    "                 repo_name for repo_name in row['GitLab Dependents']]\n",
    "    dependent = pd.DataFrame({'Link': dependent})\n",
    "    dependent.to_json(os.path.join(path_gitlab_repo_labelled,\n",
    "                      f'{row[\"Tool\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Gitlab valid dependents general information for each tool\n",
    "project_categories = {'Project', 'Toolkit', 'Research'}\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_repo_labelled, '*.json')):\n",
    "    repos = pd.read_json(file_name)\n",
    "    repos_name = []\n",
    "    for index, row in repos.iterrows():\n",
    "        if row['taxonomy'][0]['taxonomy'][0][0] in project_categories:\n",
    "            repo_name = row['Link'].removeprefix('gitlab.com/')\n",
    "            repos_name.append(repo_name)\n",
    "\n",
    "    if not repos_name:\n",
    "        continue\n",
    "\n",
    "    repos_data, errors_data = gitlab_miner.scrape_repo_list(repos_name)\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "\n",
    "    if not repos_data.empty:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_gitlab_repo_scraped, f'{tool_name}.json'), indent=4, orient='records')\n",
    "    if not errors_data.empty:\n",
    "        errors_data.to_json(os.path.join(\n",
    "            path_gitlab_repo_scraped, f'Discarded.{tool_name}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Gitlab dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_gitlab_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos without any issues\n",
    "        repos = repos[repos['#Issues'] > 0]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(f'{row[\"Name\"]}: {repos[\"#Issues\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = gitlab_miner.scrape_issues_list(repos['Repo'].tolist())\n",
    "        issues.to_json(os.path.join(path_gitlab_issue_raw,\n",
    "                       f'{row[\"Name\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude issues that are not related to each tool\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "    for index, issue in issues.iterrows():\n",
    "        if tools_keywords[tool_name] in nltk.word_tokenize(issue['Issue_title'].lower()):\n",
    "            valid_issue = pd.DataFrame([issue])\n",
    "            valid_issues = pd.concat(\n",
    "                [valid_issues, valid_issue], ignore_index=True)\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues.to_json(os.path.join(\n",
    "            path_gitlab_issue_filtered, f'{tool_name}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tool  #Issue  #Closed\n",
       "0  MLflow       3        0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_gitlab = pd.DataFrame()\n",
    "for file_name in glob.glob(os.path.join(path_gitlab_issue_filtered, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    row = {\n",
    "        'Tool': os.path.split(file_name)[1].split('.')[0],\n",
    "        '#Issue': len(issues),\n",
    "        '#Closed': issues['Issue_closed_time'].notnull().sum()\n",
    "    }\n",
    "    row = pd.DataFrame([row])\n",
    "    summary_gitlab = pd.concat([summary_gitlab, row], ignore_index=True)\n",
    "summary_gitlab.to_csv(os.path.join(path_gitlab_issue, 'summary.csv'), index=False)\n",
    "summary_gitlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>#Issue</th>\n",
       "      <th>#Closed</th>\n",
       "      <th>#Sample Issue</th>\n",
       "      <th>#Sample Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLflow</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tool  #Issue  #Closed  #Sample Issue  #Sample Closed\n",
       "0  MLflow       3        0              3               0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_gitlab_issue, 'summary.csv'))\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tool-specific posts accordingly\n",
    "for index, row in df_summary.iterrows():\n",
    "    file_name = os.path.join(path_gitlab_issue_filtered, f'{row[\"Tool\"]}.json')\n",
    "    issues = pd.read_json(file_name)\n",
    "    issues.sample(n=row['#Sample Issue'], random_state=0).to_json(os.path.join(\n",
    "        path_gitlab_issue_sampled_all, row['Tool'] + '.json'), orient='records', indent=4)\n",
    "    closed_issues = issues[issues['Issue_closed_time'].notnull()]\n",
    "    if not closed_issues.empty:\n",
    "        closed_issues.sample(n=row['#Sample Closed'], random_state=0).to_json(os.path.join(\n",
    "            path_gitlab_issue_sampled_closed, row['Tool'] + '.json'), orient='records', indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape Github dependents general information for each tool\n",
    "for index, row in df_dependents.iterrows():\n",
    "    print(f'{index}: {row[\"Tool\"]}')\n",
    "    repos_data, errors_data = github_miner.scrape_repo_list(\n",
    "        row['GitHub Dependents'])\n",
    "\n",
    "    if repos_data is not None:\n",
    "        repos_data = repos_data.sort_values(by='#Issues', ascending=False)\n",
    "        repos_data.to_json(os.path.join(\n",
    "            path_github_repo_scraped, f'{row[\"Tool\"]}.json'), indent=4, orient='records')\n",
    "\n",
    "    if errors_data is not None:\n",
    "        errors_data.to_json(os.path.join(path_github_repo_scraped,\n",
    "                            f'Discarded.{row[\"Tool\"]}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape issues of Github dependents for each tool\n",
    "for index, row in df_tools.iterrows():\n",
    "    file_name = os.path.join(path_github_repo_scraped, f'{row[\"Name\"]}.json')\n",
    "    if os.path.exists(file_name):\n",
    "        repos = pd.read_json(file_name)\n",
    "        # filter out repos with only pr-based issues\n",
    "        repos = repos[repos['#Issues'] > repos['#Pull Requests']]\n",
    "        # filter out repos created before the tool's first release date\n",
    "        repos = repos[repos['Repo Creation Date'] > row['First Release Date']]\n",
    "        print(\n",
    "            f'{row[\"Name\"]}: {repos[\"#Issues\"].sum() - repos[\"#Pull Requests\"].sum()}')\n",
    "        # scrape issues for the current tool\n",
    "        issues = github_miner.scrape_issues_list(repos['Repo'].tolist())\n",
    "        if not issues.empty:\n",
    "            issues.to_json(os.path.join(path_github_issue_raw,\n",
    "                           f'{row[\"Name\"]}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude issues that are not related to each tool\n",
    "for file_name in glob.glob(os.path.join(path_github_issue_raw, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    valid_issues = pd.DataFrame()\n",
    "    tool_name = os.path.split(file_name)[1].split('.')[0]\n",
    "    for index, issue in issues.iterrows():\n",
    "        if tools_keywords[tool_name] in nltk.word_tokenize(issue['Issue_title'].lower()):\n",
    "            valid_issue = pd.DataFrame([issue])\n",
    "            valid_issues = pd.concat(\n",
    "                [valid_issues, valid_issue], ignore_index=True)\n",
    "    if not valid_issues.empty:\n",
    "        valid_issues.to_json(os.path.join(\n",
    "            path_github_issue_filtered, f'{tool_name}.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_github = pd.DataFrame()\n",
    "for file_name in glob.glob(os.path.join(path_github_issue_filtered, '*.json')):\n",
    "    issues = pd.read_json(file_name)\n",
    "    row = {\n",
    "        'Tool': os.path.split(file_name)[1].split('.')[0],\n",
    "        '#Issue': len(issues),\n",
    "        '#Closed': issues['Issue_closed_time'].notnull().sum()\n",
    "    }\n",
    "    row = pd.DataFrame([row])\n",
    "    summary_github = pd.concat([summary_github, row], ignore_index=True)\n",
    "summary_github.to_csv(os.path.join(\n",
    "    path_github_issue, 'summary.csv'), index=False)\n",
    "summary_github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After having the population for each tool and discussion channel, we then find out the minimum number of necessary samples with the [calculator](https://www.calculator.net/sample-size-calculator.html).\n",
    "df_summary = pd.read_csv(os.path.join(path_github_issue, 'summary.csv'))\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tool-specific posts accordingly\n",
    "for index, row in df_summary.iterrows():\n",
    "    file_name = os.path.join(path_github_issue_filtered, f'{row[\"Tool\"]}.json')\n",
    "    issues = pd.read_json(file_name)\n",
    "    issues.sample(n=row['#Sample Issue'], random_state=0).to_json(os.path.join(\n",
    "        path_github_issue_sampled_all, row['Tool'] + '.json'), orient='records', indent=4)\n",
    "    closed_issues = issues[issues['Issue_closed_time'].notnull()]\n",
    "    if not closed_issues.empty:\n",
    "        closed_issues.sample(n=row['#Sample Closed'], random_state=0).to_json(os.path.join(\n",
    "            path_github_issue_sampled_closed, row['Tool'] + '.json'), orient='records', indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9e7b88a259684df50811b5249344f7cc06d54cdb1cf11111ce301ae44eac9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
